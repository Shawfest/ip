{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as LR\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total training batch number: 300\n",
      "==>>> total testing batch number: 50\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "print('==>>> total training batch number: {}'.format(len(trainloader)))\n",
    "print('==>>> total testing batch number: {}'.format(len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, layersize, eta=None):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "    def update(self, u, v, eta=None):\n",
    "        pass\n",
    "    \n",
    "class BN(nn.Module):\n",
    "    def __init__(self, layersize, eta=None):\n",
    "        super(BN, self).__init__()\n",
    "        self.gain = nn.Parameter(torch.ones(layersize))\n",
    "        self.bias = nn.Parameter(torch.zeros(layersize))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        beta = x.mean(0, keepdim=True)\n",
    "        alpha = ((x-beta)**2).mean(0, keepdim=True).sqrt()\n",
    "\n",
    "        # Normalize\n",
    "        nx = (x-beta)/alpha\n",
    "\n",
    "        # Adjust using learned parameters\n",
    "        o = self.gain*nx + self.bias\n",
    "        return o\n",
    "\n",
    "    def update(self, u, v, eta=None):\n",
    "        pass\n",
    "\n",
    "class IP(nn.Module):\n",
    "    def __init__(self, layersize, eta=1):\n",
    "        super(IP, self).__init__()\n",
    "        self.eta = eta\n",
    "        \n",
    "        # gain/bias are the learned output distribution params\n",
    "        self.gain = nn.Parameter(torch.ones(layersize))\n",
    "        self.bias = nn.Parameter(torch.zeros(layersize))\n",
    "        \n",
    "        # Alpha and beta are the ip normalization parameters\n",
    "        self.register_buffer('alpha', torch.ones(layersize))\n",
    "        self.register_buffer('beta', torch.zeros(layersize))\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Normalize\n",
    "        nx = (x-self.beta)/self.alpha\n",
    "\n",
    "        # Adjust using learned parameters\n",
    "        o = self.gain*nx + self.bias\n",
    "        return  o\n",
    "        \n",
    "    def update(self, u, v, eta=None):\n",
    "\n",
    "        if (eta is None):\n",
    "            eta = self.eta\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            Eu = u.mean(0, keepdim=True)\n",
    "            Euu = (u**2).mean(0, keepdim=True)\n",
    "            Ev = v.mean(0, keepdim=True)\n",
    "            Evv = (v**2).mean(0, keepdim=True)\n",
    "            Euv = (u*v).mean(0, keepdim=True)\n",
    "\n",
    "        self.alpha = (1-eta)*self.alpha + eta * (2*(Euv))\n",
    "        self.beta = (1-eta)*self.beta + eta * (2*Ev)\n",
    "        \n",
    "        self.eta = eta * 0.99\n",
    "\n",
    "\n",
    "class DNet(nn.Module):\n",
    "    def __init__(self, layersize, norm=None, eta=1):\n",
    "        super(DNet, self).__init__()\n",
    "        \n",
    "        # Dense Layers\n",
    "        self.fc1 = nn.Linear(28*28, layersize)\n",
    "        self.fc2 = nn.Linear(layersize, layersize)\n",
    "        self.fc3 = nn.Linear(layersize, layersize)\n",
    "        self.fc4 = nn.Linear(layersize, layersize)\n",
    "        self.fc5 = nn.Linear(layersize, layersize)\n",
    "        self.fc6 = nn.Linear(layersize, layersize)\n",
    "        self.fc7 = nn.Linear(layersize, layersize)\n",
    "        self.fc8 = nn.Linear(layersize, layersize)\n",
    "        self.fc9 = nn.Linear(layersize, 10)\n",
    "        \n",
    "        # Normalization Layers\n",
    "        self.n1 = norm(layersize, eta)\n",
    "        self.n2 = norm(layersize, eta)\n",
    "        self.n3 = norm(layersize, eta)\n",
    "        self.n4 = norm(layersize, eta)\n",
    "        self.n5 = norm(layersize, eta)\n",
    "        self.n6 = norm(layersize, eta)\n",
    "        self.n7 = norm(layersize, eta)\n",
    "        self.n8 = norm(layersize, eta)\n",
    "        \n",
    "    def forward(self, x, eta=None):\n",
    "        x = x.view(-1, 28*28)\n",
    "        u1 = self.fc1(x)\n",
    "        v1 = F.tanh(self.n1(u1))\n",
    "        u2 = self.fc2(v1)\n",
    "        v2 = F.tanh(self.n2(u2))\n",
    "        u3 = self.fc3(v2)\n",
    "        v3 = F.tanh(self.n3(u3))\n",
    "        u4 = self.fc4(v3)\n",
    "        v4 = F.tanh(self.n4(u4))\n",
    "        u5 = self.fc5(v4)\n",
    "        v5 = F.tanh(self.n5(u5))\n",
    "        u6 = self.fc6(v5)\n",
    "        v6 = F.tanh(self.n6(u6))\n",
    "        u7 = self.fc7(v6)\n",
    "        v7 = F.tanh(self.n7(u7))\n",
    "        u8 = self.fc8(v7)\n",
    "        v8 = F.tanh(self.n8(u8))\n",
    "        # Note you should not normalize after the last linear layer (you delete info)\n",
    "        o = F.relu(self.fc9(v8))\n",
    "        \n",
    "        # Lets do the updates to the normalizations\n",
    "        self.n1.update(u1, v1, eta)\n",
    "        self.n2.update(u2, v2, eta)\n",
    "        self.n3.update(u3, v3, eta)\n",
    "        self.n4.update(u4, v4, eta)\n",
    "        self.n5.update(u5, v5, eta)\n",
    "        self.n6.update(u6, v6, eta)\n",
    "        self.n7.update(u7, v7, eta)\n",
    "        self.n8.update(u8, v8, eta)\n",
    "        \n",
    "        \n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_deep_model(network, optimization, seed, epochs):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    loss_tracker = []\n",
    "    episode = 1\n",
    "    \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimization.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            y = network(inputs)\n",
    "            loss = criterion(y, labels)\n",
    "            loss.backward()\n",
    "            optimization.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "            \n",
    "            loss_tracker.append([episode,loss.item()])\n",
    "            episode += 1\n",
    "            \n",
    "    print(\"Finished training!\\n\")\n",
    "    return(np.transpose(loss_tracker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IP Net\n",
      "[1,   100] loss: 1.094\n",
      "[1,   200] loss: 0.352\n",
      "[1,   300] loss: 0.261\n",
      "[2,   100] loss: 0.225\n",
      "[2,   200] loss: 0.209\n",
      "[2,   300] loss: 0.196\n",
      "[3,   100] loss: 0.159\n",
      "[3,   200] loss: 0.163\n",
      "[3,   300] loss: 0.161\n",
      "[4,   100] loss: 0.136\n",
      "[4,   200] loss: 0.138\n",
      "[4,   300] loss: 0.142\n",
      "[5,   100] loss: 0.121\n",
      "[5,   200] loss: 0.119\n",
      "[5,   300] loss: 0.130\n",
      "[6,   100] loss: 0.102\n",
      "[6,   200] loss: 0.106\n",
      "[6,   300] loss: 0.114\n",
      "[7,   100] loss: 0.088\n",
      "[7,   200] loss: 0.098\n",
      "[7,   300] loss: 0.112\n",
      "[8,   100] loss: 0.086\n",
      "[8,   200] loss: 0.092\n",
      "[8,   300] loss: 0.093\n",
      "[9,   100] loss: 0.081\n",
      "[9,   200] loss: 0.082\n",
      "[9,   300] loss: 0.097\n",
      "[10,   100] loss: 0.080\n",
      "[10,   200] loss: 0.081\n",
      "[10,   300] loss: 0.087\n",
      "[11,   100] loss: 0.080\n",
      "[11,   200] loss: 0.077\n",
      "[11,   300] loss: 0.074\n",
      "[12,   100] loss: 0.072\n",
      "[12,   200] loss: 0.078\n",
      "[12,   300] loss: 0.076\n",
      "[13,   100] loss: 0.062\n",
      "[13,   200] loss: 0.059\n",
      "[13,   300] loss: 0.078\n",
      "[14,   100] loss: 0.060\n",
      "[14,   200] loss: 0.061\n",
      "[14,   300] loss: 0.080\n",
      "[15,   100] loss: 0.055\n",
      "[15,   200] loss: 0.065\n",
      "[15,   300] loss: 0.069\n",
      "[16,   100] loss: 0.063\n",
      "[16,   200] loss: 0.056\n",
      "[16,   300] loss: 0.072\n",
      "[17,   100] loss: 0.062\n",
      "[17,   200] loss: 0.062\n",
      "[17,   300] loss: 0.055\n",
      "[18,   100] loss: 0.043\n",
      "[18,   200] loss: 0.056\n",
      "[18,   300] loss: 0.058\n",
      "[19,   100] loss: 0.047\n",
      "[19,   200] loss: 0.056\n",
      "[19,   300] loss: 0.064\n",
      "[20,   100] loss: 0.045\n",
      "[20,   200] loss: 0.053\n",
      "[20,   300] loss: 0.057\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.803\n",
      "[1,   200] loss: 1.095\n",
      "[1,   300] loss: 0.902\n",
      "[2,   100] loss: 0.758\n",
      "[2,   200] loss: 0.667\n",
      "[2,   300] loss: 0.602\n",
      "[3,   100] loss: 0.506\n",
      "[3,   200] loss: 0.446\n",
      "[3,   300] loss: 0.380\n",
      "[4,   100] loss: 0.299\n",
      "[4,   200] loss: 0.282\n",
      "[4,   300] loss: 0.257\n",
      "[5,   100] loss: 0.219\n",
      "[5,   200] loss: 0.207\n",
      "[5,   300] loss: 0.207\n",
      "[6,   100] loss: 0.173\n",
      "[6,   200] loss: 0.181\n",
      "[6,   300] loss: 0.166\n",
      "[7,   100] loss: 0.149\n",
      "[7,   200] loss: 0.145\n",
      "[7,   300] loss: 0.144\n",
      "[8,   100] loss: 0.132\n",
      "[8,   200] loss: 0.127\n",
      "[8,   300] loss: 0.125\n",
      "[9,   100] loss: 0.114\n",
      "[9,   200] loss: 0.113\n",
      "[9,   300] loss: 0.107\n",
      "[10,   100] loss: 0.100\n",
      "[10,   200] loss: 0.103\n",
      "[10,   300] loss: 0.105\n",
      "[11,   100] loss: 0.085\n",
      "[11,   200] loss: 0.094\n",
      "[11,   300] loss: 0.094\n",
      "[12,   100] loss: 0.080\n",
      "[12,   200] loss: 0.082\n",
      "[12,   300] loss: 0.093\n",
      "[13,   100] loss: 0.080\n",
      "[13,   200] loss: 0.077\n",
      "[13,   300] loss: 0.074\n",
      "[14,   100] loss: 0.066\n",
      "[14,   200] loss: 0.068\n",
      "[14,   300] loss: 0.076\n",
      "[15,   100] loss: 0.058\n",
      "[15,   200] loss: 0.068\n",
      "[15,   300] loss: 0.067\n",
      "[16,   100] loss: 0.059\n",
      "[16,   200] loss: 0.059\n",
      "[16,   300] loss: 0.065\n",
      "[17,   100] loss: 0.048\n",
      "[17,   200] loss: 0.062\n",
      "[17,   300] loss: 0.059\n",
      "[18,   100] loss: 0.051\n",
      "[18,   200] loss: 0.056\n",
      "[18,   300] loss: 0.052\n",
      "[19,   100] loss: 0.043\n",
      "[19,   200] loss: 0.050\n",
      "[19,   300] loss: 0.057\n",
      "[20,   100] loss: 0.044\n",
      "[20,   200] loss: 0.049\n",
      "[20,   300] loss: 0.048\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.064\n",
      "[1,   200] loss: 0.360\n",
      "[1,   300] loss: 0.273\n",
      "[2,   100] loss: 0.214\n",
      "[2,   200] loss: 0.199\n",
      "[2,   300] loss: 0.190\n",
      "[3,   100] loss: 0.155\n",
      "[3,   200] loss: 0.153\n",
      "[3,   300] loss: 0.149\n",
      "[4,   100] loss: 0.135\n",
      "[4,   200] loss: 0.120\n",
      "[4,   300] loss: 0.126\n",
      "[5,   100] loss: 0.126\n",
      "[5,   200] loss: 0.106\n",
      "[5,   300] loss: 0.112\n",
      "[6,   100] loss: 0.091\n",
      "[6,   200] loss: 0.096\n",
      "[6,   300] loss: 0.117\n",
      "[7,   100] loss: 0.088\n",
      "[7,   200] loss: 0.090\n",
      "[7,   300] loss: 0.093\n",
      "[8,   100] loss: 0.072\n",
      "[8,   200] loss: 0.089\n",
      "[8,   300] loss: 0.079\n",
      "[9,   100] loss: 0.076\n",
      "[9,   200] loss: 0.075\n",
      "[9,   300] loss: 0.085\n",
      "[10,   100] loss: 0.073\n",
      "[10,   200] loss: 0.075\n",
      "[10,   300] loss: 0.075\n",
      "[11,   100] loss: 0.065\n",
      "[11,   200] loss: 0.067\n",
      "[11,   300] loss: 0.067\n",
      "[12,   100] loss: 0.054\n",
      "[12,   200] loss: 0.066\n",
      "[12,   300] loss: 0.067\n",
      "[13,   100] loss: 0.051\n",
      "[13,   200] loss: 0.062\n",
      "[13,   300] loss: 0.066\n",
      "[14,   100] loss: 0.055\n",
      "[14,   200] loss: 0.052\n",
      "[14,   300] loss: 0.061\n",
      "[15,   100] loss: 0.050\n",
      "[15,   200] loss: 0.054\n",
      "[15,   300] loss: 0.063\n",
      "[16,   100] loss: 0.051\n",
      "[16,   200] loss: 0.052\n",
      "[16,   300] loss: 0.057\n",
      "[17,   100] loss: 0.047\n",
      "[17,   200] loss: 0.055\n",
      "[17,   300] loss: 0.056\n",
      "[18,   100] loss: 0.052\n",
      "[18,   200] loss: 0.051\n",
      "[18,   300] loss: 0.052\n",
      "[19,   100] loss: 0.041\n",
      "[19,   200] loss: 0.042\n",
      "[19,   300] loss: 0.053\n",
      "[20,   100] loss: 0.036\n",
      "[20,   200] loss: 0.040\n",
      "[20,   300] loss: 0.043\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.758\n",
      "[1,   200] loss: 1.027\n",
      "[1,   300] loss: 0.777\n",
      "[2,   100] loss: 0.635\n",
      "[2,   200] loss: 0.578\n",
      "[2,   300] loss: 0.555\n",
      "[3,   100] loss: 0.510\n",
      "[3,   200] loss: 0.496\n",
      "[3,   300] loss: 0.477\n",
      "[4,   100] loss: 0.460\n",
      "[4,   200] loss: 0.449\n",
      "[4,   300] loss: 0.426\n",
      "[5,   100] loss: 0.413\n",
      "[5,   200] loss: 0.403\n",
      "[5,   300] loss: 0.405\n",
      "[6,   100] loss: 0.392\n",
      "[6,   200] loss: 0.371\n",
      "[6,   300] loss: 0.387\n",
      "[7,   100] loss: 0.370\n",
      "[7,   200] loss: 0.365\n",
      "[7,   300] loss: 0.370\n",
      "[8,   100] loss: 0.337\n",
      "[8,   200] loss: 0.358\n",
      "[8,   300] loss: 0.359\n",
      "[9,   100] loss: 0.346\n",
      "[9,   200] loss: 0.343\n",
      "[9,   300] loss: 0.337\n",
      "[10,   100] loss: 0.334\n",
      "[10,   200] loss: 0.318\n",
      "[10,   300] loss: 0.330\n",
      "[11,   100] loss: 0.316\n",
      "[11,   200] loss: 0.324\n",
      "[11,   300] loss: 0.319\n",
      "[12,   100] loss: 0.160\n",
      "[12,   200] loss: 0.102\n",
      "[12,   300] loss: 0.103\n",
      "[13,   100] loss: 0.086\n",
      "[13,   200] loss: 0.094\n",
      "[13,   300] loss: 0.091\n",
      "[14,   100] loss: 0.082\n",
      "[14,   200] loss: 0.078\n",
      "[14,   300] loss: 0.085\n",
      "[15,   100] loss: 0.068\n",
      "[15,   200] loss: 0.069\n",
      "[15,   300] loss: 0.080\n",
      "[16,   100] loss: 0.067\n",
      "[16,   200] loss: 0.066\n",
      "[16,   300] loss: 0.065\n",
      "[17,   100] loss: 0.060\n",
      "[17,   200] loss: 0.062\n",
      "[17,   300] loss: 0.070\n",
      "[18,   100] loss: 0.062\n",
      "[18,   200] loss: 0.054\n",
      "[18,   300] loss: 0.057\n",
      "[19,   100] loss: 0.050\n",
      "[19,   200] loss: 0.053\n",
      "[19,   300] loss: 0.057\n",
      "[20,   100] loss: 0.043\n",
      "[20,   200] loss: 0.049\n",
      "[20,   300] loss: 0.057\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.943\n",
      "[1,   200] loss: 0.337\n",
      "[1,   300] loss: 0.268\n",
      "[2,   100] loss: 0.212\n",
      "[2,   200] loss: 0.201\n",
      "[2,   300] loss: 0.185\n",
      "[3,   100] loss: 0.152\n",
      "[3,   200] loss: 0.163\n",
      "[3,   300] loss: 0.154\n",
      "[4,   100] loss: 0.133\n",
      "[4,   200] loss: 0.132\n",
      "[4,   300] loss: 0.135\n",
      "[5,   100] loss: 0.110\n",
      "[5,   200] loss: 0.114\n",
      "[5,   300] loss: 0.120\n",
      "[6,   100] loss: 0.092\n",
      "[6,   200] loss: 0.101\n",
      "[6,   300] loss: 0.113\n",
      "[7,   100] loss: 0.079\n",
      "[7,   200] loss: 0.107\n",
      "[7,   300] loss: 0.097\n",
      "[8,   100] loss: 0.081\n",
      "[8,   200] loss: 0.088\n",
      "[8,   300] loss: 0.095\n",
      "[9,   100] loss: 0.077\n",
      "[9,   200] loss: 0.077\n",
      "[9,   300] loss: 0.083\n",
      "[10,   100] loss: 0.071\n",
      "[10,   200] loss: 0.078\n",
      "[10,   300] loss: 0.079\n",
      "[11,   100] loss: 0.060\n",
      "[11,   200] loss: 0.068\n",
      "[11,   300] loss: 0.075\n",
      "[12,   100] loss: 0.069\n",
      "[12,   200] loss: 0.067\n",
      "[12,   300] loss: 0.074\n",
      "[13,   100] loss: 0.059\n",
      "[13,   200] loss: 0.074\n",
      "[13,   300] loss: 0.071\n",
      "[14,   100] loss: 0.061\n",
      "[14,   200] loss: 0.057\n",
      "[14,   300] loss: 0.068\n",
      "[15,   100] loss: 0.055\n",
      "[15,   200] loss: 0.063\n",
      "[15,   300] loss: 0.065\n",
      "[16,   100] loss: 0.050\n",
      "[16,   200] loss: 0.052\n",
      "[16,   300] loss: 0.064\n",
      "[17,   100] loss: 0.049\n",
      "[17,   200] loss: 0.045\n",
      "[17,   300] loss: 0.061\n",
      "[18,   100] loss: 0.053\n",
      "[18,   200] loss: 0.052\n",
      "[18,   300] loss: 0.060\n",
      "[19,   100] loss: 0.043\n",
      "[19,   200] loss: 0.047\n",
      "[19,   300] loss: 0.049\n",
      "[20,   100] loss: 0.041\n",
      "[20,   200] loss: 0.047\n",
      "[20,   300] loss: 0.043\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.547\n",
      "[1,   200] loss: 0.668\n",
      "[1,   300] loss: 0.445\n",
      "[2,   100] loss: 0.344\n",
      "[2,   200] loss: 0.309\n",
      "[2,   300] loss: 0.276\n",
      "[3,   100] loss: 0.247\n",
      "[3,   200] loss: 0.236\n",
      "[3,   300] loss: 0.207\n",
      "[4,   100] loss: 0.195\n",
      "[4,   200] loss: 0.184\n",
      "[4,   300] loss: 0.175\n",
      "[5,   100] loss: 0.155\n",
      "[5,   200] loss: 0.152\n",
      "[5,   300] loss: 0.161\n",
      "[6,   100] loss: 0.139\n",
      "[6,   200] loss: 0.137\n",
      "[6,   300] loss: 0.139\n",
      "[7,   100] loss: 0.109\n",
      "[7,   200] loss: 0.120\n",
      "[7,   300] loss: 0.121\n",
      "[8,   100] loss: 0.095\n",
      "[8,   200] loss: 0.110\n",
      "[8,   300] loss: 0.105\n",
      "[9,   100] loss: 0.098\n",
      "[9,   200] loss: 0.097\n",
      "[9,   300] loss: 0.097\n",
      "[10,   100] loss: 0.093\n",
      "[10,   200] loss: 0.085\n",
      "[10,   300] loss: 0.088\n",
      "[11,   100] loss: 0.079\n",
      "[11,   200] loss: 0.078\n",
      "[11,   300] loss: 0.084\n",
      "[12,   100] loss: 0.082\n",
      "[12,   200] loss: 0.071\n",
      "[12,   300] loss: 0.076\n",
      "[13,   100] loss: 0.064\n",
      "[13,   200] loss: 0.071\n",
      "[13,   300] loss: 0.068\n",
      "[14,   100] loss: 0.063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,   200] loss: 0.065\n",
      "[14,   300] loss: 0.068\n",
      "[15,   100] loss: 0.050\n",
      "[15,   200] loss: 0.063\n",
      "[15,   300] loss: 0.061\n",
      "[16,   100] loss: 0.051\n",
      "[16,   200] loss: 0.055\n",
      "[16,   300] loss: 0.060\n",
      "[17,   100] loss: 0.045\n",
      "[17,   200] loss: 0.057\n",
      "[17,   300] loss: 0.064\n",
      "[18,   100] loss: 0.045\n",
      "[18,   200] loss: 0.055\n",
      "[18,   300] loss: 0.059\n",
      "[19,   100] loss: 0.044\n",
      "[19,   200] loss: 0.041\n",
      "[19,   300] loss: 0.047\n",
      "[20,   100] loss: 0.039\n",
      "[20,   200] loss: 0.043\n",
      "[20,   300] loss: 0.044\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.017\n",
      "[1,   200] loss: 0.347\n",
      "[1,   300] loss: 0.270\n",
      "[2,   100] loss: 0.207\n",
      "[2,   200] loss: 0.199\n",
      "[2,   300] loss: 0.195\n",
      "[3,   100] loss: 0.159\n",
      "[3,   200] loss: 0.154\n",
      "[3,   300] loss: 0.151\n",
      "[4,   100] loss: 0.121\n",
      "[4,   200] loss: 0.137\n",
      "[4,   300] loss: 0.127\n",
      "[5,   100] loss: 0.112\n",
      "[5,   200] loss: 0.108\n",
      "[5,   300] loss: 0.120\n",
      "[6,   100] loss: 0.099\n",
      "[6,   200] loss: 0.098\n",
      "[6,   300] loss: 0.107\n",
      "[7,   100] loss: 0.085\n",
      "[7,   200] loss: 0.090\n",
      "[7,   300] loss: 0.093\n",
      "[8,   100] loss: 0.088\n",
      "[8,   200] loss: 0.082\n",
      "[8,   300] loss: 0.081\n",
      "[9,   100] loss: 0.070\n",
      "[9,   200] loss: 0.089\n",
      "[9,   300] loss: 0.082\n",
      "[10,   100] loss: 0.064\n",
      "[10,   200] loss: 0.072\n",
      "[10,   300] loss: 0.074\n",
      "[11,   100] loss: 0.064\n",
      "[11,   200] loss: 0.066\n",
      "[11,   300] loss: 0.070\n",
      "[12,   100] loss: 0.070\n",
      "[12,   200] loss: 0.064\n",
      "[12,   300] loss: 0.069\n",
      "[13,   100] loss: 0.067\n",
      "[13,   200] loss: 0.062\n",
      "[13,   300] loss: 0.067\n",
      "[14,   100] loss: 0.053\n",
      "[14,   200] loss: 0.054\n",
      "[14,   300] loss: 0.059\n",
      "[15,   100] loss: 0.047\n",
      "[15,   200] loss: 0.053\n",
      "[15,   300] loss: 0.060\n",
      "[16,   100] loss: 0.049\n",
      "[16,   200] loss: 0.049\n",
      "[16,   300] loss: 0.057\n",
      "[17,   100] loss: 0.038\n",
      "[17,   200] loss: 0.044\n",
      "[17,   300] loss: 0.053\n",
      "[18,   100] loss: 0.042\n",
      "[18,   200] loss: 0.046\n",
      "[18,   300] loss: 0.046\n",
      "[19,   100] loss: 0.041\n",
      "[19,   200] loss: 0.056\n",
      "[19,   300] loss: 0.048\n",
      "[20,   100] loss: 0.037\n",
      "[20,   200] loss: 0.043\n",
      "[20,   300] loss: 0.041\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.502\n",
      "[1,   200] loss: 0.616\n",
      "[1,   300] loss: 0.446\n",
      "[2,   100] loss: 0.353\n",
      "[2,   200] loss: 0.305\n",
      "[2,   300] loss: 0.276\n",
      "[3,   100] loss: 0.241\n",
      "[3,   200] loss: 0.214\n",
      "[3,   300] loss: 0.212\n",
      "[4,   100] loss: 0.190\n",
      "[4,   200] loss: 0.184\n",
      "[4,   300] loss: 0.170\n",
      "[5,   100] loss: 0.152\n",
      "[5,   200] loss: 0.165\n",
      "[5,   300] loss: 0.150\n",
      "[6,   100] loss: 0.135\n",
      "[6,   200] loss: 0.131\n",
      "[6,   300] loss: 0.136\n",
      "[7,   100] loss: 0.121\n",
      "[7,   200] loss: 0.117\n",
      "[7,   300] loss: 0.121\n",
      "[8,   100] loss: 0.105\n",
      "[8,   200] loss: 0.110\n",
      "[8,   300] loss: 0.100\n",
      "[9,   100] loss: 0.091\n",
      "[9,   200] loss: 0.099\n",
      "[9,   300] loss: 0.095\n",
      "[10,   100] loss: 0.095\n",
      "[10,   200] loss: 0.084\n",
      "[10,   300] loss: 0.090\n",
      "[11,   100] loss: 0.088\n",
      "[11,   200] loss: 0.078\n",
      "[11,   300] loss: 0.084\n",
      "[12,   100] loss: 0.068\n",
      "[12,   200] loss: 0.081\n",
      "[12,   300] loss: 0.075\n",
      "[13,   100] loss: 0.070\n",
      "[13,   200] loss: 0.071\n",
      "[13,   300] loss: 0.071\n",
      "[14,   100] loss: 0.066\n",
      "[14,   200] loss: 0.063\n",
      "[14,   300] loss: 0.070\n",
      "[15,   100] loss: 0.058\n",
      "[15,   200] loss: 0.065\n",
      "[15,   300] loss: 0.070\n",
      "[16,   100] loss: 0.057\n",
      "[16,   200] loss: 0.056\n",
      "[16,   300] loss: 0.066\n",
      "[17,   100] loss: 0.054\n",
      "[17,   200] loss: 0.056\n",
      "[17,   300] loss: 0.062\n",
      "[18,   100] loss: 0.048\n",
      "[18,   200] loss: 0.052\n",
      "[18,   300] loss: 0.056\n",
      "[19,   100] loss: 0.044\n",
      "[19,   200] loss: 0.051\n",
      "[19,   300] loss: 0.055\n",
      "[20,   100] loss: 0.043\n",
      "[20,   200] loss: 0.050\n",
      "[20,   300] loss: 0.046\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.059\n",
      "[1,   200] loss: 0.355\n",
      "[1,   300] loss: 0.273\n",
      "[2,   100] loss: 0.212\n",
      "[2,   200] loss: 0.203\n",
      "[2,   300] loss: 0.203\n",
      "[3,   100] loss: 0.163\n",
      "[3,   200] loss: 0.152\n",
      "[3,   300] loss: 0.150\n",
      "[4,   100] loss: 0.128\n",
      "[4,   200] loss: 0.129\n",
      "[4,   300] loss: 0.136\n",
      "[5,   100] loss: 0.110\n",
      "[5,   200] loss: 0.120\n",
      "[5,   300] loss: 0.114\n",
      "[6,   100] loss: 0.091\n",
      "[6,   200] loss: 0.111\n",
      "[6,   300] loss: 0.106\n",
      "[7,   100] loss: 0.087\n",
      "[7,   200] loss: 0.090\n",
      "[7,   300] loss: 0.096\n",
      "[8,   100] loss: 0.072\n",
      "[8,   200] loss: 0.087\n",
      "[8,   300] loss: 0.095\n",
      "[9,   100] loss: 0.073\n",
      "[9,   200] loss: 0.074\n",
      "[9,   300] loss: 0.088\n",
      "[10,   100] loss: 0.062\n",
      "[10,   200] loss: 0.070\n",
      "[10,   300] loss: 0.087\n",
      "[11,   100] loss: 0.062\n",
      "[11,   200] loss: 0.069\n",
      "[11,   300] loss: 0.073\n",
      "[12,   100] loss: 0.061\n",
      "[12,   200] loss: 0.064\n",
      "[12,   300] loss: 0.060\n",
      "[13,   100] loss: 0.053\n",
      "[13,   200] loss: 0.058\n",
      "[13,   300] loss: 0.063\n",
      "[14,   100] loss: 0.048\n",
      "[14,   200] loss: 0.056\n",
      "[14,   300] loss: 0.060\n",
      "[15,   100] loss: 0.048\n",
      "[15,   200] loss: 0.053\n",
      "[15,   300] loss: 0.057\n",
      "[16,   100] loss: 0.053\n",
      "[16,   200] loss: 0.050\n",
      "[16,   300] loss: 0.054\n",
      "[17,   100] loss: 0.049\n",
      "[17,   200] loss: 0.056\n",
      "[17,   300] loss: 0.056\n",
      "[18,   100] loss: 0.041\n",
      "[18,   200] loss: 0.043\n",
      "[18,   300] loss: 0.047\n",
      "[19,   100] loss: 0.040\n",
      "[19,   200] loss: 0.040\n",
      "[19,   300] loss: 0.051\n",
      "[20,   100] loss: 0.031\n",
      "[20,   200] loss: 0.038\n",
      "[20,   300] loss: 0.056\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.303\n",
      "[1,   200] loss: 2.303\n",
      "[1,   300] loss: 2.303\n",
      "[2,   100] loss: 2.303\n",
      "[2,   200] loss: 2.303\n",
      "[2,   300] loss: 2.303\n",
      "[3,   100] loss: 2.303\n",
      "[3,   200] loss: 2.303\n",
      "[3,   300] loss: 2.303\n",
      "[4,   100] loss: 2.303\n",
      "[4,   200] loss: 2.303\n",
      "[4,   300] loss: 2.303\n",
      "[5,   100] loss: 2.303\n",
      "[5,   200] loss: 2.303\n",
      "[5,   300] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[6,   300] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[7,   300] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[8,   300] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[9,   300] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[10,   300] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[11,   300] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[12,   300] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[13,   300] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[14,   300] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[15,   300] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[16,   300] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[17,   300] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[18,   300] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[19,   300] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[20,   300] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.030\n",
      "[1,   200] loss: 0.354\n",
      "[1,   300] loss: 0.264\n",
      "[2,   100] loss: 0.213\n",
      "[2,   200] loss: 0.210\n",
      "[2,   300] loss: 0.180\n",
      "[3,   100] loss: 0.169\n",
      "[3,   200] loss: 0.156\n",
      "[3,   300] loss: 0.147\n",
      "[4,   100] loss: 0.133\n",
      "[4,   200] loss: 0.128\n",
      "[4,   300] loss: 0.124\n",
      "[5,   100] loss: 0.112\n",
      "[5,   200] loss: 0.112\n",
      "[5,   300] loss: 0.115\n",
      "[6,   100] loss: 0.094\n",
      "[6,   200] loss: 0.092\n",
      "[6,   300] loss: 0.105\n",
      "[7,   100] loss: 0.084\n",
      "[7,   200] loss: 0.091\n",
      "[7,   300] loss: 0.092\n",
      "[8,   100] loss: 0.072\n",
      "[8,   200] loss: 0.081\n",
      "[8,   300] loss: 0.082\n",
      "[9,   100] loss: 0.078\n",
      "[9,   200] loss: 0.084\n",
      "[9,   300] loss: 0.080\n",
      "[10,   100] loss: 0.071\n",
      "[10,   200] loss: 0.070\n",
      "[10,   300] loss: 0.071\n",
      "[11,   100] loss: 0.058\n",
      "[11,   200] loss: 0.061\n",
      "[11,   300] loss: 0.071\n",
      "[12,   100] loss: 0.064\n",
      "[12,   200] loss: 0.065\n",
      "[12,   300] loss: 0.066\n",
      "[13,   100] loss: 0.062\n",
      "[13,   200] loss: 0.057\n",
      "[13,   300] loss: 0.055\n",
      "[14,   100] loss: 0.057\n",
      "[14,   200] loss: 0.061\n",
      "[14,   300] loss: 0.055\n",
      "[15,   100] loss: 0.041\n",
      "[15,   200] loss: 0.052\n",
      "[15,   300] loss: 0.061\n",
      "[16,   100] loss: 0.042\n",
      "[16,   200] loss: 0.050\n",
      "[16,   300] loss: 0.055\n",
      "[17,   100] loss: 0.056\n",
      "[17,   200] loss: 0.042\n",
      "[17,   300] loss: 0.056\n",
      "[18,   100] loss: 0.039\n",
      "[18,   200] loss: 0.042\n",
      "[18,   300] loss: 0.049\n",
      "[19,   100] loss: 0.043\n",
      "[19,   200] loss: 0.048\n",
      "[19,   300] loss: 0.047\n",
      "[20,   100] loss: 0.032\n",
      "[20,   200] loss: 0.042\n",
      "[20,   300] loss: 0.055\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.630\n",
      "[1,   200] loss: 0.879\n",
      "[1,   300] loss: 0.697\n",
      "[2,   100] loss: 0.641\n",
      "[2,   200] loss: 0.524\n",
      "[2,   300] loss: 0.315\n",
      "[3,   100] loss: 0.296\n",
      "[3,   200] loss: 0.259\n",
      "[3,   300] loss: 0.237\n",
      "[4,   100] loss: 0.219\n",
      "[4,   200] loss: 0.203\n",
      "[4,   300] loss: 0.192\n",
      "[5,   100] loss: 0.172\n",
      "[5,   200] loss: 0.175\n",
      "[5,   300] loss: 0.166\n",
      "[6,   100] loss: 0.144\n",
      "[6,   200] loss: 0.147\n",
      "[6,   300] loss: 0.147\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   100] loss: 0.130\n",
      "[7,   200] loss: 0.126\n",
      "[7,   300] loss: 0.117\n",
      "[8,   100] loss: 0.111\n",
      "[8,   200] loss: 0.118\n",
      "[8,   300] loss: 0.112\n",
      "[9,   100] loss: 0.098\n",
      "[9,   200] loss: 0.099\n",
      "[9,   300] loss: 0.097\n",
      "[10,   100] loss: 0.089\n",
      "[10,   200] loss: 0.091\n",
      "[10,   300] loss: 0.093\n",
      "[11,   100] loss: 0.083\n",
      "[11,   200] loss: 0.077\n",
      "[11,   300] loss: 0.083\n",
      "[12,   100] loss: 0.076\n",
      "[12,   200] loss: 0.077\n",
      "[12,   300] loss: 0.069\n",
      "[13,   100] loss: 0.067\n",
      "[13,   200] loss: 0.065\n",
      "[13,   300] loss: 0.077\n",
      "[14,   100] loss: 0.067\n",
      "[14,   200] loss: 0.061\n",
      "[14,   300] loss: 0.062\n",
      "[15,   100] loss: 0.054\n",
      "[15,   200] loss: 0.057\n",
      "[15,   300] loss: 0.061\n",
      "[16,   100] loss: 0.052\n",
      "[16,   200] loss: 0.060\n",
      "[16,   300] loss: 0.061\n",
      "[17,   100] loss: 0.054\n",
      "[17,   200] loss: 0.050\n",
      "[17,   300] loss: 0.059\n",
      "[18,   100] loss: 0.049\n",
      "[18,   200] loss: 0.051\n",
      "[18,   300] loss: 0.050\n",
      "[19,   100] loss: 0.042\n",
      "[19,   200] loss: 0.048\n",
      "[19,   300] loss: 0.049\n",
      "[20,   100] loss: 0.043\n",
      "[20,   200] loss: 0.046\n",
      "[20,   300] loss: 0.048\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.031\n",
      "[1,   200] loss: 0.343\n",
      "[1,   300] loss: 0.277\n",
      "[2,   100] loss: 0.217\n",
      "[2,   200] loss: 0.206\n",
      "[2,   300] loss: 0.197\n",
      "[3,   100] loss: 0.154\n",
      "[3,   200] loss: 0.158\n",
      "[3,   300] loss: 0.167\n",
      "[4,   100] loss: 0.130\n",
      "[4,   200] loss: 0.142\n",
      "[4,   300] loss: 0.133\n",
      "[5,   100] loss: 0.117\n",
      "[5,   200] loss: 0.115\n",
      "[5,   300] loss: 0.130\n",
      "[6,   100] loss: 0.110\n",
      "[6,   200] loss: 0.105\n",
      "[6,   300] loss: 0.112\n",
      "[7,   100] loss: 0.097\n",
      "[7,   200] loss: 0.102\n",
      "[7,   300] loss: 0.107\n",
      "[8,   100] loss: 0.088\n",
      "[8,   200] loss: 0.097\n",
      "[8,   300] loss: 0.092\n",
      "[9,   100] loss: 0.086\n",
      "[9,   200] loss: 0.079\n",
      "[9,   300] loss: 0.091\n",
      "[10,   100] loss: 0.071\n",
      "[10,   200] loss: 0.077\n",
      "[10,   300] loss: 0.084\n",
      "[11,   100] loss: 0.059\n",
      "[11,   200] loss: 0.074\n",
      "[11,   300] loss: 0.081\n",
      "[12,   100] loss: 0.059\n",
      "[12,   200] loss: 0.072\n",
      "[12,   300] loss: 0.070\n",
      "[13,   100] loss: 0.060\n",
      "[13,   200] loss: 0.063\n",
      "[13,   300] loss: 0.069\n",
      "[14,   100] loss: 0.055\n",
      "[14,   200] loss: 0.052\n",
      "[14,   300] loss: 0.071\n",
      "[15,   100] loss: 0.060\n",
      "[15,   200] loss: 0.054\n",
      "[15,   300] loss: 0.061\n",
      "[16,   100] loss: 0.055\n",
      "[16,   200] loss: 0.054\n",
      "[16,   300] loss: 0.062\n",
      "[17,   100] loss: 0.048\n",
      "[17,   200] loss: 0.055\n",
      "[17,   300] loss: 0.049\n",
      "[18,   100] loss: 0.045\n",
      "[18,   200] loss: 0.048\n",
      "[18,   300] loss: 0.053\n",
      "[19,   100] loss: 0.054\n",
      "[19,   200] loss: 0.068\n",
      "[19,   300] loss: 0.055\n",
      "[20,   100] loss: 0.046\n",
      "[20,   200] loss: 0.048\n",
      "[20,   300] loss: 0.051\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.679\n",
      "[1,   200] loss: 1.006\n",
      "[1,   300] loss: 0.801\n",
      "[2,   100] loss: 0.633\n",
      "[2,   200] loss: 0.558\n",
      "[2,   300] loss: 0.472\n",
      "[3,   100] loss: 0.384\n",
      "[3,   200] loss: 0.347\n",
      "[3,   300] loss: 0.314\n",
      "[4,   100] loss: 0.270\n",
      "[4,   200] loss: 0.256\n",
      "[4,   300] loss: 0.237\n",
      "[5,   100] loss: 0.209\n",
      "[5,   200] loss: 0.206\n",
      "[5,   300] loss: 0.205\n",
      "[6,   100] loss: 0.185\n",
      "[6,   200] loss: 0.178\n",
      "[6,   300] loss: 0.164\n",
      "[7,   100] loss: 0.153\n",
      "[7,   200] loss: 0.155\n",
      "[7,   300] loss: 0.152\n",
      "[8,   100] loss: 0.132\n",
      "[8,   200] loss: 0.139\n",
      "[8,   300] loss: 0.144\n",
      "[9,   100] loss: 0.125\n",
      "[9,   200] loss: 0.124\n",
      "[9,   300] loss: 0.121\n",
      "[10,   100] loss: 0.109\n",
      "[10,   200] loss: 0.111\n",
      "[10,   300] loss: 0.117\n",
      "[11,   100] loss: 0.095\n",
      "[11,   200] loss: 0.106\n",
      "[11,   300] loss: 0.103\n",
      "[12,   100] loss: 0.091\n",
      "[12,   200] loss: 0.097\n",
      "[12,   300] loss: 0.094\n",
      "[13,   100] loss: 0.080\n",
      "[13,   200] loss: 0.084\n",
      "[13,   300] loss: 0.097\n",
      "[14,   100] loss: 0.081\n",
      "[14,   200] loss: 0.074\n",
      "[14,   300] loss: 0.082\n",
      "[15,   100] loss: 0.072\n",
      "[15,   200] loss: 0.077\n",
      "[15,   300] loss: 0.073\n",
      "[16,   100] loss: 0.066\n",
      "[16,   200] loss: 0.069\n",
      "[16,   300] loss: 0.070\n",
      "[17,   100] loss: 0.056\n",
      "[17,   200] loss: 0.060\n",
      "[17,   300] loss: 0.064\n",
      "[18,   100] loss: 0.057\n",
      "[18,   200] loss: 0.058\n",
      "[18,   300] loss: 0.062\n",
      "[19,   100] loss: 0.060\n",
      "[19,   200] loss: 0.060\n",
      "[19,   300] loss: 0.055\n",
      "[20,   100] loss: 0.050\n",
      "[20,   200] loss: 0.053\n",
      "[20,   300] loss: 0.059\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.091\n",
      "[1,   200] loss: 0.375\n",
      "[1,   300] loss: 0.285\n",
      "[2,   100] loss: 0.222\n",
      "[2,   200] loss: 0.211\n",
      "[2,   300] loss: 0.195\n",
      "[3,   100] loss: 0.161\n",
      "[3,   200] loss: 0.154\n",
      "[3,   300] loss: 0.156\n",
      "[4,   100] loss: 0.125\n",
      "[4,   200] loss: 0.136\n",
      "[4,   300] loss: 0.133\n",
      "[5,   100] loss: 0.106\n",
      "[5,   200] loss: 0.118\n",
      "[5,   300] loss: 0.111\n",
      "[6,   100] loss: 0.093\n",
      "[6,   200] loss: 0.104\n",
      "[6,   300] loss: 0.106\n",
      "[7,   100] loss: 0.082\n",
      "[7,   200] loss: 0.086\n",
      "[7,   300] loss: 0.095\n",
      "[8,   100] loss: 0.079\n",
      "[8,   200] loss: 0.086\n",
      "[8,   300] loss: 0.085\n",
      "[9,   100] loss: 0.073\n",
      "[9,   200] loss: 0.081\n",
      "[9,   300] loss: 0.082\n",
      "[10,   100] loss: 0.068\n",
      "[10,   200] loss: 0.066\n",
      "[10,   300] loss: 0.074\n",
      "[11,   100] loss: 0.065\n",
      "[11,   200] loss: 0.069\n",
      "[11,   300] loss: 0.075\n",
      "[12,   100] loss: 0.066\n",
      "[12,   200] loss: 0.053\n",
      "[12,   300] loss: 0.071\n",
      "[13,   100] loss: 0.048\n",
      "[13,   200] loss: 0.060\n",
      "[13,   300] loss: 0.056\n",
      "[14,   100] loss: 0.056\n",
      "[14,   200] loss: 0.055\n",
      "[14,   300] loss: 0.068\n",
      "[15,   100] loss: 0.050\n",
      "[15,   200] loss: 0.054\n",
      "[15,   300] loss: 0.050\n",
      "[16,   100] loss: 0.041\n",
      "[16,   200] loss: 0.058\n",
      "[16,   300] loss: 0.058\n",
      "[17,   100] loss: 0.045\n",
      "[17,   200] loss: 0.047\n",
      "[17,   300] loss: 0.045\n",
      "[18,   100] loss: 0.036\n",
      "[18,   200] loss: 0.048\n",
      "[18,   300] loss: 0.054\n",
      "[19,   100] loss: 0.046\n",
      "[19,   200] loss: 0.050\n",
      "[19,   300] loss: 0.049\n",
      "[20,   100] loss: 0.035\n",
      "[20,   200] loss: 0.042\n",
      "[20,   300] loss: 0.049\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.656\n",
      "[1,   200] loss: 0.920\n",
      "[1,   300] loss: 0.638\n",
      "[2,   100] loss: 0.462\n",
      "[2,   200] loss: 0.383\n",
      "[2,   300] loss: 0.328\n",
      "[3,   100] loss: 0.283\n",
      "[3,   200] loss: 0.265\n",
      "[3,   300] loss: 0.247\n",
      "[4,   100] loss: 0.203\n",
      "[4,   200] loss: 0.205\n",
      "[4,   300] loss: 0.204\n",
      "[5,   100] loss: 0.165\n",
      "[5,   200] loss: 0.168\n",
      "[5,   300] loss: 0.165\n",
      "[6,   100] loss: 0.143\n",
      "[6,   200] loss: 0.145\n",
      "[6,   300] loss: 0.140\n",
      "[7,   100] loss: 0.136\n",
      "[7,   200] loss: 0.124\n",
      "[7,   300] loss: 0.125\n",
      "[8,   100] loss: 0.112\n",
      "[8,   200] loss: 0.119\n",
      "[8,   300] loss: 0.113\n",
      "[9,   100] loss: 0.113\n",
      "[9,   200] loss: 0.102\n",
      "[9,   300] loss: 0.111\n",
      "[10,   100] loss: 0.094\n",
      "[10,   200] loss: 0.093\n",
      "[10,   300] loss: 0.107\n",
      "[11,   100] loss: 0.080\n",
      "[11,   200] loss: 0.093\n",
      "[11,   300] loss: 0.092\n",
      "[12,   100] loss: 0.081\n",
      "[12,   200] loss: 0.077\n",
      "[12,   300] loss: 0.081\n",
      "[13,   100] loss: 0.078\n",
      "[13,   200] loss: 0.077\n",
      "[13,   300] loss: 0.082\n",
      "[14,   100] loss: 0.074\n",
      "[14,   200] loss: 0.077\n",
      "[14,   300] loss: 0.070\n",
      "[15,   100] loss: 0.059\n",
      "[15,   200] loss: 0.069\n",
      "[15,   300] loss: 0.075\n",
      "[16,   100] loss: 0.063\n",
      "[16,   200] loss: 0.063\n",
      "[16,   300] loss: 0.068\n",
      "[17,   100] loss: 0.055\n",
      "[17,   200] loss: 0.057\n",
      "[17,   300] loss: 0.059\n",
      "[18,   100] loss: 0.046\n",
      "[18,   200] loss: 0.057\n",
      "[18,   300] loss: 0.063\n",
      "[19,   100] loss: 0.051\n",
      "[19,   200] loss: 0.051\n",
      "[19,   300] loss: 0.056\n",
      "[20,   100] loss: 0.046\n",
      "[20,   200] loss: 0.059\n",
      "[20,   300] loss: 0.054\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.053\n",
      "[1,   200] loss: 0.361\n",
      "[1,   300] loss: 0.273\n",
      "[2,   100] loss: 0.223\n",
      "[2,   200] loss: 0.198\n",
      "[2,   300] loss: 0.197\n",
      "[3,   100] loss: 0.152\n",
      "[3,   200] loss: 0.160\n",
      "[3,   300] loss: 0.159\n",
      "[4,   100] loss: 0.129\n",
      "[4,   200] loss: 0.142\n",
      "[4,   300] loss: 0.129\n",
      "[5,   100] loss: 0.111\n",
      "[5,   200] loss: 0.126\n",
      "[5,   300] loss: 0.115\n",
      "[6,   100] loss: 0.094\n",
      "[6,   200] loss: 0.108\n",
      "[6,   300] loss: 0.108\n",
      "[7,   100] loss: 0.094\n",
      "[7,   200] loss: 0.092\n",
      "[7,   300] loss: 0.099\n",
      "[8,   100] loss: 0.081\n",
      "[8,   200] loss: 0.091\n",
      "[8,   300] loss: 0.086\n",
      "[9,   100] loss: 0.082\n",
      "[9,   200] loss: 0.078\n",
      "[9,   300] loss: 0.085\n",
      "[10,   100] loss: 0.067\n",
      "[10,   200] loss: 0.075\n",
      "[10,   300] loss: 0.073\n",
      "[11,   100] loss: 0.065\n",
      "[11,   200] loss: 0.078\n",
      "[11,   300] loss: 0.074\n",
      "[12,   100] loss: 0.058\n",
      "[12,   200] loss: 0.065\n",
      "[12,   300] loss: 0.075\n",
      "[13,   100] loss: 0.062\n",
      "[13,   200] loss: 0.065\n",
      "[13,   300] loss: 0.066\n",
      "[14,   100] loss: 0.060\n",
      "[14,   200] loss: 0.064\n",
      "[14,   300] loss: 0.062\n",
      "[15,   100] loss: 0.054\n",
      "[15,   200] loss: 0.054\n",
      "[15,   300] loss: 0.065\n",
      "[16,   100] loss: 0.052\n",
      "[16,   200] loss: 0.055\n",
      "[16,   300] loss: 0.065\n",
      "[17,   100] loss: 0.044\n",
      "[17,   200] loss: 0.049\n",
      "[17,   300] loss: 0.060\n",
      "[18,   100] loss: 0.048\n",
      "[18,   200] loss: 0.049\n",
      "[18,   300] loss: 0.052\n",
      "[19,   100] loss: 0.050\n",
      "[19,   200] loss: 0.041\n",
      "[19,   300] loss: 0.045\n",
      "[20,   100] loss: 0.044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,   200] loss: 0.049\n",
      "[20,   300] loss: 0.050\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.857\n",
      "[1,   200] loss: 1.089\n",
      "[1,   300] loss: 0.796\n",
      "[2,   100] loss: 0.655\n",
      "[2,   200] loss: 0.561\n",
      "[2,   300] loss: 0.465\n",
      "[3,   100] loss: 0.358\n",
      "[3,   200] loss: 0.318\n",
      "[3,   300] loss: 0.291\n",
      "[4,   100] loss: 0.237\n",
      "[4,   200] loss: 0.230\n",
      "[4,   300] loss: 0.203\n",
      "[5,   100] loss: 0.187\n",
      "[5,   200] loss: 0.175\n",
      "[5,   300] loss: 0.170\n",
      "[6,   100] loss: 0.142\n",
      "[6,   200] loss: 0.152\n",
      "[6,   300] loss: 0.145\n",
      "[7,   100] loss: 0.122\n",
      "[7,   200] loss: 0.118\n",
      "[7,   300] loss: 0.136\n",
      "[8,   100] loss: 0.101\n",
      "[8,   200] loss: 0.116\n",
      "[8,   300] loss: 0.108\n",
      "[9,   100] loss: 0.098\n",
      "[9,   200] loss: 0.094\n",
      "[9,   300] loss: 0.095\n",
      "[10,   100] loss: 0.080\n",
      "[10,   200] loss: 0.100\n",
      "[10,   300] loss: 0.094\n",
      "[11,   100] loss: 0.078\n",
      "[11,   200] loss: 0.087\n",
      "[11,   300] loss: 0.092\n",
      "[12,   100] loss: 0.076\n",
      "[12,   200] loss: 0.072\n",
      "[12,   300] loss: 0.078\n",
      "[13,   100] loss: 0.063\n",
      "[13,   200] loss: 0.074\n",
      "[13,   300] loss: 0.071\n",
      "[14,   100] loss: 0.061\n",
      "[14,   200] loss: 0.063\n",
      "[14,   300] loss: 0.075\n",
      "[15,   100] loss: 0.061\n",
      "[15,   200] loss: 0.057\n",
      "[15,   300] loss: 0.070\n",
      "[16,   100] loss: 0.053\n",
      "[16,   200] loss: 0.057\n",
      "[16,   300] loss: 0.065\n",
      "[17,   100] loss: 0.052\n",
      "[17,   200] loss: 0.053\n",
      "[17,   300] loss: 0.058\n",
      "[18,   100] loss: 0.048\n",
      "[18,   200] loss: 0.054\n",
      "[18,   300] loss: 0.053\n",
      "[19,   100] loss: 0.044\n",
      "[19,   200] loss: 0.053\n",
      "[19,   300] loss: 0.050\n",
      "[20,   100] loss: 0.046\n",
      "[20,   200] loss: 0.040\n",
      "[20,   300] loss: 0.060\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.103\n",
      "[1,   200] loss: 0.375\n",
      "[1,   300] loss: 0.271\n",
      "[2,   100] loss: 0.225\n",
      "[2,   200] loss: 0.200\n",
      "[2,   300] loss: 0.204\n",
      "[3,   100] loss: 0.154\n",
      "[3,   200] loss: 0.165\n",
      "[3,   300] loss: 0.144\n",
      "[4,   100] loss: 0.123\n",
      "[4,   200] loss: 0.135\n",
      "[4,   300] loss: 0.133\n",
      "[5,   100] loss: 0.104\n",
      "[5,   200] loss: 0.109\n",
      "[5,   300] loss: 0.120\n",
      "[6,   100] loss: 0.085\n",
      "[6,   200] loss: 0.108\n",
      "[6,   300] loss: 0.104\n",
      "[7,   100] loss: 0.085\n",
      "[7,   200] loss: 0.089\n",
      "[7,   300] loss: 0.096\n",
      "[8,   100] loss: 0.076\n",
      "[8,   200] loss: 0.080\n",
      "[8,   300] loss: 0.075\n",
      "[9,   100] loss: 0.066\n",
      "[9,   200] loss: 0.079\n",
      "[9,   300] loss: 0.089\n",
      "[10,   100] loss: 0.070\n",
      "[10,   200] loss: 0.072\n",
      "[10,   300] loss: 0.082\n",
      "[11,   100] loss: 0.059\n",
      "[11,   200] loss: 0.062\n",
      "[11,   300] loss: 0.072\n",
      "[12,   100] loss: 0.055\n",
      "[12,   200] loss: 0.062\n",
      "[12,   300] loss: 0.065\n",
      "[13,   100] loss: 0.056\n",
      "[13,   200] loss: 0.062\n",
      "[13,   300] loss: 0.057\n",
      "[14,   100] loss: 0.053\n",
      "[14,   200] loss: 0.051\n",
      "[14,   300] loss: 0.057\n",
      "[15,   100] loss: 0.049\n",
      "[15,   200] loss: 0.051\n",
      "[15,   300] loss: 0.047\n",
      "[16,   100] loss: 0.041\n",
      "[16,   200] loss: 0.039\n",
      "[16,   300] loss: 0.063\n",
      "[17,   100] loss: 0.047\n",
      "[17,   200] loss: 0.053\n",
      "[17,   300] loss: 0.051\n",
      "[18,   100] loss: 0.041\n",
      "[18,   200] loss: 0.051\n",
      "[18,   300] loss: 0.045\n",
      "[19,   100] loss: 0.032\n",
      "[19,   200] loss: 0.052\n",
      "[19,   300] loss: 0.045\n",
      "[20,   100] loss: 0.036\n",
      "[20,   200] loss: 0.051\n",
      "[20,   300] loss: 0.052\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.760\n",
      "[1,   200] loss: 0.973\n",
      "[1,   300] loss: 0.718\n",
      "[2,   100] loss: 0.640\n",
      "[2,   200] loss: 0.580\n",
      "[2,   300] loss: 0.565\n",
      "[3,   100] loss: 0.323\n",
      "[3,   200] loss: 0.296\n",
      "[3,   300] loss: 0.257\n",
      "[4,   100] loss: 0.230\n",
      "[4,   200] loss: 0.221\n",
      "[4,   300] loss: 0.217\n",
      "[5,   100] loss: 0.182\n",
      "[5,   200] loss: 0.182\n",
      "[5,   300] loss: 0.186\n",
      "[6,   100] loss: 0.148\n",
      "[6,   200] loss: 0.155\n",
      "[6,   300] loss: 0.150\n",
      "[7,   100] loss: 0.127\n",
      "[7,   200] loss: 0.138\n",
      "[7,   300] loss: 0.128\n",
      "[8,   100] loss: 0.121\n",
      "[8,   200] loss: 0.116\n",
      "[8,   300] loss: 0.109\n",
      "[9,   100] loss: 0.103\n",
      "[9,   200] loss: 0.103\n",
      "[9,   300] loss: 0.109\n",
      "[10,   100] loss: 0.095\n",
      "[10,   200] loss: 0.098\n",
      "[10,   300] loss: 0.093\n",
      "[11,   100] loss: 0.081\n",
      "[11,   200] loss: 0.089\n",
      "[11,   300] loss: 0.088\n",
      "[12,   100] loss: 0.076\n",
      "[12,   200] loss: 0.083\n",
      "[12,   300] loss: 0.088\n",
      "[13,   100] loss: 0.075\n",
      "[13,   200] loss: 0.073\n",
      "[13,   300] loss: 0.076\n",
      "[14,   100] loss: 0.072\n",
      "[14,   200] loss: 0.067\n",
      "[14,   300] loss: 0.068\n",
      "[15,   100] loss: 0.061\n",
      "[15,   200] loss: 0.065\n",
      "[15,   300] loss: 0.061\n",
      "[16,   100] loss: 0.053\n",
      "[16,   200] loss: 0.055\n",
      "[16,   300] loss: 0.064\n",
      "[17,   100] loss: 0.055\n",
      "[17,   200] loss: 0.054\n",
      "[17,   300] loss: 0.058\n",
      "[18,   100] loss: 0.054\n",
      "[18,   200] loss: 0.054\n",
      "[18,   300] loss: 0.051\n",
      "[19,   100] loss: 0.049\n",
      "[19,   200] loss: 0.047\n",
      "[19,   300] loss: 0.059\n",
      "[20,   100] loss: 0.038\n",
      "[20,   200] loss: 0.053\n",
      "[20,   300] loss: 0.056\n",
      "Finished training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAYERSIZE = 50\n",
    "\n",
    "test_runs = 10\n",
    "\n",
    "int_lr = 0.3\n",
    "syn_lr = 0.001\n",
    "\n",
    "seed = random.randint(0, 1000000)\n",
    "\n",
    "#Train IP Model\n",
    "torch.manual_seed(seed)\n",
    "IPnet = DNet(LAYERSIZE, IP, eta=int_lr)\n",
    "IPnet = IPnet.to(device)\n",
    "\n",
    "optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "print(\"Training IP Net\")\n",
    "ip_losses = train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "#Train Standard Model\n",
    "torch.manual_seed(seed)\n",
    "net = DNet(LAYERSIZE, NN, eta=int_lr)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "print(\"Training Standard Net\")\n",
    "standard_losses = train_deep_model(net, optimizer2, seed)\n",
    "\n",
    "for i in range(test_runs-1):\n",
    "    seed = random.randint(0, 1000000)\n",
    "    \n",
    "    #Train IP Model\n",
    "    torch.manual_seed(seed)\n",
    "    IPnet = DNet(LAYERSIZE, IP, eta=int_lr)\n",
    "    IPnet = IPnet.to(device)\n",
    "\n",
    "    optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training IP Net\")\n",
    "    ip_losses += train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "    #Train Standard Model\n",
    "    torch.manual_seed(seed)\n",
    "    net = DNet(LAYERSIZE, NN, eta=int_lr)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "    print(\"Training Standard Net\")\n",
    "    standard_losses += train_deep_model(net, optimizer2, seed)\n",
    "    \n",
    "ip_losses = ip_losses/test_runs\n",
    "standard_losses = standard_losses/test_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAFNCAYAAADSGTgvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd8VFX6x/Hvk57Qm/QmFpBFEaKgWHDtFUV3Xdvae93V\n3bWtYuFnWdeuq7h2V9eOFTtgRQQWaQKCIL1DIED6+f1xZphJSEIgc2eY4fN+vfKaO7fNc29CyHPP\nOc8x55wAAAAAAEgmaYkOAAAAAACArUUyCwAAAABIOiSzAAAAAICkQzILAAAAAEg6JLMAAAAAgKRD\nMgsAAAAASDokswCA7YaZjTCzsxMdx/bAzO40sxVmtiSg848yswuCOHeyM7OBZrYg0XEAAGpHMgsA\nkJnNNbPDEh2Hc+5o59zziY4j0cysk6RrJe3hnGuT6Hi2B2bWxcycmWUkOhYAwPaBZBYAEBepkITE\n8Ro6SVrpnFu2tQemwn1OJO4fACQPklkAQK3M7Dgzm2hma8zsWzPbM2rb9WY228zWmdk0Mzspats5\nZvaNmT1gZislDQmt+9rM7jOz1WY2x8yOjjpmU9fXOuzb1cy+DH32Z2b2mJm9VMt1DApdx9pQzEeF\n1ldqlTazIeHzRLUGnm9m8yR9EeoKfUWVc/9oZoNDy93N7FMzW2VmM8zs91H7HRO6T+vMbKGZXVdN\nnIdJ+lRSOzMrNLPnQutPMLOpoe/DKDPrEXXMXDP7m5lNkrS+uoTMzA43s+lmVmBmj0qyKtvPM7Of\nQvf6YzPrHLWttmt6zsyeCG1fZ2ajo4+t8hnh+3m2mc0LdaO+KWp7WtTP1Eoze83Mmoc2fxl6XRO6\nL/uZ2a9m1jd07Bmhc/cMvT/fzIaHlrPN7EEzWxT6etDMskPbBprZgtD9WyLp2Wrivir0fetgZi3N\n7P3Q92GVmX1lZvw9BQAJwC9fAECNzGxvSc9IulhSC0lPSno3nAhImi3pQElNJN0m6SUzaxt1in6S\nfpHUWtLQqHUzJLWUdK+kp82sUmJV5fia9n1Z0thQXEMknVXLdewr6QVJf5HUVNJBkuZu6fqjHCyp\nh6QjJb0i6bSoc+8hqbOkD8ysgXwi+rKknST9QdLjoX0k6WlJFzvnGkn6jaQvqn6Qc+4zSUdLWuSc\na+icO8fMdgt97jWSWkn6UNJ7ZpYVdehpko6V1NQ5V1bl+ltKekvSzfL3crakAVHbB0m6UdLg0Pm/\nCn2e6nBNknSGpDtC554o6T+13EtJOkDS7pIOlXRLVGJ+paQT5e93O0mrJT0W2nZQ6LVp6L58J2m0\npIGh9QfL/6wdFPV+dGj5Jkn9JfWWtJekfUP3IqyNpOby38eLogM1s1sknSPpYOfcAvnu3wtC96m1\n/H1zW7heAEAASGYBALW5SNKTzrnvnXPlofGsxfKJgZxzrzvnFjnnKpxzr0r6WT5RCFvknHvEOVfm\nnNsYWverc+4p51y5pOcltZVPCqpT7b7mx5TuI+kW51yJc+5rSe/Wch3nS3rGOfdpKNaFzrnpW3Ef\nhjjn1oeu4W1JvaNaH8+Q9JZzrljScZLmOueeDV3z/yS9Kel3oX1LJe1hZo2dc6udcxPq+PmnSvog\nFH+ppPsk5UraP2qfh51z86Puc7RjJE11zr0ROv5BSdGFpS6RdJdz7qdQIvx/Ude4pWtSKLYvQ/fg\nJkn7mVnHWq7nNufcRufcj5J+lE8ww3Hc5JxbEDrXEEmnVNfSHDJaPmmV/EOVu6LeRyezZ0i63Tm3\nzDm3XP7BS/TDjwpJtzrniqPun5nZ/ZKOkHRI6DjJfw/bSursnCt1zn3lnCOZBYAEIJkFANSms6Rr\nQ10q15jZGkkd5VvNZGZ/tEgX5DXyrY0to46fX805NyVRzrkNocWGNXx+Tfu2k7Qqal1NnxXWUb41\nclttOrdzbp2kD+RbKCXfIhpuiewsqV+V+3WGfMufJJ0sn1j+GuqOu18dP7+dpF+jYqgIxdS+uhhr\nOD76GlyV/TtLeigq5lXy3ZDb1+GaKn22c64wdHy7WuKJTqQ3KPL97yzp7ajP+UlSuWp+2DFa0oGh\n3gDpkl6TNMDMusj3FpgYdf2/Rh33a5X4ljvniqqcu6n8w5y7nHMFUev/IWmWpE/M7Bczu76W6wQA\nBIhkFgBQm/mShjrnmkZ95TnnXgm12j0l6QpJLZxzTSVNUeWxmEG1WC2W1NzM8qLW1dYSOF9Stxq2\nrZcUfZ7qqgdXvY5XJJ0WSkZzJI2M+pzRVe5XQ+fcpZLknPvBOTdIvrvucPnkqy4WySd6knyTofz1\nLqwlxmiLFXV/oo4Pmy/f/Tk67lzn3LdbuqaQ6HM3lO+yu6iO1xZtvqSjq3xWjnNuYXXX55ybJZ8M\nXynpS+fcWvlE+SJJX4eSfqnK/ZMvsBUdX3X3brV8q/SzZrapS7Zzbp1z7lrn3M6STpD0ZzM7dBuu\nFQBQTySzAICwTDPLifrKkE9WLzGzfuY1MLNjzayRpAbyScBySTKzc+VbZgPnnPtV0jj5olJZoaTy\n+FoOeVrSuWZ2aKjIUHsz6x7aNlHSH8ws08zyJZ1ShxA+lE+Obpf0alTS9L6k3czsrND5Ms1sHzPr\nEYrzDDNrEurqu1a+e2tdvCbp2FD8mfLjNoslfVvH4z+Q1NPMBoe+r1epctL+hKQbooonNTGzcDfi\nGq8p6vhjzOyA0BjeOySNcc7V1lJckyckDQ134TazVqHxvJL/OauQtHOVY0bLP1AJdykeVeW95B8+\n3Bw6X0tJt0iqsVhYmHNulELdyEPjrsMF0XYJPRAokG85ruv3EQAQQySzAICwDyVtjPoa4pwbJ+lC\nSY/Kt1TNki+GI+fcNEn/lPSdpKWSekn6Jo7xniFpP0krJd0p6VX5BG8zzrmxks6V9IB8AjJakZa6\nv8u32q6WH0v58pY+ODSe8y1Jh0XvH+qCfIR8F+RF8q2E90gKF8w6S9JcM1srPz70jLpcqHNuhqQz\nJT0iaYV84n68c66kjsevkB/jerf8/dpVUd8r59zboTj/G4ptinwRqrpck0L34Fb57sV9Q7Fui4fk\nxz5/YmbrJI2RLwIW7mY+VNI3oW7I/UPHjJbUSJFqx1XfS/7nY5ykSZImS5oQWrdFzrlPJZ0nX3Cr\nj/y9+0xSofzP/uPOuZG1nAIAEBCjZgEAIBWY2auSpjvnbk10LDsS81MHLXDO3bylfQEAiCVaZgEA\nSSnU1bVbqNvwUZIGyY9DBQAAO4DAktnQeKux5ieSn2pmt1Wzj5nZw2Y2y8wmhbrvAABQF23kx0cW\nSnpY0qWhaWMAAMAOILBuxqHCCA2cc4WhYhVfS7raOTcmap9j5CsQHiM/JuYh51y/QAICAAAAAKSM\nwFpmnVcYepsZ+qqaOQ+S9EJo3zGSmobmigMAAAAAoEaBjpk1s3QzmyhpmaRPnXPfV9mlvSpP2r5A\nlSeABwAAAABgMxlBntw5Vy6pt5k1lfS2mf3GOTdla89jZhfJT4CuBg0a9O3evfsWjgAAAAAAJKPx\n48evcM612tJ+gSazYc65NWY2UtJR8nPXhS2U1DHqfYfQuqrHD5M0TJLy8/PduHHjAowWAAAAAJAo\nZvZrXfYLsppxq1CLrMwsV9LhkqZX2e1dSX8MVTXuL6nAObc4qJgAAAAAAKkhyJbZtpKeN7N0+aT5\nNefc+2Z2iSQ5556Q9KF8JeNZkjZIOjfAeAAAAAAAKSKwZNY5N0nS3tWsfyJq2Um6PKgYAAAAAACp\nKS5jZgEAAAAglZSWlmrBggUqKipKdChJKycnRx06dFBmZuY2HU8yCwAAAABbacGCBWrUqJG6dOki\nM0t0OEnHOaeVK1dqwYIF6tq16zadI9B5ZgEAAAAgFRUVFalFixYkstvIzNSiRYt6tWyTzAIAAADA\nNiCRrZ/63j+SWQAAAABIQg0bNpQkzZ07V7m5uerdu7f22GMPXXLJJaqoqEhwdMEjmQUAAACAJNet\nWzdNnDhRkyZN0rRp0zR8+PBEhxQ4klkAAAAASBEZGRnaf//9NWvWrESHEjiSWQAAAABIERs2bNDn\nn3+uXr16JTqUwDE1DwAAAADUw23vTdW0RWtjes492jXWrcf3rPP+s2fPVu/evWVmGjRokI4++uiY\nxrM9IpkFAAAAgCQXHjO7IyGZBQAAAIB62JoWVMQOY2YBAAAAAEmHZBYAAAAAklBhYaEkqUuXLpoy\nZUqCo4k/klkAAAAAQNIhmQUAAAAAJB2SWQAAAABA0iGZBQAAAAAkHZJZAAAAAEDSIZkFAAAAACQd\nklkAAAAASFJDhw5Vz549teeee6p37976/vvv9eCDD2rDhg0x+4wuXbpoxYoV23z8qFGjdNxxx8Us\nnrCMmJ8RAAAAABC47777Tu+//74mTJig7OxsrVixQiUlJTr11FN15plnKi8vLyFxlZeXKz09PfDP\noWUWAAAAAJLQ4sWL1bJlS2VnZ0uSWrZsqTfeeEOLFi3SIYccokMOOUSSdOmllyo/P189e/bUrbfe\nuun4Ll266NZbb1WfPn3Uq1cvTZ8+XZK0cuVKHXHEEerZs6cuuOACOec2HXPiiSeqb9++6tmzp4YN\nG7ZpfcOGDXXttddqr7320nfffaePPvpI3bt3V58+ffTWW28Fcv0kswAAAACQhI444gjNnz9fu+22\nmy677DKNHj1aV111ldq1a6eRI0dq5MiRknxX5HHjxmnSpEkaPXq0Jk2atOkcLVu21IQJE3TppZfq\nvvvukyTddtttOuCAAzR16lSddNJJmjdv3qb9n3nmGY0fP17jxo3Tww8/rJUrV0qS1q9fr379+unH\nH39Ufn6+LrzwQr333nsaP368lixZEsj1080YAAAAAOpjxPXSksmxPWebXtLRd9e6S8OGDTV+/Hh9\n9dVXGjlypE499VTdfffmx7z22msaNmyYysrKtHjxYk2bNk177rmnJGnw4MGSpL59+25qQf3yyy83\nLR977LFq1qzZpnM9/PDDevvttyVJ8+fP188//6wWLVooPT1dJ598siRp+vTp6tq1q3bddVdJ0pln\nnlmpFTdWSGYBAAAAIEmlp6dr4MCBGjhwoHr16qXnn3++0vY5c+bovvvu0w8//KBmzZrpnHPOUVFR\n0abt4S7K6enpKisrq/WzRo0apc8++0zfffed8vLyNHDgwE3nysnJics42WgkswAAAABQH1toQQ3K\njBkzlJaWtqkFdOLEiercubPmzp2rdevWqWXLllq7dq0aNGigJk2aaOnSpRoxYoQGDhxY63kPOugg\nvfzyy7r55ps1YsQIrV69WpJUUFCgZs2aKS8vT9OnT9eYMWOqPb579+6aO3euZs+erW7duumVV16J\n6XWHkcwCAAAAQBIqLCzUlVdeqTVr1igjI0O77LKLhg0bpldeeUVHHXXUprGze++9t7p3766OHTtq\nwIABWzzvrbfeqtNOO009e/bU/vvvr06dOkmSjjrqKD3xxBPq0aOHdt99d/Xv37/a43NycjRs2DAd\ne+yxysvL04EHHqh169bF9NolyaIrUyWD/Px8N27cuESHAQAAAGAH9tNPP6lHjx6JDiPpVXcfzWy8\ncy5/S8dSzRgAAAAAkHRIZgEAAAAASYdkFgAAAACQdEhmAQAAAGAbJFv9oe1Nfe8fySwAAAAAbKWc\nnBytXLmShHYbOee0cuVK5eTkbPM5mJoHAAAAALZShw4dtGDBAi1fvjzRoSStnJwcdejQYZuPJ5kF\nAAAAgK2UmZmprl27JjqMHVpg3YzNrKOZjTSzaWY21cyurmafgWZWYGYTQ1+3BBUPAAAAACB1BNky\nWybpWufcBDNrJGm8mX3qnJtWZb+vnHPHBRgHAAAAACDFBNYy65xb7JybEFpeJ+knSe2D+jwAAAAA\nwI4jLtWMzayLpL0lfV/N5v3NbJKZjTCznvGIBwAAAACQ3AIvAGVmDSW9Keka59zaKpsnSOrknCs0\ns2MkDZe0azXnuEjSRZLUqVOngCMGAAAAAGzvAm2ZNbNM+UT2P865t6pud86tdc4VhpY/lJRpZi2r\n2W+Ycy7fOZffqlWrIEMGAAAAACSBIKsZm6SnJf3knLu/hn3ahPaTme0bimdlUDEBAAAAAFJDkN2M\nB0g6S9JkM5sYWnejpE6S5Jx7QtIpki41szJJGyX9wTnnAowJAAAAAJACAktmnXNfS7It7POopEeD\nigEAAAAAkJriUs0YAAAAAIBYIpkFAAAAACQdklkAAAAAQNIhmQUAAAAAJB2SWQAAAABA0iGZBQAA\nAAAkHZJZAAAAAEDSIZkFAAAAACQdklkAAAAAQNIhmQUAAAAAJB2SWQAAAABA0iGZjaHiDWv15aOX\naNK7jyQ6FAAAAABIaRmJDiCVZGVk6KAVr0grJPU/TNqpR6JDAgAAAICURMtsDFlWns5s/KzKlC5N\nfj3R4QAAAABAyiKZjbF1WTtpTtbu0tyvEx0KAAAAAKQsktkYy85I17Ss30gLx0tlJYkOBwAAAABS\nEslsjGVnpmmBtZEqyqT1yxIdDgAAAACkJJLZGMvOSNMy18y/WbckscEAAAAAQIoimY2xrIw0LQkn\ns2sXJTYYAAAAAEhRTM0TY2s3lumnldlSjmiZBQAAAICAkMzG2NezVsjUSC4tQ7ZucaLDAQAAAICU\nRDfjADilqbxBa1pmAQAAACAgJLMxdunAbpKksrzWEi2zAAAAABAIktkY69W+iSSpNK+1VLAgwdEA\nAAAAQGoimY2x7Ax/Szc27iqt+kVyLsERAQAAAEDqIZmNsaxQMluU1Uxy5VJRQYIjAgAAAIDUQzIb\nY9kZ6ZKkosymfsWGlQmMBgAAAABSE8lsjG3qZpzR2K/YuDqB0QAAAABAaiKZjbHsTH9L16eHW2ZX\nJTAaAAAAAEhNJLMxlpXub+mG9FDLLN2MAQAAACDmSGZjLDvTj5ldl+an6NEnNycwGgAAAABITSSz\nMRYeM1uoPL9iw4oERgMAAAAAqSkj0QGkmnAyW1zupLa96WYMAAAAAAEgmY2x8NQ8xWUV0uKJfmXJ\neimrQQKjAgAAAIDUQjfjGMvKSFNmuml9cVlk5cY1iQsIAAAAAFJQYMmsmXU0s5FmNs3MpprZ1dXs\nY2b2sJnNMrNJZtYnqHjiqWF2hgqLy6Rj/+lXFK9NbEAAAAAAkGKC7GZcJula59wEM2skabyZfeqc\nmxa1z9GSdg199ZP0r9BrUmuYk6HCojKpWVe/oqggsQEBAAAAQIoJrGXWObfYOTchtLxO0k+S2lfZ\nbZCkF5w3RlJTM2sbVEzx0iArQ+uKy6Scpn4FySwAAAAAxFRcxsyaWRdJe0v6vsqm9pLmR71foM0T\n3qTTKNwy27CVX7FuSWIDAgAAAIAUE3gya2YNJb0p6Rrn3DYNHjWzi8xsnJmNW758eWwDDMCmMbON\n2kmWLq35NdEhAQAAAEBKCTSZNbNM+UT2P865t6rZZaGkjlHvO4TWVeKcG+acy3fO5bdq1SqYYGOo\nQXaGr2acniG16CYtm57okAAAAAAgpQRZzdgkPS3pJ+fc/TXs9q6kP4aqGveXVOCcWxxUTPHSvEGW\nlhcW+zeN2kgbViY2IAAAAABIMUFWMx4g6SxJk81sYmjdjZI6SZJz7glJH0o6RtIsSRsknRtgPHGz\nU6NsrSsqU3FZubIzG0gbVyc6JAAAAABIKYEls865ryXZFvZxki4PKoZEyUz3Dd5l5U7ZWXlSyfoE\nRwQAAAAAqSUu1Yx3NOFktrS8QspqIJVsSHBEAAAAAJBaSGYDkJnhb2tJeYWU2UBav/1XYAYAAACA\nZEIyG4CsdN+7uqzcSavnSq5c+vW7xAYFAAAAACmEZDYAGWlR3Yx7neJXPntUAiMCAAAAgNRCMhuA\ncDfj0vIKqVX3BEcDAAAAAKmHZDYA4W7GpeVOatI+tLbWws4AAAAAgK0Q5DyzO6xK1Yxzm0ktdpXa\n9EpwVAAAAACQOmiZDUBGdDIrSZm5UinT8wAAAABArNAyG4DMUDfjkjLnVyyZ5L9K1vt5ZwEAAAAA\n9ULLbACyQi2zywuLK29YMy8B0QAAAABA6iGZDUDTvCxJ0uI1GytvqChLQDQAAAAAkHpIZgPQoVmu\nJKncucobyksTEA0AAAAApB6S2QBkh+aZLSqtqLyhdGM1ewMAAAAAthbJbADMTNkZaSouLa+84blj\nEhMQAAAAAKQYktmA5GSma2M4mT3jzciG4nWJCQgAAAAAUgjJbEByMtNUFE5mu/02soFxswAAAABQ\nbySzAcnJTI+MmU2Lus2MmwUAAACAeiOZDUhORnqkZTZaWVH8gwEAAACAFEMyG5CczDQVlVVsvoFk\nFgAAAADqjWQ2IL6bcTUts6UkswAAAABQXySzAcnJTN98ah5Jmv1F/IMBAAAAgBRDMhuQ3OipeSTp\n+If868g7ExMQAAAAAKQQktmANMnNVMHGqGl4eg5OXDAAAAAAkGJIZgPSNC9TazZEJbM5jSPLq+bE\nPyAAAAAASCEkswHJzUpXcVmFKirc5htXzY5/QAAAAACQQkhmA5KbmS5JKiqLGje712n+NS0jAREB\nAAAAQOogmQ1ITiiZ3VgSlczmn+9fK8oSEBEAAAAApA6S2YBEWmYrIivT/DqVk8wCAAAAQH2QzAYk\nJ6ualtlw9+IxjycgIgAAAABIHSSzAcnJ8Le2KHqu2bA5o+McDQAAAACkFpLZgOSGWmYrJbMVpTXs\nDQAAAADYGiSzAQmPmd0YncyWk8wCAAAAQCyQzAak2mrGzbpGlpfPiHNEAAAAAJA6SGYDklNdy2yj\n1pHlooI4RwQAAAAAqaNOyayZdTOz7NDyQDO7ysyaBhtacguPmS0urah+h4IFcYwGAAAAAFJLXVtm\n35RUbma7SBomqaOkl2s7wMyeMbNlZjalhu0DzazAzCaGvm7Zqsi3c9WOmY32xrlxjAYAAAAAUktd\nk9kK51yZpJMkPeKc+4uktls45jlJR21hn6+cc71DX7fXMZakkJPpb22NySwAAAAAYJvVNZktNbPT\nJJ0t6f3QuszaDnDOfSlpVT1iS2o5GdVMzSNJhw2JeywAAAAAkGrqmsyeK2k/SUOdc3PMrKukF2Pw\n+fub2SQzG2FmPWNwvu1GWpopOyNt85bZfpf41+bd4h8UAAAAAKSIjLrs5JybJukqSTKzZpIaOefu\nqednT5DUyTlXaGbHSBouadfqdjSziyRdJEmdOnWq58fGT05muopKqiSzmblS9+Ok6e9XfxAAAAAA\nYIvqWs14lJk1NrPm8knoU2Z2f30+2Dm31jlXGFr+UFKmmbWsYd9hzrl851x+q1at6vOxcZWbmV79\nmNl1i/3r3G/iGxAAAAAApIi6djNu4pxbK2mwpBecc/0kHVafDzazNmZmoeV9Q7GsrM85tze5Wekq\nqm5qnvAcs88dE9+AAAAAACBF1DWZzTCztpJ+r0gBqFqZ2SuSvpO0u5ktMLPzzewSMwsNGtUpkqaY\n2Y+SHpb0B+ec28r4t2vVjpmVpN6nxz8YAAAAAEghdRozK+l2SR9L+sY594OZ7Szp59oOcM6dtoXt\nj0p6tI6fn5R8y2w1yez+V0ufp9RMRAAAAAAQV3UtAPW6pNej3v8i6eSggkoVuZk1JLPpUbe9rFjK\nyI5fUAAAAACQAupaAKqDmb1tZstCX2+aWYegg0t2kxcU6Ie5q1VeUU3v6Z4n+deNa+IbFAAAAACk\ngLqOmX1W0ruS2oW+3gutQy3WFZdJklYWFm++sftx/rWIZBYAAAAAtlZdk9lWzrlnnXNloa/nJCXP\nHDkJVlxWTUXjBqFZiAqXxjcYAAAAAEgBdU1mV5rZmWaWHvo6Uyk2jU6Q1peUbb6y5e7+dfmM+AYD\nAAAAACmgrsnsefLT8iyRtFh+Wp1zAoopZQw7q68kaX1xNUWgGrXxr6t+iWNEAAAAAJAa6pTMOud+\ndc6d4Jxr5ZzbyTl3oqhmvEXNG2RJktYXV9Mya+ZfxzwulVezHQAAAABQo7q2zFbnzzGLIkU1yPZT\n8GyorptxtPXL4xANAAAAAKSO+iSzFrMoUlSDLJ/MFlbXzTja57fHIRoAAAAASB31SWarmTwV0Rpk\np0uqpWW2dS//WlQQp4gAAAAAIDVk1LbRzNap+qTVJOUGElEKycsKdzOuoWW27Z7S0slSRlYcowIA\nAACA5Fdry6xzrpFzrnE1X42cc7UmwpAy031P7NLq5pmVpIP/5l+nvh2niAAAAAAgNdSnmzG2ICM9\nTWkmlZTXkMxmZEeWN6yKT1AAAAAAkAJIZgOWmZ5WczKb3SiyvGpOfAICAAAAgBRAMhuw4rIKjZ1T\nQ6trVgOpcXu/PPGl+AUFAAAAAEmOZDYO/jdvTc0bBz/lX8c9I83+Ij4BAQAAAECSI5kNWOvG2era\nskHNO2RGFYV+8aTgAwIAAACAFEAyG7C9OjRVdkYtt7nd3pXfV9QwjQ8AAAAAYBOS2YDlZqVrY2kt\nCapZ5fffPxlsQAAAAACQAkhmA5abma6NJVvR2rpqdnDBAAAAAECKIJkNWG7WViazjdsFFwwAAAAA\npAiS2YDlZqZrQ23djCXpvI8jy5/fHmxAAAAAAJACSGYDlpeVrvIKp5Kyipp36tRf6ntu5P2ou4MP\nDAAAAACSGMlswHKzMiRJG0rKat/x+Acjy6PuCjAiAAAAAEh+JLMBy8tKlyQtWlOU4EgAAAAAIHWQ\nzAasWV6WJGnp2joks73PjCw/vLfkXEBRAQAAAEByI5kNWNeWDSRJG+pS0Ti6q/GqX6SpbwUUFQAA\nAAAkN5LZgIW7GW9xzKwkpWdKp78eef/TewFFBQAAAADJjWQ2YLmhZLZoS9PzhO18cGR56tsBRAQA\nAAAAyY9kNmCRltk6JrMZ2ZXfl5fGOCIAAAAASH4kswHLydjKZLaqO1rGMBoAAAAASA0kswFLSzPl\nZqZrY127GUvS7sdWfr9wfGyDAgAAAIAkRzIbB3lZ6XUrABU26NHK75/6rbR8RmyDAgAAAIAkRjIb\nB7lZ6VvXzTivuTSkoPK618+NbVAAAAAAkMRIZuMgLytdG7dlzGzTzpHlZVOlia/ELigAAAAASGKB\nJbNm9oyxRa0+AAAgAElEQVSZLTOzKTVsNzN72MxmmdkkM+sTVCyJlpu5lS2zYd0Oqfx++CXSkCZS\nyYbYBAYAAAAASSrIltnnJB1Vy/ajJe0a+rpI0r8CjCWhZi9fr9Ezl2veyq1MQo9/SNrr9M3XFyyI\nTWAAAAAAkKQCS2adc19KWlXLLoMkveC8MZKamlnboOJJpMJiX/xp9MxlW3/wiY9LF39VeZ0rl5ZO\nkwoWxiA6AAAAAEg+iRwz217S/Kj3C0LrNmNmF5nZODMbt3z58rgEF4TM9G243WZSXovK68qKpX/t\nJz2wR2wCAwAAAIAkkxQFoJxzw5xz+c65/FatWiU6nG22TcmsJDVuV/n9SyfXPxgAAAAASGKJTGYX\nSuoY9b5DaF3KKq9w23agWeX3G1bUPxgAAAAASGKJTGbflfTHUFXj/pIKnHOLExhPYN68dD9J0vqS\nsm0/yd/mxiYYAAAAAEgBQU7N84qk7yTtbmYLzOx8M7vEzC4J7fKhpF8kzZL0lKTLgool0Xq2ayJJ\n2zY9T1huM+maamY5eu64bT8nAAAAACSpjKBO7Jw7bQvbnaTLg/r87Ul2Rpqy0tO0tqi0fidq2nHz\ndXO/kr57XEpLl/pdXL/zAwAAAECSCCyZRYSZqXFuptZurGcyW5OPb/CvJLMAAAAAdhBJUc04FeRm\npamotCLYD1kyRfr5s2A/AwAAAAC2AySzcbJ8XbHe/l8MijV3PUhq31c6+PrNtz0xQPrPydLYp+r/\nOQAAAACwHSOZjZNwq+yG+lQ0lqSz35Mu/ELa5/ya95n+/ubrVs6u3+cCAAAAwHaEZDbO6lXROFrD\nnaTOB1S/rW1vaeOayPvZX0iP9JEmvxGbzwYAAACABCOZjbP1xfVsmY2Wll79+m8elO7pLA3xUwJp\n6VT/uuh/sftsAAAAAEggktk4OW7PtpKk9cUxapmVpEGP+tdev5MGXFP9Pk8fKU182S+bxe6zAQAA\nACCBmJonTk7dp6Pen7S4/mNmozXtJN2y2iepZr5Ftqr5YyLLxrMLAAAAAKmB7CZO8rL8c4O1RTGe\nazYtLdLimplX+74kswAAAABSBNlNnOzauqEkadqitcF9yHUzpevn1bz96wekfx8u/fcMaerbwcUB\nAAAAAAEjmY2TxjmZatskR7OXrw/uQ7IbSTlNpMOGSOnZUpcDN99nwVg/dc/r5wQXBwAAAAAEjGQ2\njnZqnKOV60uC/6AD/iT9fZnUsV/dj1m/UloyObiYAAAAACCGSGbjKDsjTcWlMaxmvCU9T6x9+/t/\n9kns9A/9PLRP1DBvLQAAAABsZ6hmHEfOOf28rDB+H9imlzSkwC/f31Nau6Dy9nFP+69oFeXSxtXS\n4/tJZ73lzwEAAAAA2xlaZuPoh7mrtXpDjKsZ19WfptRtv9ubSzM/ktYvk759xK+rqJBG3SMVLgsu\nPgAAAADYCrTMJkBJWYWyMuL8HCE8fU9dzPrMv056Vep6sPT9v/x42pkjpAu+8NMBAQAAAEACkZXE\n0V4dmkiS3pm4MMGRbEH0tD3vXBYpDLXof9LtzaRJryUmLgAAAAAIIZmNo247+blml60rTmwgNy2t\n3/FvXSgNbSut+Dk28QAAAADAViKZjaObjukhScrNTE9MAOd/Kp07QsrMkf46R2rUNrLtvI+37lyl\nG6RH8yPjaiVpxkfSpNdjEysAAAAA1IJkNo6a5WUpI820ojBBLbMd95U67++X85pLf3xXymwgXT1J\n6rDPtp3zk5ulogJpwXjplVOlty6Qls+IXcwAAAAAUA2S2ThKSzPlZqbr8VGzEx2K12o36aZFUrPO\nUlq6dMNC6dh/bv157u4k/fu3kfdL61g5GQAAAAC2EclsnLVukiNJqqhwCY6kGtkNpX0ukI5/uH7n\neeM8aeYnktsOrxEAAABASiCZjbPT9+0kSSrYmKD5Zuui79nSdbN89+O9z9y2c7z8O+mHf0feV5T7\n1/Iyqby08vo187Y9VgAAAAA7JJLZOGvZKFuStDxR42brqmEr3/140GN+rtlt8dkQadwz0qo50u3N\npclvSI/2le5oJRWEpica+X/Sg71IaAEAAABslYxEB7CjadkwS5K0Yl2xdmvdKMHR1NHvX5AK5vv5\nZzsPkFyFr2I8Z3Ttx5UUSu//Sco/z7+f/Ia0eq5ffmAPqe+50vhn/ftxz0iH3CSlZwZ2GQAAAABS\nB8lsnO0Uapn9ZvYK7b9LywRHU0e5Tf1Xm16RdbseLv3wtPTBn7d8/Lhn/OvMEZXXhxNZSfr6Ad/l\n+Ig76h8vAAAAgJRHN+M4a9nQJ7OPjZyt8u2xCNTW2Od8aUiB1Gl/aY8T63++xT9KG9dIc7+u/7kA\nAAAApDSS2ThrkhvpRjv0g58SGEkMnTdC+t1z0umv1e88c0ZL93SWnjvWV0MGAAAAgBqQzMaZmW1a\nfuabOQmMJMbMpN2OlJp2js35hl8qbVgVm3MBAAAASDkkswlw7eG7JTqE4FwxTvrLbOnP030X5G21\nYYX07pVSaZFUuDx28QEAAABICSSzCZCRHrntziX5uNmqMrKkBi2lxm0rr79msjQ4at7ZdntLDdvU\nfq5Vv0ivnCrdt4t/v26JtGii9MnfI1P7AAAAANghUc04AaJ6GqukvELZGemJCyZof53jLzi3mdS0\nk/TWBX79RaOkFbOkx/bxU/1UZ9k0/yVJP38m/efkyLZvH/avZ78vdT3QL4/+h+/q3HbPIK4EAAAA\nwHaEltkE6N2x6abl9cXlCYwkDvKa+0Q27A8vSxeO9Mstd5HO+7hu54lOZKM9f5z0/PHSvwZII++U\nnjxQ2lJr94ZV0gfX+i7MAAAAAJISyWwC9N+5he4e7OdsveGtSQmOJs66Hyu17xN53z5fOvhv0rUz\n/Rjbv25DUaw5X0pLp0Te39ZUeqCXNKSp9Ph+UskGv760yCeyn98u/fBvacobNZ9zxc/SkCbSshSp\nOA0AAACkmECTWTM7ysxmmNksM7u+mu0DzazAzCaGvm4JMp7tyS47NZQkfTx1aYIjSbC0NOmQG6VG\nrf37vOaxOW/BPEnOd1P+v7bS+Oekoa2le7tK45+tvO/U4dKLg32L7rhnfLI7dbjfNvn12MQDAAAA\nIKYCGzNrZumSHpN0uKQFkn4ws3edc9Oq7PqVc+64oOLYXpVXRLrClpVXVCoKtcPr80dpwguxPed7\nV2++7p3LfcXk8JjdV8+Upr/vlw+5KbRTaIBzeZl/TWeYOQAAALA9CDKD2lfSLOfcL865Ekn/lTQo\nwM9LKm2b5G5afvjznxMYyXbohEek6+dLB/wp+M+KLj4VTmQlaeRQ/7pogvT6OdL93aU7Wviux5Nr\n6Z4MAAAAIC6CTGbbS5of9X5BaF1V+5vZJDMbYWY9A4xnu9KpRd6m5Ye/mJXASLZTOY2lw4ZIHfap\neZ+2vaUrJ0iH3hpcHLO/kKa+La2Pmuv2zfOlJw+SVv+6+f4V5dIvoyqvmz9Weu44X5EZAAAAQEwk\num/rBEmdnHN7SnpE0vDqdjKzi8xsnJmNW758eXW7JKU9OzTZtDxlYUECI9mOpWf714u/8l1/r50h\n7XOh1KaXdPFoqUU36cA/++JRjUPPSm5cLJ3xpnTCo1LzbtL5ASSRi3+URt8rff+kNOMj6bPbpEX/\nk14+VXphkDT9A+k/v/PTBQ2/VJr7la/IPPeb2s+7bon08U1Seal/X1EuvXWRL0gFAAAAYBNzW5rG\nZFtPbLafpCHOuSND72+QJOfcXbUcM1dSvnNuRU375Ofnu3HjxsU42sQY/Pg3mjBvjSSpdeNs3XJc\nTx27Z9sER7WdKVgoTXxZOui6yhP0VmftIikjp/oiUkOabL4uXjLzpNJQReXux0n9LpE6D5BeGizt\nMUh6/xq/7e8rfAL8y0jp9Nell39X+TxDQg883rzAF6Y65j5p3wvjdx0AAABAHJjZeOdc/pb2C7Jl\n9gdJu5pZVzPLkvQHSe9G72Bmbcx8hmJm+4biWRlgTNuVoSf12rS8dG2xLn95QgKj2U41aS8d/Jct\nJ7KS1Lhd3aohHzYkstxyt22NrO7Ciazkx+U+f5xUtMYnreFEVvLJ7S+hOXirJrKS9MBvpAXjIxWW\nP7zOv65d7JP1nz/1LbkrfvZTEJVuDOZ6qnLOJ9hzvozP5wEAAAAKsJqxc67MzK6Q9LGkdEnPOOem\nmtkloe1PSDpF0qVmViZpo6Q/uKCairdDPdo23mxdUWm5cjLTExBNijvnA2nW59Kht/jEuHUvqcsB\nUmaO7yqc10Jq/RspM1dq0tFPGRRka+69XTdft6VksGC+9O/fVl63ZIr0xAC//J9TKm9rvrN02Rgp\nI3vb45R8YjxjhLT3GdVvL93gE+ypb0u31PAsauVsKbdZ7KZeAgAAwA4vsG7GQUmlbsaSdMA9X2jB\n6kgL2nVH7KYrfrtrAiPCJuFk9si7fAGor++Xdj5E+uPwxHZb3lrX/Sz9+q20Zp7U43ipeSiRXj7D\nj/Pd6w+Rfcc+5Vt8D/iT9PUD0plvSmP/Lc0cIQ16XHrnMt+V++ao+ZELl0v37eKXT/uvv0czR/gC\nXeHPCt+vIYwNBwAAQO3q2s2YZDbBVq8v0d53fFpp3dCTfqMz+nVOUETYZO430nPH+GmCchr79216\n+eWv7pc+vy3REW6bPmf7xDbcpfmCL3yLb7s+fiqiqtr0kpZM3nz9BZ9L7faWfv5EeuUPm2+XpJ6D\npeMfku7u6N+f/pq025G+u3TpeqnrQXWLecF4qX2fmrub/+8lad1i6cDrpI2rfQvw4h/98s4Daz7v\nwglSg1ZS0451iwMAAACBI5lNIs45db3hw0rrZv/fMUpPq8M4USTOD//241QXT5I67iNNe8evv2mJ\nL0b1SJ/ExpcMrpooNWzt5/vNblj9PrM+k1462Re86n2GVF4sZTaQMrIi+4Rbfg+8TvrqPql9vrQw\n9Huiamtw6Ubp20elfhdJd3eqfp/yMmnFDKn1DjNbGAAAwHaDZDbJdLn+g0rvHzu9D5WNk4VzvsVw\nSBNfufimxX79ip+lVXN8Mafdj5FmhB5YXDtTmjZcKl4rfXGnH7978Wg/p23Vca+Xfiu9OFgqXBLf\na4qX7MY+uawok64cL31xhx97K/mpmEYOlVr1kJb/VM3BJnU9UDrqHulf+9X8GZePlVrtLr10ilRW\nJK2c5Vtxow0pkCoqpJkfSW+c65PhX7/28xi36Fb/6ywr8a/RCXhtlkyRmnWWshv59xUV0tf/lPqc\nIzVsJa36RWrUzo/5BgAASDEks0nm7GfGavTMynPofvmXQ9SpRV6CIsJWm/OV1KzL5l1WC5f7rskz\nP5JymlTu9jrve6njvpHus1OHS536S//cXTr8DmnAVX79e9dIjdr68a0P7bnlWLIaSiWFMbioFHHN\nZOnBXjVvz24s7fl739pe1an/kXoc57+/TTv5YmHhVuSNq31hsTfP9+93P1Y67WXffXnh+MjUSXe2\nkbLyfMI+4UVpvyt8y6+l+UQ7bP5YP1Z5xodSq+5S085++65H+CrY3Y+TTnlWurOV37/TftIx//Bd\nwYOyaKK0U4/6FxIDAACoI5LZJFNR4bTzjR9utn7u3ccmIBps1z64Tur2W2npFD92t11vad530olP\nSMMvkfa/UjriTun+PaS1C7d8vuMekN7/k18+9BZfuOmlwZvvd+UE33X6mPsi0wLtKHKb+cQ17MQn\npLZ7Vd8ifNqr0iun+uX+l/vxu1/cUXmfI++SPr7BLx//kPTxzdLBf5U+/Xv1n7/Hib41v1E7X4Ds\nsX0rb//rnM0rRRcu870GGrWu2zUWFUiv/VH6ZVSkRXrNPP8QoO85fvxz6UY/5tnM7//D01L+ub6Q\nWLcqlba/Hybtepivqv3rt9J/z5Cu+p+U2zSyT3GhlJbuq4gHafGPUmmR1KlfsJ8DAABigmQ2CfW5\n41OtWl9Sad1Xfz1En05bqulL1ureU/ZKUGTYrpWX+S7LOU2k7x6T8s+rPP50zTw/3ZCZT8ju6RLZ\ndu3M6pOdqtWa9z5LGvSon8fW0qSPbpC+/5ff1qSTdOHn0jNH+u6vB/zZv84YIZ37ofTcsb57L4Iz\n+N++9fjjG6Wl06Rj75OeOEBq2EY67n7fzb14rU9uf/3WF+6yNOmfoXmWW+ziu19HO2KoH68cLhQW\n1u9S3xL8zmWb71+6URp5p3Tw9dLou/36W1ZLLw7yU0+d9bZvbW7Q0rdev3ii/7k97VU/9dSev/fj\n0Fvu5lu2J70m/e45/zAg/zxp9VypfV+fEK/6RUrP9nNRV+fFwf66Drkh8jM/pEBa9pOU01Rq3FZa\nv8L/m2hZTQV553zF7526b8U3og6ck8pLfEt3ean/PqRFTcdWViKlZfjpweJt3VJpxF+kEx71vUkA\nAEgQktkkVXXsbEaaqazCf4/uObmXTu7TQRnpCfgjB6lj4stSkw61VxJe9Yv08N5++Ypxvvt0embl\nfcrLpA0rpEZtIuuWTfcJRHqVKazD44qXz5BeGFR5zOqep0qTXq3XJSFFtO4lLa1SOXvngb61ONpv\nTpamvBl5f+gtPsn95Gap77m+YvcdLTY/f/550rhn/PKQAukfu0rrl/neCfnnRfZbMUt6tG/k/S2r\nI8mlc77Xw/rl0mFDpJ4n+q7nhct8YlpdZeyKCmnqW1LPk/yDoLFP+sreL//ejwnf53z/IGDAVZtP\nY1W60ReUi8XYbcm3vrfpJeWfv3lr/gfX+q72R98r9bu48rbwv+FoG9f4eboHXBV86zoAYIdCMpuk\nCjaUaq/bP6lx+y3H7aHzDugax4iwwyorkco2+pazWCpYID1/gu8uu3yGn5c2nHgce79vkWve1RfH\nCjv8dt+t94VB/v3ffvUJd+lGacVM6f1r/Po/TfMtdYsnSTvtUTmhOfx26dNbNl+WpKt/lL5+0CdE\nE16QTn9Vupd/ZzuU/pf5hypFa6W2e/qfw7ALPvcPYL5/Upr7Ve3n2WOQHwt/2BBfebthG19UrHTD\nlmMIdyevTmYD6dQXfQKakesT6AYtKyeYG1ZFEtTvh/lq3F0GRLYvmy49HtXV+uh/+CJqO/XwielD\ne/ru45Jv7W+4k59X+rNb/VCGTvv7ruNLp/pk+LNbpQU/+P2vmezHlAMAEAMks0lsZWGx+t75WY3b\np9x2pPIy05XG1D1IFeHfQ+E/zMvLfGvcvG+lr/4pXfiFTzSLCqSVs/2cs9FKN/o/uqu2HJWsD3XZ\nzPBdOe9o5bt4Xj3J/+Heqoc06DGpQ19tZs08afLrUuP2vmUsPK/wHoMi0zBF632m1O0QX8F65J2b\nb5eks9+TXj3TX8dZw6XOA6T5Y3xi8q/9I/uFi39VbSEM++scfz13kzxA0g0LpI9vkiY8v/m2s9+T\nnj8+PnH89u/SgdfWPB90XVRU+H/z+1TTclyd8tLNe40AAJIeyWySe/WHefrbm5O3uN/bl+2vvTs1\ni0NEQIKUboxdF8b1K31rc5MOfvqblrvVfboc53xyHD0euWS9NGygL+LUOSoZfeq3vmXvmilS4VLp\n+yd899cuA3yL8oJxfnxotPJSP25U8kWTwlb87Ltum/kxy6UbIlP2fD/Mj3Gsyakv+eRZktrsKS2Z\n5JcP+qtPyFfMiOy7z4V+HOd3j/r3l4/1haYatvYVlN+53Cf+o++R5oze/LNa7OqvaeTQmuPBjuGQ\nm3xBM0ka84QvDtZqt8j2inLf86K8xD8c6hhV0Gz2F9KLJ0m/OUU65enIOH0z/6Bo/XLpsyH+35yr\n8D+jh93me2J0yPc9STau9r83Pr7Rj4c+9BYFrqIiUpfg3q7S71/w11bVmH9Jq3+Vjr678voJL/iH\nW7HqTg4ASY5kNgV0u/FDlVds+ftDxWNgB1ayXpr+gS/y9NN7vqJ1p/2l80b47cMvlya+JN26pnKL\nmXPSyP+TvrzXV7C+OJSgTnxZat7NV/5dMsV3NW24U93j2bjat553yPcVhIeGCowd/Q9p/vfSlDci\n+zbrKq2e45d/+3efqOQ08QlzTfpd4h8OVKddH2nxRJ/kVHvspb5wWf/LpLFPSRWldb+ueEqFiuE5\nTaWB10sfXe/f37jIP7CZ/YUvvBX9EKbnYD+mWPLDDsJFx05+OjLt1S6HS7M+3bZYblzsu4lHJ4qL\n/id997h0wiN+GrOcpn7oQb+L/RzP0Sa9LjVu54uGffhX32vjN4N9YTw5P0/2Q3v562i7l+9+He3Q\nW3yL9dS3pdfPiawPT+VVUS7d3tzPU37SE1L342suAFZRIX19v2+5nj/WdyVv0iGyvazEt1SH/607\n5x+evX6OdNEoP091pfOVSz+967u4S1LRGmnmJ/7BlAtd29qF/uFcx37VjwkPSnGhf3i4IFS3YelU\n/6Avp7F/wBF+qLfiZ7+c28zHm9UguJic879/ev1ealDNuHwAMUMymwIG/mOk5q6swzgrSU+fna9D\ne9RxCg4AO47yMt+aW1t12uqK+8RKuKBROJmeMcInyV0OkDrv56srt+peuUvpj6/6YkRX/+j/uG7R\nTSpe58ezNmnvE/gnD/Z/yB9+u080fnrXJxOrfpGGX+rnB576lh9T3edsPw62qqlv+zmGw1NRDSnw\n1aBH3+OTmlmfSwNvkOR8S196pvTOFdJ+l0nPHS+Vro+c6/Kx/iHAl/f6hwrt+0r/e9FvO+ERadcj\nfat1p/18t/KyjdK4Z33i1qSj7yZ/RWj8qZn/vDXz/R/z9/fYunvePl9aWIf/J6MTR0nqsK+vPB5u\nwa9OWmblhwB9z5HGP7d18SXKQX+ROuwjjR3mK3XXpsM+kfHAsdB8Z/+zuTUOuVn66R3pwlFS4RLf\nIj359c33u2WVn8e8rEh64zw/j3W7vf381OOfqzzlV//Lpb3P8IXI5oz29+TLf/ht7ftWHitenYtG\n+XM753udRBcAlHwyXVLoE8uafqcULJCePVq6+Evp1bP8v/EloZ5olu4T/7WL/EO4o+6RPvpb9ec5\n+33/eyN6iIYk3bSk7r15Fv8Y+f2XkVu5B4Hkf+e8cIKv8F28Tlq3yN/j3Y7ytRXWr/QP4MJFDxdN\n9Pf7+If8GPtDb5XSs/z4+awG0tNH+orqN8yrW3ySf4AhV7nqubT58JzaFC6Tlk2LzHO/eq7vdTP3\nGz9m/tmj/Tz2+17kx+LHWnmZL7a3fLqU29xPKVgXZSV17z21tSoq/MOPLZ3fOf97cudDqr/XW/N9\nwFYhmU0Biws2auycVbr6vxPrfMwrF/ZXswaZ6tAsT7e8M0UH79ZKh/VorQc+nalrDt9NZ/z7ezXN\nzdTz5+275ZMBQH19cK3vArrP+YmOpGbjn5O6HLj1XTynveu7ag+4Jvhxm875ruGvn+0T4vzz/HRK\n+10uZTX0f6w2bhvZf8lknyyPezpSjfnhPlKjttIZr/s/LJt1kZbP9AlM79Mix8782P/Rudfp/vo6\n9vOJz86/9ef51wDfGtjrd76y9Pyxvnv6L6P8FFBIbReN9j9XE16ovP6cD/xUbNHCLeqW5ntMVJ2z\nOwh9z/Vd2I+6y//bSEuX3r0qMqa8SSffE2XRBOmlkzc//viHpb1DwzNuDz1k67SfL4JWnS4H+nnf\nt/a6GraWrpvp/21PfsM/4Op5ki/GVrRGarm7v8/h3g2S9Oef/LzwTTv7quiStM8F0rH/9Mnz2Kf8\nDAHNukjvXlH9tHhNO/neBTVp3cvfuxa7+N8ppUX+wUXVHguFy/zvpD1/L2U18g+5lk/3vRMkfz8y\n8/zDo09urnzskAL/QKlggVSywT8gnPuN79Hz5MFSy1188vjBn6WO/f05J7/mh8N8ea//nXTGG5Ir\nl7Kb+B5JGTnSCQ9vfj2Fy/wDmyOG+sQ1/PDi9XP9A8+qvZbCQ5uc8z0Xpg33PUSOvtfH8cyRfso4\n5yQ5/3BDki4c6Xs5/fyJn2s+XJAyVqZ/6B/sXDHODwkKW7fUT7FYVux7M4R7DKxd7B/ANG7nH6iU\nFPrr/Op+f/zAGzZ/QLKdIZlNIeHpeg7arZW+nLl8m89z2cBuenzUbEl0TQaApFS01v+BWHX6q7oK\nshW+dKM0tM2W9wOwZQ1b+yQy2Qx6zNdYqE3H/r74YSzse5FPmCU/XGXfi6S7O0ZimTFCmv6+79b/\ny8i6VZbvcqCvYbF6rm9dDxeA3Br550m7HS1N/I9/MND9WH++acP9ePqeg/0DyTmjfW+akUN9bQvJ\nP8xYPsNXz9/34siDi7Dux0mDn/IPaKIfdmyty8dKrXbf9uMDRjKbQqYtWqvyCqdeHXx3vf3u+lyL\nC6p52rYFZ/XvrBfH/CqJZBYAEIDyMp8sFxX4QkidB/iWozfOlS7/wbcI7XqYnz5rxUzfYlC6QRp1\nl/9Dr6q/r/B/0E16XTroOmneGH/+UXdFWpeOukcqWScdeJ2v8F281s8d/P6f/Pbaxlk3ahuZ9zp6\naqTDb5f2Ok26b9fK+3faz5/78f6bnyv6+NP+K8350nfDzsj2U38NuNr/gfrOZdJVE/0f1q/9Ucpr\n6efsjoWGbXyX5Fg46UmflFSUxeZ8ACL2v0r6tpqW5HiKdetxjJHMprCXxvyqm4dPqdc5PvnTQdqt\ndaMYRQQAQBUVFTUXMqpO6UZfJCozz3dJrSiTsvKq37e4UHq4tzR4mK+WvCXfPuLHBhYu8+OX/xGq\nGD6koPJ+83/wRcnC1cYLl/sWmuxGPkHvEPq7avlM361yzle+i1+r7v7826qsxFdBXzrZj2ts3k06\ncqjvpp/VQDrmH9K6JdIb50snPi6t/NkXPso/33dxD9+vcPfDKW9JYx73434Pu81f95jHIuOpr5zg\nW/1+fMV3F77kG+m1s/xndT3Yf+12RCS+kvX++l8+1RdqCz8A2FYDb/TFqMIPHCQ/5diKn6VnQp+7\n+zH+unOa+haskUN9F87TX5d2OdT/rCwc74u+tdzdr7ut6ZY/e8A10jcP+uV2e/tiYFvS8yTfK2L2\n5+bS4PsAACAASURBVP59jxN8F87wmPN2e/s4+57tH7KE5zHPaui7d4Yrbn//ROQc24OcJv77GsuW\n0ppkN47NMIQTHpHevbL+54F/WLgdT21GMpvCnHM6+9kfdNMxPdStVQO98N2vuv39aVt9nnDr7FsT\nFmh9SbnO6t9ZH01ZrMUFRTp3QNdYhw0AwPahrMQngJk5iY4koqzYV/zuelDszx0e/7et3dNrs2GV\nL8QUnp4o3I29rDjy2XNG++uqWphp7SJJVnm8d339Msp3Ey0r9nOVzxsjTXlTuvS7yPe7vMw/jMjM\n9cvpGdKy6b6QVtOOPpEefa9/7bjP1sewcLx/wFFTZeX5Y/19qyjzyXiv30tzv/QPL/a/0k9DNf19\nv++Ni3wF8DGP+2T4pCd9F1VX4RPRMY/75Hz3Y6TTXvEPPYrX+WmpJD8Gd+UsX4Qsr7kfY1lSKDVo\nVbkwYMFC//Bo1Rxpw0p/Hyf+JzIWuM8ffcLesLW/d5/9f3v3HR5VlT5w/HtmJr0TEkggCRBCCb0L\nSJMizV5QLKy6uqxdV117b79d17br2kAFC64VERUFpPdeAySEdEjvySRTzu+POxkSSGgmQOD9PA9P\nZs69c+fM5GSY95T3PHv065rwT+P9iuxzOPnfxNeMNa4RPY2M1JmbYc07kJtgrHu1VRr5Cg7tMBKv\nlWUbCakAYkfXDf79W8NDe41gdvvXxjrj0c8Yr2/r5/W/16EdjeNgBO2+oUayq46jjWR/A++AN7od\nPr/LZGNGxYLHjE6j2m74xugASFtrZGYPamPUud+fjOSB7w42pv96+BzeFq+2IxPoAVw5A77789Hn\nTpsPsybXLYu72FjP/dVNxv3ANsb7Ne5FI5v/R+OMzpqBtxtt5tPLjd/f1K+NzqntXx9+rlt/heh6\nZpicRSSYPY9orckorGRzWqE7WVTyyxP59+9JvLFoX4OPS3l1Ek6npsPjPwPwxe2DmPrhOgAu6RXJ\n/WPiiA3zJ72ggrIqO+EBXtz75Raeu7Q7HcP961zrr59tok90MHcMr5tAxeHUzNuWyaW92mA2SaY3\nIYQQQojjyksygs3aW6PZq+om/6mRudlY+9jY2xI5nbBlthFs1zdLovTQ4YzWNVsp1aiuMOp6KkmG\ntDYSbkUPNjpHTiarsdNpJKIKjjq8fZO12FjSYPaqf7aI02EsXQiPN7bdqlGWCz7Bpz56ufM7I2lU\nTXJBrY3g0m6FDTOMjPzdrzp8rKIASjLAZDGOWUuM5GnF6UYnQu2s//UpzjAC3HMks7IEs+ep7BIr\n/l4W/LwsaK15Y1EildV2PlxxoNGeI9DbwrKHR7EmOZ+7vtjMtMHt+GR1CgCJL03gULGVBTsPUWq1\n0SrImye+38noLuF8cHN/zCbFW4sSeWPRPg68MpEdmcV0ahWAt8fZnVFNCCGEEEIIcXpIMCvcHE7N\nk3N3UFRh45edjZQY4hTEhvmRkl+Bw2m0uSUPjWTUa0sBeHxiF0Z1Dier2EpEkLes5xVCCCGEEOI8\nJcGsqFfNNj9ngyAfD4orbfUe2//yxCablqy1JjGnTAJmIYQQQgghzkInGsyeRJpBcS5Y9egJZH08\nTRoKZAGW7Mmpt9zp1BzIKz+q/Kp3VzN7TcoJPe/wfy5h3BvLWZuc7y6rsjuYsSKZEqtRp6KKajan\nNfHG7kIIIYQQQohTJsHseaZNsA8pr05iUs/DmQPvuagjW54ay9y7hnJlnzaMi291BmtoSM4ro6C8\nGqvNUad85soDjHptKT9tP8j1H6zlu80ZbEgpYFNqIU//sIsdGcX8uC2LmhkHi3Znu/fW/XnHQbal\nF5FeUAnA3kOlAOzLLuXhr7fz4k8J9Hz2N/63IY0bZ67jyv+uprxK9tcTQgghhBDibCTTjM9jW9IK\nyS6xcnG31qh6Mp89OXcHKxPzSMmvcJelvDqpzlTl+IhAHhzbiX8vSWJbelGdxz86oQuv/rLnD9dz\nXHwrhnUKw8/TzINfbTvhxw2La8mKxGNvRD+0YyirkvKPec5D4zpxw6AY1iTnc+fnm7l5cAw/7zjE\n2scuwmL+4/1B2SVWDhVbMSnFW4v38a9rexPkc/bu+yWEEEIIIURTkjWzolE5nRoNmE2K4kobm9MK\nueXjDfSOCmbuXUMB2J1VwsS3V9Am2Mc9nbkm8H1qcjwdwvy46/PNtA7y5u3r+jBnfRoOp+bLDeln\n6mX9IePiWzFtSDu6RQYS7OvJF+vSSM0v57GJXQHIK6uipX89KfRdSqw2vlyfxuw1qWQUVtIhzI/k\nXGMK9W8PDGfh7mzuHBnLQVdSrJoOh6veXc3eQ6XsfO5iACqrHfy04yAB3hb6Rofw3eYMMosq6RMd\nzBV92jbxuyCEEEIIIUTjkmBWNKm8sir6v7iI167pxdX9DgdM+WVVBHh74GkxRixLrDZMSuHv1fBG\n7ekFFaxKyuPR73Y0eb2byoyb+/Pn2Ua7/Pf1fcgusfLiTwncPqw9X65Pp7TKzrC4lsycNgBPi8n9\n/p2oXlHBjO0aTnGlrc42S/dc1JF//57kvj+wfQvWHyhw339wbCemDoo+ZlB9MhxOjc3hPGorpaV7\nc+gbE0Kg9+ER5UW7s/nz7I28MaUX7UL9iAjyIaOwgmqHkyGxLRulPuertcn57Msu5ebB7c50VYQQ\nQgghGp0Es6JZmrslk8/XpbIhRZIvNZYxXcN5+YoepBdW0C/m6A23iytt3DhjHX8f3wUPs0IDHmYT\nH608wE87DnJxt1aM6hxOpc3BptRC5m8/yPrHRxMe6E2p1UZ2SRVjXl9Gl9YB/O8vg1mckE1EkA/3\nzNlCXllVvXVKemkC+eXVtAr0rve41eYgraDihDNOV9kdJGaXER7oRXiAcc29h0opsdoY0K4FWmuc\nGlLyy4kK8XV3tny86gAdw/0ZFhfmvpbTqXn2x13cMCiGzq0bN+O1zeGksLya8AZe94mqmfGQ8uqk\nxqiWEEIIIcRZRYJZ0azVt4WQt4cJq80JgKfFxOxbB5JXVsWE7hHMWJHMK671uWaTYtdzF1NWZWf8\nmyu4YVA0m9MKWZGYR9sQHzIKjQRQb13Xm/u+3ArABzf1w9/LwrvL9h93nW1zdnnvSFYk5pFfXs2l\nvSKZty3rlK/VPyaEjal/rNPhuzuH0Dc6pE5Ztd1Jpyd/AWDbM+MaXD+8Zn8+L8zfTXGljcyiSnf5\nDYOi6RoRyJNzdwJGwPfesv111m9P6hHBf6b2of1jPwPwyS0DGNk5nILyat5btp8PlicDsPfF8XhZ\njFHoXVnFtAr0/kOj3E/N3cmna1PZ8MQYbpq5jmcu6cbg2FBu+Xg9vl4WrunXlsyiSm4YFON+TEZh\nBTmlVXXep6YMZqvsDvdrPlJidin+3hYignwa/XmFEEIIIWpIMCuatX3Zpew9VIqH2VgnOr57xHEe\nAeVVdro98yu3Dm3P05fE1zm2OCGb22Zt5Ovpg+kdFYxTa7wsZt5ZkkRsmD/ju7cGwO5wkllUic2h\nmbnyAHPWp/HtX4fw+Hc7mNwzgukjY3FqTecnFzT+iz4PBXhZWPDAcCICvckqruTC/1tS5/j6x0dj\nMin3lOyr+7WlY7h/oyQWOxE3XhDNi5f3AA4HkO/f1I+hHVseNXX+4jeWc3W/ttw+vAPFlTZySqx0\nCPPHbFKk5pdjUoph/1hy1HPU7lSpMapzGGaTMXq8KCEbMN6rH+4eSlJOGXd8uglonGC2uNLGyz8l\n8MTkrqxLLuD22RuZf8+FdG8TVOe8wvJq+rywsMHnXZyQzYD2LdxTzXNKrEz/bBPxkYHu9/BkFFVU\n0/v5hfxnah8m94w8hVd2emmtsTs1Ho2QFK45efWXPYyNb0W/mJDjn3yafbg8mYu6hhMb5n+mqyKE\nEOIkSTArzkvFFTb8vS2YTUdnZy6usBHk2zhZgq9+d/UxRyW7twnE18PC+hRj/Wp8RCCh/p6sSMzj\n/jFxvLko0X3umK6tWJSQTUSQN4dKrNx0QQyz1xjbCc2c1p/bZh1u7/eNjuOtxYk05C8jOhAV4svV\n/drS5SkJuBvDR3/qz87MEl5fuM9d5utpZsqAKKw2B6uS8nn1qh5M/XAdADueHUePZ39zn/vj3Rdy\nyX9WNmkdn7u0G9OGtKtT9u2mDAK8LYzrZnTUlFhtzFmXxnebM9mbXcrvfxvBkr25vDB/d73X7BDm\nx+IHR6CUcid3qzHr1oGM6BRGUk4pY15fXudx254eR5XDwcCXFrvLljw0kv8uSeKFy7vXWW9darXx\n5qJEbruwPbNWp3BJr0i6tA7AbFKsSc53v6fJL0/k550HeX3hPqb0j+K2C9uzJb2IAe0OT5svr7Lj\nYTbhaTFx9burySur4oo+bRneyeh4SM2v4MsNaSxKyOGdqX0xm2D6Z5sB+PDm/ow9hS3JtqYXERnk\nTXigNx+vOsBzP+5m05NjCPX3IquokshgYwS7sLyaED9P4PCU+NqdBc/9uIuPV6UAsOu5i/HzslBi\ntbE7q4QB7VrU+3l2uhWWV2M2qzrr4p1OTYfHjdkNZ3rK+5a0QsIDvWnjes8rqu3EP/0rcPJ1szmc\n512nhBBCnG0kmBWiCdkdTvLKqrn2/TWYFHw1fTDL9xnTmC/oEOo+LyWvnEMlVnq1DcbH8/CX+LT8\nCnZkFnPXF5t57ZpedIsMpH1LP/cXfadToxQopbA7nCTmlOHvZSGqhS9lVXb8XNdq/9jPjOnaignd\nWzO2W6s6XzTzy6rodxJJpv6o/91xAfd9uZVDJVYAxndrjUNrFu7OPm11OJ/NunUgK/bl4uNp5p6L\n4txTta8fGMWc9Y2fMbxrRCAJB0tO6NzBHUJZk2xsgfXwxZ2Z0L01z8/fTbCPB3O3nvpU9xcu705s\nmJ876AV4ZHxn/rFg70lfa+OTYwj186yzTdmMFckMjg2lW+ThwLOowvi7n9QjkjcWGR0cbYJ93FPd\nA72Nv9NdWSX88+qePPzNdgCm9I/C7tR8uznDfa07R8ZyWe82XPzm4Q6B2bcOxM/LwlXvrgagS+sA\nvCwm/jO1L1EtfCkor8bTYjpmUr36/PPXPVzYMYzkvDKemruT3c+PJ7e0irYhPiTllPHesmS2pBfy\n2W2D+GR1CtklVi7v04an5u7khkEx/N8CYzbEgVcmkppfwTPzdnHnyFimfLAWgP0vTzwq6HY6NR2f\n+BmnhrhwfxY+OAIwps7/uiub6wZE4VfP69ifW0b7UD9M9QTxZVV2vtucwcQeEbT092JxQjaFFTYe\n+trYtm3ZwyOJCfUjt7SKAS8Zn3+LHhxBTomVIR2Pn3hu3rYs7p2zhaUPjaRdS796z1mw8xDL9uXw\nypU9AdiWXsTB4srjziDalFpAYbmNMUd0nGitsdqcdf6PaGq7s0rYlFpARlEl1/aPokNLPzanFRET\n6sus1SncP6aT+/dZVFHNUz/sonWgF09Mij/Olc8f/7dgDyl55bx7Y7/jnvvpmhQGx4bSMbxx8zAI\ncS6TYFaIZiA1v5yY0Pq/MJ0Ih1NjcgW99am9tnL2mhSe/mEXL17endX781ixL4+pg6J5f3kyD1/c\nmQHtWmC1OegVFUyv54yRxct6R/LD1iyu7teWh8Z1pnWQN8UVNu74dCMvXN4ds0mRXWKlb3SIOxCv\nPQoFh78cwukZpTyeaYNjmDooxh1ALHpwOL/uyiYpp4zIYG9yS6toHeTDl+vTyCmtP4GVODkB3hZK\nrfYzXY0TphQ8MKaTezT+X9f0osRq47kf6x/FPl2evSSeZ1116B0VTGW1g8GxoTw1OZ7iShvL9+Xy\n8aoDvHNDX1Yl5fH9lkzGxRsdB6fDgVcmutehp7w6iQN55Yx6bWmd4wNeWlwnMdx7N/YlrlUAo/+1\nDC+LifBAL9ILKrmiTxu+35LJ5J4R3DK0PX2jg8ksquTlnxP4ecchwMgcf4/rs6W22DA/9ru2Oavt\n+zuH0DUiEItJYTGb+HB5MuO6tarzGXzvnC3GZ9boOGasSOaO4R24Y3gHPMwmdmYW886S/e6p/9NH\nxDK0Yyg3zVwPQJ/oYPbnlNGjbRDTBrfjmXm7OFhsJT4ikMm9ItydLB3D/bGYFINjQ3l6cjy3fLKB\npXtz+cfVPZnUI+KoAL/K7kBrjsoiX1xpo6TSRlQL3zrnGp0UvmitWbovl+IKGwATerTGy2JmdVIe\nU2es41jemNILp9N4TQ9/s51NrplIDY1y55Ra3cn3ahSWVzP8n0v4+E8D6BcTgta4OyhqkvItSsgm\nuoUvXSMC3Y9zOjVXvLsah9PJ/HuGucu3ZxSRX1bNhyuSWb0/n4UPDKdDmD+ZhZVEh/pitTnYn1tW\np/OpNq01mUWVtA3xrff4idJaU2V3umc/3XtRR/4yIpZ1B/JJOFjKnSNjKauyU2lzkJxbzsLd2cxc\naexCUDNz42xwsLiSMH8vLGYTuaVVHMgrZ2D7o5NEngnFFTaW7svhst5tmuT6VpsDq81BsK9ng39f\nzUluaRVmk6JFre9eYLTVmr+7dcn5hPp7NqsOFQlmhRBU251Y7Y46I7YnIiWvnMhgHzwtJtLyK4gM\n9sZyitPuCsqrGfHPJbx+bW/3VM6ViXl0au1fZypqDU+zicV/G3HU+lIfDzOVNgfBvh48MKYTz8zb\nBcCeF8ZTWe3gxpnrmDltAKVWG0E+HphNCqvdydBXfwfg9mHt+du4znh7mN3rP5+5JJ5bhrZvsO7H\nm05+Kq7q25ayKhu/7jK+EN94QTSfrU2jQ0s/Xry8O1NnrKN7m0BeurwHV727GrtT88Xtg9ieUexe\nK/z8Zd3Yn1PGLNd09D9iRKcwlu3L/cPXEaJfTIg76Dnbzb51IDd/ZASh1w+MwsNsci/vONMCvCyU\nVtm5eXAMHmaTOxACY+lJXHgASuH+jNz69Fie+3E3fl5mPlubBhgj4Yk5ZXWuO7JzGGH+Xny9KYM/\n4vM/DyLQ24P4yECq7A73dO7BHUJ58YrutA/1o8Rq45r31pCYU0a3yEAyiyopqrBx8+AYpg6KZvyb\nK466bu0ZHDWemNiVl35OOG6dnpoc714y8eHN/dmaXsg1/aLw9TITHuDNvuxSPlp5wL2vfYC3hQ1P\njGHK+2t4ZHwX9hwqpVWgF5N6RJBVbMXDrNicWoRTayb2ODziXntq/an6z9Q+LN+Xi9lk4olJXRuc\nZVFtd5JTaiXY17POOXaHk4e/2c4VfdrwxqJ9BPl48Mwl3bhnzmYGtgvlT0PaUV5tx2xShPh6Ulxp\nY+neHA7klVNUYUOjWZWUT3GljYHtW9C5VQCfrj3c9jc8MYawACPg/mD5fsICvPh2UyYzpvU/KuDL\nK6vCx8OMr6eZ9AKjUwGMjgyTSRHk40G13UlGYQXztx/Ew2wiJtSXiT0iqLI7KCiv5roP1vLJLQNp\n39KPzKJK0gsquM414+MfV/Xk2gFR3Pn5JobFheHUmie+38lfR8by9/Fd3PVYti8XD7Nyb/u351AJ\n1XYnPdsGo7Umt7SK8EBvUvPLaRXozW2zNrAqKZ/ElyYQ94Qxi2n9E6N5/Lsd+HhasNmdvHeTMeKu\ntWbp3lz+PHsjvz0wnKgQX77bnEELP0/3Mh4wZpR4mk3cOHMdqfkV/Hj3hfRoW3/HyqlIyinji3Vp\nPDK+Mzszi2nf0o9Qfy+sNoe7Y2XLU2PZkFLAD1uzuLR3JH/5dBM+HmbWPjaaXs8bgxS/PTD8hHeK\nONMkmBVCnPWq7U7Kquws35dLCz9P+rcLwdfT+E+7rMpOtd3p7mmssjvo/OQC7h8Tx/1jOlFWZcfL\nYjru2rYJb63A38vM19OH1Cm3OZxYTKrBUW0wgvqRry1FKfj8tkF8tTGdAe1bsCopzz06BMbU2fHd\nWzP57ZVU2hwAhAV48dG0AbQK9OKrjem89ts+Vjwyqs4oyvHklFrJKKx0ZzIusdpIy69wr7f8ZlMG\n7y3bT9IRX1qP9ODYw6OMNaPtT02O57YLjUD++R9389GqAwR4W/jlvmFkFVm59v013Ds6jgfHdmJl\nYh43zlxHiK8HhRU2HpvQxZ09fPqIWMbGh/Pl+nSeu6wbd8zexMqkPAa0CyEswKvO+3SiakYg37+p\nH39xJbuqbVhcSwa2a8G/aq1jBiP79Ja0IlLzy8kssvL24kQ8LSb2PD+eeduyWJGYR2ZRBZHBPkzq\nEcG/f09ia3rRSdevqXQI8yO51oji9QOj8PO0MKNWMCPE2cTP00x5teNMV+OYXr6iB49/f2L72HuY\nFTZH3e/FHVr6UVBRze3DOvDPX09+CcPxtAv15b4xcZiU4q1FiSTnlfO3sZ3YlFbI0r2HOxp9Pc18\netsg9xKEpnbvRR15u9Y+9vdc1JHKagczVh5gYPsWvH5tr6OSNgI8OakrL/50/A6II/1pSDs+WZ1y\nwucPi2tJbmkVr1zZgyv+a7wnEUHefD19sLtev9w3jGvfX0Op1c51A6LcnRmny4L7hxEXHoDN4cSk\nFGkF5fh5WZi7JYvbh7Unp7SK4kobXSMCSS+o4KkfdpJVVEl6QSWPTezC/O0H2ZRaiMNZf6x2Sa9I\nfjzFXSlevbIHUwZEHfM70JkmwawQ4pxT83l1Nnz4Wm0OvCwmCsqrCfH1rLO+b3dWCW2CfdwJx7TW\nlFjtDW4z1Bh1+WxtqvsLxHUDopg+IpZfdh7i1gvbNbjVzvGueaxpV8UVNpxa15lSXsPucGJ2dRTs\nzy1j9L+W4Wk24etl5sZBMWxJL+SdqX3p/+Ii7E7NK1f2oF2oHw6nxuyaflkjv6yKjMJKAn08GPXa\nUvrFhPDtX4e467gjs5hr3lvDvLuH0rNtcJ16JBwsIcTXk9ZBDe/rO2d9Go99Z3zR/fX+4XXWr9b2\nypU9MCvFJ6tTeHRCF37fk0NZlZ1vNmUQ5OPBm1N6c8snG9znL7h/GOuSC1iUkM19o+NIOFjCUz/s\nwsOsGNk5nCn9oyirsnP//7bSoaUfs28bSNsQXxIOlhDk40GAt4UA14yK+rYq+yNeu6aXe43pkVb+\nfRRT3l/LI+M7sym1kMcndmV/bhmT3jaWB7wztS93fWEkzrqyTxu+25IJGNulVdudjVK/Czq0YG1y\nwSk99vnLulFUYauTsE0IIc4247u1ZsEuo7N3VOcwluw9/TOkvv3rkLMyE32NsyKYVUqNB94CzMAM\nrfWrRxxXruMTgQrgT1rrzce6pgSzQghRv2q7MdpcX+Kcs1Gp1YbdUX9AfLo4nZqFCdmMi2/l7iSp\n6Ry48YIYHE5jy52GOiJySqx4eZjdx5Nyyigor6537ZnDqVFw0r+fDSkFFJZXu6fpa417qqO/l4WN\nT47h+fm7+WJdGoseHE5MqB8eZhP7c8vYkVHMpJ4RaG0EnDVmr0mhT1QInVr7U2q1u7crO5EOl4Ly\najzMyh1sG3XS7vWyAJf2iuT+MXFEtfDl6R920SbYm0k9I1mzP59r+7fFbDJGwCqrHRRUVLNmfz6D\nY0NJOFjCxd1ak19Wxb7sMjqE+bE7qwSr3cFFXcKxmEz8+/dEFu7OZs+hUi7s2JJXruxBld1x1Fqw\nxOxSxr6xnL+M6ICX2YSvl4WPVh447lr4b6YPpsruZGjHlry+cB+7s0pYlJDNqkcvIsjHA5OCQ8VW\nftiaxeDYUPy9LESH+nLvnC38aUg73l+WjJeHCQV8cHN/nFrzyDfbCfbxIMDbg8hgH6YMiMJsUmht\nbAP35Yb0emdYHG8/8GBfD4pca2Lvuagj/641kgZGJn1jOqJnvdOo599zIf5eFrKKKpk6Yx0f3NSP\n3QdLeHNRIksfGklMqC9P/bCTz9amcfPgmEabij19RCxx4f7MXpvKthOYHfHohC58tSGdoR1bclnv\nSGavSWXetizCA7zcv8+bLoipM122qfx1ZCzvLt1PbJgf79/Uj799vZ3rB0SRXVJFYUX1SY0unk2a\nW24D8ccdeGXiWTE40JAzHswqpczAPmAskAFsAK7XWu+udc5E4B6MYHYQ8JbWetCxrivBrBBCCHH2\ncTqNxDjeHqYm/4KktWZXVslR+yEf6US22cksquSTVQeYNqQdvp6Wo5KonC4bUgq4d84WFj44Ak+z\niaScMuIjDydGSskrJybUF7tTYzEpCitstPDzZFdWMTGhfvh7WdwdJjXJp2ZMM74H2h1O1h8oIDmv\nnA5hfny5Pp0r+rZhVOfwk6qjzeHk0zWphPp7smxfLvll1VRWO3jzut7MWHGAUH9PPMyK6wZGE+jt\nQVZRJRmFldgcRudAekHFUUst8sqqSM2voF9MCNklVn7bnc2Ng6KpsjvZlVVCeIDXUY9JzS/ntlkb\n+eL2QSgUDqemdZA3JVYbn61NxdfDzBV92xLobaH/i4vIL69m6UMjmbMhjS/WptE7OpgViXnu6901\nKpa+0SHszS6lc6sAbpu1kTbBPix8cDgv/ZTA5rQiHp/YhW3pRdx9UVyD74/TqTlUYuXrjRlM6NGa\nDi396uSbKLHa8PEw42E2kZJXTnm1ncggIxv62uR8NqUWcnmfNjidmveWJxPobeHlK4zOmgf+t40d\nmcWseGQUgT4e/LrzEG8tTmT+PRfi5WHC4fr7a+lKMLU7q4R2LX3x9bSQcLCENfvz3cngHr64MzcM\nisbm0Py4LYtJPSNoFWjMYPl11yEcTs1XG9PrTHM+nhGdwri0VyQhfh7M25pVJ1P9s5fEszG1kC6t\nA3jtt318+9chtA3xYXFCDtEtfNmWUcRdozqyL7sUL4uJA3nlZBVZaeHnQXxEEFEtjC23aj5X+r+4\nqE4iuWNpHehN76hg2oT4cEWfNiTllFHtcHJFnzZsTS+ivMrOtvRi+kQH0yHMj4SDpdw+u26cMbBd\nC9anFPDI+M78ZXgs7y/fz+QekVjMih+3ZfHKL3u4ul9bBrZvQXxEIDNXHuB716yVP+rxiV34bG0a\naQUVtG/px4G8usntrh8YzZz1aQyLa0lRhY3/3tCXg8VWft+Tw3vL9nP9wCg6twogwNuD6FBff2iB\n6AAACYVJREFUViflk1NqpVWgN/eObrgtnw3OhmB2MPCs1vpi1/3HALTWr9Q6531gqdZ6juv+XmCk\n1vpgQ9eVYFYIIYQQQpwqm8NJYnaZe1T9fFFQXo2CE54Nc7C4kmfn7eJf1/YGjESMv+w8SESQNz3a\nBONhVhSUVxPs61lnay6tjRktp2O/5spqB6VVNsqrHPy0PYthcWH0igo+/gOPIyWvnFB/zzozUE6U\nzeHks7WpFJRXk1taxcjOYcSE+nHNe2vo2TaI8AAv5m7N4rEJXbh+UDQWkyLhYAkH8iq4ul9bAFbv\nz8PphAvjWlJtd/Lu0v3cPrw9KXkVdI0IoLDC6Bg5nVt6nW5nQzB7NTBea/1n1/2bgEFa67trnTMf\neFVrvdJ1fzHwd611g9GqBLNCCCGEEEIIce460WC26btMGoFS6g6l1Eal1MbcXNlCQgghhBBCCCHO\nd00ZzGYCUbXut3WVnew5aK0/0Fr311r3DwsLa/SKCiGEEEIIIYRoXpoymN0AxCml2iulPIHrgHlH\nnDMPuFkZLgCKj7VeVgghhBBCCCGEALA01YW11nal1N3Arxhb83yktd6llJruOv4e8DNGJuMkjK15\nbmmq+gghhBBCCCGEOHc0WTALoLX+GSNgrV32Xq3bGrirKesghBBCCCGEEOLc0ywSQAkhhBBCCCGE\nELVJMCuEEEIIIYQQotmRYFYIIYQQQgghRLMjwawQQgghhBBCiGZHGTmYmg+lVC6QeqbrcRwtgbwz\nXQlxVpK2IRoibUMci7QP0RBpG6Ih0jZEQ5pD24jRWocd76RmF8w2B0qpjVrr/me6HuLsI21DNETa\nhjgWaR+iIdI2REOkbYiGnEttQ6YZCyGEEEIIIYRodiSYFUIIIYQQQgjR7Egw2zQ+ONMVEGctaRui\nIdI2xLFI+xANkbYhGiJtQzTknGkbsmZWCCGEEEIIIUSzIyOzQgghhBBCCCGaHQlmG5FSarxSaq9S\nKkkp9eiZro9oekqpj5RSOUqpnbXKWiilFiqlEl0/Q2ode8zVPvYqpS6uVd5PKbXDdextpZQ63a9F\nNC6lVJRSaolSardSapdS6j5XubQPgVLKWym1Xim1zdU+nnOVS/sQACilzEqpLUqp+a770jYESqkU\n1+90q1Jqo6tM2oZAKRWslPpGKbVHKZWglBp8PrQNCWYbiVLKDLwDTADigeuVUvFntlbiNPgEGH9E\n2aPAYq11HLDYdR9Xe7gO6OZ6zH9d7QbgXeB2IM7178hriubHDvxNax0PXADc5WoD0j4EQBVwkda6\nF9AbGK+UugBpH+Kw+4CEWvelbYgao7TWvWttrSJtQwC8BSzQWncBemF8fpzzbUOC2cYzEEjSWidr\nrauBL4HLznCdRBPTWi8HCo4ovgyY5bo9C7i8VvmXWusqrfUBIAkYqJSKAAK11mu1sYh9dq3HiGZK\na31Qa73ZdbsU4z+VNkj7EIA2lLnuerj+aaR9CEAp1RaYBMyoVSxtQzRE2sZ5TikVBAwHZgJorau1\n1kWcB21DgtnG0wZIr3U/w1Umzj+ttNYHXbcPAa1ctxtqI21ct48sF+cIpVQ7oA+wDmkfwsU1jXQr\nkAMs1FpL+xA13gQeAZy1yqRtCDA6vRYppTYppe5wlUnbEO2BXOBj1/KEGUopP86DtiHBrBBNyNWr\nJSnDz2NKKX/gW+B+rXVJ7WPSPs5vWmuH1ro30BajR7z7EcelfZyHlFKTgRyt9aaGzpG2cV670PW5\nMQFj+crw2gelbZy3LEBf4F2tdR+gHNeU4hrnatuQYLbxZAJRte63dZWJ80+2a5oGrp85rvKG2kim\n6/aR5aKZU0p5YASyn2utv3MVS/sQdbimgi3BWJck7UMMBS5VSqVgLFm6SCn1GdI2BKC1znT9zAG+\nx1jmJm1DZAAZrhk+AN9gBLfnfNuQYLbxbADilFLtlVKeGIuq553hOokzYx4wzXV7GvBDrfLrlFJe\nSqn2GIvq17umf5QopS5wZYy7udZjRDPl+l3OBBK01q/XOiTtQ6CUClNKBbtu+wBjgT1I+zjvaa0f\n01q31Vq3w/gu8bvW+kakbZz3lFJ+SqmAmtvAOGAn0jbOe1rrQ0C6Uqqzq2g0sJvzoG1YznQFzhVa\na7tS6m7gV8AMfKS13nWGqyWamFJqDjASaKmUygCeAV4FvlJK3QakAtcCaK13KaW+wvhwsQN3aa0d\nrkvdiZEZ2Qf4xfVPNG9DgZuAHa51kQCPI+1DGCKAWa7skSbgK631fKXUGqR9iPrJZ4doBXzv2inF\nAnyhtV6glNqAtA0B9wCfuwbVkoFbcP3/ci63DWVMnxZCCCGEEEIIIZoPmWYshBBCCCGEEKLZkWBW\nCCGEEEIIIUSzI8GsEEIIIYQQQohmR4JZIYQQQgghhBDNjgSzQgghhBBCCCGaHQlmhRBCiCaglHIo\npbbW+vfocc6frpS6uRGeN0Up1fKPXkcIIYQ428nWPEIIIUQTUEqVaa39z8DzpgD9tdZ5p/u5hRBC\niNNJRmaFEEKI08g1cvoPpdQOpdR6pVRHV/mzSqmHXLfvVUrtVkptV0p96SproZSa6ypbq5Tq6SoP\nVUr9ppTapZSaAahaz3Wj6zm2KqXeV0qZz8BLFkIIIZqEBLNCCCFE0/A5YprxlFrHirXWPYD/AG/W\n89hHgT5a657AdFfZc8AWV9njwGxX+TPASq11N+B7IBpAKdUVmAIM1Vr3BhzADY37EoUQQogzx3Km\nKyCEEEKcoypdQWR95tT6+UY9x7cDnyul5gJzXWUXAlcBaK1/d43IBgLDgStd5T8ppQpd548G+gEb\nlFIAPkDOH3tJQgghxNlDglkhhBDi9NMN3K4xCSNIvQR4QinV4xSeQwGztNaPncJjhRBCiLOeTDMW\nQgghTr8ptX6uqX1AKWUCorTWS4C/A0GAP7AC1zRhpdRIIE9rXQIsB6a6yicAIa5LLQauVkqFu461\nUErFNOFrEkIIIU4rGZkVQgghmoaPUmprrfsLtNY12/OEKKW2A1XA9Uc8zgx8ppQKwhhdfVtrXaSU\nehb4yPW4CmCa6/zngDlKqV3AaiANQGu9Wyn1JPCbK0C2AXcBqY39QoUQQogzQbbmEUIIIU4j2TpH\nCCGEaBwyzVgIIYQQQgghRLMjI7NCCCGEEEIIIZodGZkVQgghhBBCCNHsSDArhBBCCCGEEKLZkWBW\nCCGEEEIIIUSzI8GsEEIIIYQQQohmR4JZIYQQQgghhBDNjgSzQgghhBBCCCGanf8HsQkJKzGyz1sA\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f01ec7abcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.ylim([-0.1, 3])\n",
    "plt.title(\"Learning curves for deep networks\")\n",
    "plt.plot(ip_losses[0], ip_losses[1], label=\"IP\")\n",
    "# plt.plot(bn_losses[0], bn_losses[1], label=\"BN\")\n",
    "plt.plot(standard_losses[0], standard_losses[1], label=\"Standard\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the standard network on the 10000 test images: 96.6800 %\n",
      "Accuracy of the IP network on the 10000 test images: 96.5700 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        y = net(images)\n",
    "        _, predicted = torch.max(y.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the standard network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        y = IPnet(images)\n",
    "        _, predicted = torch.max(y.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the IP network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IP Net\n",
      "[1,   100] loss: 0.895\n",
      "[1,   200] loss: 0.318\n",
      "[1,   300] loss: 0.270\n",
      "[2,   100] loss: 0.234\n",
      "[2,   200] loss: 0.232\n",
      "[2,   300] loss: 0.215\n",
      "[3,   100] loss: 0.178\n",
      "[3,   200] loss: 0.183\n",
      "[3,   300] loss: 0.160\n",
      "[4,   100] loss: 0.151\n",
      "[4,   200] loss: 0.157\n",
      "[4,   300] loss: 0.160\n",
      "[5,   100] loss: 0.141\n",
      "[5,   200] loss: 0.148\n",
      "[5,   300] loss: 0.150\n",
      "[6,   100] loss: 0.136\n",
      "[6,   200] loss: 0.127\n",
      "[6,   300] loss: 0.128\n",
      "[7,   100] loss: 0.114\n",
      "[7,   200] loss: 0.124\n",
      "[7,   300] loss: 0.129\n",
      "[8,   100] loss: 0.117\n",
      "[8,   200] loss: 0.115\n",
      "[8,   300] loss: 0.114\n",
      "[9,   100] loss: 0.100\n",
      "[9,   200] loss: 0.114\n",
      "[9,   300] loss: 0.110\n",
      "[10,   100] loss: 0.103\n",
      "[10,   200] loss: 0.100\n",
      "[10,   300] loss: 0.094\n",
      "[11,   100] loss: 0.084\n",
      "[11,   200] loss: 0.092\n",
      "[11,   300] loss: 0.096\n",
      "[12,   100] loss: 0.070\n",
      "[12,   200] loss: 0.091\n",
      "[12,   300] loss: 0.094\n",
      "[13,   100] loss: 0.085\n",
      "[13,   200] loss: 0.084\n",
      "[13,   300] loss: 0.087\n",
      "[14,   100] loss: 0.080\n",
      "[14,   200] loss: 0.091\n",
      "[14,   300] loss: 0.085\n",
      "[15,   100] loss: 0.075\n",
      "[15,   200] loss: 0.071\n",
      "[15,   300] loss: 0.078\n",
      "[16,   100] loss: 0.061\n",
      "[16,   200] loss: 0.073\n",
      "[16,   300] loss: 0.072\n",
      "[17,   100] loss: 0.070\n",
      "[17,   200] loss: 0.064\n",
      "[17,   300] loss: 0.059\n",
      "[18,   100] loss: 0.059\n",
      "[18,   200] loss: 0.069\n",
      "[18,   300] loss: 0.078\n",
      "[19,   100] loss: 0.059\n",
      "[19,   200] loss: 0.067\n",
      "[19,   300] loss: 0.059\n",
      "[20,   100] loss: 0.052\n",
      "[20,   200] loss: 0.059\n",
      "[20,   300] loss: 0.063\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.423\n",
      "[1,   200] loss: 0.803\n",
      "[1,   300] loss: 0.538\n",
      "[2,   100] loss: 0.387\n",
      "[2,   200] loss: 0.328\n",
      "[2,   300] loss: 0.290\n",
      "[3,   100] loss: 0.241\n",
      "[3,   200] loss: 0.229\n",
      "[3,   300] loss: 0.203\n",
      "[4,   100] loss: 0.181\n",
      "[4,   200] loss: 0.177\n",
      "[4,   300] loss: 0.178\n",
      "[5,   100] loss: 0.150\n",
      "[5,   200] loss: 0.149\n",
      "[5,   300] loss: 0.149\n",
      "[6,   100] loss: 0.135\n",
      "[6,   200] loss: 0.135\n",
      "[6,   300] loss: 0.128\n",
      "[7,   100] loss: 0.118\n",
      "[7,   200] loss: 0.114\n",
      "[7,   300] loss: 0.116\n",
      "[8,   100] loss: 0.103\n",
      "[8,   200] loss: 0.104\n",
      "[8,   300] loss: 0.109\n",
      "[9,   100] loss: 0.099\n",
      "[9,   200] loss: 0.098\n",
      "[9,   300] loss: 0.104\n",
      "[10,   100] loss: 0.084\n",
      "[10,   200] loss: 0.094\n",
      "[10,   300] loss: 0.088\n",
      "[11,   100] loss: 0.078\n",
      "[11,   200] loss: 0.083\n",
      "[11,   300] loss: 0.095\n",
      "[12,   100] loss: 0.077\n",
      "[12,   200] loss: 0.082\n",
      "[12,   300] loss: 0.085\n",
      "[13,   100] loss: 0.077\n",
      "[13,   200] loss: 0.071\n",
      "[13,   300] loss: 0.088\n",
      "[14,   100] loss: 0.071\n",
      "[14,   200] loss: 0.064\n",
      "[14,   300] loss: 0.078\n",
      "[15,   100] loss: 0.067\n",
      "[15,   200] loss: 0.061\n",
      "[15,   300] loss: 0.079\n",
      "[16,   100] loss: 0.059\n",
      "[16,   200] loss: 0.059\n",
      "[16,   300] loss: 0.070\n",
      "[17,   100] loss: 0.061\n",
      "[17,   200] loss: 0.071\n",
      "[17,   300] loss: 0.069\n",
      "[18,   100] loss: 0.057\n",
      "[18,   200] loss: 0.062\n",
      "[18,   300] loss: 0.065\n",
      "[19,   100] loss: 0.060\n",
      "[19,   200] loss: 0.075\n",
      "[19,   300] loss: 0.063\n",
      "[20,   100] loss: 0.051\n",
      "[20,   200] loss: 0.060\n",
      "[20,   300] loss: 0.074\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.798\n",
      "[1,   200] loss: 0.303\n",
      "[1,   300] loss: 0.260\n",
      "[2,   100] loss: 0.222\n",
      "[2,   200] loss: 0.192\n",
      "[2,   300] loss: 0.200\n",
      "[3,   100] loss: 0.167\n",
      "[3,   200] loss: 0.166\n",
      "[3,   300] loss: 0.165\n",
      "[4,   100] loss: 0.137\n",
      "[4,   200] loss: 0.151\n",
      "[4,   300] loss: 0.133\n",
      "[5,   100] loss: 0.125\n",
      "[5,   200] loss: 0.134\n",
      "[5,   300] loss: 0.136\n",
      "[6,   100] loss: 0.112\n",
      "[6,   200] loss: 0.123\n",
      "[6,   300] loss: 0.115\n",
      "[7,   100] loss: 0.099\n",
      "[7,   200] loss: 0.102\n",
      "[7,   300] loss: 0.116\n",
      "[8,   100] loss: 0.109\n",
      "[8,   200] loss: 0.103\n",
      "[8,   300] loss: 0.104\n",
      "[9,   100] loss: 0.089\n",
      "[9,   200] loss: 0.094\n",
      "[9,   300] loss: 0.094\n",
      "[10,   100] loss: 0.091\n",
      "[10,   200] loss: 0.087\n",
      "[10,   300] loss: 0.101\n",
      "[11,   100] loss: 0.084\n",
      "[11,   200] loss: 0.078\n",
      "[11,   300] loss: 0.084\n",
      "[12,   100] loss: 0.072\n",
      "[12,   200] loss: 0.069\n",
      "[12,   300] loss: 0.075\n",
      "[13,   100] loss: 0.075\n",
      "[13,   200] loss: 0.082\n",
      "[13,   300] loss: 0.076\n",
      "[14,   100] loss: 0.065\n",
      "[14,   200] loss: 0.080\n",
      "[14,   300] loss: 0.081\n",
      "[15,   100] loss: 0.062\n",
      "[15,   200] loss: 0.064\n",
      "[15,   300] loss: 0.083\n",
      "[16,   100] loss: 0.063\n",
      "[16,   200] loss: 0.056\n",
      "[16,   300] loss: 0.069\n",
      "[17,   100] loss: 0.061\n",
      "[17,   200] loss: 0.060\n",
      "[17,   300] loss: 0.071\n",
      "[18,   100] loss: 0.061\n",
      "[18,   200] loss: 0.059\n",
      "[18,   300] loss: 0.062\n",
      "[19,   100] loss: 0.061\n",
      "[19,   200] loss: 0.054\n",
      "[19,   300] loss: 0.058\n",
      "[20,   100] loss: 0.053\n",
      "[20,   200] loss: 0.052\n",
      "[20,   300] loss: 0.053\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.164\n",
      "[1,   200] loss: 0.409\n",
      "[1,   300] loss: 0.314\n",
      "[2,   100] loss: 0.254\n",
      "[2,   200] loss: 0.225\n",
      "[2,   300] loss: 0.215\n",
      "[3,   100] loss: 0.177\n",
      "[3,   200] loss: 0.178\n",
      "[3,   300] loss: 0.175\n",
      "[4,   100] loss: 0.144\n",
      "[4,   200] loss: 0.147\n",
      "[4,   300] loss: 0.142\n",
      "[5,   100] loss: 0.130\n",
      "[5,   200] loss: 0.130\n",
      "[5,   300] loss: 0.123\n",
      "[6,   100] loss: 0.106\n",
      "[6,   200] loss: 0.109\n",
      "[6,   300] loss: 0.114\n",
      "[7,   100] loss: 0.093\n",
      "[7,   200] loss: 0.098\n",
      "[7,   300] loss: 0.104\n",
      "[8,   100] loss: 0.087\n",
      "[8,   200] loss: 0.083\n",
      "[8,   300] loss: 0.092\n",
      "[9,   100] loss: 0.081\n",
      "[9,   200] loss: 0.081\n",
      "[9,   300] loss: 0.088\n",
      "[10,   100] loss: 0.075\n",
      "[10,   200] loss: 0.079\n",
      "[10,   300] loss: 0.078\n",
      "[11,   100] loss: 0.073\n",
      "[11,   200] loss: 0.067\n",
      "[11,   300] loss: 0.077\n",
      "[12,   100] loss: 0.068\n",
      "[12,   200] loss: 0.067\n",
      "[12,   300] loss: 0.073\n",
      "[13,   100] loss: 0.061\n",
      "[13,   200] loss: 0.064\n",
      "[13,   300] loss: 0.072\n",
      "[14,   100] loss: 0.054\n",
      "[14,   200] loss: 0.069\n",
      "[14,   300] loss: 0.076\n",
      "[15,   100] loss: 0.061\n",
      "[15,   200] loss: 0.060\n",
      "[15,   300] loss: 0.063\n",
      "[16,   100] loss: 0.065\n",
      "[16,   200] loss: 0.066\n",
      "[16,   300] loss: 0.060\n",
      "[17,   100] loss: 0.046\n",
      "[17,   200] loss: 0.048\n",
      "[17,   300] loss: 0.069\n",
      "[18,   100] loss: 0.053\n",
      "[18,   200] loss: 0.050\n",
      "[18,   300] loss: 0.056\n",
      "[19,   100] loss: 0.049\n",
      "[19,   200] loss: 0.061\n",
      "[19,   300] loss: 0.057\n",
      "[20,   100] loss: 0.046\n",
      "[20,   200] loss: 0.054\n",
      "[20,   300] loss: 0.056\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.820\n",
      "[1,   200] loss: 0.305\n",
      "[1,   300] loss: 0.247\n",
      "[2,   100] loss: 0.225\n",
      "[2,   200] loss: 0.196\n",
      "[2,   300] loss: 0.199\n",
      "[3,   100] loss: 0.172\n",
      "[3,   200] loss: 0.160\n",
      "[3,   300] loss: 0.167\n",
      "[4,   100] loss: 0.131\n",
      "[4,   200] loss: 0.148\n",
      "[4,   300] loss: 0.151\n",
      "[5,   100] loss: 0.121\n",
      "[5,   200] loss: 0.142\n",
      "[5,   300] loss: 0.132\n",
      "[6,   100] loss: 0.109\n",
      "[6,   200] loss: 0.120\n",
      "[6,   300] loss: 0.126\n",
      "[7,   100] loss: 0.091\n",
      "[7,   200] loss: 0.112\n",
      "[7,   300] loss: 0.116\n",
      "[8,   100] loss: 0.100\n",
      "[8,   200] loss: 0.100\n",
      "[8,   300] loss: 0.092\n",
      "[9,   100] loss: 0.088\n",
      "[9,   200] loss: 0.093\n",
      "[9,   300] loss: 0.096\n",
      "[10,   100] loss: 0.080\n",
      "[10,   200] loss: 0.086\n",
      "[10,   300] loss: 0.097\n",
      "[11,   100] loss: 0.066\n",
      "[11,   200] loss: 0.099\n",
      "[11,   300] loss: 0.082\n",
      "[12,   100] loss: 0.075\n",
      "[12,   200] loss: 0.068\n",
      "[12,   300] loss: 0.082\n",
      "[13,   100] loss: 0.077\n",
      "[13,   200] loss: 0.070\n",
      "[13,   300] loss: 0.086\n",
      "[14,   100] loss: 0.064\n",
      "[14,   200] loss: 0.064\n",
      "[14,   300] loss: 0.072\n",
      "[15,   100] loss: 0.059\n",
      "[15,   200] loss: 0.066\n",
      "[15,   300] loss: 0.069\n",
      "[16,   100] loss: 0.056\n",
      "[16,   200] loss: 0.067\n",
      "[16,   300] loss: 0.061\n",
      "[17,   100] loss: 0.070\n",
      "[17,   200] loss: 0.053\n",
      "[17,   300] loss: 0.068\n",
      "[18,   100] loss: 0.050\n",
      "[18,   200] loss: 0.060\n",
      "[18,   300] loss: 0.072\n",
      "[19,   100] loss: 0.049\n",
      "[19,   200] loss: 0.055\n",
      "[19,   300] loss: 0.052\n",
      "[20,   100] loss: 0.047\n",
      "[20,   200] loss: 0.049\n",
      "[20,   300] loss: 0.054\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.334\n",
      "[1,   200] loss: 0.668\n",
      "[1,   300] loss: 0.492\n",
      "[2,   100] loss: 0.373\n",
      "[2,   200] loss: 0.317\n",
      "[2,   300] loss: 0.275\n",
      "[3,   100] loss: 0.227\n",
      "[3,   200] loss: 0.208\n",
      "[3,   300] loss: 0.204\n",
      "[4,   100] loss: 0.161\n",
      "[4,   200] loss: 0.173\n",
      "[4,   300] loss: 0.177\n",
      "[5,   100] loss: 0.137\n",
      "[5,   200] loss: 0.156\n",
      "[5,   300] loss: 0.132\n",
      "[6,   100] loss: 0.112\n",
      "[6,   200] loss: 0.125\n",
      "[6,   300] loss: 0.132\n",
      "[7,   100] loss: 0.100\n",
      "[7,   200] loss: 0.111\n",
      "[7,   300] loss: 0.117\n",
      "[8,   100] loss: 0.110\n",
      "[8,   200] loss: 0.095\n",
      "[8,   300] loss: 0.092\n",
      "[9,   100] loss: 0.086\n",
      "[9,   200] loss: 0.089\n",
      "[9,   300] loss: 0.089\n",
      "[10,   100] loss: 0.082\n",
      "[10,   200] loss: 0.089\n",
      "[10,   300] loss: 0.088\n",
      "[11,   100] loss: 0.075\n",
      "[11,   200] loss: 0.083\n",
      "[11,   300] loss: 0.076\n",
      "[12,   100] loss: 0.076\n",
      "[12,   200] loss: 0.074\n",
      "[12,   300] loss: 0.079\n",
      "[13,   100] loss: 0.064\n",
      "[13,   200] loss: 0.072\n",
      "[13,   300] loss: 0.080\n",
      "[14,   100] loss: 0.065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,   200] loss: 0.066\n",
      "[14,   300] loss: 0.069\n",
      "[15,   100] loss: 0.062\n",
      "[15,   200] loss: 0.070\n",
      "[15,   300] loss: 0.075\n",
      "[16,   100] loss: 0.063\n",
      "[16,   200] loss: 0.070\n",
      "[16,   300] loss: 0.060\n",
      "[17,   100] loss: 0.057\n",
      "[17,   200] loss: 0.058\n",
      "[17,   300] loss: 0.065\n",
      "[18,   100] loss: 0.060\n",
      "[18,   200] loss: 0.061\n",
      "[18,   300] loss: 0.064\n",
      "[19,   100] loss: 0.048\n",
      "[19,   200] loss: 0.060\n",
      "[19,   300] loss: 0.061\n",
      "[20,   100] loss: 0.053\n",
      "[20,   200] loss: 0.061\n",
      "[20,   300] loss: 0.066\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.790\n",
      "[1,   200] loss: 0.280\n",
      "[1,   300] loss: 0.257\n",
      "[2,   100] loss: 0.197\n",
      "[2,   200] loss: 0.206\n",
      "[2,   300] loss: 0.195\n",
      "[3,   100] loss: 0.174\n",
      "[3,   200] loss: 0.172\n",
      "[3,   300] loss: 0.175\n",
      "[4,   100] loss: 0.144\n",
      "[4,   200] loss: 0.160\n",
      "[4,   300] loss: 0.150\n",
      "[5,   100] loss: 0.127\n",
      "[5,   200] loss: 0.136\n",
      "[5,   300] loss: 0.135\n",
      "[6,   100] loss: 0.128\n",
      "[6,   200] loss: 0.121\n",
      "[6,   300] loss: 0.132\n",
      "[7,   100] loss: 0.116\n",
      "[7,   200] loss: 0.119\n",
      "[7,   300] loss: 0.104\n",
      "[8,   100] loss: 0.104\n",
      "[8,   200] loss: 0.115\n",
      "[8,   300] loss: 0.107\n",
      "[9,   100] loss: 0.097\n",
      "[9,   200] loss: 0.108\n",
      "[9,   300] loss: 0.097\n",
      "[10,   100] loss: 0.094\n",
      "[10,   200] loss: 0.101\n",
      "[10,   300] loss: 0.101\n",
      "[11,   100] loss: 0.089\n",
      "[11,   200] loss: 0.095\n",
      "[11,   300] loss: 0.090\n",
      "[12,   100] loss: 0.072\n",
      "[12,   200] loss: 0.078\n",
      "[12,   300] loss: 0.093\n",
      "[13,   100] loss: 0.071\n",
      "[13,   200] loss: 0.069\n",
      "[13,   300] loss: 0.082\n",
      "[14,   100] loss: 0.080\n",
      "[14,   200] loss: 0.086\n",
      "[14,   300] loss: 0.079\n",
      "[15,   100] loss: 0.063\n",
      "[15,   200] loss: 0.070\n",
      "[15,   300] loss: 0.077\n",
      "[16,   100] loss: 0.059\n",
      "[16,   200] loss: 0.065\n",
      "[16,   300] loss: 0.076\n",
      "[17,   100] loss: 0.062\n",
      "[17,   200] loss: 0.068\n",
      "[17,   300] loss: 0.071\n",
      "[18,   100] loss: 0.058\n",
      "[18,   200] loss: 0.061\n",
      "[18,   300] loss: 0.072\n",
      "[19,   100] loss: 0.061\n",
      "[19,   200] loss: 0.059\n",
      "[19,   300] loss: 0.063\n",
      "[20,   100] loss: 0.049\n",
      "[20,   200] loss: 0.057\n",
      "[20,   300] loss: 0.063\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.160\n",
      "[1,   200] loss: 0.440\n",
      "[1,   300] loss: 0.343\n",
      "[2,   100] loss: 0.253\n",
      "[2,   200] loss: 0.246\n",
      "[2,   300] loss: 0.214\n",
      "[3,   100] loss: 0.178\n",
      "[3,   200] loss: 0.170\n",
      "[3,   300] loss: 0.179\n",
      "[4,   100] loss: 0.142\n",
      "[4,   200] loss: 0.146\n",
      "[4,   300] loss: 0.146\n",
      "[5,   100] loss: 0.119\n",
      "[5,   200] loss: 0.129\n",
      "[5,   300] loss: 0.131\n",
      "[6,   100] loss: 0.112\n",
      "[6,   200] loss: 0.112\n",
      "[6,   300] loss: 0.121\n",
      "[7,   100] loss: 0.099\n",
      "[7,   200] loss: 0.110\n",
      "[7,   300] loss: 0.091\n",
      "[8,   100] loss: 0.085\n",
      "[8,   200] loss: 0.100\n",
      "[8,   300] loss: 0.090\n",
      "[9,   100] loss: 0.082\n",
      "[9,   200] loss: 0.084\n",
      "[9,   300] loss: 0.079\n",
      "[10,   100] loss: 0.075\n",
      "[10,   200] loss: 0.084\n",
      "[10,   300] loss: 0.082\n",
      "[11,   100] loss: 0.066\n",
      "[11,   200] loss: 0.074\n",
      "[11,   300] loss: 0.074\n",
      "[12,   100] loss: 0.070\n",
      "[12,   200] loss: 0.074\n",
      "[12,   300] loss: 0.084\n",
      "[13,   100] loss: 0.065\n",
      "[13,   200] loss: 0.064\n",
      "[13,   300] loss: 0.067\n",
      "[14,   100] loss: 0.064\n",
      "[14,   200] loss: 0.066\n",
      "[14,   300] loss: 0.070\n",
      "[15,   100] loss: 0.057\n",
      "[15,   200] loss: 0.069\n",
      "[15,   300] loss: 0.063\n",
      "[16,   100] loss: 0.055\n",
      "[16,   200] loss: 0.049\n",
      "[16,   300] loss: 0.068\n",
      "[17,   100] loss: 0.048\n",
      "[17,   200] loss: 0.063\n",
      "[17,   300] loss: 0.063\n",
      "[18,   100] loss: 0.060\n",
      "[18,   200] loss: 0.061\n",
      "[18,   300] loss: 0.061\n",
      "[19,   100] loss: 0.046\n",
      "[19,   200] loss: 0.060\n",
      "[19,   300] loss: 0.066\n",
      "[20,   100] loss: 0.053\n",
      "[20,   200] loss: 0.053\n",
      "[20,   300] loss: 0.063\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.817\n",
      "[1,   200] loss: 0.300\n",
      "[1,   300] loss: 0.256\n",
      "[2,   100] loss: 0.215\n",
      "[2,   200] loss: 0.212\n",
      "[2,   300] loss: 0.196\n",
      "[3,   100] loss: 0.163\n",
      "[3,   200] loss: 0.150\n",
      "[3,   300] loss: 0.172\n",
      "[4,   100] loss: 0.142\n",
      "[4,   200] loss: 0.131\n",
      "[4,   300] loss: 0.147\n",
      "[5,   100] loss: 0.124\n",
      "[5,   200] loss: 0.127\n",
      "[5,   300] loss: 0.128\n",
      "[6,   100] loss: 0.113\n",
      "[6,   200] loss: 0.116\n",
      "[6,   300] loss: 0.123\n",
      "[7,   100] loss: 0.104\n",
      "[7,   200] loss: 0.105\n",
      "[7,   300] loss: 0.115\n",
      "[8,   100] loss: 0.093\n",
      "[8,   200] loss: 0.097\n",
      "[8,   300] loss: 0.102\n",
      "[9,   100] loss: 0.086\n",
      "[9,   200] loss: 0.093\n",
      "[9,   300] loss: 0.087\n",
      "[10,   100] loss: 0.078\n",
      "[10,   200] loss: 0.076\n",
      "[10,   300] loss: 0.088\n",
      "[11,   100] loss: 0.078\n",
      "[11,   200] loss: 0.080\n",
      "[11,   300] loss: 0.093\n",
      "[12,   100] loss: 0.067\n",
      "[12,   200] loss: 0.078\n",
      "[12,   300] loss: 0.080\n",
      "[13,   100] loss: 0.070\n",
      "[13,   200] loss: 0.073\n",
      "[13,   300] loss: 0.083\n",
      "[14,   100] loss: 0.069\n",
      "[14,   200] loss: 0.069\n",
      "[14,   300] loss: 0.072\n",
      "[15,   100] loss: 0.058\n",
      "[15,   200] loss: 0.067\n",
      "[15,   300] loss: 0.072\n",
      "[16,   100] loss: 0.063\n",
      "[16,   200] loss: 0.064\n",
      "[16,   300] loss: 0.061\n",
      "[17,   100] loss: 0.049\n",
      "[17,   200] loss: 0.059\n",
      "[17,   300] loss: 0.064\n",
      "[18,   100] loss: 0.051\n",
      "[18,   200] loss: 0.058\n",
      "[18,   300] loss: 0.069\n",
      "[19,   100] loss: 0.051\n",
      "[19,   200] loss: 0.057\n",
      "[19,   300] loss: 0.054\n",
      "[20,   100] loss: 0.049\n",
      "[20,   200] loss: 0.046\n",
      "[20,   300] loss: 0.060\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.566\n",
      "[1,   200] loss: 0.758\n",
      "[1,   300] loss: 0.424\n",
      "[2,   100] loss: 0.329\n",
      "[2,   200] loss: 0.280\n",
      "[2,   300] loss: 0.256\n",
      "[3,   100] loss: 0.216\n",
      "[3,   200] loss: 0.207\n",
      "[3,   300] loss: 0.200\n",
      "[4,   100] loss: 0.176\n",
      "[4,   200] loss: 0.160\n",
      "[4,   300] loss: 0.167\n",
      "[5,   100] loss: 0.147\n",
      "[5,   200] loss: 0.144\n",
      "[5,   300] loss: 0.138\n",
      "[6,   100] loss: 0.122\n",
      "[6,   200] loss: 0.123\n",
      "[6,   300] loss: 0.130\n",
      "[7,   100] loss: 0.113\n",
      "[7,   200] loss: 0.107\n",
      "[7,   300] loss: 0.110\n",
      "[8,   100] loss: 0.100\n",
      "[8,   200] loss: 0.110\n",
      "[8,   300] loss: 0.109\n",
      "[9,   100] loss: 0.085\n",
      "[9,   200] loss: 0.092\n",
      "[9,   300] loss: 0.101\n",
      "[10,   100] loss: 0.080\n",
      "[10,   200] loss: 0.087\n",
      "[10,   300] loss: 0.091\n",
      "[11,   100] loss: 0.084\n",
      "[11,   200] loss: 0.088\n",
      "[11,   300] loss: 0.084\n",
      "[12,   100] loss: 0.072\n",
      "[12,   200] loss: 0.082\n",
      "[12,   300] loss: 0.085\n",
      "[13,   100] loss: 0.078\n",
      "[13,   200] loss: 0.070\n",
      "[13,   300] loss: 0.074\n",
      "[14,   100] loss: 0.073\n",
      "[14,   200] loss: 0.067\n",
      "[14,   300] loss: 0.069\n",
      "[15,   100] loss: 0.064\n",
      "[15,   200] loss: 0.067\n",
      "[15,   300] loss: 0.070\n",
      "[16,   100] loss: 0.067\n",
      "[16,   200] loss: 0.068\n",
      "[16,   300] loss: 0.063\n",
      "[17,   100] loss: 0.065\n",
      "[17,   200] loss: 0.055\n",
      "[17,   300] loss: 0.067\n",
      "[18,   100] loss: 0.059\n",
      "[18,   200] loss: 0.061\n",
      "[18,   300] loss: 0.063\n",
      "[19,   100] loss: 0.051\n",
      "[19,   200] loss: 0.060\n",
      "[19,   300] loss: 0.054\n",
      "[20,   100] loss: 0.055\n",
      "[20,   200] loss: 0.051\n",
      "[20,   300] loss: 0.071\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.747\n",
      "[1,   200] loss: 0.285\n",
      "[1,   300] loss: 0.250\n",
      "[2,   100] loss: 0.196\n",
      "[2,   200] loss: 0.192\n",
      "[2,   300] loss: 0.190\n",
      "[3,   100] loss: 0.164\n",
      "[3,   200] loss: 0.149\n",
      "[3,   300] loss: 0.167\n",
      "[4,   100] loss: 0.139\n",
      "[4,   200] loss: 0.152\n",
      "[4,   300] loss: 0.133\n",
      "[5,   100] loss: 0.120\n",
      "[5,   200] loss: 0.125\n",
      "[5,   300] loss: 0.126\n",
      "[6,   100] loss: 0.113\n",
      "[6,   200] loss: 0.115\n",
      "[6,   300] loss: 0.126\n",
      "[7,   100] loss: 0.103\n",
      "[7,   200] loss: 0.102\n",
      "[7,   300] loss: 0.112\n",
      "[8,   100] loss: 0.094\n",
      "[8,   200] loss: 0.088\n",
      "[8,   300] loss: 0.101\n",
      "[9,   100] loss: 0.082\n",
      "[9,   200] loss: 0.085\n",
      "[9,   300] loss: 0.094\n",
      "[10,   100] loss: 0.080\n",
      "[10,   200] loss: 0.081\n",
      "[10,   300] loss: 0.086\n",
      "[11,   100] loss: 0.075\n",
      "[11,   200] loss: 0.079\n",
      "[11,   300] loss: 0.078\n",
      "[12,   100] loss: 0.068\n",
      "[12,   200] loss: 0.079\n",
      "[12,   300] loss: 0.075\n",
      "[13,   100] loss: 0.068\n",
      "[13,   200] loss: 0.076\n",
      "[13,   300] loss: 0.072\n",
      "[14,   100] loss: 0.056\n",
      "[14,   200] loss: 0.068\n",
      "[14,   300] loss: 0.074\n",
      "[15,   100] loss: 0.063\n",
      "[15,   200] loss: 0.064\n",
      "[15,   300] loss: 0.068\n",
      "[16,   100] loss: 0.055\n",
      "[16,   200] loss: 0.062\n",
      "[16,   300] loss: 0.058\n",
      "[17,   100] loss: 0.058\n",
      "[17,   200] loss: 0.058\n",
      "[17,   300] loss: 0.064\n",
      "[18,   100] loss: 0.050\n",
      "[18,   200] loss: 0.057\n",
      "[18,   300] loss: 0.057\n",
      "[19,   100] loss: 0.061\n",
      "[19,   200] loss: 0.049\n",
      "[19,   300] loss: 0.052\n",
      "[20,   100] loss: 0.042\n",
      "[20,   200] loss: 0.052\n",
      "[20,   300] loss: 0.051\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.483\n",
      "[1,   200] loss: 0.812\n",
      "[1,   300] loss: 0.510\n",
      "[2,   100] loss: 0.367\n",
      "[2,   200] loss: 0.297\n",
      "[2,   300] loss: 0.266\n",
      "[3,   100] loss: 0.205\n",
      "[3,   200] loss: 0.196\n",
      "[3,   300] loss: 0.201\n",
      "[4,   100] loss: 0.175\n",
      "[4,   200] loss: 0.160\n",
      "[4,   300] loss: 0.146\n",
      "[5,   100] loss: 0.130\n",
      "[5,   200] loss: 0.125\n",
      "[5,   300] loss: 0.132\n",
      "[6,   100] loss: 0.116\n",
      "[6,   200] loss: 0.122\n",
      "[6,   300] loss: 0.118\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   100] loss: 0.103\n",
      "[7,   200] loss: 0.102\n",
      "[7,   300] loss: 0.115\n",
      "[8,   100] loss: 0.097\n",
      "[8,   200] loss: 0.090\n",
      "[8,   300] loss: 0.100\n",
      "[9,   100] loss: 0.085\n",
      "[9,   200] loss: 0.084\n",
      "[9,   300] loss: 0.096\n",
      "[10,   100] loss: 0.081\n",
      "[10,   200] loss: 0.082\n",
      "[10,   300] loss: 0.092\n",
      "[11,   100] loss: 0.080\n",
      "[11,   200] loss: 0.085\n",
      "[11,   300] loss: 0.087\n",
      "[12,   100] loss: 0.069\n",
      "[12,   200] loss: 0.078\n",
      "[12,   300] loss: 0.084\n",
      "[13,   100] loss: 0.072\n",
      "[13,   200] loss: 0.068\n",
      "[13,   300] loss: 0.074\n",
      "[14,   100] loss: 0.070\n",
      "[14,   200] loss: 0.070\n",
      "[14,   300] loss: 0.071\n",
      "[15,   100] loss: 0.067\n",
      "[15,   200] loss: 0.070\n",
      "[15,   300] loss: 0.061\n",
      "[16,   100] loss: 0.055\n",
      "[16,   200] loss: 0.065\n",
      "[16,   300] loss: 0.065\n",
      "[17,   100] loss: 0.055\n",
      "[17,   200] loss: 0.057\n",
      "[17,   300] loss: 0.062\n",
      "[18,   100] loss: 0.062\n",
      "[18,   200] loss: 0.058\n",
      "[18,   300] loss: 0.054\n",
      "[19,   100] loss: 0.060\n",
      "[19,   200] loss: 0.056\n",
      "[19,   300] loss: 0.061\n",
      "[20,   100] loss: 0.049\n",
      "[20,   200] loss: 0.059\n",
      "[20,   300] loss: 0.056\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.827\n",
      "[1,   200] loss: 0.299\n",
      "[1,   300] loss: 0.244\n",
      "[2,   100] loss: 0.202\n",
      "[2,   200] loss: 0.201\n",
      "[2,   300] loss: 0.196\n",
      "[3,   100] loss: 0.159\n",
      "[3,   200] loss: 0.165\n",
      "[3,   300] loss: 0.160\n",
      "[4,   100] loss: 0.141\n",
      "[4,   200] loss: 0.142\n",
      "[4,   300] loss: 0.152\n",
      "[5,   100] loss: 0.129\n",
      "[5,   200] loss: 0.140\n",
      "[5,   300] loss: 0.135\n",
      "[6,   100] loss: 0.133\n",
      "[6,   200] loss: 0.119\n",
      "[6,   300] loss: 0.109\n",
      "[7,   100] loss: 0.107\n",
      "[7,   200] loss: 0.103\n",
      "[7,   300] loss: 0.112\n",
      "[8,   100] loss: 0.092\n",
      "[8,   200] loss: 0.107\n",
      "[8,   300] loss: 0.112\n",
      "[9,   100] loss: 0.085\n",
      "[9,   200] loss: 0.102\n",
      "[9,   300] loss: 0.102\n",
      "[10,   100] loss: 0.087\n",
      "[10,   200] loss: 0.092\n",
      "[10,   300] loss: 0.099\n",
      "[11,   100] loss: 0.079\n",
      "[11,   200] loss: 0.086\n",
      "[11,   300] loss: 0.090\n",
      "[12,   100] loss: 0.086\n",
      "[12,   200] loss: 0.083\n",
      "[12,   300] loss: 0.081\n",
      "[13,   100] loss: 0.072\n",
      "[13,   200] loss: 0.074\n",
      "[13,   300] loss: 0.085\n",
      "[14,   100] loss: 0.071\n",
      "[14,   200] loss: 0.067\n",
      "[14,   300] loss: 0.077\n",
      "[15,   100] loss: 0.065\n",
      "[15,   200] loss: 0.073\n",
      "[15,   300] loss: 0.069\n",
      "[16,   100] loss: 0.061\n",
      "[16,   200] loss: 0.058\n",
      "[16,   300] loss: 0.072\n",
      "[17,   100] loss: 0.057\n",
      "[17,   200] loss: 0.067\n",
      "[17,   300] loss: 0.062\n",
      "[18,   100] loss: 0.056\n",
      "[18,   200] loss: 0.061\n",
      "[18,   300] loss: 0.067\n",
      "[19,   100] loss: 0.045\n",
      "[19,   200] loss: 0.059\n",
      "[19,   300] loss: 0.064\n",
      "[20,   100] loss: 0.060\n",
      "[20,   200] loss: 0.060\n",
      "[20,   300] loss: 0.067\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.487\n",
      "[1,   200] loss: 0.738\n",
      "[1,   300] loss: 0.584\n",
      "[2,   100] loss: 0.503\n",
      "[2,   200] loss: 0.473\n",
      "[2,   300] loss: 0.451\n",
      "[3,   100] loss: 0.415\n",
      "[3,   200] loss: 0.400\n",
      "[3,   300] loss: 0.406\n",
      "[4,   100] loss: 0.376\n",
      "[4,   200] loss: 0.368\n",
      "[4,   300] loss: 0.360\n",
      "[5,   100] loss: 0.357\n",
      "[5,   200] loss: 0.353\n",
      "[5,   300] loss: 0.351\n",
      "[6,   100] loss: 0.340\n",
      "[6,   200] loss: 0.337\n",
      "[6,   300] loss: 0.337\n",
      "[7,   100] loss: 0.324\n",
      "[7,   200] loss: 0.321\n",
      "[7,   300] loss: 0.333\n",
      "[8,   100] loss: 0.313\n",
      "[8,   200] loss: 0.313\n",
      "[8,   300] loss: 0.330\n",
      "[9,   100] loss: 0.307\n",
      "[9,   200] loss: 0.315\n",
      "[9,   300] loss: 0.311\n",
      "[10,   100] loss: 0.293\n",
      "[10,   200] loss: 0.306\n",
      "[10,   300] loss: 0.314\n",
      "[11,   100] loss: 0.293\n",
      "[11,   200] loss: 0.302\n",
      "[11,   300] loss: 0.308\n",
      "[12,   100] loss: 0.294\n",
      "[12,   200] loss: 0.304\n",
      "[12,   300] loss: 0.308\n",
      "[13,   100] loss: 0.292\n",
      "[13,   200] loss: 0.291\n",
      "[13,   300] loss: 0.295\n",
      "[14,   100] loss: 0.284\n",
      "[14,   200] loss: 0.289\n",
      "[14,   300] loss: 0.294\n",
      "[15,   100] loss: 0.285\n",
      "[15,   200] loss: 0.298\n",
      "[15,   300] loss: 0.295\n",
      "[16,   100] loss: 0.276\n",
      "[16,   200] loss: 0.294\n",
      "[16,   300] loss: 0.289\n",
      "[17,   100] loss: 0.283\n",
      "[17,   200] loss: 0.285\n",
      "[17,   300] loss: 0.283\n",
      "[18,   100] loss: 0.273\n",
      "[18,   200] loss: 0.280\n",
      "[18,   300] loss: 0.284\n",
      "[19,   100] loss: 0.281\n",
      "[19,   200] loss: 0.277\n",
      "[19,   300] loss: 0.284\n",
      "[20,   100] loss: 0.273\n",
      "[20,   200] loss: 0.283\n",
      "[20,   300] loss: 0.283\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.881\n",
      "[1,   200] loss: 0.308\n",
      "[1,   300] loss: 0.242\n",
      "[2,   100] loss: 0.207\n",
      "[2,   200] loss: 0.196\n",
      "[2,   300] loss: 0.169\n",
      "[3,   100] loss: 0.145\n",
      "[3,   200] loss: 0.159\n",
      "[3,   300] loss: 0.168\n",
      "[4,   100] loss: 0.130\n",
      "[4,   200] loss: 0.137\n",
      "[4,   300] loss: 0.131\n",
      "[5,   100] loss: 0.125\n",
      "[5,   200] loss: 0.123\n",
      "[5,   300] loss: 0.115\n",
      "[6,   100] loss: 0.099\n",
      "[6,   200] loss: 0.114\n",
      "[6,   300] loss: 0.110\n",
      "[7,   100] loss: 0.098\n",
      "[7,   200] loss: 0.104\n",
      "[7,   300] loss: 0.104\n",
      "[8,   100] loss: 0.086\n",
      "[8,   200] loss: 0.101\n",
      "[8,   300] loss: 0.099\n",
      "[9,   100] loss: 0.097\n",
      "[9,   200] loss: 0.097\n",
      "[9,   300] loss: 0.085\n",
      "[10,   100] loss: 0.082\n",
      "[10,   200] loss: 0.083\n",
      "[10,   300] loss: 0.093\n",
      "[11,   100] loss: 0.072\n",
      "[11,   200] loss: 0.074\n",
      "[11,   300] loss: 0.082\n",
      "[12,   100] loss: 0.071\n",
      "[12,   200] loss: 0.073\n",
      "[12,   300] loss: 0.079\n",
      "[13,   100] loss: 0.069\n",
      "[13,   200] loss: 0.075\n",
      "[13,   300] loss: 0.067\n",
      "[14,   100] loss: 0.057\n",
      "[14,   200] loss: 0.059\n",
      "[14,   300] loss: 0.072\n",
      "[15,   100] loss: 0.061\n",
      "[15,   200] loss: 0.062\n",
      "[15,   300] loss: 0.066\n",
      "[16,   100] loss: 0.053\n",
      "[16,   200] loss: 0.061\n",
      "[16,   300] loss: 0.064\n",
      "[17,   100] loss: 0.056\n",
      "[17,   200] loss: 0.065\n",
      "[17,   300] loss: 0.057\n",
      "[18,   100] loss: 0.053\n",
      "[18,   200] loss: 0.058\n",
      "[18,   300] loss: 0.056\n",
      "[19,   100] loss: 0.045\n",
      "[19,   200] loss: 0.047\n",
      "[19,   300] loss: 0.058\n",
      "[20,   100] loss: 0.050\n",
      "[20,   200] loss: 0.048\n",
      "[20,   300] loss: 0.054\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.337\n",
      "[1,   200] loss: 0.698\n",
      "[1,   300] loss: 0.474\n",
      "[2,   100] loss: 0.384\n",
      "[2,   200] loss: 0.335\n",
      "[2,   300] loss: 0.290\n",
      "[3,   100] loss: 0.240\n",
      "[3,   200] loss: 0.225\n",
      "[3,   300] loss: 0.218\n",
      "[4,   100] loss: 0.172\n",
      "[4,   200] loss: 0.191\n",
      "[4,   300] loss: 0.166\n",
      "[5,   100] loss: 0.156\n",
      "[5,   200] loss: 0.161\n",
      "[5,   300] loss: 0.154\n",
      "[6,   100] loss: 0.125\n",
      "[6,   200] loss: 0.147\n",
      "[6,   300] loss: 0.131\n",
      "[7,   100] loss: 0.108\n",
      "[7,   200] loss: 0.124\n",
      "[7,   300] loss: 0.120\n",
      "[8,   100] loss: 0.099\n",
      "[8,   200] loss: 0.115\n",
      "[8,   300] loss: 0.115\n",
      "[9,   100] loss: 0.087\n",
      "[9,   200] loss: 0.101\n",
      "[9,   300] loss: 0.100\n",
      "[10,   100] loss: 0.090\n",
      "[10,   200] loss: 0.095\n",
      "[10,   300] loss: 0.100\n",
      "[11,   100] loss: 0.077\n",
      "[11,   200] loss: 0.086\n",
      "[11,   300] loss: 0.090\n",
      "[12,   100] loss: 0.073\n",
      "[12,   200] loss: 0.085\n",
      "[12,   300] loss: 0.087\n",
      "[13,   100] loss: 0.076\n",
      "[13,   200] loss: 0.079\n",
      "[13,   300] loss: 0.079\n",
      "[14,   100] loss: 0.071\n",
      "[14,   200] loss: 0.074\n",
      "[14,   300] loss: 0.074\n",
      "[15,   100] loss: 0.066\n",
      "[15,   200] loss: 0.074\n",
      "[15,   300] loss: 0.077\n",
      "[16,   100] loss: 0.065\n",
      "[16,   200] loss: 0.069\n",
      "[16,   300] loss: 0.063\n",
      "[17,   100] loss: 0.057\n",
      "[17,   200] loss: 0.063\n",
      "[17,   300] loss: 0.068\n",
      "[18,   100] loss: 0.060\n",
      "[18,   200] loss: 0.075\n",
      "[18,   300] loss: 0.072\n",
      "[19,   100] loss: 0.054\n",
      "[19,   200] loss: 0.063\n",
      "[19,   300] loss: 0.066\n",
      "[20,   100] loss: 0.051\n",
      "[20,   200] loss: 0.061\n",
      "[20,   300] loss: 0.060\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.763\n",
      "[1,   200] loss: 0.287\n",
      "[1,   300] loss: 0.253\n",
      "[2,   100] loss: 0.208\n",
      "[2,   200] loss: 0.180\n",
      "[2,   300] loss: 0.198\n",
      "[3,   100] loss: 0.170\n",
      "[3,   200] loss: 0.166\n",
      "[3,   300] loss: 0.165\n",
      "[4,   100] loss: 0.135\n",
      "[4,   200] loss: 0.148\n",
      "[4,   300] loss: 0.144\n",
      "[5,   100] loss: 0.124\n",
      "[5,   200] loss: 0.138\n",
      "[5,   300] loss: 0.127\n",
      "[6,   100] loss: 0.116\n",
      "[6,   200] loss: 0.118\n",
      "[6,   300] loss: 0.132\n",
      "[7,   100] loss: 0.107\n",
      "[7,   200] loss: 0.101\n",
      "[7,   300] loss: 0.111\n",
      "[8,   100] loss: 0.090\n",
      "[8,   200] loss: 0.109\n",
      "[8,   300] loss: 0.097\n",
      "[9,   100] loss: 0.082\n",
      "[9,   200] loss: 0.088\n",
      "[9,   300] loss: 0.108\n",
      "[10,   100] loss: 0.091\n",
      "[10,   200] loss: 0.099\n",
      "[10,   300] loss: 0.087\n",
      "[11,   100] loss: 0.074\n",
      "[11,   200] loss: 0.089\n",
      "[11,   300] loss: 0.094\n",
      "[12,   100] loss: 0.086\n",
      "[12,   200] loss: 0.073\n",
      "[12,   300] loss: 0.091\n",
      "[13,   100] loss: 0.061\n",
      "[13,   200] loss: 0.073\n",
      "[13,   300] loss: 0.073\n",
      "[14,   100] loss: 0.071\n",
      "[14,   200] loss: 0.074\n",
      "[14,   300] loss: 0.087\n",
      "[15,   100] loss: 0.063\n",
      "[15,   200] loss: 0.062\n",
      "[15,   300] loss: 0.074\n",
      "[16,   100] loss: 0.058\n",
      "[16,   200] loss: 0.067\n",
      "[16,   300] loss: 0.072\n",
      "[17,   100] loss: 0.054\n",
      "[17,   200] loss: 0.064\n",
      "[17,   300] loss: 0.065\n",
      "[18,   100] loss: 0.056\n",
      "[18,   200] loss: 0.061\n",
      "[18,   300] loss: 0.057\n",
      "[19,   100] loss: 0.049\n",
      "[19,   200] loss: 0.062\n",
      "[19,   300] loss: 0.056\n",
      "[20,   100] loss: 0.048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,   200] loss: 0.049\n",
      "[20,   300] loss: 0.064\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.403\n",
      "[1,   200] loss: 0.800\n",
      "[1,   300] loss: 0.584\n",
      "[2,   100] loss: 0.459\n",
      "[2,   200] loss: 0.370\n",
      "[2,   300] loss: 0.357\n",
      "[3,   100] loss: 0.279\n",
      "[3,   200] loss: 0.243\n",
      "[3,   300] loss: 0.218\n",
      "[4,   100] loss: 0.185\n",
      "[4,   200] loss: 0.190\n",
      "[4,   300] loss: 0.176\n",
      "[5,   100] loss: 0.155\n",
      "[5,   200] loss: 0.163\n",
      "[5,   300] loss: 0.161\n",
      "[6,   100] loss: 0.140\n",
      "[6,   200] loss: 0.135\n",
      "[6,   300] loss: 0.142\n",
      "[7,   100] loss: 0.130\n",
      "[7,   200] loss: 0.120\n",
      "[7,   300] loss: 0.134\n",
      "[8,   100] loss: 0.114\n",
      "[8,   200] loss: 0.117\n",
      "[8,   300] loss: 0.116\n",
      "[9,   100] loss: 0.100\n",
      "[9,   200] loss: 0.101\n",
      "[9,   300] loss: 0.107\n",
      "[10,   100] loss: 0.092\n",
      "[10,   200] loss: 0.106\n",
      "[10,   300] loss: 0.100\n",
      "[11,   100] loss: 0.091\n",
      "[11,   200] loss: 0.088\n",
      "[11,   300] loss: 0.095\n",
      "[12,   100] loss: 0.078\n",
      "[12,   200] loss: 0.078\n",
      "[12,   300] loss: 0.095\n",
      "[13,   100] loss: 0.078\n",
      "[13,   200] loss: 0.088\n",
      "[13,   300] loss: 0.086\n",
      "[14,   100] loss: 0.069\n",
      "[14,   200] loss: 0.083\n",
      "[14,   300] loss: 0.079\n",
      "[15,   100] loss: 0.076\n",
      "[15,   200] loss: 0.076\n",
      "[15,   300] loss: 0.074\n",
      "[16,   100] loss: 0.068\n",
      "[16,   200] loss: 0.070\n",
      "[16,   300] loss: 0.079\n",
      "[17,   100] loss: 0.062\n",
      "[17,   200] loss: 0.070\n",
      "[17,   300] loss: 0.061\n",
      "[18,   100] loss: 0.065\n",
      "[18,   200] loss: 0.072\n",
      "[18,   300] loss: 0.068\n",
      "[19,   100] loss: 0.073\n",
      "[19,   200] loss: 0.077\n",
      "[19,   300] loss: 0.067\n",
      "[20,   100] loss: 0.056\n",
      "[20,   200] loss: 0.058\n",
      "[20,   300] loss: 0.065\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.753\n",
      "[1,   200] loss: 0.295\n",
      "[1,   300] loss: 0.259\n",
      "[2,   100] loss: 0.215\n",
      "[2,   200] loss: 0.208\n",
      "[2,   300] loss: 0.209\n",
      "[3,   100] loss: 0.183\n",
      "[3,   200] loss: 0.174\n",
      "[3,   300] loss: 0.184\n",
      "[4,   100] loss: 0.155\n",
      "[4,   200] loss: 0.142\n",
      "[4,   300] loss: 0.165\n",
      "[5,   100] loss: 0.137\n",
      "[5,   200] loss: 0.145\n",
      "[5,   300] loss: 0.142\n",
      "[6,   100] loss: 0.122\n",
      "[6,   200] loss: 0.133\n",
      "[6,   300] loss: 0.130\n",
      "[7,   100] loss: 0.112\n",
      "[7,   200] loss: 0.128\n",
      "[7,   300] loss: 0.130\n",
      "[8,   100] loss: 0.108\n",
      "[8,   200] loss: 0.106\n",
      "[8,   300] loss: 0.118\n",
      "[9,   100] loss: 0.106\n",
      "[9,   200] loss: 0.098\n",
      "[9,   300] loss: 0.101\n",
      "[10,   100] loss: 0.098\n",
      "[10,   200] loss: 0.109\n",
      "[10,   300] loss: 0.103\n",
      "[11,   100] loss: 0.088\n",
      "[11,   200] loss: 0.106\n",
      "[11,   300] loss: 0.107\n",
      "[12,   100] loss: 0.088\n",
      "[12,   200] loss: 0.089\n",
      "[12,   300] loss: 0.083\n",
      "[13,   100] loss: 0.087\n",
      "[13,   200] loss: 0.096\n",
      "[13,   300] loss: 0.086\n",
      "[14,   100] loss: 0.080\n",
      "[14,   200] loss: 0.081\n",
      "[14,   300] loss: 0.096\n",
      "[15,   100] loss: 0.085\n",
      "[15,   200] loss: 0.083\n",
      "[15,   300] loss: 0.085\n",
      "[16,   100] loss: 0.072\n",
      "[16,   200] loss: 0.086\n",
      "[16,   300] loss: 0.078\n",
      "[17,   100] loss: 0.072\n",
      "[17,   200] loss: 0.078\n",
      "[17,   300] loss: 0.078\n",
      "[18,   100] loss: 0.074\n",
      "[18,   200] loss: 0.071\n",
      "[18,   300] loss: 0.077\n",
      "[19,   100] loss: 0.064\n",
      "[19,   200] loss: 0.075\n",
      "[19,   300] loss: 0.069\n",
      "[20,   100] loss: 0.064\n",
      "[20,   200] loss: 0.073\n",
      "[20,   300] loss: 0.069\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.648\n",
      "[1,   200] loss: 0.994\n",
      "[1,   300] loss: 0.655\n",
      "[2,   100] loss: 0.399\n",
      "[2,   200] loss: 0.338\n",
      "[2,   300] loss: 0.289\n",
      "[3,   100] loss: 0.245\n",
      "[3,   200] loss: 0.232\n",
      "[3,   300] loss: 0.225\n",
      "[4,   100] loss: 0.192\n",
      "[4,   200] loss: 0.176\n",
      "[4,   300] loss: 0.193\n",
      "[5,   100] loss: 0.167\n",
      "[5,   200] loss: 0.161\n",
      "[5,   300] loss: 0.164\n",
      "[6,   100] loss: 0.139\n",
      "[6,   200] loss: 0.143\n",
      "[6,   300] loss: 0.145\n",
      "[7,   100] loss: 0.121\n",
      "[7,   200] loss: 0.129\n",
      "[7,   300] loss: 0.140\n",
      "[8,   100] loss: 0.108\n",
      "[8,   200] loss: 0.128\n",
      "[8,   300] loss: 0.117\n",
      "[9,   100] loss: 0.108\n",
      "[9,   200] loss: 0.106\n",
      "[9,   300] loss: 0.111\n",
      "[10,   100] loss: 0.089\n",
      "[10,   200] loss: 0.109\n",
      "[10,   300] loss: 0.105\n",
      "[11,   100] loss: 0.090\n",
      "[11,   200] loss: 0.095\n",
      "[11,   300] loss: 0.096\n",
      "[12,   100] loss: 0.081\n",
      "[12,   200] loss: 0.088\n",
      "[12,   300] loss: 0.091\n",
      "[13,   100] loss: 0.074\n",
      "[13,   200] loss: 0.078\n",
      "[13,   300] loss: 0.089\n",
      "[14,   100] loss: 0.073\n",
      "[14,   200] loss: 0.076\n",
      "[14,   300] loss: 0.083\n",
      "[15,   100] loss: 0.083\n",
      "[15,   200] loss: 0.080\n",
      "[15,   300] loss: 0.079\n",
      "[16,   100] loss: 0.067\n",
      "[16,   200] loss: 0.082\n",
      "[16,   300] loss: 0.069\n",
      "[17,   100] loss: 0.070\n",
      "[17,   200] loss: 0.070\n",
      "[17,   300] loss: 0.074\n",
      "[18,   100] loss: 0.067\n",
      "[18,   200] loss: 0.060\n",
      "[18,   300] loss: 0.073\n",
      "[19,   100] loss: 0.062\n",
      "[19,   200] loss: 0.070\n",
      "[19,   300] loss: 0.066\n",
      "[20,   100] loss: 0.058\n",
      "[20,   200] loss: 0.071\n",
      "[20,   300] loss: 0.059\n",
      "Finished training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAYERSIZE = 50\n",
    "\n",
    "test_runs = 10\n",
    "\n",
    "int_lr = 0.3\n",
    "syn_lr = 0.003\n",
    "\n",
    "seed = random.randint(0, 1000000)\n",
    "\n",
    "#Train IP Model\n",
    "torch.manual_seed(seed)\n",
    "IPnet = DNet(LAYERSIZE, IP, eta=int_lr)\n",
    "IPnet = IPnet.to(device)\n",
    "\n",
    "optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "print(\"Training IP Net\")\n",
    "ip_losses = train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "#Train Standard Model\n",
    "torch.manual_seed(seed)\n",
    "net = DNet(LAYERSIZE, NN, eta=int_lr)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "print(\"Training Standard Net\")\n",
    "standard_losses = train_deep_model(net, optimizer2, seed)\n",
    "\n",
    "for i in range(test_runs-1):\n",
    "    seed = random.randint(0, 1000000)\n",
    "    \n",
    "    #Train IP Model\n",
    "    torch.manual_seed(seed)\n",
    "    IPnet = DNet(LAYERSIZE, IP, eta=int_lr)\n",
    "    IPnet = IPnet.to(device)\n",
    "\n",
    "    optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training IP Net\")\n",
    "    ip_losses += train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "    #Train Standard Model\n",
    "    torch.manual_seed(seed)\n",
    "    net = DNet(LAYERSIZE, NN, eta=int_lr)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "    print(\"Training Standard Net\")\n",
    "    standard_losses += train_deep_model(net, optimizer2, seed)\n",
    "    \n",
    "ip_losses = ip_losses/test_runs\n",
    "standard_losses = standard_losses/test_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAFNCAYAAADSGTgvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ne8V3AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f01ec676e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.ylim([-0.1, 3])\n",
    "plt.title(\"Learning curves for deep networks\")\n",
    "plt.plot(ip_losses[0], ip_losses[1], label=\"IP\")\n",
    "# plt.plot(bn_losses[0], bn_losses[1], label=\"BN\")\n",
    "plt.plot(standard_losses[0], standard_losses[1], label=\"Standard\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IP Net\n",
      "[1,   100] loss: 0.996\n",
      "[1,   200] loss: 0.407\n",
      "[1,   300] loss: 0.333\n",
      "[2,   100] loss: 0.270\n",
      "[2,   200] loss: 0.272\n",
      "[2,   300] loss: 0.248\n",
      "[3,   100] loss: 0.230\n",
      "[3,   200] loss: 0.212\n",
      "[3,   300] loss: 0.196\n",
      "[4,   100] loss: 0.189\n",
      "[4,   200] loss: 0.175\n",
      "[4,   300] loss: 0.184\n",
      "[5,   100] loss: 0.157\n",
      "[5,   200] loss: 0.157\n",
      "[5,   300] loss: 0.143\n",
      "[6,   100] loss: 0.132\n",
      "[6,   200] loss: 0.148\n",
      "[6,   300] loss: 0.142\n",
      "[7,   100] loss: 0.129\n",
      "[7,   200] loss: 0.135\n",
      "[7,   300] loss: 0.131\n",
      "[8,   100] loss: 0.128\n",
      "[8,   200] loss: 0.128\n",
      "[8,   300] loss: 0.119\n",
      "[9,   100] loss: 0.108\n",
      "[9,   200] loss: 0.104\n",
      "[9,   300] loss: 0.116\n",
      "[10,   100] loss: 0.090\n",
      "[10,   200] loss: 0.099\n",
      "[10,   300] loss: 0.111\n",
      "[11,   100] loss: 0.086\n",
      "[11,   200] loss: 0.104\n",
      "[11,   300] loss: 0.108\n",
      "[12,   100] loss: 0.082\n",
      "[12,   200] loss: 0.088\n",
      "[12,   300] loss: 0.095\n",
      "[13,   100] loss: 0.089\n",
      "[13,   200] loss: 0.080\n",
      "[13,   300] loss: 0.087\n",
      "[14,   100] loss: 0.078\n",
      "[14,   200] loss: 0.080\n",
      "[14,   300] loss: 0.083\n",
      "[15,   100] loss: 0.077\n",
      "[15,   200] loss: 0.083\n",
      "[15,   300] loss: 0.089\n",
      "[16,   100] loss: 0.074\n",
      "[16,   200] loss: 0.075\n",
      "[16,   300] loss: 0.078\n",
      "[17,   100] loss: 0.061\n",
      "[17,   200] loss: 0.082\n",
      "[17,   300] loss: 0.081\n",
      "[18,   100] loss: 0.067\n",
      "[18,   200] loss: 0.066\n",
      "[18,   300] loss: 0.073\n",
      "[19,   100] loss: 0.068\n",
      "[19,   200] loss: 0.066\n",
      "[19,   300] loss: 0.070\n",
      "[20,   100] loss: 0.057\n",
      "[20,   200] loss: 0.071\n",
      "[20,   300] loss: 0.073\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.322\n",
      "[1,   200] loss: 0.842\n",
      "[1,   300] loss: 0.753\n",
      "[2,   100] loss: 0.653\n",
      "[2,   200] loss: 0.510\n",
      "[2,   300] loss: 0.415\n",
      "[3,   100] loss: 0.391\n",
      "[3,   200] loss: 0.371\n",
      "[3,   300] loss: 0.400\n",
      "[4,   100] loss: 0.348\n",
      "[4,   200] loss: 0.325\n",
      "[4,   300] loss: 0.335\n",
      "[5,   100] loss: 0.364\n",
      "[5,   200] loss: 0.376\n",
      "[5,   300] loss: 0.358\n",
      "[6,   100] loss: 0.403\n",
      "[6,   200] loss: 0.349\n",
      "[6,   300] loss: 0.370\n",
      "[7,   100] loss: 0.347\n",
      "[7,   200] loss: 0.340\n",
      "[7,   300] loss: 0.301\n",
      "[8,   100] loss: 0.318\n",
      "[8,   200] loss: 0.315\n",
      "[8,   300] loss: 0.342\n",
      "[9,   100] loss: 0.325\n",
      "[9,   200] loss: 0.328\n",
      "[9,   300] loss: 0.344\n",
      "[10,   100] loss: 0.330\n",
      "[10,   200] loss: 0.351\n",
      "[10,   300] loss: 0.338\n",
      "[11,   100] loss: 0.312\n",
      "[11,   200] loss: 0.354\n",
      "[11,   300] loss: 0.329\n",
      "[12,   100] loss: 0.330\n",
      "[12,   200] loss: 0.352\n",
      "[12,   300] loss: 0.320\n",
      "[13,   100] loss: 0.351\n",
      "[13,   200] loss: 0.386\n",
      "[13,   300] loss: 0.356\n",
      "[14,   100] loss: 0.366\n",
      "[14,   200] loss: 0.334\n",
      "[14,   300] loss: 0.332\n",
      "[15,   100] loss: 0.389\n",
      "[15,   200] loss: 0.361\n",
      "[15,   300] loss: 0.345\n",
      "[16,   100] loss: 0.351\n",
      "[16,   200] loss: 0.358\n",
      "[16,   300] loss: 0.381\n",
      "[17,   100] loss: 0.416\n",
      "[17,   200] loss: 0.415\n",
      "[17,   300] loss: 0.420\n",
      "[18,   100] loss: 0.372\n",
      "[18,   200] loss: 0.396\n",
      "[18,   300] loss: 0.390\n",
      "[19,   100] loss: 0.418\n",
      "[19,   200] loss: 0.383\n",
      "[19,   300] loss: 0.398\n",
      "[20,   100] loss: 0.407\n",
      "[20,   200] loss: 0.421\n",
      "[20,   300] loss: 0.400\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.053\n",
      "[1,   200] loss: 0.524\n",
      "[1,   300] loss: 0.371\n",
      "[2,   100] loss: 0.315\n",
      "[2,   200] loss: 0.275\n",
      "[2,   300] loss: 0.250\n",
      "[3,   100] loss: 0.221\n",
      "[3,   200] loss: 0.226\n",
      "[3,   300] loss: 0.223\n",
      "[4,   100] loss: 0.194\n",
      "[4,   200] loss: 0.195\n",
      "[4,   300] loss: 0.185\n",
      "[5,   100] loss: 0.179\n",
      "[5,   200] loss: 0.172\n",
      "[5,   300] loss: 0.159\n",
      "[6,   100] loss: 0.153\n",
      "[6,   200] loss: 0.144\n",
      "[6,   300] loss: 0.157\n",
      "[7,   100] loss: 0.136\n",
      "[7,   200] loss: 0.140\n",
      "[7,   300] loss: 0.140\n",
      "[8,   100] loss: 0.119\n",
      "[8,   200] loss: 0.138\n",
      "[8,   300] loss: 0.128\n",
      "[9,   100] loss: 0.117\n",
      "[9,   200] loss: 0.138\n",
      "[9,   300] loss: 0.128\n",
      "[10,   100] loss: 0.116\n",
      "[10,   200] loss: 0.109\n",
      "[10,   300] loss: 0.109\n",
      "[11,   100] loss: 0.096\n",
      "[11,   200] loss: 0.112\n",
      "[11,   300] loss: 0.115\n",
      "[12,   100] loss: 0.103\n",
      "[12,   200] loss: 0.114\n",
      "[12,   300] loss: 0.111\n",
      "[13,   100] loss: 0.104\n",
      "[13,   200] loss: 0.100\n",
      "[13,   300] loss: 0.103\n",
      "[14,   100] loss: 0.100\n",
      "[14,   200] loss: 0.100\n",
      "[14,   300] loss: 0.104\n",
      "[15,   100] loss: 0.081\n",
      "[15,   200] loss: 0.095\n",
      "[15,   300] loss: 0.101\n",
      "[16,   100] loss: 0.085\n",
      "[16,   200] loss: 0.098\n",
      "[16,   300] loss: 0.103\n",
      "[17,   100] loss: 0.085\n",
      "[17,   200] loss: 0.092\n",
      "[17,   300] loss: 0.090\n",
      "[18,   100] loss: 0.082\n",
      "[18,   200] loss: 0.092\n",
      "[18,   300] loss: 0.085\n",
      "[19,   100] loss: 0.076\n",
      "[19,   200] loss: 0.084\n",
      "[19,   300] loss: 0.098\n",
      "[20,   100] loss: 0.082\n",
      "[20,   200] loss: 0.082\n",
      "[20,   300] loss: 0.095\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.642\n",
      "[1,   200] loss: 1.206\n",
      "[1,   300] loss: 1.120\n",
      "[2,   100] loss: 1.145\n",
      "[2,   200] loss: 1.068\n",
      "[2,   300] loss: 0.965\n",
      "[3,   100] loss: 0.823\n",
      "[3,   200] loss: 0.750\n",
      "[3,   300] loss: 0.723\n",
      "[4,   100] loss: 0.647\n",
      "[4,   200] loss: 0.610\n",
      "[4,   300] loss: 0.560\n",
      "[5,   100] loss: 0.532\n",
      "[5,   200] loss: 0.496\n",
      "[5,   300] loss: 0.494\n",
      "[6,   100] loss: 0.469\n",
      "[6,   200] loss: 0.457\n",
      "[6,   300] loss: 0.482\n",
      "[7,   100] loss: 0.524\n",
      "[7,   200] loss: 0.481\n",
      "[7,   300] loss: 0.472\n",
      "[8,   100] loss: 0.447\n",
      "[8,   200] loss: 0.495\n",
      "[8,   300] loss: 0.526\n",
      "[9,   100] loss: 0.433\n",
      "[9,   200] loss: 0.440\n",
      "[9,   300] loss: 0.463\n",
      "[10,   100] loss: 0.453\n",
      "[10,   200] loss: 0.434\n",
      "[10,   300] loss: 0.445\n",
      "[11,   100] loss: 0.398\n",
      "[11,   200] loss: 0.440\n",
      "[11,   300] loss: 0.420\n",
      "[12,   100] loss: 0.442\n",
      "[12,   200] loss: 0.400\n",
      "[12,   300] loss: 0.406\n",
      "[13,   100] loss: 0.410\n",
      "[13,   200] loss: 0.424\n",
      "[13,   300] loss: 0.457\n",
      "[14,   100] loss: 0.407\n",
      "[14,   200] loss: 0.406\n",
      "[14,   300] loss: 0.404\n",
      "[15,   100] loss: 0.400\n",
      "[15,   200] loss: 0.390\n",
      "[15,   300] loss: 0.407\n",
      "[16,   100] loss: 0.404\n",
      "[16,   200] loss: 0.399\n",
      "[16,   300] loss: 0.402\n",
      "[17,   100] loss: 0.403\n",
      "[17,   200] loss: 0.480\n",
      "[17,   300] loss: 0.470\n",
      "[18,   100] loss: 0.444\n",
      "[18,   200] loss: 0.438\n",
      "[18,   300] loss: 0.421\n",
      "[19,   100] loss: 0.446\n",
      "[19,   200] loss: 0.395\n",
      "[19,   300] loss: 0.491\n",
      "[20,   100] loss: 0.444\n",
      "[20,   200] loss: 0.485\n",
      "[20,   300] loss: 0.472\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.925\n",
      "[1,   200] loss: 0.397\n",
      "[1,   300] loss: 0.324\n",
      "[2,   100] loss: 0.281\n",
      "[2,   200] loss: 0.283\n",
      "[2,   300] loss: 0.247\n",
      "[3,   100] loss: 0.231\n",
      "[3,   200] loss: 0.224\n",
      "[3,   300] loss: 0.210\n",
      "[4,   100] loss: 0.173\n",
      "[4,   200] loss: 0.195\n",
      "[4,   300] loss: 0.181\n",
      "[5,   100] loss: 0.177\n",
      "[5,   200] loss: 0.175\n",
      "[5,   300] loss: 0.179\n",
      "[6,   100] loss: 0.146\n",
      "[6,   200] loss: 0.148\n",
      "[6,   300] loss: 0.148\n",
      "[7,   100] loss: 0.138\n",
      "[7,   200] loss: 0.136\n",
      "[7,   300] loss: 0.153\n",
      "[8,   100] loss: 0.125\n",
      "[8,   200] loss: 0.141\n",
      "[8,   300] loss: 0.150\n",
      "[9,   100] loss: 0.131\n",
      "[9,   200] loss: 0.129\n",
      "[9,   300] loss: 0.142\n",
      "[10,   100] loss: 0.122\n",
      "[10,   200] loss: 0.117\n",
      "[10,   300] loss: 0.122\n",
      "[11,   100] loss: 0.106\n",
      "[11,   200] loss: 0.121\n",
      "[11,   300] loss: 0.112\n",
      "[12,   100] loss: 0.097\n",
      "[12,   200] loss: 0.110\n",
      "[12,   300] loss: 0.128\n",
      "[13,   100] loss: 0.106\n",
      "[13,   200] loss: 0.112\n",
      "[13,   300] loss: 0.123\n",
      "[14,   100] loss: 0.107\n",
      "[14,   200] loss: 0.111\n",
      "[14,   300] loss: 0.104\n",
      "[15,   100] loss: 0.101\n",
      "[15,   200] loss: 0.110\n",
      "[15,   300] loss: 0.091\n",
      "[16,   100] loss: 0.096\n",
      "[16,   200] loss: 0.099\n",
      "[16,   300] loss: 0.098\n",
      "[17,   100] loss: 0.090\n",
      "[17,   200] loss: 0.097\n",
      "[17,   300] loss: 0.094\n",
      "[18,   100] loss: 0.089\n",
      "[18,   200] loss: 0.098\n",
      "[18,   300] loss: 0.097\n",
      "[19,   100] loss: 0.084\n",
      "[19,   200] loss: 0.098\n",
      "[19,   300] loss: 0.098\n",
      "[20,   100] loss: 0.073\n",
      "[20,   200] loss: 0.094\n",
      "[20,   300] loss: 0.094\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.353\n",
      "[1,   200] loss: 0.845\n",
      "[1,   300] loss: 0.962\n",
      "[2,   100] loss: 0.771\n",
      "[2,   200] loss: 0.715\n",
      "[2,   300] loss: 0.633\n",
      "[3,   100] loss: 0.629\n",
      "[3,   200] loss: 0.603\n",
      "[3,   300] loss: 0.554\n",
      "[4,   100] loss: 0.512\n",
      "[4,   200] loss: 0.526\n",
      "[4,   300] loss: 0.501\n",
      "[5,   100] loss: 0.470\n",
      "[5,   200] loss: 0.396\n",
      "[5,   300] loss: 0.442\n",
      "[6,   100] loss: 0.424\n",
      "[6,   200] loss: 0.449\n",
      "[6,   300] loss: 0.448\n",
      "[7,   100] loss: 0.401\n",
      "[7,   200] loss: 0.390\n",
      "[7,   300] loss: 0.386\n",
      "[8,   100] loss: 0.380\n",
      "[8,   200] loss: 0.418\n",
      "[8,   300] loss: 0.398\n",
      "[9,   100] loss: 0.382\n",
      "[9,   200] loss: 0.394\n",
      "[9,   300] loss: 0.412\n",
      "[10,   100] loss: 0.372\n",
      "[10,   200] loss: 0.378\n",
      "[10,   300] loss: 0.410\n",
      "[11,   100] loss: 0.382\n",
      "[11,   200] loss: 0.360\n",
      "[11,   300] loss: 0.386\n",
      "[12,   100] loss: 0.367\n",
      "[12,   200] loss: 0.348\n",
      "[12,   300] loss: 0.378\n",
      "[13,   100] loss: 0.400\n",
      "[13,   200] loss: 0.417\n",
      "[13,   300] loss: 0.364\n",
      "[14,   100] loss: 0.403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,   200] loss: 0.356\n",
      "[14,   300] loss: 0.354\n",
      "[15,   100] loss: 0.362\n",
      "[15,   200] loss: 0.382\n",
      "[15,   300] loss: 0.387\n",
      "[16,   100] loss: 0.415\n",
      "[16,   200] loss: 0.463\n",
      "[16,   300] loss: 0.444\n",
      "[17,   100] loss: 0.409\n",
      "[17,   200] loss: 0.394\n",
      "[17,   300] loss: 0.413\n",
      "[18,   100] loss: 0.446\n",
      "[18,   200] loss: 0.386\n",
      "[18,   300] loss: 0.398\n",
      "[19,   100] loss: 0.442\n",
      "[19,   200] loss: 0.437\n",
      "[19,   300] loss: 0.431\n",
      "[20,   100] loss: 0.416\n",
      "[20,   200] loss: 0.414\n",
      "[20,   300] loss: 0.439\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.752\n",
      "[1,   200] loss: 0.348\n",
      "[1,   300] loss: 0.287\n",
      "[2,   100] loss: 0.237\n",
      "[2,   200] loss: 0.217\n",
      "[2,   300] loss: 0.215\n",
      "[3,   100] loss: 0.188\n",
      "[3,   200] loss: 0.179\n",
      "[3,   300] loss: 0.178\n",
      "[4,   100] loss: 0.190\n",
      "[4,   200] loss: 0.172\n",
      "[4,   300] loss: 0.188\n",
      "[5,   100] loss: 0.161\n",
      "[5,   200] loss: 0.148\n",
      "[5,   300] loss: 0.172\n",
      "[6,   100] loss: 0.154\n",
      "[6,   200] loss: 0.137\n",
      "[6,   300] loss: 0.134\n",
      "[7,   100] loss: 0.129\n",
      "[7,   200] loss: 0.126\n",
      "[7,   300] loss: 0.125\n",
      "[8,   100] loss: 0.115\n",
      "[8,   200] loss: 0.109\n",
      "[8,   300] loss: 0.127\n",
      "[9,   100] loss: 0.123\n",
      "[9,   200] loss: 0.114\n",
      "[9,   300] loss: 0.117\n",
      "[10,   100] loss: 0.115\n",
      "[10,   200] loss: 0.116\n",
      "[10,   300] loss: 0.117\n",
      "[11,   100] loss: 0.103\n",
      "[11,   200] loss: 0.111\n",
      "[11,   300] loss: 0.112\n",
      "[12,   100] loss: 0.093\n",
      "[12,   200] loss: 0.097\n",
      "[12,   300] loss: 0.097\n",
      "[13,   100] loss: 0.105\n",
      "[13,   200] loss: 0.098\n",
      "[13,   300] loss: 0.099\n",
      "[14,   100] loss: 0.090\n",
      "[14,   200] loss: 0.099\n",
      "[14,   300] loss: 0.096\n",
      "[15,   100] loss: 0.087\n",
      "[15,   200] loss: 0.108\n",
      "[15,   300] loss: 0.088\n",
      "[16,   100] loss: 0.083\n",
      "[16,   200] loss: 0.082\n",
      "[16,   300] loss: 0.085\n",
      "[17,   100] loss: 0.070\n",
      "[17,   200] loss: 0.077\n",
      "[17,   300] loss: 0.081\n",
      "[18,   100] loss: 0.073\n",
      "[18,   200] loss: 0.084\n",
      "[18,   300] loss: 0.090\n",
      "[19,   100] loss: 0.074\n",
      "[19,   200] loss: 0.081\n",
      "[19,   300] loss: 0.094\n",
      "[20,   100] loss: 0.081\n",
      "[20,   200] loss: 0.076\n",
      "[20,   300] loss: 0.078\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.086\n",
      "[1,   200] loss: 0.569\n",
      "[1,   300] loss: 0.469\n",
      "[2,   100] loss: 0.411\n",
      "[2,   200] loss: 0.396\n",
      "[2,   300] loss: 0.390\n",
      "[3,   100] loss: 0.343\n",
      "[3,   200] loss: 0.349\n",
      "[3,   300] loss: 0.353\n",
      "[4,   100] loss: 0.366\n",
      "[4,   200] loss: 0.352\n",
      "[4,   300] loss: 0.332\n",
      "[5,   100] loss: 0.321\n",
      "[5,   200] loss: 0.323\n",
      "[5,   300] loss: 0.317\n",
      "[6,   100] loss: 0.329\n",
      "[6,   200] loss: 0.326\n",
      "[6,   300] loss: 0.307\n",
      "[7,   100] loss: 0.315\n",
      "[7,   200] loss: 0.323\n",
      "[7,   300] loss: 0.307\n",
      "[8,   100] loss: 0.310\n",
      "[8,   200] loss: 0.315\n",
      "[8,   300] loss: 0.318\n",
      "[9,   100] loss: 0.403\n",
      "[9,   200] loss: 0.344\n",
      "[9,   300] loss: 0.357\n",
      "[10,   100] loss: 0.350\n",
      "[10,   200] loss: 0.377\n",
      "[10,   300] loss: 0.342\n",
      "[11,   100] loss: 0.323\n",
      "[11,   200] loss: 0.313\n",
      "[11,   300] loss: 0.357\n",
      "[12,   100] loss: 0.304\n",
      "[12,   200] loss: 0.308\n",
      "[12,   300] loss: 0.346\n",
      "[13,   100] loss: 0.380\n",
      "[13,   200] loss: 0.373\n",
      "[13,   300] loss: 0.385\n",
      "[14,   100] loss: 0.335\n",
      "[14,   200] loss: 0.346\n",
      "[14,   300] loss: 0.372\n",
      "[15,   100] loss: 0.391\n",
      "[15,   200] loss: 0.404\n",
      "[15,   300] loss: 0.433\n",
      "[16,   100] loss: 0.393\n",
      "[16,   200] loss: 0.436\n",
      "[16,   300] loss: 0.386\n",
      "[17,   100] loss: 0.404\n",
      "[17,   200] loss: 0.434\n",
      "[17,   300] loss: 0.423\n",
      "[18,   100] loss: 0.351\n",
      "[18,   200] loss: 0.366\n",
      "[18,   300] loss: 0.370\n",
      "[19,   100] loss: 0.407\n",
      "[19,   200] loss: 0.385\n",
      "[19,   300] loss: 0.354\n",
      "[20,   100] loss: 0.343\n",
      "[20,   200] loss: 0.362\n",
      "[20,   300] loss: 0.383\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.960\n",
      "[1,   200] loss: 0.436\n",
      "[1,   300] loss: 0.330\n",
      "[2,   100] loss: 0.284\n",
      "[2,   200] loss: 0.297\n",
      "[2,   300] loss: 0.266\n",
      "[3,   100] loss: 0.221\n",
      "[3,   200] loss: 0.223\n",
      "[3,   300] loss: 0.211\n",
      "[4,   100] loss: 0.184\n",
      "[4,   200] loss: 0.189\n",
      "[4,   300] loss: 0.200\n",
      "[5,   100] loss: 0.163\n",
      "[5,   200] loss: 0.165\n",
      "[5,   300] loss: 0.169\n",
      "[6,   100] loss: 0.146\n",
      "[6,   200] loss: 0.138\n",
      "[6,   300] loss: 0.147\n",
      "[7,   100] loss: 0.131\n",
      "[7,   200] loss: 0.133\n",
      "[7,   300] loss: 0.155\n",
      "[8,   100] loss: 0.132\n",
      "[8,   200] loss: 0.118\n",
      "[8,   300] loss: 0.126\n",
      "[9,   100] loss: 0.135\n",
      "[9,   200] loss: 0.136\n",
      "[9,   300] loss: 0.132\n",
      "[10,   100] loss: 0.119\n",
      "[10,   200] loss: 0.115\n",
      "[10,   300] loss: 0.120\n",
      "[11,   100] loss: 0.099\n",
      "[11,   200] loss: 0.107\n",
      "[11,   300] loss: 0.117\n",
      "[12,   100] loss: 0.094\n",
      "[12,   200] loss: 0.109\n",
      "[12,   300] loss: 0.112\n",
      "[13,   100] loss: 0.096\n",
      "[13,   200] loss: 0.113\n",
      "[13,   300] loss: 0.102\n",
      "[14,   100] loss: 0.098\n",
      "[14,   200] loss: 0.110\n",
      "[14,   300] loss: 0.106\n",
      "[15,   100] loss: 0.088\n",
      "[15,   200] loss: 0.087\n",
      "[15,   300] loss: 0.092\n",
      "[16,   100] loss: 0.093\n",
      "[16,   200] loss: 0.098\n",
      "[16,   300] loss: 0.097\n",
      "[17,   100] loss: 0.089\n",
      "[17,   200] loss: 0.083\n",
      "[17,   300] loss: 0.089\n",
      "[18,   100] loss: 0.079\n",
      "[18,   200] loss: 0.090\n",
      "[18,   300] loss: 0.097\n",
      "[19,   100] loss: 0.081\n",
      "[19,   200] loss: 0.089\n",
      "[19,   300] loss: 0.089\n",
      "[20,   100] loss: 0.078\n",
      "[20,   200] loss: 0.076\n",
      "[20,   300] loss: 0.082\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.079\n",
      "[1,   200] loss: 0.517\n",
      "[1,   300] loss: 0.445\n",
      "[2,   100] loss: 0.405\n",
      "[2,   200] loss: 0.407\n",
      "[2,   300] loss: 0.377\n",
      "[3,   100] loss: 0.349\n",
      "[3,   200] loss: 0.347\n",
      "[3,   300] loss: 0.339\n",
      "[4,   100] loss: 0.322\n",
      "[4,   200] loss: 0.293\n",
      "[4,   300] loss: 0.319\n",
      "[5,   100] loss: 0.326\n",
      "[5,   200] loss: 0.302\n",
      "[5,   300] loss: 0.295\n",
      "[6,   100] loss: 0.296\n",
      "[6,   200] loss: 0.297\n",
      "[6,   300] loss: 0.284\n",
      "[7,   100] loss: 0.288\n",
      "[7,   200] loss: 0.300\n",
      "[7,   300] loss: 0.325\n",
      "[8,   100] loss: 0.297\n",
      "[8,   200] loss: 0.276\n",
      "[8,   300] loss: 0.325\n",
      "[9,   100] loss: 0.285\n",
      "[9,   200] loss: 0.299\n",
      "[9,   300] loss: 0.310\n",
      "[10,   100] loss: 0.334\n",
      "[10,   200] loss: 0.337\n",
      "[10,   300] loss: 0.346\n",
      "[11,   100] loss: 0.331\n",
      "[11,   200] loss: 0.320\n",
      "[11,   300] loss: 0.342\n",
      "[12,   100] loss: 0.321\n",
      "[12,   200] loss: 0.342\n",
      "[12,   300] loss: 0.322\n",
      "[13,   100] loss: 0.375\n",
      "[13,   200] loss: 0.325\n",
      "[13,   300] loss: 0.316\n",
      "[14,   100] loss: 0.345\n",
      "[14,   200] loss: 0.342\n",
      "[14,   300] loss: 0.355\n",
      "[15,   100] loss: 0.353\n",
      "[15,   200] loss: 0.361\n",
      "[15,   300] loss: 0.396\n",
      "[16,   100] loss: 0.371\n",
      "[16,   200] loss: 0.379\n",
      "[16,   300] loss: 0.390\n",
      "[17,   100] loss: 0.371\n",
      "[17,   200] loss: 0.360\n",
      "[17,   300] loss: 0.367\n",
      "[18,   100] loss: 0.375\n",
      "[18,   200] loss: 0.410\n",
      "[18,   300] loss: 0.404\n",
      "[19,   100] loss: 0.397\n",
      "[19,   200] loss: 0.383\n",
      "[19,   300] loss: 0.388\n",
      "[20,   100] loss: 0.408\n",
      "[20,   200] loss: 0.383\n",
      "[20,   300] loss: 0.397\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.835\n",
      "[1,   200] loss: 0.409\n",
      "[1,   300] loss: 0.324\n",
      "[2,   100] loss: 0.260\n",
      "[2,   200] loss: 0.251\n",
      "[2,   300] loss: 0.233\n",
      "[3,   100] loss: 0.200\n",
      "[3,   200] loss: 0.194\n",
      "[3,   300] loss: 0.191\n",
      "[4,   100] loss: 0.163\n",
      "[4,   200] loss: 0.190\n",
      "[4,   300] loss: 0.185\n",
      "[5,   100] loss: 0.155\n",
      "[5,   200] loss: 0.163\n",
      "[5,   300] loss: 0.160\n",
      "[6,   100] loss: 0.152\n",
      "[6,   200] loss: 0.159\n",
      "[6,   300] loss: 0.150\n",
      "[7,   100] loss: 0.135\n",
      "[7,   200] loss: 0.134\n",
      "[7,   300] loss: 0.117\n",
      "[8,   100] loss: 0.118\n",
      "[8,   200] loss: 0.126\n",
      "[8,   300] loss: 0.131\n",
      "[9,   100] loss: 0.127\n",
      "[9,   200] loss: 0.123\n",
      "[9,   300] loss: 0.123\n",
      "[10,   100] loss: 0.099\n",
      "[10,   200] loss: 0.105\n",
      "[10,   300] loss: 0.109\n",
      "[11,   100] loss: 0.102\n",
      "[11,   200] loss: 0.097\n",
      "[11,   300] loss: 0.106\n",
      "[12,   100] loss: 0.093\n",
      "[12,   200] loss: 0.092\n",
      "[12,   300] loss: 0.109\n",
      "[13,   100] loss: 0.092\n",
      "[13,   200] loss: 0.101\n",
      "[13,   300] loss: 0.110\n",
      "[14,   100] loss: 0.093\n",
      "[14,   200] loss: 0.098\n",
      "[14,   300] loss: 0.101\n",
      "[15,   100] loss: 0.087\n",
      "[15,   200] loss: 0.099\n",
      "[15,   300] loss: 0.097\n",
      "[16,   100] loss: 0.088\n",
      "[16,   200] loss: 0.092\n",
      "[16,   300] loss: 0.086\n",
      "[17,   100] loss: 0.077\n",
      "[17,   200] loss: 0.086\n",
      "[17,   300] loss: 0.081\n",
      "[18,   100] loss: 0.084\n",
      "[18,   200] loss: 0.087\n",
      "[18,   300] loss: 0.087\n",
      "[19,   100] loss: 0.074\n",
      "[19,   200] loss: 0.072\n",
      "[19,   300] loss: 0.084\n",
      "[20,   100] loss: 0.072\n",
      "[20,   200] loss: 0.083\n",
      "[20,   300] loss: 0.078\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.147\n",
      "[1,   200] loss: 0.860\n",
      "[1,   300] loss: 0.730\n",
      "[2,   100] loss: 0.670\n",
      "[2,   200] loss: 0.528\n",
      "[2,   300] loss: 0.481\n",
      "[3,   100] loss: 0.444\n",
      "[3,   200] loss: 0.411\n",
      "[3,   300] loss: 0.423\n",
      "[4,   100] loss: 0.391\n",
      "[4,   200] loss: 0.389\n",
      "[4,   300] loss: 0.358\n",
      "[5,   100] loss: 0.366\n",
      "[5,   200] loss: 0.386\n",
      "[5,   300] loss: 0.356\n",
      "[6,   100] loss: 0.342\n",
      "[6,   200] loss: 0.363\n",
      "[6,   300] loss: 0.357\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   100] loss: 0.381\n",
      "[7,   200] loss: 0.349\n",
      "[7,   300] loss: 0.323\n",
      "[8,   100] loss: 0.360\n",
      "[8,   200] loss: 0.341\n",
      "[8,   300] loss: 0.333\n",
      "[9,   100] loss: 0.344\n",
      "[9,   200] loss: 0.349\n",
      "[9,   300] loss: 0.351\n",
      "[10,   100] loss: 0.379\n",
      "[10,   200] loss: 0.369\n",
      "[10,   300] loss: 0.345\n",
      "[11,   100] loss: 0.371\n",
      "[11,   200] loss: 0.386\n",
      "[11,   300] loss: 0.391\n",
      "[12,   100] loss: 0.416\n",
      "[12,   200] loss: 0.389\n",
      "[12,   300] loss: 0.369\n",
      "[13,   100] loss: 0.402\n",
      "[13,   200] loss: 0.418\n",
      "[13,   300] loss: 0.377\n",
      "[14,   100] loss: 0.413\n",
      "[14,   200] loss: 0.384\n",
      "[14,   300] loss: 0.373\n",
      "[15,   100] loss: 0.388\n",
      "[15,   200] loss: 0.404\n",
      "[15,   300] loss: 0.352\n",
      "[16,   100] loss: 0.399\n",
      "[16,   200] loss: 0.425\n",
      "[16,   300] loss: 0.398\n",
      "[17,   100] loss: 0.387\n",
      "[17,   200] loss: 0.402\n",
      "[17,   300] loss: 0.403\n",
      "[18,   100] loss: 0.400\n",
      "[18,   200] loss: 0.417\n",
      "[18,   300] loss: 0.388\n",
      "[19,   100] loss: 0.372\n",
      "[19,   200] loss: 0.396\n",
      "[19,   300] loss: 0.380\n",
      "[20,   100] loss: 0.399\n",
      "[20,   200] loss: 0.393\n",
      "[20,   300] loss: 0.423\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.109\n",
      "[1,   200] loss: 0.500\n",
      "[1,   300] loss: 0.409\n",
      "[2,   100] loss: 0.298\n",
      "[2,   200] loss: 0.275\n",
      "[2,   300] loss: 0.256\n",
      "[3,   100] loss: 0.228\n",
      "[3,   200] loss: 0.211\n",
      "[3,   300] loss: 0.191\n",
      "[4,   100] loss: 0.182\n",
      "[4,   200] loss: 0.199\n",
      "[4,   300] loss: 0.192\n",
      "[5,   100] loss: 0.172\n",
      "[5,   200] loss: 0.160\n",
      "[5,   300] loss: 0.161\n",
      "[6,   100] loss: 0.152\n",
      "[6,   200] loss: 0.166\n",
      "[6,   300] loss: 0.148\n",
      "[7,   100] loss: 0.141\n",
      "[7,   200] loss: 0.129\n",
      "[7,   300] loss: 0.142\n",
      "[8,   100] loss: 0.142\n",
      "[8,   200] loss: 0.129\n",
      "[8,   300] loss: 0.128\n",
      "[9,   100] loss: 0.118\n",
      "[9,   200] loss: 0.119\n",
      "[9,   300] loss: 0.138\n",
      "[10,   100] loss: 0.111\n",
      "[10,   200] loss: 0.110\n",
      "[10,   300] loss: 0.121\n",
      "[11,   100] loss: 0.115\n",
      "[11,   200] loss: 0.107\n",
      "[11,   300] loss: 0.103\n",
      "[12,   100] loss: 0.099\n",
      "[12,   200] loss: 0.112\n",
      "[12,   300] loss: 0.107\n",
      "[13,   100] loss: 0.092\n",
      "[13,   200] loss: 0.092\n",
      "[13,   300] loss: 0.106\n",
      "[14,   100] loss: 0.096\n",
      "[14,   200] loss: 0.100\n",
      "[14,   300] loss: 0.108\n",
      "[15,   100] loss: 0.109\n",
      "[15,   200] loss: 0.093\n",
      "[15,   300] loss: 0.102\n",
      "[16,   100] loss: 0.076\n",
      "[16,   200] loss: 0.088\n",
      "[16,   300] loss: 0.092\n",
      "[17,   100] loss: 0.083\n",
      "[17,   200] loss: 0.101\n",
      "[17,   300] loss: 0.095\n",
      "[18,   100] loss: 0.078\n",
      "[18,   200] loss: 0.076\n",
      "[18,   300] loss: 0.074\n",
      "[19,   100] loss: 0.075\n",
      "[19,   200] loss: 0.072\n",
      "[19,   300] loss: 0.077\n",
      "[20,   100] loss: 0.071\n",
      "[20,   200] loss: 0.080\n",
      "[20,   300] loss: 0.078\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.489\n",
      "[1,   200] loss: 1.050\n",
      "[1,   300] loss: 0.877\n",
      "[2,   100] loss: 0.791\n",
      "[2,   200] loss: 0.843\n",
      "[2,   300] loss: 0.738\n",
      "[3,   100] loss: 0.724\n",
      "[3,   200] loss: 0.697\n",
      "[3,   300] loss: 0.707\n",
      "[4,   100] loss: 0.618\n",
      "[4,   200] loss: 0.653\n",
      "[4,   300] loss: 0.638\n",
      "[5,   100] loss: 0.550\n",
      "[5,   200] loss: 0.524\n",
      "[5,   300] loss: 0.529\n",
      "[6,   100] loss: 0.525\n",
      "[6,   200] loss: 0.499\n",
      "[6,   300] loss: 0.433\n",
      "[7,   100] loss: 0.435\n",
      "[7,   200] loss: 0.406\n",
      "[7,   300] loss: 0.424\n",
      "[8,   100] loss: 0.428\n",
      "[8,   200] loss: 0.385\n",
      "[8,   300] loss: 0.402\n",
      "[9,   100] loss: 0.445\n",
      "[9,   200] loss: 0.474\n",
      "[9,   300] loss: 0.491\n",
      "[10,   100] loss: 0.423\n",
      "[10,   200] loss: 0.408\n",
      "[10,   300] loss: 0.417\n",
      "[11,   100] loss: 0.400\n",
      "[11,   200] loss: 0.399\n",
      "[11,   300] loss: 0.380\n",
      "[12,   100] loss: 0.415\n",
      "[12,   200] loss: 0.415\n",
      "[12,   300] loss: 0.387\n",
      "[13,   100] loss: 0.403\n",
      "[13,   200] loss: 0.378\n",
      "[13,   300] loss: 0.365\n",
      "[14,   100] loss: 0.440\n",
      "[14,   200] loss: 0.403\n",
      "[14,   300] loss: 0.419\n",
      "[15,   100] loss: 0.402\n",
      "[15,   200] loss: 0.401\n",
      "[15,   300] loss: 0.402\n",
      "[16,   100] loss: 0.387\n",
      "[16,   200] loss: 0.396\n",
      "[16,   300] loss: 0.395\n",
      "[17,   100] loss: 0.411\n",
      "[17,   200] loss: 0.413\n",
      "[17,   300] loss: 0.414\n",
      "[18,   100] loss: 0.488\n",
      "[18,   200] loss: 0.543\n",
      "[18,   300] loss: 0.539\n",
      "[19,   100] loss: 0.503\n",
      "[19,   200] loss: 0.462\n",
      "[19,   300] loss: 0.452\n",
      "[20,   100] loss: 0.466\n",
      "[20,   200] loss: 0.417\n",
      "[20,   300] loss: 0.447\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.775\n",
      "[1,   200] loss: 0.355\n",
      "[1,   300] loss: 0.342\n",
      "[2,   100] loss: 0.259\n",
      "[2,   200] loss: 0.244\n",
      "[2,   300] loss: 0.230\n",
      "[3,   100] loss: 0.199\n",
      "[3,   200] loss: 0.206\n",
      "[3,   300] loss: 0.201\n",
      "[4,   100] loss: 0.188\n",
      "[4,   200] loss: 0.170\n",
      "[4,   300] loss: 0.183\n",
      "[5,   100] loss: 0.172\n",
      "[5,   200] loss: 0.162\n",
      "[5,   300] loss: 0.157\n",
      "[6,   100] loss: 0.149\n",
      "[6,   200] loss: 0.142\n",
      "[6,   300] loss: 0.154\n",
      "[7,   100] loss: 0.130\n",
      "[7,   200] loss: 0.129\n",
      "[7,   300] loss: 0.137\n",
      "[8,   100] loss: 0.120\n",
      "[8,   200] loss: 0.129\n",
      "[8,   300] loss: 0.137\n",
      "[9,   100] loss: 0.122\n",
      "[9,   200] loss: 0.115\n",
      "[9,   300] loss: 0.123\n",
      "[10,   100] loss: 0.109\n",
      "[10,   200] loss: 0.113\n",
      "[10,   300] loss: 0.122\n",
      "[11,   100] loss: 0.104\n",
      "[11,   200] loss: 0.107\n",
      "[11,   300] loss: 0.112\n",
      "[12,   100] loss: 0.095\n",
      "[12,   200] loss: 0.106\n",
      "[12,   300] loss: 0.112\n",
      "[13,   100] loss: 0.106\n",
      "[13,   200] loss: 0.107\n",
      "[13,   300] loss: 0.099\n",
      "[14,   100] loss: 0.089\n",
      "[14,   200] loss: 0.094\n",
      "[14,   300] loss: 0.095\n",
      "[15,   100] loss: 0.082\n",
      "[15,   200] loss: 0.081\n",
      "[15,   300] loss: 0.100\n",
      "[16,   100] loss: 0.086\n",
      "[16,   200] loss: 0.086\n",
      "[16,   300] loss: 0.085\n",
      "[17,   100] loss: 0.087\n",
      "[17,   200] loss: 0.076\n",
      "[17,   300] loss: 0.082\n",
      "[18,   100] loss: 0.084\n",
      "[18,   200] loss: 0.082\n",
      "[18,   300] loss: 0.084\n",
      "[19,   100] loss: 0.072\n",
      "[19,   200] loss: 0.083\n",
      "[19,   300] loss: 0.085\n",
      "[20,   100] loss: 0.071\n",
      "[20,   200] loss: 0.080\n",
      "[20,   300] loss: 0.089\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.477\n",
      "[1,   200] loss: 0.885\n",
      "[1,   300] loss: 0.709\n",
      "[2,   100] loss: 0.567\n",
      "[2,   200] loss: 0.546\n",
      "[2,   300] loss: 0.482\n",
      "[3,   100] loss: 0.479\n",
      "[3,   200] loss: 0.428\n",
      "[3,   300] loss: 0.438\n",
      "[4,   100] loss: 0.386\n",
      "[4,   200] loss: 0.398\n",
      "[4,   300] loss: 0.382\n",
      "[5,   100] loss: 0.388\n",
      "[5,   200] loss: 0.359\n",
      "[5,   300] loss: 0.378\n",
      "[6,   100] loss: 0.356\n",
      "[6,   200] loss: 0.346\n",
      "[6,   300] loss: 0.336\n",
      "[7,   100] loss: 0.355\n",
      "[7,   200] loss: 0.351\n",
      "[7,   300] loss: 0.331\n",
      "[8,   100] loss: 0.333\n",
      "[8,   200] loss: 0.324\n",
      "[8,   300] loss: 0.314\n",
      "[9,   100] loss: 0.325\n",
      "[9,   200] loss: 0.377\n",
      "[9,   300] loss: 0.368\n",
      "[10,   100] loss: 0.359\n",
      "[10,   200] loss: 0.354\n",
      "[10,   300] loss: 0.353\n",
      "[11,   100] loss: 0.365\n",
      "[11,   200] loss: 0.349\n",
      "[11,   300] loss: 0.334\n",
      "[12,   100] loss: 0.317\n",
      "[12,   200] loss: 0.317\n",
      "[12,   300] loss: 0.351\n",
      "[13,   100] loss: 0.373\n",
      "[13,   200] loss: 0.436\n",
      "[13,   300] loss: 0.374\n",
      "[14,   100] loss: 0.401\n",
      "[14,   200] loss: 0.403\n",
      "[14,   300] loss: 0.330\n",
      "[15,   100] loss: 0.371\n",
      "[15,   200] loss: 0.400\n",
      "[15,   300] loss: 0.406\n",
      "[16,   100] loss: 0.391\n",
      "[16,   200] loss: 0.412\n",
      "[16,   300] loss: 0.392\n",
      "[17,   100] loss: 0.401\n",
      "[17,   200] loss: 0.432\n",
      "[17,   300] loss: 0.377\n",
      "[18,   100] loss: 0.391\n",
      "[18,   200] loss: 0.444\n",
      "[18,   300] loss: 0.388\n",
      "[19,   100] loss: 0.370\n",
      "[19,   200] loss: 0.392\n",
      "[19,   300] loss: 0.384\n",
      "[20,   100] loss: 0.372\n",
      "[20,   200] loss: 0.395\n",
      "[20,   300] loss: 0.435\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.233\n",
      "[1,   200] loss: 0.593\n",
      "[1,   300] loss: 0.493\n",
      "[2,   100] loss: 0.410\n",
      "[2,   200] loss: 0.372\n",
      "[2,   300] loss: 0.318\n",
      "[3,   100] loss: 0.316\n",
      "[3,   200] loss: 0.257\n",
      "[3,   300] loss: 0.280\n",
      "[4,   100] loss: 0.256\n",
      "[4,   200] loss: 0.239\n",
      "[4,   300] loss: 0.225\n",
      "[5,   100] loss: 0.228\n",
      "[5,   200] loss: 0.222\n",
      "[5,   300] loss: 0.208\n",
      "[6,   100] loss: 0.198\n",
      "[6,   200] loss: 0.189\n",
      "[6,   300] loss: 0.213\n",
      "[7,   100] loss: 0.179\n",
      "[7,   200] loss: 0.197\n",
      "[7,   300] loss: 0.193\n",
      "[8,   100] loss: 0.165\n",
      "[8,   200] loss: 0.180\n",
      "[8,   300] loss: 0.182\n",
      "[9,   100] loss: 0.145\n",
      "[9,   200] loss: 0.165\n",
      "[9,   300] loss: 0.167\n",
      "[10,   100] loss: 0.140\n",
      "[10,   200] loss: 0.160\n",
      "[10,   300] loss: 0.166\n",
      "[11,   100] loss: 0.124\n",
      "[11,   200] loss: 0.146\n",
      "[11,   300] loss: 0.142\n",
      "[12,   100] loss: 0.135\n",
      "[12,   200] loss: 0.136\n",
      "[12,   300] loss: 0.132\n",
      "[13,   100] loss: 0.140\n",
      "[13,   200] loss: 0.122\n",
      "[13,   300] loss: 0.127\n",
      "[14,   100] loss: 0.135\n",
      "[14,   200] loss: 0.132\n",
      "[14,   300] loss: 0.130\n",
      "[15,   100] loss: 0.113\n",
      "[15,   200] loss: 0.131\n",
      "[15,   300] loss: 0.117\n",
      "[16,   100] loss: 0.129\n",
      "[16,   200] loss: 0.124\n",
      "[16,   300] loss: 0.119\n",
      "[17,   100] loss: 0.109\n",
      "[17,   200] loss: 0.123\n",
      "[17,   300] loss: 0.129\n",
      "[18,   100] loss: 0.124\n",
      "[18,   200] loss: 0.104\n",
      "[18,   300] loss: 0.116\n",
      "[19,   100] loss: 0.104\n",
      "[19,   200] loss: 0.110\n",
      "[19,   300] loss: 0.109\n",
      "[20,   100] loss: 0.098\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,   200] loss: 0.095\n",
      "[20,   300] loss: 0.109\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.021\n",
      "[1,   200] loss: 0.518\n",
      "[1,   300] loss: 0.419\n",
      "[2,   100] loss: 0.420\n",
      "[2,   200] loss: 0.436\n",
      "[2,   300] loss: 0.397\n",
      "[3,   100] loss: 0.373\n",
      "[3,   200] loss: 0.338\n",
      "[3,   300] loss: 0.384\n",
      "[4,   100] loss: 0.376\n",
      "[4,   200] loss: 0.348\n",
      "[4,   300] loss: 0.333\n",
      "[5,   100] loss: 0.360\n",
      "[5,   200] loss: 0.372\n",
      "[5,   300] loss: 0.373\n",
      "[6,   100] loss: 0.344\n",
      "[6,   200] loss: 0.339\n",
      "[6,   300] loss: 0.367\n",
      "[7,   100] loss: 0.314\n",
      "[7,   200] loss: 0.324\n",
      "[7,   300] loss: 0.329\n",
      "[8,   100] loss: 0.294\n",
      "[8,   200] loss: 0.319\n",
      "[8,   300] loss: 0.303\n",
      "[9,   100] loss: 0.327\n",
      "[9,   200] loss: 0.329\n",
      "[9,   300] loss: 0.386\n",
      "[10,   100] loss: 0.367\n",
      "[10,   200] loss: 0.354\n",
      "[10,   300] loss: 0.342\n",
      "[11,   100] loss: 0.360\n",
      "[11,   200] loss: 0.326\n",
      "[11,   300] loss: 0.348\n",
      "[12,   100] loss: 0.345\n",
      "[12,   200] loss: 0.379\n",
      "[12,   300] loss: 0.355\n",
      "[13,   100] loss: 0.349\n",
      "[13,   200] loss: 0.373\n",
      "[13,   300] loss: 0.366\n",
      "[14,   100] loss: 0.344\n",
      "[14,   200] loss: 0.328\n",
      "[14,   300] loss: 0.381\n",
      "[15,   100] loss: 0.364\n",
      "[15,   200] loss: 0.370\n",
      "[15,   300] loss: 0.377\n",
      "[16,   100] loss: 0.405\n",
      "[16,   200] loss: 0.411\n",
      "[16,   300] loss: 0.416\n",
      "[17,   100] loss: 0.477\n",
      "[17,   200] loss: 0.463\n",
      "[17,   300] loss: 0.457\n",
      "[18,   100] loss: 0.439\n",
      "[18,   200] loss: 0.415\n",
      "[18,   300] loss: 0.402\n",
      "[19,   100] loss: 0.391\n",
      "[19,   200] loss: 0.376\n",
      "[19,   300] loss: 0.408\n",
      "[20,   100] loss: 0.371\n",
      "[20,   200] loss: 0.395\n",
      "[20,   300] loss: 0.374\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.008\n",
      "[1,   200] loss: 0.464\n",
      "[1,   300] loss: 0.384\n",
      "[2,   100] loss: 0.323\n",
      "[2,   200] loss: 0.323\n",
      "[2,   300] loss: 0.287\n",
      "[3,   100] loss: 0.256\n",
      "[3,   200] loss: 0.248\n",
      "[3,   300] loss: 0.232\n",
      "[4,   100] loss: 0.196\n",
      "[4,   200] loss: 0.201\n",
      "[4,   300] loss: 0.192\n",
      "[5,   100] loss: 0.173\n",
      "[5,   200] loss: 0.177\n",
      "[5,   300] loss: 0.173\n",
      "[6,   100] loss: 0.161\n",
      "[6,   200] loss: 0.158\n",
      "[6,   300] loss: 0.163\n",
      "[7,   100] loss: 0.139\n",
      "[7,   200] loss: 0.151\n",
      "[7,   300] loss: 0.150\n",
      "[8,   100] loss: 0.139\n",
      "[8,   200] loss: 0.136\n",
      "[8,   300] loss: 0.134\n",
      "[9,   100] loss: 0.115\n",
      "[9,   200] loss: 0.131\n",
      "[9,   300] loss: 0.141\n",
      "[10,   100] loss: 0.122\n",
      "[10,   200] loss: 0.126\n",
      "[10,   300] loss: 0.114\n",
      "[11,   100] loss: 0.102\n",
      "[11,   200] loss: 0.115\n",
      "[11,   300] loss: 0.112\n",
      "[12,   100] loss: 0.112\n",
      "[12,   200] loss: 0.106\n",
      "[12,   300] loss: 0.104\n",
      "[13,   100] loss: 0.108\n",
      "[13,   200] loss: 0.101\n",
      "[13,   300] loss: 0.114\n",
      "[14,   100] loss: 0.089\n",
      "[14,   200] loss: 0.092\n",
      "[14,   300] loss: 0.100\n",
      "[15,   100] loss: 0.088\n",
      "[15,   200] loss: 0.095\n",
      "[15,   300] loss: 0.097\n",
      "[16,   100] loss: 0.094\n",
      "[16,   200] loss: 0.087\n",
      "[16,   300] loss: 0.105\n",
      "[17,   100] loss: 0.077\n",
      "[17,   200] loss: 0.099\n",
      "[17,   300] loss: 0.095\n",
      "[18,   100] loss: 0.089\n",
      "[18,   200] loss: 0.082\n",
      "[18,   300] loss: 0.084\n",
      "[19,   100] loss: 0.074\n",
      "[19,   200] loss: 0.081\n",
      "[19,   300] loss: 0.089\n",
      "[20,   100] loss: 0.081\n",
      "[20,   200] loss: 0.082\n",
      "[20,   300] loss: 0.089\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.177\n",
      "[1,   200] loss: 0.600\n",
      "[1,   300] loss: 0.518\n",
      "[2,   100] loss: 0.420\n",
      "[2,   200] loss: 0.388\n",
      "[2,   300] loss: 0.384\n",
      "[3,   100] loss: 0.372\n",
      "[3,   200] loss: 0.363\n",
      "[3,   300] loss: 0.355\n",
      "[4,   100] loss: 0.355\n",
      "[4,   200] loss: 0.343\n",
      "[4,   300] loss: 0.319\n",
      "[5,   100] loss: 0.301\n",
      "[5,   200] loss: 0.310\n",
      "[5,   300] loss: 0.281\n",
      "[6,   100] loss: 0.292\n",
      "[6,   200] loss: 0.268\n",
      "[6,   300] loss: 0.278\n",
      "[7,   100] loss: 0.273\n",
      "[7,   200] loss: 0.279\n",
      "[7,   300] loss: 0.301\n",
      "[8,   100] loss: 0.324\n",
      "[8,   200] loss: 0.308\n",
      "[8,   300] loss: 0.298\n",
      "[9,   100] loss: 0.304\n",
      "[9,   200] loss: 0.314\n",
      "[9,   300] loss: 0.303\n",
      "[10,   100] loss: 0.295\n",
      "[10,   200] loss: 0.306\n",
      "[10,   300] loss: 0.302\n",
      "[11,   100] loss: 0.297\n",
      "[11,   200] loss: 0.289\n",
      "[11,   300] loss: 0.318\n",
      "[12,   100] loss: 0.365\n",
      "[12,   200] loss: 0.348\n",
      "[12,   300] loss: 0.340\n",
      "[13,   100] loss: 0.342\n",
      "[13,   200] loss: 0.343\n",
      "[13,   300] loss: 0.334\n",
      "[14,   100] loss: 0.335\n",
      "[14,   200] loss: 0.345\n",
      "[14,   300] loss: 0.337\n",
      "[15,   100] loss: 0.402\n",
      "[15,   200] loss: 0.406\n",
      "[15,   300] loss: 0.376\n",
      "[16,   100] loss: 0.391\n",
      "[16,   200] loss: 0.384\n",
      "[16,   300] loss: 0.383\n",
      "[17,   100] loss: 0.410\n",
      "[17,   200] loss: 0.401\n",
      "[17,   300] loss: 0.389\n",
      "[18,   100] loss: 0.388\n",
      "[18,   200] loss: 0.385\n",
      "[18,   300] loss: 0.413\n",
      "[19,   100] loss: 0.376\n",
      "[19,   200] loss: 0.413\n",
      "[19,   300] loss: 0.389\n",
      "[20,   100] loss: 0.415\n",
      "[20,   200] loss: 0.417\n",
      "[20,   300] loss: 0.441\n",
      "Finished training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAYERSIZE = 50\n",
    "\n",
    "test_runs = 10\n",
    "\n",
    "int_lr = 0.3\n",
    "syn_lr = 0.01\n",
    "\n",
    "seed = random.randint(0, 1000000)\n",
    "\n",
    "#Train IP Model\n",
    "torch.manual_seed(seed)\n",
    "IPnet = DNet(LAYERSIZE, IP, eta=int_lr)\n",
    "IPnet = IPnet.to(device)\n",
    "\n",
    "optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "print(\"Training IP Net\")\n",
    "ip_losses = train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "#Train Standard Model\n",
    "torch.manual_seed(seed)\n",
    "net = DNet(LAYERSIZE, NN, eta=int_lr)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "print(\"Training Standard Net\")\n",
    "standard_losses = train_deep_model(net, optimizer2, seed)\n",
    "\n",
    "for i in range(test_runs-1):\n",
    "    seed = random.randint(0, 1000000)\n",
    "    \n",
    "    #Train IP Model\n",
    "    torch.manual_seed(seed)\n",
    "    IPnet = DNet(LAYERSIZE, IP, eta=int_lr)\n",
    "    IPnet = IPnet.to(device)\n",
    "\n",
    "    optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training IP Net\")\n",
    "    ip_losses += train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "    #Train Standard Model\n",
    "    torch.manual_seed(seed)\n",
    "    net = DNet(LAYERSIZE, NN, eta=int_lr)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "    print(\"Training Standard Net\")\n",
    "    standard_losses += train_deep_model(net, optimizer2, seed)\n",
    "    \n",
    "ip_losses = ip_losses/test_runs\n",
    "standard_losses = standard_losses/test_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAFNCAYAAADSGTgvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f01f5dd71d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.ylim([-0.1, 3])\n",
    "plt.title(\"Learning curves for deep networks\")\n",
    "plt.plot(ip_losses[0], ip_losses[1], label=\"IP\")\n",
    "# plt.plot(bn_losses[0], bn_losses[1], label=\"BN\")\n",
    "plt.plot(standard_losses[0], standard_losses[1], label=\"Standard\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IP Net\n",
      "[1,   100] loss: 0.997\n",
      "[1,   200] loss: 0.484\n",
      "[1,   300] loss: 0.414\n",
      "[2,   100] loss: 0.366\n",
      "[2,   200] loss: 0.301\n",
      "[2,   300] loss: 0.296\n",
      "[3,   100] loss: 0.257\n",
      "[3,   200] loss: 0.252\n",
      "[3,   300] loss: 0.228\n",
      "[4,   100] loss: 0.218\n",
      "[4,   200] loss: 0.200\n",
      "[4,   300] loss: 0.199\n",
      "[5,   100] loss: 0.183\n",
      "[5,   200] loss: 0.197\n",
      "[5,   300] loss: 0.189\n",
      "[6,   100] loss: 0.162\n",
      "[6,   200] loss: 0.181\n",
      "[6,   300] loss: 0.191\n",
      "[7,   100] loss: 0.167\n",
      "[7,   200] loss: 0.145\n",
      "[7,   300] loss: 0.168\n",
      "[8,   100] loss: 0.149\n",
      "[8,   200] loss: 0.149\n",
      "[8,   300] loss: 0.159\n",
      "[9,   100] loss: 0.139\n",
      "[9,   200] loss: 0.143\n",
      "[9,   300] loss: 0.138\n",
      "[10,   100] loss: 0.140\n",
      "[10,   200] loss: 0.135\n",
      "[10,   300] loss: 0.149\n",
      "[11,   100] loss: 0.135\n",
      "[11,   200] loss: 0.126\n",
      "[11,   300] loss: 0.130\n",
      "[12,   100] loss: 0.119\n",
      "[12,   200] loss: 0.146\n",
      "[12,   300] loss: 0.140\n",
      "[13,   100] loss: 0.121\n",
      "[13,   200] loss: 0.116\n",
      "[13,   300] loss: 0.123\n",
      "[14,   100] loss: 0.117\n",
      "[14,   200] loss: 0.113\n",
      "[14,   300] loss: 0.114\n",
      "[15,   100] loss: 0.110\n",
      "[15,   200] loss: 0.116\n",
      "[15,   300] loss: 0.138\n",
      "[16,   100] loss: 0.115\n",
      "[16,   200] loss: 0.125\n",
      "[16,   300] loss: 0.117\n",
      "[17,   100] loss: 0.105\n",
      "[17,   200] loss: 0.113\n",
      "[17,   300] loss: 0.114\n",
      "[18,   100] loss: 0.113\n",
      "[18,   200] loss: 0.105\n",
      "[18,   300] loss: 0.122\n",
      "[19,   100] loss: 0.117\n",
      "[19,   200] loss: 0.117\n",
      "[19,   300] loss: 0.107\n",
      "[20,   100] loss: 0.104\n",
      "[20,   200] loss: 0.116\n",
      "[20,   300] loss: 0.113\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.287\n",
      "[1,   200] loss: 2.303\n",
      "[1,   300] loss: 2.303\n",
      "[2,   100] loss: 2.303\n",
      "[2,   200] loss: 2.303\n",
      "[2,   300] loss: 2.303\n",
      "[3,   100] loss: 2.303\n",
      "[3,   200] loss: 2.303\n",
      "[3,   300] loss: 2.303\n",
      "[4,   100] loss: 2.303\n",
      "[4,   200] loss: 2.303\n",
      "[4,   300] loss: 2.303\n",
      "[5,   100] loss: 2.303\n",
      "[5,   200] loss: 2.303\n",
      "[5,   300] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[6,   300] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[7,   300] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[8,   300] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[9,   300] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[10,   300] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[11,   300] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[12,   300] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[13,   300] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[14,   300] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[15,   300] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[16,   300] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[17,   300] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[18,   300] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[19,   300] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[20,   300] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.249\n",
      "[1,   200] loss: 2.303\n",
      "[1,   300] loss: 2.303\n",
      "[2,   100] loss: 2.303\n",
      "[2,   200] loss: 2.303\n",
      "[2,   300] loss: 2.303\n",
      "[3,   100] loss: 2.303\n",
      "[3,   200] loss: 2.303\n",
      "[3,   300] loss: 2.303\n",
      "[4,   100] loss: 2.303\n",
      "[4,   200] loss: 2.303\n",
      "[4,   300] loss: 2.303\n",
      "[5,   100] loss: 2.303\n",
      "[5,   200] loss: 2.303\n",
      "[5,   300] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[6,   300] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[7,   300] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[8,   300] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[9,   300] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[10,   300] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[11,   300] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[12,   300] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[13,   300] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[14,   300] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[15,   300] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[16,   300] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[17,   300] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[18,   300] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[19,   300] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[20,   300] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.365\n",
      "[1,   200] loss: 1.383\n",
      "[1,   300] loss: 1.331\n",
      "[2,   100] loss: 1.193\n",
      "[2,   200] loss: 0.949\n",
      "[2,   300] loss: 0.885\n",
      "[3,   100] loss: 0.789\n",
      "[3,   200] loss: 0.736\n",
      "[3,   300] loss: 0.773\n",
      "[4,   100] loss: 0.753\n",
      "[4,   200] loss: 0.756\n",
      "[4,   300] loss: 0.839\n",
      "[5,   100] loss: 0.757\n",
      "[5,   200] loss: 0.661\n",
      "[5,   300] loss: 0.657\n",
      "[6,   100] loss: 0.669\n",
      "[6,   200] loss: 0.758\n",
      "[6,   300] loss: 0.713\n",
      "[7,   100] loss: 0.737\n",
      "[7,   200] loss: 0.694\n",
      "[7,   300] loss: 0.646\n",
      "[8,   100] loss: 0.676\n",
      "[8,   200] loss: 0.655\n",
      "[8,   300] loss: 0.662\n",
      "[9,   100] loss: 0.729\n",
      "[9,   200] loss: 0.961\n",
      "[9,   300] loss: 0.895\n",
      "[10,   100] loss: 1.106\n",
      "[10,   200] loss: 1.217\n",
      "[10,   300] loss: 1.027\n",
      "[11,   100] loss: 1.130\n",
      "[11,   200] loss: 1.054\n",
      "[11,   300] loss: 1.019\n",
      "[12,   100] loss: 1.151\n",
      "[12,   200] loss: 1.011\n",
      "[12,   300] loss: 1.368\n",
      "[13,   100] loss: 1.232\n",
      "[13,   200] loss: 1.091\n",
      "[13,   300] loss: 1.177\n",
      "[14,   100] loss: 1.074\n",
      "[14,   200] loss: 1.177\n",
      "[14,   300] loss: 1.207\n",
      "[15,   100] loss: 1.272\n",
      "[15,   200] loss: 1.248\n",
      "[15,   300] loss: 1.394\n",
      "[16,   100] loss: 1.132\n",
      "[16,   200] loss: 1.118\n",
      "[16,   300] loss: 1.112\n",
      "[17,   100] loss: 1.036\n",
      "[17,   200] loss: 1.174\n",
      "[17,   300] loss: 1.143\n",
      "[18,   100] loss: 1.122\n",
      "[18,   200] loss: 1.282\n",
      "[18,   300] loss: 1.296\n",
      "[19,   100] loss: 1.335\n",
      "[19,   200] loss: 1.263\n",
      "[19,   300] loss: 1.398\n",
      "[20,   100] loss: 1.803\n",
      "[20,   200] loss: 2.038\n",
      "[20,   300] loss: 2.045\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.478\n",
      "[1,   200] loss: 0.836\n",
      "[1,   300] loss: 0.742\n",
      "[2,   100] loss: 0.583\n",
      "[2,   200] loss: 0.537\n",
      "[2,   300] loss: 0.502\n",
      "[3,   100] loss: 0.453\n",
      "[3,   200] loss: 0.360\n",
      "[3,   300] loss: 0.322\n",
      "[4,   100] loss: 0.293\n",
      "[4,   200] loss: 0.276\n",
      "[4,   300] loss: 0.261\n",
      "[5,   100] loss: 0.241\n",
      "[5,   200] loss: 0.235\n",
      "[5,   300] loss: 0.220\n",
      "[6,   100] loss: 0.219\n",
      "[6,   200] loss: 0.219\n",
      "[6,   300] loss: 0.202\n",
      "[7,   100] loss: 0.207\n",
      "[7,   200] loss: 0.190\n",
      "[7,   300] loss: 0.209\n",
      "[8,   100] loss: 0.179\n",
      "[8,   200] loss: 0.176\n",
      "[8,   300] loss: 0.183\n",
      "[9,   100] loss: 0.159\n",
      "[9,   200] loss: 0.179\n",
      "[9,   300] loss: 0.175\n",
      "[10,   100] loss: 0.160\n",
      "[10,   200] loss: 0.159\n",
      "[10,   300] loss: 0.170\n",
      "[11,   100] loss: 0.153\n",
      "[11,   200] loss: 0.167\n",
      "[11,   300] loss: 0.176\n",
      "[12,   100] loss: 0.180\n",
      "[12,   200] loss: 0.153\n",
      "[12,   300] loss: 0.165\n",
      "[13,   100] loss: 0.140\n",
      "[13,   200] loss: 0.148\n",
      "[13,   300] loss: 0.146\n",
      "[14,   100] loss: 0.146\n",
      "[14,   200] loss: 0.142\n",
      "[14,   300] loss: 0.137\n",
      "[15,   100] loss: 0.129\n",
      "[15,   200] loss: 0.157\n",
      "[15,   300] loss: 0.136\n",
      "[16,   100] loss: 0.128\n",
      "[16,   200] loss: 0.132\n",
      "[16,   300] loss: 0.145\n",
      "[17,   100] loss: 0.119\n",
      "[17,   200] loss: 0.139\n",
      "[17,   300] loss: 0.147\n",
      "[18,   100] loss: 0.124\n",
      "[18,   200] loss: 0.129\n",
      "[18,   300] loss: 0.133\n",
      "[19,   100] loss: 0.116\n",
      "[19,   200] loss: 0.143\n",
      "[19,   300] loss: 0.147\n",
      "[20,   100] loss: 0.153\n",
      "[20,   200] loss: 0.167\n",
      "[20,   300] loss: 0.170\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.132\n",
      "[1,   200] loss: 2.238\n",
      "[1,   300] loss: 2.234\n",
      "[2,   100] loss: 2.229\n",
      "[2,   200] loss: 2.222\n",
      "[2,   300] loss: 2.286\n",
      "[3,   100] loss: 2.303\n",
      "[3,   200] loss: 2.303\n",
      "[3,   300] loss: 2.303\n",
      "[4,   100] loss: 2.303\n",
      "[4,   200] loss: 2.303\n",
      "[4,   300] loss: 2.303\n",
      "[5,   100] loss: 2.303\n",
      "[5,   200] loss: 2.303\n",
      "[5,   300] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[6,   300] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[7,   300] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[8,   300] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[9,   300] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[10,   300] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[11,   300] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[12,   300] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[13,   300] loss: 2.303\n",
      "[14,   100] loss: 2.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,   200] loss: 2.303\n",
      "[14,   300] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[15,   300] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[16,   300] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[17,   300] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[18,   300] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[19,   300] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[20,   300] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.308\n",
      "[1,   200] loss: 2.303\n",
      "[1,   300] loss: 2.303\n",
      "[2,   100] loss: 2.303\n",
      "[2,   200] loss: 2.303\n",
      "[2,   300] loss: 2.303\n",
      "[3,   100] loss: 2.303\n",
      "[3,   200] loss: 2.303\n",
      "[3,   300] loss: 2.303\n",
      "[4,   100] loss: 2.303\n",
      "[4,   200] loss: 2.303\n",
      "[4,   300] loss: 2.303\n",
      "[5,   100] loss: 2.303\n",
      "[5,   200] loss: 2.303\n",
      "[5,   300] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[6,   300] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[7,   300] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[8,   300] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[9,   300] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[10,   300] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[11,   300] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[12,   300] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[13,   300] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[14,   300] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[15,   300] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[16,   300] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[17,   300] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[18,   300] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[19,   300] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[20,   300] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.196\n",
      "[1,   200] loss: 2.196\n",
      "[1,   300] loss: 2.249\n",
      "[2,   100] loss: 2.303\n",
      "[2,   200] loss: 2.303\n",
      "[2,   300] loss: 2.303\n",
      "[3,   100] loss: 2.303\n",
      "[3,   200] loss: 2.303\n",
      "[3,   300] loss: 2.303\n",
      "[4,   100] loss: 2.303\n",
      "[4,   200] loss: 2.303\n",
      "[4,   300] loss: 2.303\n",
      "[5,   100] loss: 2.303\n",
      "[5,   200] loss: 2.303\n",
      "[5,   300] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[6,   300] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[7,   300] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[8,   300] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[9,   300] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[10,   300] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[11,   300] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[12,   300] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[13,   300] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[14,   300] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[15,   300] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[16,   300] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[17,   300] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[18,   300] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[19,   300] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[20,   300] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.656\n",
      "[1,   200] loss: 1.316\n",
      "[1,   300] loss: 1.168\n",
      "[2,   100] loss: 1.017\n",
      "[2,   200] loss: 0.891\n",
      "[2,   300] loss: 0.834\n",
      "[3,   100] loss: 1.556\n",
      "[3,   200] loss: 1.273\n",
      "[3,   300] loss: 1.383\n",
      "[4,   100] loss: 1.448\n",
      "[4,   200] loss: 1.811\n",
      "[4,   300] loss: 2.181\n",
      "[5,   100] loss: 2.273\n",
      "[5,   200] loss: 2.303\n",
      "[5,   300] loss: 2.302\n",
      "[6,   100] loss: 2.302\n",
      "[6,   200] loss: 2.302\n",
      "[6,   300] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[7,   300] loss: 2.302\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.302\n",
      "[8,   300] loss: 2.302\n",
      "[9,   100] loss: 2.302\n",
      "[9,   200] loss: 2.303\n",
      "[9,   300] loss: 2.302\n",
      "[10,   100] loss: 2.302\n",
      "[10,   200] loss: 2.303\n",
      "[10,   300] loss: 2.302\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.302\n",
      "[11,   300] loss: 2.302\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.302\n",
      "[12,   300] loss: 2.302\n",
      "[13,   100] loss: 2.302\n",
      "[13,   200] loss: 2.303\n",
      "[13,   300] loss: 2.303\n",
      "[14,   100] loss: 2.302\n",
      "[14,   200] loss: 2.303\n",
      "[14,   300] loss: 2.303\n",
      "[15,   100] loss: 2.302\n",
      "[15,   200] loss: 2.303\n",
      "[15,   300] loss: 2.302\n",
      "[16,   100] loss: 2.302\n",
      "[16,   200] loss: 2.302\n",
      "[16,   300] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[17,   300] loss: 2.302\n",
      "[18,   100] loss: 2.302\n",
      "[18,   200] loss: 2.303\n",
      "[18,   300] loss: 2.302\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.302\n",
      "[19,   300] loss: 2.302\n",
      "[20,   100] loss: 2.302\n",
      "[20,   200] loss: 2.303\n",
      "[20,   300] loss: 2.302\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.376\n",
      "[1,   200] loss: 1.032\n",
      "[1,   300] loss: 1.009\n",
      "[2,   100] loss: 0.749\n",
      "[2,   200] loss: 0.711\n",
      "[2,   300] loss: 0.637\n",
      "[3,   100] loss: 0.585\n",
      "[3,   200] loss: 0.555\n",
      "[3,   300] loss: 0.527\n",
      "[4,   100] loss: 0.539\n",
      "[4,   200] loss: 0.536\n",
      "[4,   300] loss: 0.496\n",
      "[5,   100] loss: 0.518\n",
      "[5,   200] loss: 0.546\n",
      "[5,   300] loss: 0.529\n",
      "[6,   100] loss: 0.623\n",
      "[6,   200] loss: 0.661\n",
      "[6,   300] loss: 0.627\n",
      "[7,   100] loss: 0.655\n",
      "[7,   200] loss: 0.678\n",
      "[7,   300] loss: 0.676\n",
      "[8,   100] loss: 0.622\n",
      "[8,   200] loss: 0.679\n",
      "[8,   300] loss: 0.749\n",
      "[9,   100] loss: 0.671\n",
      "[9,   200] loss: 0.775\n",
      "[9,   300] loss: 0.730\n",
      "[10,   100] loss: 0.762\n",
      "[10,   200] loss: 0.828\n",
      "[10,   300] loss: 0.883\n",
      "[11,   100] loss: 0.923\n",
      "[11,   200] loss: 0.921\n",
      "[11,   300] loss: 0.894\n",
      "[12,   100] loss: 0.859\n",
      "[12,   200] loss: 0.866\n",
      "[12,   300] loss: 0.970\n",
      "[13,   100] loss: 1.022\n",
      "[13,   200] loss: 0.918\n",
      "[13,   300] loss: 1.150\n",
      "[14,   100] loss: 1.135\n",
      "[14,   200] loss: 0.981\n",
      "[14,   300] loss: 0.976\n",
      "[15,   100] loss: 0.994\n",
      "[15,   200] loss: 0.973\n",
      "[15,   300] loss: 0.995\n",
      "[16,   100] loss: 0.852\n",
      "[16,   200] loss: 0.935\n",
      "[16,   300] loss: 1.003\n",
      "[17,   100] loss: 1.071\n",
      "[17,   200] loss: 1.058\n",
      "[17,   300] loss: 1.024\n",
      "[18,   100] loss: 0.961\n",
      "[18,   200] loss: 0.934\n",
      "[18,   300] loss: 0.907\n",
      "[19,   100] loss: 0.970\n",
      "[19,   200] loss: 1.024\n",
      "[19,   300] loss: 1.151\n",
      "[20,   100] loss: 1.215\n",
      "[20,   200] loss: 1.374\n",
      "[20,   300] loss: 1.309\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.690\n",
      "[1,   200] loss: 1.016\n",
      "[1,   300] loss: 0.691\n",
      "[2,   100] loss: 0.546\n",
      "[2,   200] loss: 0.525\n",
      "[2,   300] loss: 0.529\n",
      "[3,   100] loss: 0.488\n",
      "[3,   200] loss: 0.459\n",
      "[3,   300] loss: 0.428\n",
      "[4,   100] loss: 0.377\n",
      "[4,   200] loss: 0.400\n",
      "[4,   300] loss: 0.379\n",
      "[5,   100] loss: 0.338\n",
      "[5,   200] loss: 0.313\n",
      "[5,   300] loss: 0.304\n",
      "[6,   100] loss: 0.293\n",
      "[6,   200] loss: 0.290\n",
      "[6,   300] loss: 0.292\n",
      "[7,   100] loss: 0.282\n",
      "[7,   200] loss: 0.287\n",
      "[7,   300] loss: 0.280\n",
      "[8,   100] loss: 0.237\n",
      "[8,   200] loss: 0.239\n",
      "[8,   300] loss: 0.298\n",
      "[9,   100] loss: 0.251\n",
      "[9,   200] loss: 0.264\n",
      "[9,   300] loss: 0.246\n",
      "[10,   100] loss: 0.253\n",
      "[10,   200] loss: 0.298\n",
      "[10,   300] loss: 0.240\n",
      "[11,   100] loss: 0.210\n",
      "[11,   200] loss: 0.237\n",
      "[11,   300] loss: 0.236\n",
      "[12,   100] loss: 0.206\n",
      "[12,   200] loss: 0.213\n",
      "[12,   300] loss: 0.207\n",
      "[13,   100] loss: 0.199\n",
      "[13,   200] loss: 0.222\n",
      "[13,   300] loss: 0.198\n",
      "[14,   100] loss: 0.196\n",
      "[14,   200] loss: 0.191\n",
      "[14,   300] loss: 0.200\n",
      "[15,   100] loss: 0.185\n",
      "[15,   200] loss: 0.185\n",
      "[15,   300] loss: 0.216\n",
      "[16,   100] loss: 0.184\n",
      "[16,   200] loss: 0.180\n",
      "[16,   300] loss: 0.213\n",
      "[17,   100] loss: 0.185\n",
      "[17,   200] loss: 0.196\n",
      "[17,   300] loss: 0.213\n",
      "[18,   100] loss: 0.185\n",
      "[18,   200] loss: 0.227\n",
      "[18,   300] loss: 0.211\n",
      "[19,   100] loss: 0.194\n",
      "[19,   200] loss: 0.200\n",
      "[19,   300] loss: 0.178\n",
      "[20,   100] loss: 0.157\n",
      "[20,   200] loss: 0.174\n",
      "[20,   300] loss: 0.168\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.173\n",
      "[1,   200] loss: 2.211\n",
      "[1,   300] loss: 2.156\n",
      "[2,   100] loss: 2.280\n",
      "[2,   200] loss: 2.278\n",
      "[2,   300] loss: 2.270\n",
      "[3,   100] loss: 2.280\n",
      "[3,   200] loss: 2.303\n",
      "[3,   300] loss: 2.303\n",
      "[4,   100] loss: 2.303\n",
      "[4,   200] loss: 2.303\n",
      "[4,   300] loss: 2.303\n",
      "[5,   100] loss: 2.303\n",
      "[5,   200] loss: 2.303\n",
      "[5,   300] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[6,   300] loss: 2.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[7,   300] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[8,   300] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[9,   300] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[10,   300] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[11,   300] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[12,   300] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[13,   300] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[14,   300] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[15,   300] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[16,   300] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[17,   300] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[18,   300] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[19,   300] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[20,   300] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.686\n",
      "[1,   200] loss: 0.999\n",
      "[1,   300] loss: 0.756\n",
      "[2,   100] loss: 0.696\n",
      "[2,   200] loss: 0.602\n",
      "[2,   300] loss: 0.585\n",
      "[3,   100] loss: 0.573\n",
      "[3,   200] loss: 0.577\n",
      "[3,   300] loss: 0.565\n",
      "[4,   100] loss: 0.462\n",
      "[4,   200] loss: 0.432\n",
      "[4,   300] loss: 0.493\n",
      "[5,   100] loss: 0.451\n",
      "[5,   200] loss: 0.445\n",
      "[5,   300] loss: 0.416\n",
      "[6,   100] loss: 0.396\n",
      "[6,   200] loss: 0.408\n",
      "[6,   300] loss: 0.387\n",
      "[7,   100] loss: 0.377\n",
      "[7,   200] loss: 0.380\n",
      "[7,   300] loss: 0.360\n",
      "[8,   100] loss: 0.329\n",
      "[8,   200] loss: 0.322\n",
      "[8,   300] loss: 0.340\n",
      "[9,   100] loss: 0.310\n",
      "[9,   200] loss: 0.334\n",
      "[9,   300] loss: 0.332\n",
      "[10,   100] loss: 0.326\n",
      "[10,   200] loss: 0.332\n",
      "[10,   300] loss: 0.312\n",
      "[11,   100] loss: 0.316\n",
      "[11,   200] loss: 0.309\n",
      "[11,   300] loss: 0.371\n",
      "[12,   100] loss: 0.329\n",
      "[12,   200] loss: 0.313\n",
      "[12,   300] loss: 0.321\n",
      "[13,   100] loss: 0.322\n",
      "[13,   200] loss: 0.312\n",
      "[13,   300] loss: 0.283\n",
      "[14,   100] loss: 0.288\n",
      "[14,   200] loss: 0.265\n",
      "[14,   300] loss: 0.291\n",
      "[15,   100] loss: 0.259\n",
      "[15,   200] loss: 0.272\n",
      "[15,   300] loss: 0.268\n",
      "[16,   100] loss: 0.273\n",
      "[16,   200] loss: 0.269\n",
      "[16,   300] loss: 0.278\n",
      "[17,   100] loss: 0.256\n",
      "[17,   200] loss: 0.278\n",
      "[17,   300] loss: 0.254\n",
      "[18,   100] loss: 0.295\n",
      "[18,   200] loss: 0.258\n",
      "[18,   300] loss: 0.259\n",
      "[19,   100] loss: 0.260\n",
      "[19,   200] loss: 0.250\n",
      "[19,   300] loss: 0.261\n",
      "[20,   100] loss: 0.243\n",
      "[20,   200] loss: 0.260\n",
      "[20,   300] loss: 0.234\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.291\n",
      "[1,   200] loss: 2.303\n",
      "[1,   300] loss: 2.303\n",
      "[2,   100] loss: 2.303\n",
      "[2,   200] loss: 2.303\n",
      "[2,   300] loss: 2.303\n",
      "[3,   100] loss: 2.303\n",
      "[3,   200] loss: 2.303\n",
      "[3,   300] loss: 2.303\n",
      "[4,   100] loss: 2.303\n",
      "[4,   200] loss: 2.303\n",
      "[4,   300] loss: 2.303\n",
      "[5,   100] loss: 2.303\n",
      "[5,   200] loss: 2.303\n",
      "[5,   300] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[6,   300] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[7,   300] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[8,   300] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[9,   300] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[10,   300] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[11,   300] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[12,   300] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[13,   300] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[14,   300] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[15,   300] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[16,   300] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[17,   300] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[18,   300] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[19,   300] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[20,   300] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.866\n",
      "[1,   200] loss: 0.445\n",
      "[1,   300] loss: 0.414\n",
      "[2,   100] loss: 0.338\n",
      "[2,   200] loss: 0.298\n",
      "[2,   300] loss: 0.291\n",
      "[3,   100] loss: 0.263\n",
      "[3,   200] loss: 0.253\n",
      "[3,   300] loss: 0.233\n",
      "[4,   100] loss: 0.197\n",
      "[4,   200] loss: 0.201\n",
      "[4,   300] loss: 0.193\n",
      "[5,   100] loss: 0.165\n",
      "[5,   200] loss: 0.183\n",
      "[5,   300] loss: 0.180\n",
      "[6,   100] loss: 0.163\n",
      "[6,   200] loss: 0.166\n",
      "[6,   300] loss: 0.156\n",
      "[7,   100] loss: 0.148\n",
      "[7,   200] loss: 0.149\n",
      "[7,   300] loss: 0.147\n",
      "[8,   100] loss: 0.138\n",
      "[8,   200] loss: 0.166\n",
      "[8,   300] loss: 0.134\n",
      "[9,   100] loss: 0.146\n",
      "[9,   200] loss: 0.162\n",
      "[9,   300] loss: 0.147\n",
      "[10,   100] loss: 0.128\n",
      "[10,   200] loss: 0.125\n",
      "[10,   300] loss: 0.123\n",
      "[11,   100] loss: 0.102\n",
      "[11,   200] loss: 0.111\n",
      "[11,   300] loss: 0.121\n",
      "[12,   100] loss: 0.113\n",
      "[12,   200] loss: 0.132\n",
      "[12,   300] loss: 0.123\n",
      "[13,   100] loss: 0.126\n",
      "[13,   200] loss: 0.105\n",
      "[13,   300] loss: 0.119\n",
      "[14,   100] loss: 0.102\n",
      "[14,   200] loss: 0.105\n",
      "[14,   300] loss: 0.105\n",
      "[15,   100] loss: 0.085\n",
      "[15,   200] loss: 0.103\n",
      "[15,   300] loss: 0.109\n",
      "[16,   100] loss: 0.097\n",
      "[16,   200] loss: 0.100\n",
      "[16,   300] loss: 0.114\n",
      "[17,   100] loss: 0.102\n",
      "[17,   200] loss: 0.100\n",
      "[17,   300] loss: 0.106\n",
      "[18,   100] loss: 0.089\n",
      "[18,   200] loss: 0.102\n",
      "[18,   300] loss: 0.117\n",
      "[19,   100] loss: 0.092\n",
      "[19,   200] loss: 0.111\n",
      "[19,   300] loss: 0.106\n",
      "[20,   100] loss: 0.092\n",
      "[20,   200] loss: 0.106\n",
      "[20,   300] loss: 0.105\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.041\n",
      "[1,   200] loss: 0.654\n",
      "[1,   300] loss: 0.631\n",
      "[2,   100] loss: 0.560\n",
      "[2,   200] loss: 0.567\n",
      "[2,   300] loss: 0.644\n",
      "[3,   100] loss: 0.665\n",
      "[3,   200] loss: 0.661\n",
      "[3,   300] loss: 0.628\n",
      "[4,   100] loss: 0.578\n",
      "[4,   200] loss: 0.533\n",
      "[4,   300] loss: 0.531\n",
      "[5,   100] loss: 0.586\n",
      "[5,   200] loss: 0.644\n",
      "[5,   300] loss: 0.616\n",
      "[6,   100] loss: 0.574\n",
      "[6,   200] loss: 0.612\n",
      "[6,   300] loss: 0.623\n",
      "[7,   100] loss: 0.557\n",
      "[7,   200] loss: 0.598\n",
      "[7,   300] loss: 0.627\n",
      "[8,   100] loss: 0.665\n",
      "[8,   200] loss: 0.684\n",
      "[8,   300] loss: 0.710\n",
      "[9,   100] loss: 0.769\n",
      "[9,   200] loss: 0.729\n",
      "[9,   300] loss: 0.725\n",
      "[10,   100] loss: 0.747\n",
      "[10,   200] loss: 0.876\n",
      "[10,   300] loss: 0.887\n",
      "[11,   100] loss: 0.870\n",
      "[11,   200] loss: 0.883\n",
      "[11,   300] loss: 0.821\n",
      "[12,   100] loss: 0.937\n",
      "[12,   200] loss: 0.898\n",
      "[12,   300] loss: 0.891\n",
      "[13,   100] loss: 0.832\n",
      "[13,   200] loss: 0.812\n",
      "[13,   300] loss: 0.852\n",
      "[14,   100] loss: 0.917\n",
      "[14,   200] loss: 0.832\n",
      "[14,   300] loss: 1.037\n",
      "[15,   100] loss: 1.104\n",
      "[15,   200] loss: 0.994\n",
      "[15,   300] loss: 1.024\n",
      "[16,   100] loss: 0.968\n",
      "[16,   200] loss: 0.903\n",
      "[16,   300] loss: 0.960\n",
      "[17,   100] loss: 1.067\n",
      "[17,   200] loss: 0.963\n",
      "[17,   300] loss: 1.028\n",
      "[18,   100] loss: 0.957\n",
      "[18,   200] loss: 0.963\n",
      "[18,   300] loss: 1.009\n",
      "[19,   100] loss: 1.096\n",
      "[19,   200] loss: 1.165\n",
      "[19,   300] loss: 1.235\n",
      "[20,   100] loss: 1.206\n",
      "[20,   200] loss: 1.211\n",
      "[20,   300] loss: 1.225\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.133\n",
      "[1,   200] loss: 2.141\n",
      "[1,   300] loss: 2.155\n",
      "[2,   100] loss: 2.112\n",
      "[2,   200] loss: 2.113\n",
      "[2,   300] loss: 2.110\n",
      "[3,   100] loss: 2.096\n",
      "[3,   200] loss: 2.113\n",
      "[3,   300] loss: 2.091\n",
      "[4,   100] loss: 2.091\n",
      "[4,   200] loss: 2.082\n",
      "[4,   300] loss: 2.110\n",
      "[5,   100] loss: 2.079\n",
      "[5,   200] loss: 2.096\n",
      "[5,   300] loss: 2.084\n",
      "[6,   100] loss: 2.102\n",
      "[6,   200] loss: 2.080\n",
      "[6,   300] loss: 2.076\n",
      "[7,   100] loss: 2.089\n",
      "[7,   200] loss: 2.095\n",
      "[7,   300] loss: 2.078\n",
      "[8,   100] loss: 2.071\n",
      "[8,   200] loss: 2.076\n",
      "[8,   300] loss: 2.081\n",
      "[9,   100] loss: 2.082\n",
      "[9,   200] loss: 2.089\n",
      "[9,   300] loss: 2.119\n",
      "[10,   100] loss: 2.085\n",
      "[10,   200] loss: 2.083\n",
      "[10,   300] loss: 2.096\n",
      "[11,   100] loss: 2.087\n",
      "[11,   200] loss: 2.071\n",
      "[11,   300] loss: 2.084\n",
      "[12,   100] loss: 2.057\n",
      "[12,   200] loss: 2.105\n",
      "[12,   300] loss: 2.120\n",
      "[13,   100] loss: 2.089\n",
      "[13,   200] loss: 2.089\n",
      "[13,   300] loss: 2.079\n",
      "[14,   100] loss: 2.081\n",
      "[14,   200] loss: 2.084\n",
      "[14,   300] loss: 2.097\n",
      "[15,   100] loss: 2.092\n",
      "[15,   200] loss: 2.091\n",
      "[15,   300] loss: 2.097\n",
      "[16,   100] loss: 2.093\n",
      "[16,   200] loss: 2.084\n",
      "[16,   300] loss: 2.102\n",
      "[17,   100] loss: 2.080\n",
      "[17,   200] loss: 2.080\n",
      "[17,   300] loss: 2.061\n",
      "[18,   100] loss: 2.061\n",
      "[18,   200] loss: 2.074\n",
      "[18,   300] loss: 2.077\n",
      "[19,   100] loss: 2.096\n",
      "[19,   200] loss: 2.197\n",
      "[19,   300] loss: 2.088\n",
      "[20,   100] loss: 2.077\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,   200] loss: 2.083\n",
      "[20,   300] loss: 2.096\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.178\n",
      "[1,   200] loss: 2.122\n",
      "[1,   300] loss: 2.100\n",
      "[2,   100] loss: 2.103\n",
      "[2,   200] loss: 2.187\n",
      "[2,   300] loss: 2.303\n",
      "[3,   100] loss: 2.303\n",
      "[3,   200] loss: 2.303\n",
      "[3,   300] loss: 2.303\n",
      "[4,   100] loss: 2.303\n",
      "[4,   200] loss: 2.303\n",
      "[4,   300] loss: 2.303\n",
      "[5,   100] loss: 2.303\n",
      "[5,   200] loss: 2.303\n",
      "[5,   300] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[6,   300] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[7,   300] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[8,   300] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[9,   300] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[10,   300] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[11,   300] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[12,   300] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[13,   300] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[14,   300] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[15,   300] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[16,   300] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[17,   300] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[18,   300] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[19,   300] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[20,   300] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.143\n",
      "[1,   200] loss: 0.521\n",
      "[1,   300] loss: 0.479\n",
      "[2,   100] loss: 0.396\n",
      "[2,   200] loss: 0.375\n",
      "[2,   300] loss: 0.334\n",
      "[3,   100] loss: 0.331\n",
      "[3,   200] loss: 0.299\n",
      "[3,   300] loss: 0.298\n",
      "[4,   100] loss: 0.278\n",
      "[4,   200] loss: 0.253\n",
      "[4,   300] loss: 0.284\n",
      "[5,   100] loss: 0.223\n",
      "[5,   200] loss: 0.236\n",
      "[5,   300] loss: 0.248\n",
      "[6,   100] loss: 0.221\n",
      "[6,   200] loss: 0.233\n",
      "[6,   300] loss: 0.238\n",
      "[7,   100] loss: 0.207\n",
      "[7,   200] loss: 0.198\n",
      "[7,   300] loss: 0.195\n",
      "[8,   100] loss: 0.178\n",
      "[8,   200] loss: 0.183\n",
      "[8,   300] loss: 0.193\n",
      "[9,   100] loss: 0.184\n",
      "[9,   200] loss: 0.170\n",
      "[9,   300] loss: 0.182\n",
      "[10,   100] loss: 0.158\n",
      "[10,   200] loss: 0.165\n",
      "[10,   300] loss: 0.173\n",
      "[11,   100] loss: 0.155\n",
      "[11,   200] loss: 0.184\n",
      "[11,   300] loss: 0.176\n",
      "[12,   100] loss: 0.159\n",
      "[12,   200] loss: 0.156\n",
      "[12,   300] loss: 0.148\n",
      "[13,   100] loss: 0.140\n",
      "[13,   200] loss: 0.151\n",
      "[13,   300] loss: 0.152\n",
      "[14,   100] loss: 0.140\n",
      "[14,   200] loss: 0.146\n",
      "[14,   300] loss: 0.146\n",
      "[15,   100] loss: 0.139\n",
      "[15,   200] loss: 0.146\n",
      "[15,   300] loss: 0.135\n",
      "[16,   100] loss: 0.133\n",
      "[16,   200] loss: 0.147\n",
      "[16,   300] loss: 0.143\n",
      "[17,   100] loss: 0.147\n",
      "[17,   200] loss: 0.137\n",
      "[17,   300] loss: 0.150\n",
      "[18,   100] loss: 0.138\n",
      "[18,   200] loss: 0.143\n",
      "[18,   300] loss: 0.137\n",
      "[19,   100] loss: 0.146\n",
      "[19,   200] loss: 0.141\n",
      "[19,   300] loss: 0.127\n",
      "[20,   100] loss: 0.128\n",
      "[20,   200] loss: 0.124\n",
      "[20,   300] loss: 0.132\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.303\n",
      "[1,   200] loss: 2.303\n",
      "[1,   300] loss: 2.303\n",
      "[2,   100] loss: 2.303\n",
      "[2,   200] loss: 2.303\n",
      "[2,   300] loss: 2.303\n",
      "[3,   100] loss: 2.303\n",
      "[3,   200] loss: 2.303\n",
      "[3,   300] loss: 2.303\n",
      "[4,   100] loss: 2.303\n",
      "[4,   200] loss: 2.303\n",
      "[4,   300] loss: 2.303\n",
      "[5,   100] loss: 2.303\n",
      "[5,   200] loss: 2.303\n",
      "[5,   300] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[6,   300] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[7,   300] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[8,   300] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[9,   300] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[10,   300] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[11,   300] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[12,   300] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[13,   300] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[14,   300] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[15,   300] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[16,   300] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[17,   300] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[18,   300] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[19,   300] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[20,   300] loss: 2.303\n",
      "Finished training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAYERSIZE = 50\n",
    "\n",
    "test_runs = 10\n",
    "\n",
    "int_lr = 0.35\n",
    "syn_lr = 0.016\n",
    "\n",
    "seed = random.randint(0, 1000000)\n",
    "\n",
    "#Train IP Model\n",
    "torch.manual_seed(seed)\n",
    "IPnet = DNet(LAYERSIZE, IP, eta=int_lr)\n",
    "IPnet = IPnet.to(device)\n",
    "\n",
    "optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "print(\"Training IP Net\")\n",
    "ip_losses = train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "#Train Standard Model\n",
    "torch.manual_seed(seed)\n",
    "net = DNet(LAYERSIZE, NN, eta=int_lr)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "print(\"Training Standard Net\")\n",
    "standard_losses = train_deep_model(net, optimizer2, seed)\n",
    "\n",
    "for i in range(test_runs-1):\n",
    "    seed = random.randint(0, 1000000)\n",
    "    \n",
    "    #Train IP Model\n",
    "    torch.manual_seed(seed)\n",
    "    IPnet = DNet(LAYERSIZE, IP, eta=int_lr)\n",
    "    IPnet = IPnet.to(device)\n",
    "\n",
    "    optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training IP Net\")\n",
    "    ip_losses += train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "    #Train Standard Model\n",
    "    torch.manual_seed(seed)\n",
    "    net = DNet(LAYERSIZE, NN, eta=int_lr)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "    print(\"Training Standard Net\")\n",
    "    standard_losses += train_deep_model(net, optimizer2, seed)\n",
    "    \n",
    "ip_losses = ip_losses/test_runs\n",
    "standard_losses = standard_losses/test_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAFNCAYAAADSGTgvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiEnD+H3xl/gczFTPnAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f01f3697f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.ylim([-0.1, 3])\n",
    "plt.title(\"Learning curves for deep networks\")\n",
    "plt.plot(ip_losses[0], ip_losses[1], label=\"IP\")\n",
    "# plt.plot(bn_losses[0], bn_losses[1], label=\"BN\")\n",
    "plt.plot(standard_losses[0], standard_losses[1], label=\"Standard\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CDNet(nn.Module):\n",
    "    def __init__(self, layersize, norm=None, eta=1):\n",
    "        super(CDNet, self).__init__()\n",
    "        \n",
    "        # Dense Layers\n",
    "        self.fc1 = nn.Linear(3*32*32, layersize)\n",
    "        self.fc2 = nn.Linear(layersize, layersize)\n",
    "        self.fc3 = nn.Linear(layersize, layersize)\n",
    "        self.fc4 = nn.Linear(layersize, layersize)\n",
    "        self.fc5 = nn.Linear(layersize, layersize)\n",
    "        self.fc6 = nn.Linear(layersize, layersize)\n",
    "        self.fc7 = nn.Linear(layersize, layersize)\n",
    "        self.fc8 = nn.Linear(layersize, layersize)\n",
    "        self.fc9 = nn.Linear(layersize, 10)\n",
    "        \n",
    "        # Normalization Layers\n",
    "        self.n1 = norm(layersize, eta)\n",
    "        self.n2 = norm(layersize, eta)\n",
    "        self.n3 = norm(layersize, eta)\n",
    "        self.n4 = norm(layersize, eta)\n",
    "        self.n5 = norm(layersize, eta)\n",
    "        self.n6 = norm(layersize, eta)\n",
    "        self.n7 = norm(layersize, eta)\n",
    "        self.n8 = norm(layersize, eta)\n",
    "        \n",
    "    def forward(self, x, eta=None):\n",
    "        x = x.view(-1, 3*32*32)\n",
    "        u1 = self.fc1(x)\n",
    "        v1 = F.tanh(self.n1(u1))\n",
    "        u2 = self.fc2(v1)\n",
    "        v2 = F.tanh(self.n2(u2))\n",
    "        u3 = self.fc3(v2)\n",
    "        v3 = F.tanh(self.n3(u3))\n",
    "        u4 = self.fc4(v3)\n",
    "        v4 = F.tanh(self.n4(u4))\n",
    "        u5 = self.fc5(v4)\n",
    "        v5 = F.tanh(self.n5(u5))\n",
    "        u6 = self.fc6(v5)\n",
    "        v6 = F.tanh(self.n6(u6))\n",
    "        u7 = self.fc7(v6)\n",
    "        v7 = F.tanh(self.n7(u7))\n",
    "        u8 = self.fc8(v7)\n",
    "        v8 = F.tanh(self.n8(u8))\n",
    "        # Note you should not normalize after the last linear layer (you delete info)\n",
    "        o = F.relu(self.fc9(v8))\n",
    "        \n",
    "        # Lets do the updates to the normalizations\n",
    "        self.n1.update(u1, v1, eta)\n",
    "        self.n2.update(u2, v2, eta)\n",
    "        self.n3.update(u3, v3, eta)\n",
    "        self.n4.update(u4, v4, eta)\n",
    "        self.n5.update(u5, v5, eta)\n",
    "        self.n6.update(u6, v6, eta)\n",
    "        self.n7.update(u7, v7, eta)\n",
    "        self.n8.update(u8, v8, eta)\n",
    "        \n",
    "        \n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batchSize = 200\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchSize,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IP Net\n",
      "[1,   100] loss: 1.952\n",
      "[1,   200] loss: 1.812\n",
      "[2,   100] loss: 1.700\n",
      "[2,   200] loss: 1.676\n",
      "[3,   100] loss: 1.595\n",
      "[3,   200] loss: 1.588\n",
      "[4,   100] loss: 1.502\n",
      "[4,   200] loss: 1.521\n",
      "[5,   100] loss: 1.437\n",
      "[5,   200] loss: 1.467\n",
      "[6,   100] loss: 1.386\n",
      "[6,   200] loss: 1.402\n",
      "[7,   100] loss: 1.324\n",
      "[7,   200] loss: 1.370\n",
      "[8,   100] loss: 1.287\n",
      "[8,   200] loss: 1.331\n",
      "[9,   100] loss: 1.239\n",
      "[9,   200] loss: 1.267\n",
      "[10,   100] loss: 1.194\n",
      "[10,   200] loss: 1.216\n",
      "[11,   100] loss: 1.147\n",
      "[11,   200] loss: 1.195\n",
      "[12,   100] loss: 1.107\n",
      "[12,   200] loss: 1.154\n",
      "[13,   100] loss: 1.060\n",
      "[13,   200] loss: 1.120\n",
      "[14,   100] loss: 1.040\n",
      "[14,   200] loss: 1.064\n",
      "[15,   100] loss: 1.010\n",
      "[15,   200] loss: 1.039\n",
      "[16,   100] loss: 0.988\n",
      "[16,   200] loss: 0.996\n",
      "[17,   100] loss: 0.936\n",
      "[17,   200] loss: 0.984\n",
      "[18,   100] loss: 0.905\n",
      "[18,   200] loss: 0.961\n",
      "[19,   100] loss: 0.880\n",
      "[19,   200] loss: 0.935\n",
      "[20,   100] loss: 0.871\n",
      "[20,   200] loss: 0.904\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.040\n",
      "[1,   200] loss: 1.861\n",
      "[2,   100] loss: 1.780\n",
      "[2,   200] loss: 1.756\n",
      "[3,   100] loss: 1.667\n",
      "[3,   200] loss: 1.672\n",
      "[4,   100] loss: 1.606\n",
      "[4,   200] loss: 1.603\n",
      "[5,   100] loss: 1.538\n",
      "[5,   200] loss: 1.561\n",
      "[6,   100] loss: 1.510\n",
      "[6,   200] loss: 1.504\n",
      "[7,   100] loss: 1.445\n",
      "[7,   200] loss: 1.476\n",
      "[8,   100] loss: 1.418\n",
      "[8,   200] loss: 1.439\n",
      "[9,   100] loss: 1.391\n",
      "[9,   200] loss: 1.401\n",
      "[10,   100] loss: 1.345\n",
      "[10,   200] loss: 1.367\n",
      "[11,   100] loss: 1.311\n",
      "[11,   200] loss: 1.346\n",
      "[12,   100] loss: 1.294\n",
      "[12,   200] loss: 1.295\n",
      "[13,   100] loss: 1.243\n",
      "[13,   200] loss: 1.277\n",
      "[14,   100] loss: 1.225\n",
      "[14,   200] loss: 1.241\n",
      "[15,   100] loss: 1.197\n",
      "[15,   200] loss: 1.203\n",
      "[16,   100] loss: 1.163\n",
      "[16,   200] loss: 1.176\n",
      "[17,   100] loss: 1.124\n",
      "[17,   200] loss: 1.162\n",
      "[18,   100] loss: 1.102\n",
      "[18,   200] loss: 1.122\n",
      "[19,   100] loss: 1.065\n",
      "[19,   200] loss: 1.108\n",
      "[20,   100] loss: 1.037\n",
      "[20,   200] loss: 1.074\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.948\n",
      "[1,   200] loss: 1.800\n",
      "[2,   100] loss: 1.697\n",
      "[2,   200] loss: 1.676\n",
      "[3,   100] loss: 1.595\n",
      "[3,   200] loss: 1.575\n",
      "[4,   100] loss: 1.511\n",
      "[4,   200] loss: 1.512\n",
      "[5,   100] loss: 1.449\n",
      "[5,   200] loss: 1.449\n",
      "[6,   100] loss: 1.383\n",
      "[6,   200] loss: 1.396\n",
      "[7,   100] loss: 1.340\n",
      "[7,   200] loss: 1.347\n",
      "[8,   100] loss: 1.287\n",
      "[8,   200] loss: 1.297\n",
      "[9,   100] loss: 1.223\n",
      "[9,   200] loss: 1.271\n",
      "[10,   100] loss: 1.206\n",
      "[10,   200] loss: 1.214\n",
      "[11,   100] loss: 1.143\n",
      "[11,   200] loss: 1.189\n",
      "[12,   100] loss: 1.103\n",
      "[12,   200] loss: 1.140\n",
      "[13,   100] loss: 1.082\n",
      "[13,   200] loss: 1.123\n",
      "[14,   100] loss: 1.038\n",
      "[14,   200] loss: 1.078\n",
      "[15,   100] loss: 1.006\n",
      "[15,   200] loss: 1.053\n",
      "[16,   100] loss: 0.972\n",
      "[16,   200] loss: 1.015\n",
      "[17,   100] loss: 0.954\n",
      "[17,   200] loss: 0.971\n",
      "[18,   100] loss: 0.914\n",
      "[18,   200] loss: 0.955\n",
      "[19,   100] loss: 0.883\n",
      "[19,   200] loss: 0.938\n",
      "[20,   100] loss: 0.857\n",
      "[20,   200] loss: 0.893\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.035\n",
      "[1,   200] loss: 1.859\n",
      "[2,   100] loss: 1.765\n",
      "[2,   200] loss: 1.728\n",
      "[3,   100] loss: 1.661\n",
      "[3,   200] loss: 1.654\n",
      "[4,   100] loss: 1.593\n",
      "[4,   200] loss: 1.599\n",
      "[5,   100] loss: 1.554\n",
      "[5,   200] loss: 1.545\n",
      "[6,   100] loss: 1.498\n",
      "[6,   200] loss: 1.506\n",
      "[7,   100] loss: 1.470\n",
      "[7,   200] loss: 1.459\n",
      "[8,   100] loss: 1.416\n",
      "[8,   200] loss: 1.431\n",
      "[9,   100] loss: 1.372\n",
      "[9,   200] loss: 1.409\n",
      "[10,   100] loss: 1.354\n",
      "[10,   200] loss: 1.360\n",
      "[11,   100] loss: 1.312\n",
      "[11,   200] loss: 1.338\n",
      "[12,   100] loss: 1.274\n",
      "[12,   200] loss: 1.308\n",
      "[13,   100] loss: 1.244\n",
      "[13,   200] loss: 1.271\n",
      "[14,   100] loss: 1.223\n",
      "[14,   200] loss: 1.239\n",
      "[15,   100] loss: 1.167\n",
      "[15,   200] loss: 1.220\n",
      "[16,   100] loss: 1.154\n",
      "[16,   200] loss: 1.188\n",
      "[17,   100] loss: 1.132\n",
      "[17,   200] loss: 1.148\n",
      "[18,   100] loss: 1.091\n",
      "[18,   200] loss: 1.131\n",
      "[19,   100] loss: 1.065\n",
      "[19,   200] loss: 1.107\n",
      "[20,   100] loss: 1.043\n",
      "[20,   200] loss: 1.071\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.951\n",
      "[1,   200] loss: 1.803\n",
      "[2,   100] loss: 1.696\n",
      "[2,   200] loss: 1.679\n",
      "[3,   100] loss: 1.593\n",
      "[3,   200] loss: 1.568\n",
      "[4,   100] loss: 1.520\n",
      "[4,   200] loss: 1.508\n",
      "[5,   100] loss: 1.414\n",
      "[5,   200] loss: 1.462\n",
      "[6,   100] loss: 1.381\n",
      "[6,   200] loss: 1.399\n",
      "[7,   100] loss: 1.331\n",
      "[7,   200] loss: 1.342\n",
      "[8,   100] loss: 1.283\n",
      "[8,   200] loss: 1.311\n",
      "[9,   100] loss: 1.235\n",
      "[9,   200] loss: 1.262\n",
      "[10,   100] loss: 1.192\n",
      "[10,   200] loss: 1.221\n",
      "[11,   100] loss: 1.172\n",
      "[11,   200] loss: 1.169\n",
      "[12,   100] loss: 1.106\n",
      "[12,   200] loss: 1.156\n",
      "[13,   100] loss: 1.075\n",
      "[13,   200] loss: 1.099\n",
      "[14,   100] loss: 1.018\n",
      "[14,   200] loss: 1.076\n",
      "[15,   100] loss: 0.995\n",
      "[15,   200] loss: 1.043\n",
      "[16,   100] loss: 0.965\n",
      "[16,   200] loss: 1.023\n",
      "[17,   100] loss: 0.935\n",
      "[17,   200] loss: 0.974\n",
      "[18,   100] loss: 0.913\n",
      "[18,   200] loss: 0.945\n",
      "[19,   100] loss: 0.909\n",
      "[19,   200] loss: 0.922\n",
      "[20,   100] loss: 0.862\n",
      "[20,   200] loss: 0.903\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.058\n",
      "[1,   200] loss: 1.878\n",
      "[2,   100] loss: 1.787\n",
      "[2,   200] loss: 1.775\n",
      "[3,   100] loss: 1.698\n",
      "[3,   200] loss: 1.675\n",
      "[4,   100] loss: 1.634\n",
      "[4,   200] loss: 1.623\n",
      "[5,   100] loss: 1.561\n",
      "[5,   200] loss: 1.578\n",
      "[6,   100] loss: 1.514\n",
      "[6,   200] loss: 1.532\n",
      "[7,   100] loss: 1.480\n",
      "[7,   200] loss: 1.476\n",
      "[8,   100] loss: 1.440\n",
      "[8,   200] loss: 1.450\n",
      "[9,   100] loss: 1.395\n",
      "[9,   200] loss: 1.413\n",
      "[10,   100] loss: 1.360\n",
      "[10,   200] loss: 1.375\n",
      "[11,   100] loss: 1.330\n",
      "[11,   200] loss: 1.336\n",
      "[12,   100] loss: 1.282\n",
      "[12,   200] loss: 1.321\n",
      "[13,   100] loss: 1.248\n",
      "[13,   200] loss: 1.276\n",
      "[14,   100] loss: 1.218\n",
      "[14,   200] loss: 1.249\n",
      "[15,   100] loss: 1.194\n",
      "[15,   200] loss: 1.214\n",
      "[16,   100] loss: 1.146\n",
      "[16,   200] loss: 1.205\n",
      "[17,   100] loss: 1.133\n",
      "[17,   200] loss: 1.170\n",
      "[18,   100] loss: 1.106\n",
      "[18,   200] loss: 1.126\n",
      "[19,   100] loss: 1.076\n",
      "[19,   200] loss: 1.108\n",
      "[20,   100] loss: 1.042\n",
      "[20,   200] loss: 1.065\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.945\n",
      "[1,   200] loss: 1.810\n",
      "[2,   100] loss: 1.710\n",
      "[2,   200] loss: 1.659\n",
      "[3,   100] loss: 1.596\n",
      "[3,   200] loss: 1.565\n",
      "[4,   100] loss: 1.523\n",
      "[4,   200] loss: 1.504\n",
      "[5,   100] loss: 1.445\n",
      "[5,   200] loss: 1.434\n",
      "[6,   100] loss: 1.381\n",
      "[6,   200] loss: 1.392\n",
      "[7,   100] loss: 1.339\n",
      "[7,   200] loss: 1.346\n",
      "[8,   100] loss: 1.277\n",
      "[8,   200] loss: 1.308\n",
      "[9,   100] loss: 1.234\n",
      "[9,   200] loss: 1.258\n",
      "[10,   100] loss: 1.187\n",
      "[10,   200] loss: 1.226\n",
      "[11,   100] loss: 1.138\n",
      "[11,   200] loss: 1.180\n",
      "[12,   100] loss: 1.107\n",
      "[12,   200] loss: 1.142\n",
      "[13,   100] loss: 1.073\n",
      "[13,   200] loss: 1.108\n",
      "[14,   100] loss: 1.026\n",
      "[14,   200] loss: 1.070\n",
      "[15,   100] loss: 1.012\n",
      "[15,   200] loss: 1.052\n",
      "[16,   100] loss: 0.973\n",
      "[16,   200] loss: 1.008\n",
      "[17,   100] loss: 0.923\n",
      "[17,   200] loss: 0.977\n",
      "[18,   100] loss: 0.903\n",
      "[18,   200] loss: 0.950\n",
      "[19,   100] loss: 0.883\n",
      "[19,   200] loss: 0.905\n",
      "[20,   100] loss: 0.850\n",
      "[20,   200] loss: 0.895\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.029\n",
      "[1,   200] loss: 1.862\n",
      "[2,   100] loss: 1.759\n",
      "[2,   200] loss: 1.719\n",
      "[3,   100] loss: 1.673\n",
      "[3,   200] loss: 1.648\n",
      "[4,   100] loss: 1.597\n",
      "[4,   200] loss: 1.591\n",
      "[5,   100] loss: 1.539\n",
      "[5,   200] loss: 1.546\n",
      "[6,   100] loss: 1.490\n",
      "[6,   200] loss: 1.505\n",
      "[7,   100] loss: 1.450\n",
      "[7,   200] loss: 1.468\n",
      "[8,   100] loss: 1.419\n",
      "[8,   200] loss: 1.428\n",
      "[9,   100] loss: 1.375\n",
      "[9,   200] loss: 1.387\n",
      "[10,   100] loss: 1.344\n",
      "[10,   200] loss: 1.366\n",
      "[11,   100] loss: 1.315\n",
      "[11,   200] loss: 1.326\n",
      "[12,   100] loss: 1.280\n",
      "[12,   200] loss: 1.309\n",
      "[13,   100] loss: 1.256\n",
      "[13,   200] loss: 1.273\n",
      "[14,   100] loss: 1.224\n",
      "[14,   200] loss: 1.234\n",
      "[15,   100] loss: 1.181\n",
      "[15,   200] loss: 1.221\n",
      "[16,   100] loss: 1.157\n",
      "[16,   200] loss: 1.168\n",
      "[17,   100] loss: 1.118\n",
      "[17,   200] loss: 1.152\n",
      "[18,   100] loss: 1.088\n",
      "[18,   200] loss: 1.119\n",
      "[19,   100] loss: 1.060\n",
      "[19,   200] loss: 1.093\n",
      "[20,   100] loss: 1.028\n",
      "[20,   200] loss: 1.055\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.939\n",
      "[1,   200] loss: 1.806\n",
      "[2,   100] loss: 1.713\n",
      "[2,   200] loss: 1.666\n",
      "[3,   100] loss: 1.586\n",
      "[3,   200] loss: 1.577\n",
      "[4,   100] loss: 1.518\n",
      "[4,   200] loss: 1.524\n",
      "[5,   100] loss: 1.444\n",
      "[5,   200] loss: 1.471\n",
      "[6,   100] loss: 1.398\n",
      "[6,   200] loss: 1.424\n",
      "[7,   100] loss: 1.343\n",
      "[7,   200] loss: 1.359\n",
      "[8,   100] loss: 1.280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   200] loss: 1.320\n",
      "[9,   100] loss: 1.255\n",
      "[9,   200] loss: 1.275\n",
      "[10,   100] loss: 1.203\n",
      "[10,   200] loss: 1.232\n",
      "[11,   100] loss: 1.159\n",
      "[11,   200] loss: 1.191\n",
      "[12,   100] loss: 1.127\n",
      "[12,   200] loss: 1.159\n",
      "[13,   100] loss: 1.089\n",
      "[13,   200] loss: 1.112\n",
      "[14,   100] loss: 1.040\n",
      "[14,   200] loss: 1.097\n",
      "[15,   100] loss: 0.999\n",
      "[15,   200] loss: 1.062\n",
      "[16,   100] loss: 0.984\n",
      "[16,   200] loss: 1.019\n",
      "[17,   100] loss: 0.946\n",
      "[17,   200] loss: 0.989\n",
      "[18,   100] loss: 0.924\n",
      "[18,   200] loss: 0.959\n",
      "[19,   100] loss: 0.892\n",
      "[19,   200] loss: 0.933\n",
      "[20,   100] loss: 0.853\n",
      "[20,   200] loss: 0.920\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.998\n",
      "[1,   200] loss: 1.866\n",
      "[2,   100] loss: 1.765\n",
      "[2,   200] loss: 1.731\n",
      "[3,   100] loss: 1.660\n",
      "[3,   200] loss: 1.665\n",
      "[4,   100] loss: 1.596\n",
      "[4,   200] loss: 1.610\n",
      "[5,   100] loss: 1.549\n",
      "[5,   200] loss: 1.551\n",
      "[6,   100] loss: 1.503\n",
      "[6,   200] loss: 1.512\n",
      "[7,   100] loss: 1.461\n",
      "[7,   200] loss: 1.467\n",
      "[8,   100] loss: 1.405\n",
      "[8,   200] loss: 1.445\n",
      "[9,   100] loss: 1.388\n",
      "[9,   200] loss: 1.401\n",
      "[10,   100] loss: 1.346\n",
      "[10,   200] loss: 1.369\n",
      "[11,   100] loss: 1.310\n",
      "[11,   200] loss: 1.349\n",
      "[12,   100] loss: 1.283\n",
      "[12,   200] loss: 1.299\n",
      "[13,   100] loss: 1.250\n",
      "[13,   200] loss: 1.270\n",
      "[14,   100] loss: 1.214\n",
      "[14,   200] loss: 1.250\n",
      "[15,   100] loss: 1.174\n",
      "[15,   200] loss: 1.229\n",
      "[16,   100] loss: 1.163\n",
      "[16,   200] loss: 1.195\n",
      "[17,   100] loss: 1.126\n",
      "[17,   200] loss: 1.160\n",
      "[18,   100] loss: 1.109\n",
      "[18,   200] loss: 1.120\n",
      "[19,   100] loss: 1.074\n",
      "[19,   200] loss: 1.099\n",
      "[20,   100] loss: 1.025\n",
      "[20,   200] loss: 1.075\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.941\n",
      "[1,   200] loss: 1.797\n",
      "[2,   100] loss: 1.692\n",
      "[2,   200] loss: 1.662\n",
      "[3,   100] loss: 1.578\n",
      "[3,   200] loss: 1.569\n",
      "[4,   100] loss: 1.504\n",
      "[4,   200] loss: 1.499\n",
      "[5,   100] loss: 1.433\n",
      "[5,   200] loss: 1.448\n",
      "[6,   100] loss: 1.362\n",
      "[6,   200] loss: 1.405\n",
      "[7,   100] loss: 1.330\n",
      "[7,   200] loss: 1.352\n",
      "[8,   100] loss: 1.278\n",
      "[8,   200] loss: 1.305\n",
      "[9,   100] loss: 1.232\n",
      "[9,   200] loss: 1.270\n",
      "[10,   100] loss: 1.201\n",
      "[10,   200] loss: 1.221\n",
      "[11,   100] loss: 1.153\n",
      "[11,   200] loss: 1.180\n",
      "[12,   100] loss: 1.108\n",
      "[12,   200] loss: 1.157\n",
      "[13,   100] loss: 1.087\n",
      "[13,   200] loss: 1.107\n",
      "[14,   100] loss: 1.042\n",
      "[14,   200] loss: 1.072\n",
      "[15,   100] loss: 1.002\n",
      "[15,   200] loss: 1.055\n",
      "[16,   100] loss: 0.975\n",
      "[16,   200] loss: 1.013\n",
      "[17,   100] loss: 0.947\n",
      "[17,   200] loss: 0.976\n",
      "[18,   100] loss: 0.916\n",
      "[18,   200] loss: 0.948\n",
      "[19,   100] loss: 0.879\n",
      "[19,   200] loss: 0.941\n",
      "[20,   100] loss: 0.858\n",
      "[20,   200] loss: 0.902\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.044\n",
      "[1,   200] loss: 1.878\n",
      "[2,   100] loss: 1.762\n",
      "[2,   200] loss: 1.735\n",
      "[3,   100] loss: 1.671\n",
      "[3,   200] loss: 1.668\n",
      "[4,   100] loss: 1.614\n",
      "[4,   200] loss: 1.599\n",
      "[5,   100] loss: 1.546\n",
      "[5,   200] loss: 1.554\n",
      "[6,   100] loss: 1.497\n",
      "[6,   200] loss: 1.519\n",
      "[7,   100] loss: 1.458\n",
      "[7,   200] loss: 1.461\n",
      "[8,   100] loss: 1.420\n",
      "[8,   200] loss: 1.434\n",
      "[9,   100] loss: 1.384\n",
      "[9,   200] loss: 1.402\n",
      "[10,   100] loss: 1.349\n",
      "[10,   200] loss: 1.363\n",
      "[11,   100] loss: 1.310\n",
      "[11,   200] loss: 1.332\n",
      "[12,   100] loss: 1.272\n",
      "[12,   200] loss: 1.306\n",
      "[13,   100] loss: 1.256\n",
      "[13,   200] loss: 1.261\n",
      "[14,   100] loss: 1.223\n",
      "[14,   200] loss: 1.231\n",
      "[15,   100] loss: 1.174\n",
      "[15,   200] loss: 1.204\n",
      "[16,   100] loss: 1.144\n",
      "[16,   200] loss: 1.178\n",
      "[17,   100] loss: 1.124\n",
      "[17,   200] loss: 1.133\n",
      "[18,   100] loss: 1.087\n",
      "[18,   200] loss: 1.115\n",
      "[19,   100] loss: 1.057\n",
      "[19,   200] loss: 1.090\n",
      "[20,   100] loss: 1.020\n",
      "[20,   200] loss: 1.063\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.947\n",
      "[1,   200] loss: 1.809\n",
      "[2,   100] loss: 1.711\n",
      "[2,   200] loss: 1.661\n",
      "[3,   100] loss: 1.586\n",
      "[3,   200] loss: 1.576\n",
      "[4,   100] loss: 1.515\n",
      "[4,   200] loss: 1.502\n",
      "[5,   100] loss: 1.437\n",
      "[5,   200] loss: 1.457\n",
      "[6,   100] loss: 1.386\n",
      "[6,   200] loss: 1.406\n",
      "[7,   100] loss: 1.331\n",
      "[7,   200] loss: 1.357\n",
      "[8,   100] loss: 1.287\n",
      "[8,   200] loss: 1.308\n",
      "[9,   100] loss: 1.239\n",
      "[9,   200] loss: 1.273\n",
      "[10,   100] loss: 1.208\n",
      "[10,   200] loss: 1.226\n",
      "[11,   100] loss: 1.157\n",
      "[11,   200] loss: 1.173\n",
      "[12,   100] loss: 1.118\n",
      "[12,   200] loss: 1.167\n",
      "[13,   100] loss: 1.086\n",
      "[13,   200] loss: 1.121\n",
      "[14,   100] loss: 1.040\n",
      "[14,   200] loss: 1.091\n",
      "[15,   100] loss: 1.001\n",
      "[15,   200] loss: 1.053\n",
      "[16,   100] loss: 0.973\n",
      "[16,   200] loss: 1.014\n",
      "[17,   100] loss: 0.944\n",
      "[17,   200] loss: 0.995\n",
      "[18,   100] loss: 0.921\n",
      "[18,   200] loss: 0.957\n",
      "[19,   100] loss: 0.896\n",
      "[19,   200] loss: 0.943\n",
      "[20,   100] loss: 0.863\n",
      "[20,   200] loss: 0.902\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.038\n",
      "[1,   200] loss: 1.884\n",
      "[2,   100] loss: 1.789\n",
      "[2,   200] loss: 1.734\n",
      "[3,   100] loss: 1.675\n",
      "[3,   200] loss: 1.670\n",
      "[4,   100] loss: 1.607\n",
      "[4,   200] loss: 1.601\n",
      "[5,   100] loss: 1.558\n",
      "[5,   200] loss: 1.558\n",
      "[6,   100] loss: 1.504\n",
      "[6,   200] loss: 1.517\n",
      "[7,   100] loss: 1.470\n",
      "[7,   200] loss: 1.481\n",
      "[8,   100] loss: 1.427\n",
      "[8,   200] loss: 1.437\n",
      "[9,   100] loss: 1.390\n",
      "[9,   200] loss: 1.412\n",
      "[10,   100] loss: 1.356\n",
      "[10,   200] loss: 1.383\n",
      "[11,   100] loss: 1.328\n",
      "[11,   200] loss: 1.329\n",
      "[12,   100] loss: 1.279\n",
      "[12,   200] loss: 1.307\n",
      "[13,   100] loss: 1.254\n",
      "[13,   200] loss: 1.278\n",
      "[14,   100] loss: 1.219\n",
      "[14,   200] loss: 1.243\n",
      "[15,   100] loss: 1.192\n",
      "[15,   200] loss: 1.222\n",
      "[16,   100] loss: 1.165\n",
      "[16,   200] loss: 1.193\n",
      "[17,   100] loss: 1.124\n",
      "[17,   200] loss: 1.162\n",
      "[18,   100] loss: 1.103\n",
      "[18,   200] loss: 1.147\n",
      "[19,   100] loss: 1.075\n",
      "[19,   200] loss: 1.097\n",
      "[20,   100] loss: 1.055\n",
      "[20,   200] loss: 1.076\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.939\n",
      "[1,   200] loss: 1.816\n",
      "[2,   100] loss: 1.706\n",
      "[2,   200] loss: 1.652\n",
      "[3,   100] loss: 1.589\n",
      "[3,   200] loss: 1.559\n",
      "[4,   100] loss: 1.497\n",
      "[4,   200] loss: 1.515\n",
      "[5,   100] loss: 1.421\n",
      "[5,   200] loss: 1.450\n",
      "[6,   100] loss: 1.381\n",
      "[6,   200] loss: 1.394\n",
      "[7,   100] loss: 1.316\n",
      "[7,   200] loss: 1.345\n",
      "[8,   100] loss: 1.279\n",
      "[8,   200] loss: 1.298\n",
      "[9,   100] loss: 1.229\n",
      "[9,   200] loss: 1.262\n",
      "[10,   100] loss: 1.185\n",
      "[10,   200] loss: 1.214\n",
      "[11,   100] loss: 1.144\n",
      "[11,   200] loss: 1.170\n",
      "[12,   100] loss: 1.101\n",
      "[12,   200] loss: 1.143\n",
      "[13,   100] loss: 1.061\n",
      "[13,   200] loss: 1.106\n",
      "[14,   100] loss: 1.035\n",
      "[14,   200] loss: 1.075\n",
      "[15,   100] loss: 1.003\n",
      "[15,   200] loss: 1.030\n",
      "[16,   100] loss: 0.976\n",
      "[16,   200] loss: 1.008\n",
      "[17,   100] loss: 0.935\n",
      "[17,   200] loss: 0.962\n",
      "[18,   100] loss: 0.896\n",
      "[18,   200] loss: 0.957\n",
      "[19,   100] loss: 0.875\n",
      "[19,   200] loss: 0.918\n",
      "[20,   100] loss: 0.854\n",
      "[20,   200] loss: 0.889\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.000\n",
      "[1,   200] loss: 1.889\n",
      "[2,   100] loss: 1.782\n",
      "[2,   200] loss: 1.732\n",
      "[3,   100] loss: 1.665\n",
      "[3,   200] loss: 1.652\n",
      "[4,   100] loss: 1.590\n",
      "[4,   200] loss: 1.607\n",
      "[5,   100] loss: 1.539\n",
      "[5,   200] loss: 1.546\n",
      "[6,   100] loss: 1.508\n",
      "[6,   200] loss: 1.499\n",
      "[7,   100] loss: 1.453\n",
      "[7,   200] loss: 1.469\n",
      "[8,   100] loss: 1.428\n",
      "[8,   200] loss: 1.425\n",
      "[9,   100] loss: 1.388\n",
      "[9,   200] loss: 1.402\n",
      "[10,   100] loss: 1.340\n",
      "[10,   200] loss: 1.355\n",
      "[11,   100] loss: 1.318\n",
      "[11,   200] loss: 1.327\n",
      "[12,   100] loss: 1.273\n",
      "[12,   200] loss: 1.299\n",
      "[13,   100] loss: 1.246\n",
      "[13,   200] loss: 1.271\n",
      "[14,   100] loss: 1.213\n",
      "[14,   200] loss: 1.244\n",
      "[15,   100] loss: 1.186\n",
      "[15,   200] loss: 1.209\n",
      "[16,   100] loss: 1.159\n",
      "[16,   200] loss: 1.186\n",
      "[17,   100] loss: 1.123\n",
      "[17,   200] loss: 1.139\n",
      "[18,   100] loss: 1.090\n",
      "[18,   200] loss: 1.141\n",
      "[19,   100] loss: 1.054\n",
      "[19,   200] loss: 1.088\n",
      "[20,   100] loss: 1.032\n",
      "[20,   200] loss: 1.066\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.942\n",
      "[1,   200] loss: 1.810\n",
      "[2,   100] loss: 1.703\n",
      "[2,   200] loss: 1.668\n",
      "[3,   100] loss: 1.583\n",
      "[3,   200] loss: 1.585\n",
      "[4,   100] loss: 1.505\n",
      "[4,   200] loss: 1.515\n",
      "[5,   100] loss: 1.438\n",
      "[5,   200] loss: 1.451\n",
      "[6,   100] loss: 1.379\n",
      "[6,   200] loss: 1.403\n",
      "[7,   100] loss: 1.340\n",
      "[7,   200] loss: 1.356\n",
      "[8,   100] loss: 1.275\n",
      "[8,   200] loss: 1.322\n",
      "[9,   100] loss: 1.253\n",
      "[9,   200] loss: 1.261\n",
      "[10,   100] loss: 1.179\n",
      "[10,   200] loss: 1.240\n",
      "[11,   100] loss: 1.146\n",
      "[11,   200] loss: 1.190\n",
      "[12,   100] loss: 1.115\n",
      "[12,   200] loss: 1.159\n",
      "[13,   100] loss: 1.075\n",
      "[13,   200] loss: 1.116\n",
      "[14,   100] loss: 1.049\n",
      "[14,   200] loss: 1.083\n",
      "[15,   100] loss: 1.007\n",
      "[15,   200] loss: 1.056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,   100] loss: 0.973\n",
      "[16,   200] loss: 1.020\n",
      "[17,   100] loss: 0.949\n",
      "[17,   200] loss: 0.981\n",
      "[18,   100] loss: 0.915\n",
      "[18,   200] loss: 0.950\n",
      "[19,   100] loss: 0.875\n",
      "[19,   200] loss: 0.938\n",
      "[20,   100] loss: 0.850\n",
      "[20,   200] loss: 0.917\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.025\n",
      "[1,   200] loss: 1.866\n",
      "[2,   100] loss: 1.772\n",
      "[2,   200] loss: 1.750\n",
      "[3,   100] loss: 1.664\n",
      "[3,   200] loss: 1.677\n",
      "[4,   100] loss: 1.604\n",
      "[4,   200] loss: 1.612\n",
      "[5,   100] loss: 1.552\n",
      "[5,   200] loss: 1.562\n",
      "[6,   100] loss: 1.502\n",
      "[6,   200] loss: 1.512\n",
      "[7,   100] loss: 1.466\n",
      "[7,   200] loss: 1.482\n",
      "[8,   100] loss: 1.415\n",
      "[8,   200] loss: 1.442\n",
      "[9,   100] loss: 1.408\n",
      "[9,   200] loss: 1.399\n",
      "[10,   100] loss: 1.347\n",
      "[10,   200] loss: 1.384\n",
      "[11,   100] loss: 1.315\n",
      "[11,   200] loss: 1.342\n",
      "[12,   100] loss: 1.285\n",
      "[12,   200] loss: 1.312\n",
      "[13,   100] loss: 1.252\n",
      "[13,   200] loss: 1.280\n",
      "[14,   100] loss: 1.221\n",
      "[14,   200] loss: 1.257\n",
      "[15,   100] loss: 1.192\n",
      "[15,   200] loss: 1.232\n",
      "[16,   100] loss: 1.169\n",
      "[16,   200] loss: 1.181\n",
      "[17,   100] loss: 1.139\n",
      "[17,   200] loss: 1.154\n",
      "[18,   100] loss: 1.107\n",
      "[18,   200] loss: 1.128\n",
      "[19,   100] loss: 1.073\n",
      "[19,   200] loss: 1.118\n",
      "[20,   100] loss: 1.039\n",
      "[20,   200] loss: 1.092\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.939\n",
      "[1,   200] loss: 1.808\n",
      "[2,   100] loss: 1.713\n",
      "[2,   200] loss: 1.666\n",
      "[3,   100] loss: 1.587\n",
      "[3,   200] loss: 1.564\n",
      "[4,   100] loss: 1.521\n",
      "[4,   200] loss: 1.513\n",
      "[5,   100] loss: 1.458\n",
      "[5,   200] loss: 1.448\n",
      "[6,   100] loss: 1.400\n",
      "[6,   200] loss: 1.405\n",
      "[7,   100] loss: 1.335\n",
      "[7,   200] loss: 1.360\n",
      "[8,   100] loss: 1.285\n",
      "[8,   200] loss: 1.300\n",
      "[9,   100] loss: 1.240\n",
      "[9,   200] loss: 1.286\n",
      "[10,   100] loss: 1.218\n",
      "[10,   200] loss: 1.233\n",
      "[11,   100] loss: 1.154\n",
      "[11,   200] loss: 1.213\n",
      "[12,   100] loss: 1.129\n",
      "[12,   200] loss: 1.162\n",
      "[13,   100] loss: 1.105\n",
      "[13,   200] loss: 1.130\n",
      "[14,   100] loss: 1.058\n",
      "[14,   200] loss: 1.103\n",
      "[15,   100] loss: 1.014\n",
      "[15,   200] loss: 1.059\n",
      "[16,   100] loss: 0.995\n",
      "[16,   200] loss: 1.039\n",
      "[17,   100] loss: 0.968\n",
      "[17,   200] loss: 1.008\n",
      "[18,   100] loss: 0.921\n",
      "[18,   200] loss: 0.971\n",
      "[19,   100] loss: 0.912\n",
      "[19,   200] loss: 0.933\n",
      "[20,   100] loss: 0.878\n",
      "[20,   200] loss: 0.921\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.029\n",
      "[1,   200] loss: 1.881\n",
      "[2,   100] loss: 1.774\n",
      "[2,   200] loss: 1.727\n",
      "[3,   100] loss: 1.663\n",
      "[3,   200] loss: 1.657\n",
      "[4,   100] loss: 1.612\n",
      "[4,   200] loss: 1.603\n",
      "[5,   100] loss: 1.554\n",
      "[5,   200] loss: 1.545\n",
      "[6,   100] loss: 1.498\n",
      "[6,   200] loss: 1.513\n",
      "[7,   100] loss: 1.455\n",
      "[7,   200] loss: 1.459\n",
      "[8,   100] loss: 1.409\n",
      "[8,   200] loss: 1.428\n",
      "[9,   100] loss: 1.372\n",
      "[9,   200] loss: 1.404\n",
      "[10,   100] loss: 1.353\n",
      "[10,   200] loss: 1.359\n",
      "[11,   100] loss: 1.297\n",
      "[11,   200] loss: 1.345\n",
      "[12,   100] loss: 1.279\n",
      "[12,   200] loss: 1.307\n",
      "[13,   100] loss: 1.236\n",
      "[13,   200] loss: 1.270\n",
      "[14,   100] loss: 1.206\n",
      "[14,   200] loss: 1.243\n",
      "[15,   100] loss: 1.176\n",
      "[15,   200] loss: 1.201\n",
      "[16,   100] loss: 1.152\n",
      "[16,   200] loss: 1.174\n",
      "[17,   100] loss: 1.122\n",
      "[17,   200] loss: 1.151\n",
      "[18,   100] loss: 1.079\n",
      "[18,   200] loss: 1.127\n",
      "[19,   100] loss: 1.058\n",
      "[19,   200] loss: 1.083\n",
      "[20,   100] loss: 1.043\n",
      "[20,   200] loss: 1.063\n",
      "Finished training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAYERSIZE = 150\n",
    "\n",
    "test_runs = 10\n",
    "\n",
    "int_lr = 0.3\n",
    "syn_lr = 0.001\n",
    "\n",
    "seed = random.randint(0, 1000000)\n",
    "\n",
    "#Train IP Model\n",
    "torch.manual_seed(seed)\n",
    "IPnet = CDNet(LAYERSIZE, IP, eta=int_lr)\n",
    "IPnet = IPnet.to(device)\n",
    "\n",
    "optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "print(\"Training IP Net\")\n",
    "ip_losses = train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "#Train Standard Model\n",
    "torch.manual_seed(seed)\n",
    "net = CDNet(LAYERSIZE, NN, eta=int_lr)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "print(\"Training Standard Net\")\n",
    "standard_losses = train_deep_model(net, optimizer2, seed)\n",
    "\n",
    "for i in range(test_runs-1):\n",
    "    seed = random.randint(0, 1000000)\n",
    "    \n",
    "    #Train IP Model\n",
    "    torch.manual_seed(seed)\n",
    "    IPnet = CDNet(LAYERSIZE, IP, eta=int_lr)\n",
    "    IPnet = IPnet.to(device)\n",
    "\n",
    "    optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training IP Net\")\n",
    "    ip_losses += train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "    #Train Standard Model\n",
    "    torch.manual_seed(seed)\n",
    "    net = CDNet(LAYERSIZE, NN, eta=int_lr)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "    print(\"Training Standard Net\")\n",
    "    standard_losses += train_deep_model(net, optimizer2, seed)\n",
    "    \n",
    "ip_losses = ip_losses/test_runs\n",
    "standard_losses = standard_losses/test_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAFNCAYAAADSGTgvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f01ec81b6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.ylim([-0.1, 3])\n",
    "plt.title(\"Learning curves for deep networks\")\n",
    "plt.plot(ip_losses[0], ip_losses[1], label=\"IP\")\n",
    "# plt.plot(bn_losses[0], bn_losses[1], label=\"BN\")\n",
    "plt.plot(standard_losses[0], standard_losses[1], label=\"Standard\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IP Net\n",
      "[1,   100] loss: 2.113\n",
      "[1,   200] loss: 2.038\n",
      "[2,   100] loss: 1.994\n",
      "[2,   200] loss: 1.996\n",
      "[3,   100] loss: 1.938\n",
      "[3,   200] loss: 1.903\n",
      "[4,   100] loss: 1.826\n",
      "[4,   200] loss: 1.803\n",
      "[5,   100] loss: 1.762\n",
      "[5,   200] loss: 1.753\n",
      "[6,   100] loss: 1.707\n",
      "[6,   200] loss: 1.694\n",
      "[7,   100] loss: 1.658\n",
      "[7,   200] loss: 1.635\n",
      "[8,   100] loss: 1.569\n",
      "[8,   200] loss: 1.567\n",
      "[9,   100] loss: 1.486\n",
      "[9,   200] loss: 1.496\n",
      "[10,   100] loss: 1.450\n",
      "[10,   200] loss: 1.445\n",
      "[11,   100] loss: 1.384\n",
      "[11,   200] loss: 1.394\n",
      "[12,   100] loss: 1.311\n",
      "[12,   200] loss: 1.326\n",
      "[13,   100] loss: 1.260\n",
      "[13,   200] loss: 1.287\n",
      "[14,   100] loss: 1.210\n",
      "[14,   200] loss: 1.235\n",
      "[15,   100] loss: 1.153\n",
      "[15,   200] loss: 1.178\n",
      "[16,   100] loss: 1.107\n",
      "[16,   200] loss: 1.109\n",
      "[17,   100] loss: 1.067\n",
      "[17,   200] loss: 1.087\n",
      "[18,   100] loss: 1.004\n",
      "[18,   200] loss: 1.035\n",
      "[19,   100] loss: 0.951\n",
      "[19,   200] loss: 0.985\n",
      "[20,   100] loss: 0.926\n",
      "[20,   200] loss: 0.949\n",
      "[21,   100] loss: 0.881\n",
      "[21,   200] loss: 0.912\n",
      "[22,   100] loss: 0.832\n",
      "[22,   200] loss: 0.866\n",
      "[23,   100] loss: 0.797\n",
      "[23,   200] loss: 0.819\n",
      "[24,   100] loss: 0.767\n",
      "[24,   200] loss: 0.792\n",
      "[25,   100] loss: 0.736\n",
      "[25,   200] loss: 0.769\n",
      "[26,   100] loss: 0.704\n",
      "[26,   200] loss: 0.734\n",
      "[27,   100] loss: 0.664\n",
      "[27,   200] loss: 0.702\n",
      "[28,   100] loss: 0.633\n",
      "[28,   200] loss: 0.685\n",
      "[29,   100] loss: 0.609\n",
      "[29,   200] loss: 0.643\n",
      "[30,   100] loss: 0.586\n",
      "[30,   200] loss: 0.632\n",
      "[31,   100] loss: 0.560\n",
      "[31,   200] loss: 0.587\n",
      "[32,   100] loss: 0.552\n",
      "[32,   200] loss: 0.560\n",
      "[33,   100] loss: 0.537\n",
      "[33,   200] loss: 0.548\n",
      "[34,   100] loss: 0.499\n",
      "[34,   200] loss: 0.526\n",
      "[35,   100] loss: 0.477\n",
      "[35,   200] loss: 0.515\n",
      "[36,   100] loss: 0.462\n",
      "[36,   200] loss: 0.482\n",
      "[37,   100] loss: 0.436\n",
      "[37,   200] loss: 0.486\n",
      "[38,   100] loss: 0.430\n",
      "[38,   200] loss: 0.455\n",
      "[39,   100] loss: 0.415\n",
      "[39,   200] loss: 0.428\n",
      "[40,   100] loss: 0.392\n",
      "[40,   200] loss: 0.432\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.144\n",
      "[1,   200] loss: 2.073\n",
      "[2,   100] loss: 2.035\n",
      "[2,   200] loss: 1.985\n",
      "[3,   100] loss: 1.980\n",
      "[3,   200] loss: 1.979\n",
      "[4,   100] loss: 1.954\n",
      "[4,   200] loss: 1.962\n",
      "[5,   100] loss: 1.960\n",
      "[5,   200] loss: 1.964\n",
      "[6,   100] loss: 1.956\n",
      "[6,   200] loss: 1.941\n",
      "[7,   100] loss: 1.932\n",
      "[7,   200] loss: 1.938\n",
      "[8,   100] loss: 1.921\n",
      "[8,   200] loss: 1.948\n",
      "[9,   100] loss: 1.923\n",
      "[9,   200] loss: 1.955\n",
      "[10,   100] loss: 1.929\n",
      "[10,   200] loss: 1.931\n",
      "[11,   100] loss: 1.945\n",
      "[11,   200] loss: 1.910\n",
      "[12,   100] loss: 1.907\n",
      "[12,   200] loss: 1.916\n",
      "[13,   100] loss: 1.911\n",
      "[13,   200] loss: 1.921\n",
      "[14,   100] loss: 1.909\n",
      "[14,   200] loss: 1.889\n",
      "[15,   100] loss: 1.899\n",
      "[15,   200] loss: 1.913\n",
      "[16,   100] loss: 1.910\n",
      "[16,   200] loss: 1.905\n",
      "[17,   100] loss: 1.924\n",
      "[17,   200] loss: 1.922\n",
      "[18,   100] loss: 1.905\n",
      "[18,   200] loss: 1.910\n",
      "[19,   100] loss: 1.913\n",
      "[19,   200] loss: 1.931\n",
      "[20,   100] loss: 1.891\n",
      "[20,   200] loss: 1.903\n",
      "[21,   100] loss: 1.892\n",
      "[21,   200] loss: 1.901\n",
      "[22,   100] loss: 1.890\n",
      "[22,   200] loss: 1.885\n",
      "[23,   100] loss: 1.882\n",
      "[23,   200] loss: 1.882\n",
      "[24,   100] loss: 1.876\n",
      "[24,   200] loss: 1.880\n",
      "[25,   100] loss: 1.881\n",
      "[25,   200] loss: 1.876\n",
      "[26,   100] loss: 1.876\n",
      "[26,   200] loss: 1.876\n",
      "[27,   100] loss: 1.868\n",
      "[27,   200] loss: 1.882\n",
      "[28,   100] loss: 1.877\n",
      "[28,   200] loss: 1.887\n",
      "[29,   100] loss: 1.889\n",
      "[29,   200] loss: 1.883\n",
      "[30,   100] loss: 1.873\n",
      "[30,   200] loss: 1.892\n",
      "[31,   100] loss: 1.884\n",
      "[31,   200] loss: 1.882\n",
      "[32,   100] loss: 1.884\n",
      "[32,   200] loss: 1.863\n",
      "[33,   100] loss: 1.853\n",
      "[33,   200] loss: 1.875\n",
      "[34,   100] loss: 1.861\n",
      "[34,   200] loss: 1.859\n",
      "[35,   100] loss: 1.849\n",
      "[35,   200] loss: 1.863\n",
      "[36,   100] loss: 1.855\n",
      "[36,   200] loss: 1.866\n",
      "[37,   100] loss: 1.856\n",
      "[37,   200] loss: 1.865\n",
      "[38,   100] loss: 1.845\n",
      "[38,   200] loss: 1.846\n",
      "[39,   100] loss: 1.835\n",
      "[39,   200] loss: 1.841\n",
      "[40,   100] loss: 1.844\n",
      "[40,   200] loss: 1.850\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.121\n",
      "[1,   200] loss: 2.026\n",
      "[2,   100] loss: 1.973\n",
      "[2,   200] loss: 1.913\n",
      "[3,   100] loss: 1.841\n",
      "[3,   200] loss: 1.837\n",
      "[4,   100] loss: 1.778\n",
      "[4,   200] loss: 1.782\n",
      "[5,   100] loss: 1.723\n",
      "[5,   200] loss: 1.710\n",
      "[6,   100] loss: 1.664\n",
      "[6,   200] loss: 1.643\n",
      "[7,   100] loss: 1.583\n",
      "[7,   200] loss: 1.584\n",
      "[8,   100] loss: 1.504\n",
      "[8,   200] loss: 1.518\n",
      "[9,   100] loss: 1.442\n",
      "[9,   200] loss: 1.467\n",
      "[10,   100] loss: 1.400\n",
      "[10,   200] loss: 1.408\n",
      "[11,   100] loss: 1.348\n",
      "[11,   200] loss: 1.346\n",
      "[12,   100] loss: 1.290\n",
      "[12,   200] loss: 1.291\n",
      "[13,   100] loss: 1.218\n",
      "[13,   200] loss: 1.247\n",
      "[14,   100] loss: 1.177\n",
      "[14,   200] loss: 1.192\n",
      "[15,   100] loss: 1.116\n",
      "[15,   200] loss: 1.143\n",
      "[16,   100] loss: 1.048\n",
      "[16,   200] loss: 1.103\n",
      "[17,   100] loss: 1.010\n",
      "[17,   200] loss: 1.049\n",
      "[18,   100] loss: 0.975\n",
      "[18,   200] loss: 1.004\n",
      "[19,   100] loss: 0.925\n",
      "[19,   200] loss: 0.972\n",
      "[20,   100] loss: 0.897\n",
      "[20,   200] loss: 0.913\n",
      "[21,   100] loss: 0.839\n",
      "[21,   200] loss: 0.886\n",
      "[22,   100] loss: 0.801\n",
      "[22,   200] loss: 0.838\n",
      "[23,   100] loss: 0.753\n",
      "[23,   200] loss: 0.801\n",
      "[24,   100] loss: 0.728\n",
      "[24,   200] loss: 0.766\n",
      "[25,   100] loss: 0.690\n",
      "[25,   200] loss: 0.724\n",
      "[26,   100] loss: 0.667\n",
      "[26,   200] loss: 0.705\n",
      "[27,   100] loss: 0.644\n",
      "[27,   200] loss: 0.665\n",
      "[28,   100] loss: 0.622\n",
      "[28,   200] loss: 0.646\n",
      "[29,   100] loss: 0.574\n",
      "[29,   200] loss: 0.623\n",
      "[30,   100] loss: 0.564\n",
      "[30,   200] loss: 0.596\n",
      "[31,   100] loss: 0.534\n",
      "[31,   200] loss: 0.567\n",
      "[32,   100] loss: 0.527\n",
      "[32,   200] loss: 0.538\n",
      "[33,   100] loss: 0.492\n",
      "[33,   200] loss: 0.533\n",
      "[34,   100] loss: 0.477\n",
      "[34,   200] loss: 0.503\n",
      "[35,   100] loss: 0.462\n",
      "[35,   200] loss: 0.493\n",
      "[36,   100] loss: 0.451\n",
      "[36,   200] loss: 0.459\n",
      "[37,   100] loss: 0.411\n",
      "[37,   200] loss: 0.462\n",
      "[38,   100] loss: 0.398\n",
      "[38,   200] loss: 0.435\n",
      "[39,   100] loss: 0.390\n",
      "[39,   200] loss: 0.437\n",
      "[40,   100] loss: 0.370\n",
      "[40,   200] loss: 0.409\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.122\n",
      "[1,   200] loss: 2.067\n",
      "[2,   100] loss: 2.064\n",
      "[2,   200] loss: 2.061\n",
      "[3,   100] loss: 2.034\n",
      "[3,   200] loss: 2.022\n",
      "[4,   100] loss: 2.022\n",
      "[4,   200] loss: 2.002\n",
      "[5,   100] loss: 1.985\n",
      "[5,   200] loss: 1.973\n",
      "[6,   100] loss: 1.977\n",
      "[6,   200] loss: 1.983\n",
      "[7,   100] loss: 1.959\n",
      "[7,   200] loss: 1.951\n",
      "[8,   100] loss: 1.946\n",
      "[8,   200] loss: 1.961\n",
      "[9,   100] loss: 1.952\n",
      "[9,   200] loss: 1.945\n",
      "[10,   100] loss: 1.928\n",
      "[10,   200] loss: 1.949\n",
      "[11,   100] loss: 1.934\n",
      "[11,   200] loss: 1.941\n",
      "[12,   100] loss: 1.939\n",
      "[12,   200] loss: 1.936\n",
      "[13,   100] loss: 1.925\n",
      "[13,   200] loss: 1.918\n",
      "[14,   100] loss: 1.919\n",
      "[14,   200] loss: 1.929\n",
      "[15,   100] loss: 1.921\n",
      "[15,   200] loss: 1.926\n",
      "[16,   100] loss: 1.916\n",
      "[16,   200] loss: 1.925\n",
      "[17,   100] loss: 1.914\n",
      "[17,   200] loss: 1.915\n",
      "[18,   100] loss: 1.923\n",
      "[18,   200] loss: 1.916\n",
      "[19,   100] loss: 1.917\n",
      "[19,   200] loss: 1.918\n",
      "[20,   100] loss: 1.913\n",
      "[20,   200] loss: 1.909\n",
      "[21,   100] loss: 1.925\n",
      "[21,   200] loss: 1.908\n",
      "[22,   100] loss: 1.903\n",
      "[22,   200] loss: 1.912\n",
      "[23,   100] loss: 1.893\n",
      "[23,   200] loss: 1.904\n",
      "[24,   100] loss: 1.903\n",
      "[24,   200] loss: 1.899\n",
      "[25,   100] loss: 1.892\n",
      "[25,   200] loss: 1.896\n",
      "[26,   100] loss: 1.888\n",
      "[26,   200] loss: 1.900\n",
      "[27,   100] loss: 1.902\n",
      "[27,   200] loss: 1.893\n",
      "[28,   100] loss: 1.893\n",
      "[28,   200] loss: 1.897\n",
      "[29,   100] loss: 1.869\n",
      "[29,   200] loss: 1.886\n",
      "[30,   100] loss: 1.875\n",
      "[30,   200] loss: 1.867\n",
      "[31,   100] loss: 1.869\n",
      "[31,   200] loss: 1.853\n",
      "[32,   100] loss: 1.871\n",
      "[32,   200] loss: 1.865\n",
      "[33,   100] loss: 1.863\n",
      "[33,   200] loss: 1.863\n",
      "[34,   100] loss: 1.874\n",
      "[34,   200] loss: 1.846\n",
      "[35,   100] loss: 1.852\n",
      "[35,   200] loss: 1.875\n",
      "[36,   100] loss: 1.862\n",
      "[36,   200] loss: 1.864\n",
      "[37,   100] loss: 1.853\n",
      "[37,   200] loss: 1.862\n",
      "[38,   100] loss: 1.847\n",
      "[38,   200] loss: 1.878\n",
      "[39,   100] loss: 1.848\n",
      "[39,   200] loss: 1.866\n",
      "[40,   100] loss: 1.850\n",
      "[40,   200] loss: 1.863\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.141\n",
      "[1,   200] loss: 2.012\n",
      "[2,   100] loss: 1.932\n",
      "[2,   200] loss: 1.900\n",
      "[3,   100] loss: 1.839\n",
      "[3,   200] loss: 1.833\n",
      "[4,   100] loss: 1.780\n",
      "[4,   200] loss: 1.767\n",
      "[5,   100] loss: 1.716\n",
      "[5,   200] loss: 1.716\n",
      "[6,   100] loss: 1.656\n",
      "[6,   200] loss: 1.668\n",
      "[7,   100] loss: 1.623\n",
      "[7,   200] loss: 1.611\n",
      "[8,   100] loss: 1.552\n",
      "[8,   200] loss: 1.548\n",
      "[9,   100] loss: 1.469\n",
      "[9,   200] loss: 1.489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   100] loss: 1.400\n",
      "[10,   200] loss: 1.428\n",
      "[11,   100] loss: 1.352\n",
      "[11,   200] loss: 1.369\n",
      "[12,   100] loss: 1.296\n",
      "[12,   200] loss: 1.315\n",
      "[13,   100] loss: 1.234\n",
      "[13,   200] loss: 1.262\n",
      "[14,   100] loss: 1.205\n",
      "[14,   200] loss: 1.189\n",
      "[15,   100] loss: 1.142\n",
      "[15,   200] loss: 1.167\n",
      "[16,   100] loss: 1.084\n",
      "[16,   200] loss: 1.108\n",
      "[17,   100] loss: 1.024\n",
      "[17,   200] loss: 1.066\n",
      "[18,   100] loss: 0.982\n",
      "[18,   200] loss: 1.025\n",
      "[19,   100] loss: 0.933\n",
      "[19,   200] loss: 0.974\n",
      "[20,   100] loss: 0.902\n",
      "[20,   200] loss: 0.931\n",
      "[21,   100] loss: 0.844\n",
      "[21,   200] loss: 0.885\n",
      "[22,   100] loss: 0.804\n",
      "[22,   200] loss: 0.849\n",
      "[23,   100] loss: 0.799\n",
      "[23,   200] loss: 0.813\n",
      "[24,   100] loss: 0.735\n",
      "[24,   200] loss: 0.782\n",
      "[25,   100] loss: 0.717\n",
      "[25,   200] loss: 0.740\n",
      "[26,   100] loss: 0.681\n",
      "[26,   200] loss: 0.712\n",
      "[27,   100] loss: 0.651\n",
      "[27,   200] loss: 0.692\n",
      "[28,   100] loss: 0.616\n",
      "[28,   200] loss: 0.660\n",
      "[29,   100] loss: 0.596\n",
      "[29,   200] loss: 0.629\n",
      "[30,   100] loss: 0.582\n",
      "[30,   200] loss: 0.605\n",
      "[31,   100] loss: 0.544\n",
      "[31,   200] loss: 0.584\n",
      "[32,   100] loss: 0.524\n",
      "[32,   200] loss: 0.571\n",
      "[33,   100] loss: 0.516\n",
      "[33,   200] loss: 0.529\n",
      "[34,   100] loss: 0.494\n",
      "[34,   200] loss: 0.513\n",
      "[35,   100] loss: 0.473\n",
      "[35,   200] loss: 0.511\n",
      "[36,   100] loss: 0.460\n",
      "[36,   200] loss: 0.480\n",
      "[37,   100] loss: 0.433\n",
      "[37,   200] loss: 0.462\n",
      "[38,   100] loss: 0.416\n",
      "[38,   200] loss: 0.454\n",
      "[39,   100] loss: 0.410\n",
      "[39,   200] loss: 0.429\n",
      "[40,   100] loss: 0.387\n",
      "[40,   200] loss: 0.436\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.194\n",
      "[1,   200] loss: 2.145\n",
      "[2,   100] loss: 2.172\n",
      "[2,   200] loss: 2.137\n",
      "[3,   100] loss: 2.107\n",
      "[3,   200] loss: 2.085\n",
      "[4,   100] loss: 2.103\n",
      "[4,   200] loss: 2.073\n",
      "[5,   100] loss: 2.032\n",
      "[5,   200] loss: 2.022\n",
      "[6,   100] loss: 2.010\n",
      "[6,   200] loss: 1.990\n",
      "[7,   100] loss: 1.994\n",
      "[7,   200] loss: 1.996\n",
      "[8,   100] loss: 1.970\n",
      "[8,   200] loss: 1.973\n",
      "[9,   100] loss: 1.953\n",
      "[9,   200] loss: 1.962\n",
      "[10,   100] loss: 1.946\n",
      "[10,   200] loss: 1.958\n",
      "[11,   100] loss: 1.948\n",
      "[11,   200] loss: 1.936\n",
      "[12,   100] loss: 1.948\n",
      "[12,   200] loss: 1.949\n",
      "[13,   100] loss: 1.935\n",
      "[13,   200] loss: 1.940\n",
      "[14,   100] loss: 1.942\n",
      "[14,   200] loss: 1.932\n",
      "[15,   100] loss: 1.920\n",
      "[15,   200] loss: 1.923\n",
      "[16,   100] loss: 1.918\n",
      "[16,   200] loss: 1.929\n",
      "[17,   100] loss: 1.916\n",
      "[17,   200] loss: 1.923\n",
      "[18,   100] loss: 1.927\n",
      "[18,   200] loss: 1.928\n",
      "[19,   100] loss: 1.921\n",
      "[19,   200] loss: 1.935\n",
      "[20,   100] loss: 1.944\n",
      "[20,   200] loss: 1.913\n",
      "[21,   100] loss: 1.921\n",
      "[21,   200] loss: 1.921\n",
      "[22,   100] loss: 1.913\n",
      "[22,   200] loss: 1.914\n",
      "[23,   100] loss: 1.906\n",
      "[23,   200] loss: 1.920\n",
      "[24,   100] loss: 1.907\n",
      "[24,   200] loss: 1.891\n",
      "[25,   100] loss: 1.894\n",
      "[25,   200] loss: 1.919\n",
      "[26,   100] loss: 1.917\n",
      "[26,   200] loss: 1.915\n",
      "[27,   100] loss: 1.889\n",
      "[27,   200] loss: 1.919\n",
      "[28,   100] loss: 1.917\n",
      "[28,   200] loss: 1.912\n",
      "[29,   100] loss: 1.906\n",
      "[29,   200] loss: 1.906\n",
      "[30,   100] loss: 1.921\n",
      "[30,   200] loss: 1.918\n",
      "[31,   100] loss: 1.917\n",
      "[31,   200] loss: 1.920\n",
      "[32,   100] loss: 1.906\n",
      "[32,   200] loss: 1.924\n",
      "[33,   100] loss: 1.911\n",
      "[33,   200] loss: 1.909\n",
      "[34,   100] loss: 1.899\n",
      "[34,   200] loss: 1.907\n",
      "[35,   100] loss: 1.902\n",
      "[35,   200] loss: 1.896\n",
      "[36,   100] loss: 1.898\n",
      "[36,   200] loss: 1.904\n",
      "[37,   100] loss: 1.892\n",
      "[37,   200] loss: 1.902\n",
      "[38,   100] loss: 1.885\n",
      "[38,   200] loss: 1.913\n",
      "[39,   100] loss: 1.904\n",
      "[39,   200] loss: 1.896\n",
      "[40,   100] loss: 1.900\n",
      "[40,   200] loss: 1.906\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.087\n",
      "[1,   200] loss: 2.021\n",
      "[2,   100] loss: 1.907\n",
      "[2,   200] loss: 1.875\n",
      "[3,   100] loss: 1.832\n",
      "[3,   200] loss: 1.815\n",
      "[4,   100] loss: 1.765\n",
      "[4,   200] loss: 1.757\n",
      "[5,   100] loss: 1.706\n",
      "[5,   200] loss: 1.710\n",
      "[6,   100] loss: 1.632\n",
      "[6,   200] loss: 1.644\n",
      "[7,   100] loss: 1.574\n",
      "[7,   200] loss: 1.569\n",
      "[8,   100] loss: 1.497\n",
      "[8,   200] loss: 1.501\n",
      "[9,   100] loss: 1.439\n",
      "[9,   200] loss: 1.461\n",
      "[10,   100] loss: 1.386\n",
      "[10,   200] loss: 1.404\n",
      "[11,   100] loss: 1.328\n",
      "[11,   200] loss: 1.344\n",
      "[12,   100] loss: 1.265\n",
      "[12,   200] loss: 1.294\n",
      "[13,   100] loss: 1.208\n",
      "[13,   200] loss: 1.240\n",
      "[14,   100] loss: 1.165\n",
      "[14,   200] loss: 1.189\n",
      "[15,   100] loss: 1.092\n",
      "[15,   200] loss: 1.151\n",
      "[16,   100] loss: 1.064\n",
      "[16,   200] loss: 1.082\n",
      "[17,   100] loss: 1.007\n",
      "[17,   200] loss: 1.033\n",
      "[18,   100] loss: 0.959\n",
      "[18,   200] loss: 1.002\n",
      "[19,   100] loss: 0.920\n",
      "[19,   200] loss: 0.937\n",
      "[20,   100] loss: 0.872\n",
      "[20,   200] loss: 0.906\n",
      "[21,   100] loss: 0.849\n",
      "[21,   200] loss: 0.859\n",
      "[22,   100] loss: 0.804\n",
      "[22,   200] loss: 0.817\n",
      "[23,   100] loss: 0.745\n",
      "[23,   200] loss: 0.793\n",
      "[24,   100] loss: 0.724\n",
      "[24,   200] loss: 0.754\n",
      "[25,   100] loss: 0.699\n",
      "[25,   200] loss: 0.714\n",
      "[26,   100] loss: 0.660\n",
      "[26,   200] loss: 0.712\n",
      "[27,   100] loss: 0.635\n",
      "[27,   200] loss: 0.666\n",
      "[28,   100] loss: 0.605\n",
      "[28,   200] loss: 0.631\n",
      "[29,   100] loss: 0.571\n",
      "[29,   200] loss: 0.596\n",
      "[30,   100] loss: 0.563\n",
      "[30,   200] loss: 0.584\n",
      "[31,   100] loss: 0.524\n",
      "[31,   200] loss: 0.572\n",
      "[32,   100] loss: 0.509\n",
      "[32,   200] loss: 0.543\n",
      "[33,   100] loss: 0.475\n",
      "[33,   200] loss: 0.527\n",
      "[34,   100] loss: 0.451\n",
      "[34,   200] loss: 0.490\n",
      "[35,   100] loss: 0.447\n",
      "[35,   200] loss: 0.483\n",
      "[36,   100] loss: 0.442\n",
      "[36,   200] loss: 0.459\n",
      "[37,   100] loss: 0.408\n",
      "[37,   200] loss: 0.450\n",
      "[38,   100] loss: 0.421\n",
      "[38,   200] loss: 0.446\n",
      "[39,   100] loss: 0.389\n",
      "[39,   200] loss: 0.421\n",
      "[40,   100] loss: 0.377\n",
      "[40,   200] loss: 0.400\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.093\n",
      "[1,   200] loss: 2.034\n",
      "[2,   100] loss: 1.987\n",
      "[2,   200] loss: 1.989\n",
      "[3,   100] loss: 1.974\n",
      "[3,   200] loss: 1.979\n",
      "[4,   100] loss: 1.956\n",
      "[4,   200] loss: 1.967\n",
      "[5,   100] loss: 1.960\n",
      "[5,   200] loss: 1.951\n",
      "[6,   100] loss: 1.948\n",
      "[6,   200] loss: 1.958\n",
      "[7,   100] loss: 1.950\n",
      "[7,   200] loss: 1.937\n",
      "[8,   100] loss: 1.931\n",
      "[8,   200] loss: 1.934\n",
      "[9,   100] loss: 1.915\n",
      "[9,   200] loss: 1.931\n",
      "[10,   100] loss: 1.905\n",
      "[10,   200] loss: 1.937\n",
      "[11,   100] loss: 1.916\n",
      "[11,   200] loss: 1.915\n",
      "[12,   100] loss: 1.908\n",
      "[12,   200] loss: 1.916\n",
      "[13,   100] loss: 1.895\n",
      "[13,   200] loss: 1.927\n",
      "[14,   100] loss: 1.907\n",
      "[14,   200] loss: 1.915\n",
      "[15,   100] loss: 1.920\n",
      "[15,   200] loss: 1.929\n",
      "[16,   100] loss: 1.900\n",
      "[16,   200] loss: 1.896\n",
      "[17,   100] loss: 1.904\n",
      "[17,   200] loss: 1.908\n",
      "[18,   100] loss: 1.892\n",
      "[18,   200] loss: 1.900\n",
      "[19,   100] loss: 1.896\n",
      "[19,   200] loss: 1.891\n",
      "[20,   100] loss: 1.889\n",
      "[20,   200] loss: 1.892\n",
      "[21,   100] loss: 1.891\n",
      "[21,   200] loss: 1.898\n",
      "[22,   100] loss: 1.875\n",
      "[22,   200] loss: 1.893\n",
      "[23,   100] loss: 1.885\n",
      "[23,   200] loss: 1.899\n",
      "[24,   100] loss: 1.884\n",
      "[24,   200] loss: 1.905\n",
      "[25,   100] loss: 1.878\n",
      "[25,   200] loss: 1.892\n",
      "[26,   100] loss: 1.905\n",
      "[26,   200] loss: 1.901\n",
      "[27,   100] loss: 1.884\n",
      "[27,   200] loss: 1.887\n",
      "[28,   100] loss: 1.882\n",
      "[28,   200] loss: 1.881\n",
      "[29,   100] loss: 1.879\n",
      "[29,   200] loss: 1.876\n",
      "[30,   100] loss: 1.873\n",
      "[30,   200] loss: 1.883\n",
      "[31,   100] loss: 1.873\n",
      "[31,   200] loss: 1.865\n",
      "[32,   100] loss: 1.883\n",
      "[32,   200] loss: 1.868\n",
      "[33,   100] loss: 1.859\n",
      "[33,   200] loss: 1.896\n",
      "[34,   100] loss: 1.865\n",
      "[34,   200] loss: 1.897\n",
      "[35,   100] loss: 1.869\n",
      "[35,   200] loss: 1.884\n",
      "[36,   100] loss: 1.860\n",
      "[36,   200] loss: 1.868\n",
      "[37,   100] loss: 1.863\n",
      "[37,   200] loss: 1.873\n",
      "[38,   100] loss: 1.872\n",
      "[38,   200] loss: 1.870\n",
      "[39,   100] loss: 1.860\n",
      "[39,   200] loss: 1.866\n",
      "[40,   100] loss: 1.860\n",
      "[40,   200] loss: 1.853\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.134\n",
      "[1,   200] loss: 2.023\n",
      "[2,   100] loss: 2.000\n",
      "[2,   200] loss: 1.950\n",
      "[3,   100] loss: 1.889\n",
      "[3,   200] loss: 1.848\n",
      "[4,   100] loss: 1.796\n",
      "[4,   200] loss: 1.781\n",
      "[5,   100] loss: 1.744\n",
      "[5,   200] loss: 1.714\n",
      "[6,   100] loss: 1.662\n",
      "[6,   200] loss: 1.665\n",
      "[7,   100] loss: 1.598\n",
      "[7,   200] loss: 1.593\n",
      "[8,   100] loss: 1.514\n",
      "[8,   200] loss: 1.528\n",
      "[9,   100] loss: 1.457\n",
      "[9,   200] loss: 1.469\n",
      "[10,   100] loss: 1.379\n",
      "[10,   200] loss: 1.406\n",
      "[11,   100] loss: 1.319\n",
      "[11,   200] loss: 1.336\n",
      "[12,   100] loss: 1.257\n",
      "[12,   200] loss: 1.299\n",
      "[13,   100] loss: 1.219\n",
      "[13,   200] loss: 1.226\n",
      "[14,   100] loss: 1.154\n",
      "[14,   200] loss: 1.178\n",
      "[15,   100] loss: 1.097\n",
      "[15,   200] loss: 1.131\n",
      "[16,   100] loss: 1.046\n",
      "[16,   200] loss: 1.079\n",
      "[17,   100] loss: 1.003\n",
      "[17,   200] loss: 1.028\n",
      "[18,   100] loss: 0.953\n",
      "[18,   200] loss: 0.990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19,   100] loss: 0.904\n",
      "[19,   200] loss: 0.948\n",
      "[20,   100] loss: 0.851\n",
      "[20,   200] loss: 0.891\n",
      "[21,   100] loss: 0.822\n",
      "[21,   200] loss: 0.850\n",
      "[22,   100] loss: 0.784\n",
      "[22,   200] loss: 0.810\n",
      "[23,   100] loss: 0.729\n",
      "[23,   200] loss: 0.783\n",
      "[24,   100] loss: 0.710\n",
      "[24,   200] loss: 0.762\n",
      "[25,   100] loss: 0.682\n",
      "[25,   200] loss: 0.704\n",
      "[26,   100] loss: 0.653\n",
      "[26,   200] loss: 0.667\n",
      "[27,   100] loss: 0.603\n",
      "[27,   200] loss: 0.651\n",
      "[28,   100] loss: 0.581\n",
      "[28,   200] loss: 0.628\n",
      "[29,   100] loss: 0.566\n",
      "[29,   200] loss: 0.590\n",
      "[30,   100] loss: 0.549\n",
      "[30,   200] loss: 0.558\n",
      "[31,   100] loss: 0.513\n",
      "[31,   200] loss: 0.531\n",
      "[32,   100] loss: 0.501\n",
      "[32,   200] loss: 0.518\n",
      "[33,   100] loss: 0.461\n",
      "[33,   200] loss: 0.497\n",
      "[34,   100] loss: 0.440\n",
      "[34,   200] loss: 0.472\n",
      "[35,   100] loss: 0.428\n",
      "[35,   200] loss: 0.458\n",
      "[36,   100] loss: 0.408\n",
      "[36,   200] loss: 0.458\n",
      "[37,   100] loss: 0.406\n",
      "[37,   200] loss: 0.421\n",
      "[38,   100] loss: 0.396\n",
      "[38,   200] loss: 0.405\n",
      "[39,   100] loss: 0.357\n",
      "[39,   200] loss: 0.383\n",
      "[40,   100] loss: 0.354\n",
      "[40,   200] loss: 0.387\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.143\n",
      "[1,   200] loss: 2.037\n",
      "[2,   100] loss: 2.014\n",
      "[2,   200] loss: 2.013\n",
      "[3,   100] loss: 2.029\n",
      "[3,   200] loss: 2.002\n",
      "[4,   100] loss: 1.956\n",
      "[4,   200] loss: 1.973\n",
      "[5,   100] loss: 1.964\n",
      "[5,   200] loss: 1.946\n",
      "[6,   100] loss: 1.936\n",
      "[6,   200] loss: 1.955\n",
      "[7,   100] loss: 1.943\n",
      "[7,   200] loss: 1.948\n",
      "[8,   100] loss: 1.939\n",
      "[8,   200] loss: 1.944\n",
      "[9,   100] loss: 1.915\n",
      "[9,   200] loss: 1.919\n",
      "[10,   100] loss: 1.927\n",
      "[10,   200] loss: 1.930\n",
      "[11,   100] loss: 1.917\n",
      "[11,   200] loss: 1.933\n",
      "[12,   100] loss: 1.908\n",
      "[12,   200] loss: 1.931\n",
      "[13,   100] loss: 1.904\n",
      "[13,   200] loss: 1.910\n",
      "[14,   100] loss: 1.912\n",
      "[14,   200] loss: 1.919\n",
      "[15,   100] loss: 1.910\n",
      "[15,   200] loss: 1.899\n",
      "[16,   100] loss: 1.910\n",
      "[16,   200] loss: 1.902\n",
      "[17,   100] loss: 1.883\n",
      "[17,   200] loss: 1.899\n",
      "[18,   100] loss: 1.900\n",
      "[18,   200] loss: 1.915\n",
      "[19,   100] loss: 1.897\n",
      "[19,   200] loss: 1.905\n",
      "[20,   100] loss: 1.881\n",
      "[20,   200] loss: 1.902\n",
      "[21,   100] loss: 1.893\n",
      "[21,   200] loss: 1.890\n",
      "[22,   100] loss: 1.897\n",
      "[22,   200] loss: 1.875\n",
      "[23,   100] loss: 1.872\n",
      "[23,   200] loss: 1.895\n",
      "[24,   100] loss: 1.892\n",
      "[24,   200] loss: 1.878\n",
      "[25,   100] loss: 1.889\n",
      "[25,   200] loss: 1.892\n",
      "[26,   100] loss: 1.894\n",
      "[26,   200] loss: 1.902\n",
      "[27,   100] loss: 1.884\n",
      "[27,   200] loss: 1.892\n",
      "[28,   100] loss: 1.872\n",
      "[28,   200] loss: 1.891\n",
      "[29,   100] loss: 1.899\n",
      "[29,   200] loss: 1.883\n",
      "[30,   100] loss: 1.892\n",
      "[30,   200] loss: 1.886\n",
      "[31,   100] loss: 1.886\n",
      "[31,   200] loss: 1.876\n",
      "[32,   100] loss: 1.876\n",
      "[32,   200] loss: 1.887\n",
      "[33,   100] loss: 1.871\n",
      "[33,   200] loss: 1.886\n",
      "[34,   100] loss: 1.882\n",
      "[34,   200] loss: 1.879\n",
      "[35,   100] loss: 1.858\n",
      "[35,   200] loss: 1.887\n",
      "[36,   100] loss: 1.868\n",
      "[36,   200] loss: 1.891\n",
      "[37,   100] loss: 1.876\n",
      "[37,   200] loss: 1.860\n",
      "[38,   100] loss: 1.883\n",
      "[38,   200] loss: 1.869\n",
      "[39,   100] loss: 1.863\n",
      "[39,   200] loss: 1.858\n",
      "[40,   100] loss: 1.862\n",
      "[40,   200] loss: 1.871\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.108\n",
      "[1,   200] loss: 2.020\n",
      "[2,   100] loss: 2.000\n",
      "[2,   200] loss: 1.941\n",
      "[3,   100] loss: 1.871\n",
      "[3,   200] loss: 1.838\n",
      "[4,   100] loss: 1.778\n",
      "[4,   200] loss: 1.778\n",
      "[5,   100] loss: 1.734\n",
      "[5,   200] loss: 1.733\n",
      "[6,   100] loss: 1.679\n",
      "[6,   200] loss: 1.653\n",
      "[7,   100] loss: 1.590\n",
      "[7,   200] loss: 1.578\n",
      "[8,   100] loss: 1.526\n",
      "[8,   200] loss: 1.536\n",
      "[9,   100] loss: 1.473\n",
      "[9,   200] loss: 1.483\n",
      "[10,   100] loss: 1.407\n",
      "[10,   200] loss: 1.419\n",
      "[11,   100] loss: 1.356\n",
      "[11,   200] loss: 1.357\n",
      "[12,   100] loss: 1.297\n",
      "[12,   200] loss: 1.308\n",
      "[13,   100] loss: 1.233\n",
      "[13,   200] loss: 1.265\n",
      "[14,   100] loss: 1.172\n",
      "[14,   200] loss: 1.210\n",
      "[15,   100] loss: 1.117\n",
      "[15,   200] loss: 1.159\n",
      "[16,   100] loss: 1.071\n",
      "[16,   200] loss: 1.112\n",
      "[17,   100] loss: 1.023\n",
      "[17,   200] loss: 1.050\n",
      "[18,   100] loss: 0.982\n",
      "[18,   200] loss: 1.009\n",
      "[19,   100] loss: 0.936\n",
      "[19,   200] loss: 0.973\n",
      "[20,   100] loss: 0.889\n",
      "[20,   200] loss: 0.932\n",
      "[21,   100] loss: 0.857\n",
      "[21,   200] loss: 0.879\n",
      "[22,   100] loss: 0.818\n",
      "[22,   200] loss: 0.839\n",
      "[23,   100] loss: 0.776\n",
      "[23,   200] loss: 0.795\n",
      "[24,   100] loss: 0.749\n",
      "[24,   200] loss: 0.753\n",
      "[25,   100] loss: 0.710\n",
      "[25,   200] loss: 0.740\n",
      "[26,   100] loss: 0.650\n",
      "[26,   200] loss: 0.724\n",
      "[27,   100] loss: 0.637\n",
      "[27,   200] loss: 0.692\n",
      "[28,   100] loss: 0.611\n",
      "[28,   200] loss: 0.658\n",
      "[29,   100] loss: 0.606\n",
      "[29,   200] loss: 0.631\n",
      "[30,   100] loss: 0.567\n",
      "[30,   200] loss: 0.591\n",
      "[31,   100] loss: 0.541\n",
      "[31,   200] loss: 0.572\n",
      "[32,   100] loss: 0.517\n",
      "[32,   200] loss: 0.553\n",
      "[33,   100] loss: 0.514\n",
      "[33,   200] loss: 0.520\n",
      "[34,   100] loss: 0.484\n",
      "[34,   200] loss: 0.519\n",
      "[35,   100] loss: 0.461\n",
      "[35,   200] loss: 0.485\n",
      "[36,   100] loss: 0.451\n",
      "[36,   200] loss: 0.469\n",
      "[37,   100] loss: 0.434\n",
      "[37,   200] loss: 0.473\n",
      "[38,   100] loss: 0.430\n",
      "[38,   200] loss: 0.427\n",
      "[39,   100] loss: 0.388\n",
      "[39,   200] loss: 0.429\n",
      "[40,   100] loss: 0.380\n",
      "[40,   200] loss: 0.424\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.091\n",
      "[1,   200] loss: 2.011\n",
      "[2,   100] loss: 1.996\n",
      "[2,   200] loss: 1.976\n",
      "[3,   100] loss: 1.968\n",
      "[3,   200] loss: 1.966\n",
      "[4,   100] loss: 1.939\n",
      "[4,   200] loss: 1.938\n",
      "[5,   100] loss: 1.923\n",
      "[5,   200] loss: 1.919\n",
      "[6,   100] loss: 1.895\n",
      "[6,   200] loss: 1.895\n",
      "[7,   100] loss: 1.890\n",
      "[7,   200] loss: 1.882\n",
      "[8,   100] loss: 1.870\n",
      "[8,   200] loss: 1.885\n",
      "[9,   100] loss: 1.868\n",
      "[9,   200] loss: 1.868\n",
      "[10,   100] loss: 1.855\n",
      "[10,   200] loss: 1.872\n",
      "[11,   100] loss: 1.848\n",
      "[11,   200] loss: 1.855\n",
      "[12,   100] loss: 1.835\n",
      "[12,   200] loss: 1.855\n",
      "[13,   100] loss: 1.849\n",
      "[13,   200] loss: 1.860\n",
      "[14,   100] loss: 1.846\n",
      "[14,   200] loss: 1.861\n",
      "[15,   100] loss: 1.826\n",
      "[15,   200] loss: 1.850\n",
      "[16,   100] loss: 1.835\n",
      "[16,   200] loss: 1.845\n",
      "[17,   100] loss: 1.820\n",
      "[17,   200] loss: 1.830\n",
      "[18,   100] loss: 1.828\n",
      "[18,   200] loss: 1.845\n",
      "[19,   100] loss: 1.825\n",
      "[19,   200] loss: 1.835\n",
      "[20,   100] loss: 1.820\n",
      "[20,   200] loss: 1.849\n",
      "[21,   100] loss: 1.827\n",
      "[21,   200] loss: 1.831\n",
      "[22,   100] loss: 1.830\n",
      "[22,   200] loss: 1.817\n",
      "[23,   100] loss: 1.821\n",
      "[23,   200] loss: 1.843\n",
      "[24,   100] loss: 1.820\n",
      "[24,   200] loss: 1.822\n",
      "[25,   100] loss: 1.820\n",
      "[25,   200] loss: 1.831\n",
      "[26,   100] loss: 1.825\n",
      "[26,   200] loss: 1.826\n",
      "[27,   100] loss: 1.820\n",
      "[27,   200] loss: 1.817\n",
      "[28,   100] loss: 1.800\n",
      "[28,   200] loss: 1.829\n",
      "[29,   100] loss: 1.820\n",
      "[29,   200] loss: 1.809\n",
      "[30,   100] loss: 1.815\n",
      "[30,   200] loss: 1.812\n",
      "[31,   100] loss: 1.806\n",
      "[31,   200] loss: 1.813\n",
      "[32,   100] loss: 1.812\n",
      "[32,   200] loss: 1.810\n",
      "[33,   100] loss: 1.799\n",
      "[33,   200] loss: 1.802\n",
      "[34,   100] loss: 1.784\n",
      "[34,   200] loss: 1.805\n",
      "[35,   100] loss: 1.788\n",
      "[35,   200] loss: 1.799\n",
      "[36,   100] loss: 1.795\n",
      "[36,   200] loss: 1.798\n",
      "[37,   100] loss: 1.787\n",
      "[37,   200] loss: 1.796\n",
      "[38,   100] loss: 1.808\n",
      "[38,   200] loss: 1.800\n",
      "[39,   100] loss: 1.789\n",
      "[39,   200] loss: 1.798\n",
      "[40,   100] loss: 1.794\n",
      "[40,   200] loss: 1.786\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.165\n",
      "[1,   200] loss: 2.030\n",
      "[2,   100] loss: 1.958\n",
      "[2,   200] loss: 1.891\n",
      "[3,   100] loss: 1.854\n",
      "[3,   200] loss: 1.839\n",
      "[4,   100] loss: 1.786\n",
      "[4,   200] loss: 1.776\n",
      "[5,   100] loss: 1.737\n",
      "[5,   200] loss: 1.728\n",
      "[6,   100] loss: 1.674\n",
      "[6,   200] loss: 1.691\n",
      "[7,   100] loss: 1.625\n",
      "[7,   200] loss: 1.616\n",
      "[8,   100] loss: 1.542\n",
      "[8,   200] loss: 1.542\n",
      "[9,   100] loss: 1.490\n",
      "[9,   200] loss: 1.484\n",
      "[10,   100] loss: 1.410\n",
      "[10,   200] loss: 1.434\n",
      "[11,   100] loss: 1.367\n",
      "[11,   200] loss: 1.381\n",
      "[12,   100] loss: 1.312\n",
      "[12,   200] loss: 1.324\n",
      "[13,   100] loss: 1.258\n",
      "[13,   200] loss: 1.285\n",
      "[14,   100] loss: 1.188\n",
      "[14,   200] loss: 1.225\n",
      "[15,   100] loss: 1.155\n",
      "[15,   200] loss: 1.172\n",
      "[16,   100] loss: 1.088\n",
      "[16,   200] loss: 1.134\n",
      "[17,   100] loss: 1.043\n",
      "[17,   200] loss: 1.078\n",
      "[18,   100] loss: 0.996\n",
      "[18,   200] loss: 1.027\n",
      "[19,   100] loss: 0.961\n",
      "[19,   200] loss: 0.994\n",
      "[20,   100] loss: 0.907\n",
      "[20,   200] loss: 0.952\n",
      "[21,   100] loss: 0.867\n",
      "[21,   200] loss: 0.907\n",
      "[22,   100] loss: 0.831\n",
      "[22,   200] loss: 0.880\n",
      "[23,   100] loss: 0.799\n",
      "[23,   200] loss: 0.824\n",
      "[24,   100] loss: 0.761\n",
      "[24,   200] loss: 0.799\n",
      "[25,   100] loss: 0.720\n",
      "[25,   200] loss: 0.769\n",
      "[26,   100] loss: 0.686\n",
      "[26,   200] loss: 0.712\n",
      "[27,   100] loss: 0.667\n",
      "[27,   200] loss: 0.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28,   100] loss: 0.638\n",
      "[28,   200] loss: 0.671\n",
      "[29,   100] loss: 0.618\n",
      "[29,   200] loss: 0.651\n",
      "[30,   100] loss: 0.593\n",
      "[30,   200] loss: 0.609\n",
      "[31,   100] loss: 0.552\n",
      "[31,   200] loss: 0.592\n",
      "[32,   100] loss: 0.537\n",
      "[32,   200] loss: 0.571\n",
      "[33,   100] loss: 0.505\n",
      "[33,   200] loss: 0.551\n",
      "[34,   100] loss: 0.504\n",
      "[34,   200] loss: 0.512\n",
      "[35,   100] loss: 0.481\n",
      "[35,   200] loss: 0.515\n",
      "[36,   100] loss: 0.451\n",
      "[36,   200] loss: 0.503\n",
      "[37,   100] loss: 0.430\n",
      "[37,   200] loss: 0.452\n",
      "[38,   100] loss: 0.416\n",
      "[38,   200] loss: 0.447\n",
      "[39,   100] loss: 0.397\n",
      "[39,   200] loss: 0.440\n",
      "[40,   100] loss: 0.388\n",
      "[40,   200] loss: 0.424\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.157\n",
      "[1,   200] loss: 2.047\n",
      "[2,   100] loss: 2.011\n",
      "[2,   200] loss: 1.986\n",
      "[3,   100] loss: 1.981\n",
      "[3,   200] loss: 1.984\n",
      "[4,   100] loss: 1.978\n",
      "[4,   200] loss: 1.965\n",
      "[5,   100] loss: 1.963\n",
      "[5,   200] loss: 1.955\n",
      "[6,   100] loss: 1.957\n",
      "[6,   200] loss: 1.970\n",
      "[7,   100] loss: 1.944\n",
      "[7,   200] loss: 1.959\n",
      "[8,   100] loss: 1.939\n",
      "[8,   200] loss: 1.946\n",
      "[9,   100] loss: 1.938\n",
      "[9,   200] loss: 1.933\n",
      "[10,   100] loss: 1.910\n",
      "[10,   200] loss: 1.918\n",
      "[11,   100] loss: 1.930\n",
      "[11,   200] loss: 1.921\n",
      "[12,   100] loss: 1.903\n",
      "[12,   200] loss: 1.909\n",
      "[13,   100] loss: 1.897\n",
      "[13,   200] loss: 1.908\n",
      "[14,   100] loss: 1.895\n",
      "[14,   200] loss: 1.910\n",
      "[15,   100] loss: 1.908\n",
      "[15,   200] loss: 1.910\n",
      "[16,   100] loss: 1.907\n",
      "[16,   200] loss: 1.900\n",
      "[17,   100] loss: 1.901\n",
      "[17,   200] loss: 1.894\n",
      "[18,   100] loss: 1.889\n",
      "[18,   200] loss: 1.889\n",
      "[19,   100] loss: 1.888\n",
      "[19,   200] loss: 1.894\n",
      "[20,   100] loss: 1.880\n",
      "[20,   200] loss: 1.889\n",
      "[21,   100] loss: 1.883\n",
      "[21,   200] loss: 1.883\n",
      "[22,   100] loss: 1.889\n",
      "[22,   200] loss: 1.889\n",
      "[23,   100] loss: 1.880\n",
      "[23,   200] loss: 1.900\n",
      "[24,   100] loss: 1.891\n",
      "[24,   200] loss: 1.889\n",
      "[25,   100] loss: 1.872\n",
      "[25,   200] loss: 1.894\n",
      "[26,   100] loss: 1.884\n",
      "[26,   200] loss: 1.886\n",
      "[27,   100] loss: 1.867\n",
      "[27,   200] loss: 1.888\n",
      "[28,   100] loss: 1.887\n",
      "[28,   200] loss: 1.879\n",
      "[29,   100] loss: 1.874\n",
      "[29,   200] loss: 1.895\n",
      "[30,   100] loss: 1.892\n",
      "[30,   200] loss: 1.883\n",
      "[31,   100] loss: 1.882\n",
      "[31,   200] loss: 1.893\n",
      "[32,   100] loss: 1.877\n",
      "[32,   200] loss: 1.873\n",
      "[33,   100] loss: 1.879\n",
      "[33,   200] loss: 1.887\n",
      "[34,   100] loss: 1.890\n",
      "[34,   200] loss: 1.870\n",
      "[35,   100] loss: 1.882\n",
      "[35,   200] loss: 1.903\n",
      "[36,   100] loss: 1.867\n",
      "[36,   200] loss: 1.891\n",
      "[37,   100] loss: 1.880\n",
      "[37,   200] loss: 1.889\n",
      "[38,   100] loss: 1.862\n",
      "[38,   200] loss: 1.864\n",
      "[39,   100] loss: 1.875\n",
      "[39,   200] loss: 1.873\n",
      "[40,   100] loss: 1.864\n",
      "[40,   200] loss: 1.886\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.088\n",
      "[1,   200] loss: 1.958\n",
      "[2,   100] loss: 1.886\n",
      "[2,   200] loss: 1.860\n",
      "[3,   100] loss: 1.820\n",
      "[3,   200] loss: 1.802\n",
      "[4,   100] loss: 1.745\n",
      "[4,   200] loss: 1.718\n",
      "[5,   100] loss: 1.694\n",
      "[5,   200] loss: 1.677\n",
      "[6,   100] loss: 1.639\n",
      "[6,   200] loss: 1.641\n",
      "[7,   100] loss: 1.600\n",
      "[7,   200] loss: 1.594\n",
      "[8,   100] loss: 1.520\n",
      "[8,   200] loss: 1.518\n",
      "[9,   100] loss: 1.462\n",
      "[9,   200] loss: 1.451\n",
      "[10,   100] loss: 1.401\n",
      "[10,   200] loss: 1.392\n",
      "[11,   100] loss: 1.330\n",
      "[11,   200] loss: 1.342\n",
      "[12,   100] loss: 1.281\n",
      "[12,   200] loss: 1.295\n",
      "[13,   100] loss: 1.215\n",
      "[13,   200] loss: 1.260\n",
      "[14,   100] loss: 1.180\n",
      "[14,   200] loss: 1.195\n",
      "[15,   100] loss: 1.118\n",
      "[15,   200] loss: 1.148\n",
      "[16,   100] loss: 1.073\n",
      "[16,   200] loss: 1.115\n",
      "[17,   100] loss: 1.041\n",
      "[17,   200] loss: 1.051\n",
      "[18,   100] loss: 0.979\n",
      "[18,   200] loss: 0.999\n",
      "[19,   100] loss: 0.936\n",
      "[19,   200] loss: 0.965\n",
      "[20,   100] loss: 0.906\n",
      "[20,   200] loss: 0.921\n",
      "[21,   100] loss: 0.838\n",
      "[21,   200] loss: 0.880\n",
      "[22,   100] loss: 0.818\n",
      "[22,   200] loss: 0.839\n",
      "[23,   100] loss: 0.782\n",
      "[23,   200] loss: 0.813\n",
      "[24,   100] loss: 0.749\n",
      "[24,   200] loss: 0.794\n",
      "[25,   100] loss: 0.705\n",
      "[25,   200] loss: 0.750\n",
      "[26,   100] loss: 0.663\n",
      "[26,   200] loss: 0.707\n",
      "[27,   100] loss: 0.658\n",
      "[27,   200] loss: 0.678\n",
      "[28,   100] loss: 0.629\n",
      "[28,   200] loss: 0.655\n",
      "[29,   100] loss: 0.582\n",
      "[29,   200] loss: 0.636\n",
      "[30,   100] loss: 0.573\n",
      "[30,   200] loss: 0.587\n",
      "[31,   100] loss: 0.538\n",
      "[31,   200] loss: 0.592\n",
      "[32,   100] loss: 0.528\n",
      "[32,   200] loss: 0.568\n",
      "[33,   100] loss: 0.512\n",
      "[33,   200] loss: 0.530\n",
      "[34,   100] loss: 0.484\n",
      "[34,   200] loss: 0.509\n",
      "[35,   100] loss: 0.448\n",
      "[35,   200] loss: 0.496\n",
      "[36,   100] loss: 0.432\n",
      "[36,   200] loss: 0.476\n",
      "[37,   100] loss: 0.440\n",
      "[37,   200] loss: 0.455\n",
      "[38,   100] loss: 0.423\n",
      "[38,   200] loss: 0.443\n",
      "[39,   100] loss: 0.407\n",
      "[39,   200] loss: 0.416\n",
      "[40,   100] loss: 0.400\n",
      "[40,   200] loss: 0.407\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.093\n",
      "[1,   200] loss: 2.011\n",
      "[2,   100] loss: 1.987\n",
      "[2,   200] loss: 1.997\n",
      "[3,   100] loss: 1.980\n",
      "[3,   200] loss: 1.975\n",
      "[4,   100] loss: 1.966\n",
      "[4,   200] loss: 1.953\n",
      "[5,   100] loss: 1.959\n",
      "[5,   200] loss: 1.951\n",
      "[6,   100] loss: 1.937\n",
      "[6,   200] loss: 1.955\n",
      "[7,   100] loss: 1.932\n",
      "[7,   200] loss: 1.938\n",
      "[8,   100] loss: 1.916\n",
      "[8,   200] loss: 1.936\n",
      "[9,   100] loss: 1.928\n",
      "[9,   200] loss: 1.919\n",
      "[10,   100] loss: 1.939\n",
      "[10,   200] loss: 1.912\n",
      "[11,   100] loss: 1.918\n",
      "[11,   200] loss: 1.911\n",
      "[12,   100] loss: 1.896\n",
      "[12,   200] loss: 1.919\n",
      "[13,   100] loss: 1.897\n",
      "[13,   200] loss: 1.902\n",
      "[14,   100] loss: 1.902\n",
      "[14,   200] loss: 1.900\n",
      "[15,   100] loss: 1.904\n",
      "[15,   200] loss: 1.883\n",
      "[16,   100] loss: 1.886\n",
      "[16,   200] loss: 1.890\n",
      "[17,   100] loss: 1.880\n",
      "[17,   200] loss: 1.897\n",
      "[18,   100] loss: 1.886\n",
      "[18,   200] loss: 1.886\n",
      "[19,   100] loss: 1.877\n",
      "[19,   200] loss: 1.880\n",
      "[20,   100] loss: 1.875\n",
      "[20,   200] loss: 1.888\n",
      "[21,   100] loss: 1.867\n",
      "[21,   200] loss: 1.877\n",
      "[22,   100] loss: 1.880\n",
      "[22,   200] loss: 1.872\n",
      "[23,   100] loss: 1.870\n",
      "[23,   200] loss: 1.870\n",
      "[24,   100] loss: 1.878\n",
      "[24,   200] loss: 1.878\n",
      "[25,   100] loss: 1.864\n",
      "[25,   200] loss: 1.876\n",
      "[26,   100] loss: 1.867\n",
      "[26,   200] loss: 1.878\n",
      "[27,   100] loss: 1.865\n",
      "[27,   200] loss: 1.849\n",
      "[28,   100] loss: 1.859\n",
      "[28,   200] loss: 1.862\n",
      "[29,   100] loss: 1.859\n",
      "[29,   200] loss: 1.858\n",
      "[30,   100] loss: 1.852\n",
      "[30,   200] loss: 1.843\n",
      "[31,   100] loss: 1.844\n",
      "[31,   200] loss: 1.861\n",
      "[32,   100] loss: 1.850\n",
      "[32,   200] loss: 1.855\n",
      "[33,   100] loss: 1.838\n",
      "[33,   200] loss: 1.857\n",
      "[34,   100] loss: 1.846\n",
      "[34,   200] loss: 1.861\n",
      "[35,   100] loss: 1.843\n",
      "[35,   200] loss: 1.827\n",
      "[36,   100] loss: 1.842\n",
      "[36,   200] loss: 1.853\n",
      "[37,   100] loss: 1.849\n",
      "[37,   200] loss: 1.836\n",
      "[38,   100] loss: 1.833\n",
      "[38,   200] loss: 1.843\n",
      "[39,   100] loss: 1.852\n",
      "[39,   200] loss: 1.839\n",
      "[40,   100] loss: 1.831\n",
      "[40,   200] loss: 1.843\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.105\n",
      "[1,   200] loss: 1.969\n",
      "[2,   100] loss: 1.888\n",
      "[2,   200] loss: 1.861\n",
      "[3,   100] loss: 1.813\n",
      "[3,   200] loss: 1.791\n",
      "[4,   100] loss: 1.745\n",
      "[4,   200] loss: 1.741\n",
      "[5,   100] loss: 1.688\n",
      "[5,   200] loss: 1.701\n",
      "[6,   100] loss: 1.629\n",
      "[6,   200] loss: 1.626\n",
      "[7,   100] loss: 1.551\n",
      "[7,   200] loss: 1.558\n",
      "[8,   100] loss: 1.493\n",
      "[8,   200] loss: 1.494\n",
      "[9,   100] loss: 1.422\n",
      "[9,   200] loss: 1.423\n",
      "[10,   100] loss: 1.355\n",
      "[10,   200] loss: 1.389\n",
      "[11,   100] loss: 1.305\n",
      "[11,   200] loss: 1.329\n",
      "[12,   100] loss: 1.246\n",
      "[12,   200] loss: 1.283\n",
      "[13,   100] loss: 1.189\n",
      "[13,   200] loss: 1.224\n",
      "[14,   100] loss: 1.150\n",
      "[14,   200] loss: 1.178\n",
      "[15,   100] loss: 1.064\n",
      "[15,   200] loss: 1.130\n",
      "[16,   100] loss: 1.039\n",
      "[16,   200] loss: 1.075\n",
      "[17,   100] loss: 0.990\n",
      "[17,   200] loss: 1.025\n",
      "[18,   100] loss: 0.954\n",
      "[18,   200] loss: 0.967\n",
      "[19,   100] loss: 0.909\n",
      "[19,   200] loss: 0.952\n",
      "[20,   100] loss: 0.852\n",
      "[20,   200] loss: 0.902\n",
      "[21,   100] loss: 0.825\n",
      "[21,   200] loss: 0.866\n",
      "[22,   100] loss: 0.781\n",
      "[22,   200] loss: 0.816\n",
      "[23,   100] loss: 0.756\n",
      "[23,   200] loss: 0.797\n",
      "[24,   100] loss: 0.723\n",
      "[24,   200] loss: 0.765\n",
      "[25,   100] loss: 0.687\n",
      "[25,   200] loss: 0.741\n",
      "[26,   100] loss: 0.649\n",
      "[26,   200] loss: 0.688\n",
      "[27,   100] loss: 0.626\n",
      "[27,   200] loss: 0.649\n",
      "[28,   100] loss: 0.590\n",
      "[28,   200] loss: 0.649\n",
      "[29,   100] loss: 0.560\n",
      "[29,   200] loss: 0.599\n",
      "[30,   100] loss: 0.550\n",
      "[30,   200] loss: 0.578\n",
      "[31,   100] loss: 0.532\n",
      "[31,   200] loss: 0.552\n",
      "[32,   100] loss: 0.499\n",
      "[32,   200] loss: 0.536\n",
      "[33,   100] loss: 0.488\n",
      "[33,   200] loss: 0.519\n",
      "[34,   100] loss: 0.437\n",
      "[34,   200] loss: 0.497\n",
      "[35,   100] loss: 0.436\n",
      "[35,   200] loss: 0.466\n",
      "[36,   100] loss: 0.424\n",
      "[36,   200] loss: 0.453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37,   100] loss: 0.398\n",
      "[37,   200] loss: 0.430\n",
      "[38,   100] loss: 0.390\n",
      "[38,   200] loss: 0.409\n",
      "[39,   100] loss: 0.375\n",
      "[39,   200] loss: 0.416\n",
      "[40,   100] loss: 0.368\n",
      "[40,   200] loss: 0.400\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.132\n",
      "[1,   200] loss: 2.037\n",
      "[2,   100] loss: 1.999\n",
      "[2,   200] loss: 2.034\n",
      "[3,   100] loss: 1.995\n",
      "[3,   200] loss: 2.003\n",
      "[4,   100] loss: 1.971\n",
      "[4,   200] loss: 1.960\n",
      "[5,   100] loss: 1.951\n",
      "[5,   200] loss: 1.967\n",
      "[6,   100] loss: 1.955\n",
      "[6,   200] loss: 1.938\n",
      "[7,   100] loss: 1.944\n",
      "[7,   200] loss: 1.950\n",
      "[8,   100] loss: 1.942\n",
      "[8,   200] loss: 1.933\n",
      "[9,   100] loss: 1.922\n",
      "[9,   200] loss: 1.917\n",
      "[10,   100] loss: 1.919\n",
      "[10,   200] loss: 1.932\n",
      "[11,   100] loss: 1.915\n",
      "[11,   200] loss: 1.956\n",
      "[12,   100] loss: 1.903\n",
      "[12,   200] loss: 1.922\n",
      "[13,   100] loss: 1.899\n",
      "[13,   200] loss: 1.913\n",
      "[14,   100] loss: 1.913\n",
      "[14,   200] loss: 1.903\n",
      "[15,   100] loss: 1.900\n",
      "[15,   200] loss: 1.912\n",
      "[16,   100] loss: 1.900\n",
      "[16,   200] loss: 1.906\n",
      "[17,   100] loss: 1.894\n",
      "[17,   200] loss: 1.895\n",
      "[18,   100] loss: 1.892\n",
      "[18,   200] loss: 1.896\n",
      "[19,   100] loss: 1.881\n",
      "[19,   200] loss: 1.906\n",
      "[20,   100] loss: 1.870\n",
      "[20,   200] loss: 1.897\n",
      "[21,   100] loss: 1.888\n",
      "[21,   200] loss: 1.876\n",
      "[22,   100] loss: 1.883\n",
      "[22,   200] loss: 1.897\n",
      "[23,   100] loss: 1.876\n",
      "[23,   200] loss: 1.900\n",
      "[24,   100] loss: 1.880\n",
      "[24,   200] loss: 1.881\n",
      "[25,   100] loss: 1.884\n",
      "[25,   200] loss: 1.881\n",
      "[26,   100] loss: 1.880\n",
      "[26,   200] loss: 1.883\n",
      "[27,   100] loss: 1.877\n",
      "[27,   200] loss: 1.898\n",
      "[28,   100] loss: 1.867\n",
      "[28,   200] loss: 1.879\n",
      "[29,   100] loss: 1.884\n",
      "[29,   200] loss: 1.889\n",
      "[30,   100] loss: 1.891\n",
      "[30,   200] loss: 1.883\n",
      "[31,   100] loss: 1.884\n",
      "[31,   200] loss: 1.876\n",
      "[32,   100] loss: 1.870\n",
      "[32,   200] loss: 1.896\n",
      "[33,   100] loss: 1.872\n",
      "[33,   200] loss: 1.878\n",
      "[34,   100] loss: 1.867\n",
      "[34,   200] loss: 1.894\n",
      "[35,   100] loss: 1.881\n",
      "[35,   200] loss: 1.874\n",
      "[36,   100] loss: 1.872\n",
      "[36,   200] loss: 1.865\n",
      "[37,   100] loss: 1.865\n",
      "[37,   200] loss: 1.879\n",
      "[38,   100] loss: 1.856\n",
      "[38,   200] loss: 1.868\n",
      "[39,   100] loss: 1.855\n",
      "[39,   200] loss: 1.853\n",
      "[40,   100] loss: 1.855\n",
      "[40,   200] loss: 1.870\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.100\n",
      "[1,   200] loss: 2.018\n",
      "[2,   100] loss: 1.952\n",
      "[2,   200] loss: 1.912\n",
      "[3,   100] loss: 1.840\n",
      "[3,   200] loss: 1.827\n",
      "[4,   100] loss: 1.762\n",
      "[4,   200] loss: 1.766\n",
      "[5,   100] loss: 1.721\n",
      "[5,   200] loss: 1.710\n",
      "[6,   100] loss: 1.668\n",
      "[6,   200] loss: 1.665\n",
      "[7,   100] loss: 1.594\n",
      "[7,   200] loss: 1.598\n",
      "[8,   100] loss: 1.527\n",
      "[8,   200] loss: 1.535\n",
      "[9,   100] loss: 1.471\n",
      "[9,   200] loss: 1.474\n",
      "[10,   100] loss: 1.402\n",
      "[10,   200] loss: 1.424\n",
      "[11,   100] loss: 1.366\n",
      "[11,   200] loss: 1.372\n",
      "[12,   100] loss: 1.299\n",
      "[12,   200] loss: 1.327\n",
      "[13,   100] loss: 1.239\n",
      "[13,   200] loss: 1.271\n",
      "[14,   100] loss: 1.181\n",
      "[14,   200] loss: 1.229\n",
      "[15,   100] loss: 1.133\n",
      "[15,   200] loss: 1.179\n",
      "[16,   100] loss: 1.098\n",
      "[16,   200] loss: 1.119\n",
      "[17,   100] loss: 1.061\n",
      "[17,   200] loss: 1.065\n",
      "[18,   100] loss: 1.000\n",
      "[18,   200] loss: 1.046\n",
      "[19,   100] loss: 0.957\n",
      "[19,   200] loss: 0.988\n",
      "[20,   100] loss: 0.909\n",
      "[20,   200] loss: 0.950\n",
      "[21,   100] loss: 0.867\n",
      "[21,   200] loss: 0.907\n",
      "[22,   100] loss: 0.842\n",
      "[22,   200] loss: 0.863\n",
      "[23,   100] loss: 0.804\n",
      "[23,   200] loss: 0.821\n",
      "[24,   100] loss: 0.775\n",
      "[24,   200] loss: 0.789\n",
      "[25,   100] loss: 0.738\n",
      "[25,   200] loss: 0.757\n",
      "[26,   100] loss: 0.702\n",
      "[26,   200] loss: 0.724\n",
      "[27,   100] loss: 0.673\n",
      "[27,   200] loss: 0.695\n",
      "[28,   100] loss: 0.651\n",
      "[28,   200] loss: 0.685\n",
      "[29,   100] loss: 0.605\n",
      "[29,   200] loss: 0.642\n",
      "[30,   100] loss: 0.584\n",
      "[30,   200] loss: 0.618\n",
      "[31,   100] loss: 0.559\n",
      "[31,   200] loss: 0.606\n",
      "[32,   100] loss: 0.536\n",
      "[32,   200] loss: 0.577\n",
      "[33,   100] loss: 0.530\n",
      "[33,   200] loss: 0.554\n",
      "[34,   100] loss: 0.496\n",
      "[34,   200] loss: 0.543\n",
      "[35,   100] loss: 0.472\n",
      "[35,   200] loss: 0.510\n",
      "[36,   100] loss: 0.463\n",
      "[36,   200] loss: 0.498\n",
      "[37,   100] loss: 0.441\n",
      "[37,   200] loss: 0.475\n",
      "[38,   100] loss: 0.426\n",
      "[38,   200] loss: 0.454\n",
      "[39,   100] loss: 0.412\n",
      "[39,   200] loss: 0.437\n",
      "[40,   100] loss: 0.387\n",
      "[40,   200] loss: 0.413\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.083\n",
      "[1,   200] loss: 2.007\n",
      "[2,   100] loss: 1.982\n",
      "[2,   200] loss: 1.979\n",
      "[3,   100] loss: 1.975\n",
      "[3,   200] loss: 1.954\n",
      "[4,   100] loss: 1.930\n",
      "[4,   200] loss: 1.962\n",
      "[5,   100] loss: 1.960\n",
      "[5,   200] loss: 1.949\n",
      "[6,   100] loss: 1.936\n",
      "[6,   200] loss: 1.950\n",
      "[7,   100] loss: 1.934\n",
      "[7,   200] loss: 1.923\n",
      "[8,   100] loss: 1.920\n",
      "[8,   200] loss: 1.920\n",
      "[9,   100] loss: 1.928\n",
      "[9,   200] loss: 1.930\n",
      "[10,   100] loss: 1.934\n",
      "[10,   200] loss: 1.935\n",
      "[11,   100] loss: 1.947\n",
      "[11,   200] loss: 1.926\n",
      "[12,   100] loss: 1.919\n",
      "[12,   200] loss: 1.914\n",
      "[13,   100] loss: 1.900\n",
      "[13,   200] loss: 1.905\n",
      "[14,   100] loss: 1.896\n",
      "[14,   200] loss: 1.903\n",
      "[15,   100] loss: 1.902\n",
      "[15,   200] loss: 1.903\n",
      "[16,   100] loss: 1.900\n",
      "[16,   200] loss: 1.899\n",
      "[17,   100] loss: 1.881\n",
      "[17,   200] loss: 1.889\n",
      "[18,   100] loss: 1.882\n",
      "[18,   200] loss: 1.889\n",
      "[19,   100] loss: 1.898\n",
      "[19,   200] loss: 1.892\n",
      "[20,   100] loss: 1.883\n",
      "[20,   200] loss: 1.878\n",
      "[21,   100] loss: 1.881\n",
      "[21,   200] loss: 1.893\n",
      "[22,   100] loss: 1.897\n",
      "[22,   200] loss: 1.882\n",
      "[23,   100] loss: 1.873\n",
      "[23,   200] loss: 1.895\n",
      "[24,   100] loss: 1.889\n",
      "[24,   200] loss: 1.874\n",
      "[25,   100] loss: 1.875\n",
      "[25,   200] loss: 1.873\n",
      "[26,   100] loss: 1.876\n",
      "[26,   200] loss: 1.882\n",
      "[27,   100] loss: 1.873\n",
      "[27,   200] loss: 1.886\n",
      "[28,   100] loss: 1.873\n",
      "[28,   200] loss: 1.875\n",
      "[29,   100] loss: 1.875\n",
      "[29,   200] loss: 1.889\n",
      "[30,   100] loss: 1.887\n",
      "[30,   200] loss: 1.885\n",
      "[31,   100] loss: 1.884\n",
      "[31,   200] loss: 1.877\n",
      "[32,   100] loss: 1.874\n",
      "[32,   200] loss: 1.896\n",
      "[33,   100] loss: 1.886\n",
      "[33,   200] loss: 1.881\n",
      "[34,   100] loss: 1.875\n",
      "[34,   200] loss: 1.890\n",
      "[35,   100] loss: 1.890\n",
      "[35,   200] loss: 1.873\n",
      "[36,   100] loss: 1.866\n",
      "[36,   200] loss: 1.878\n",
      "[37,   100] loss: 1.859\n",
      "[37,   200] loss: 1.873\n",
      "[38,   100] loss: 1.864\n",
      "[38,   200] loss: 1.865\n",
      "[39,   100] loss: 1.856\n",
      "[39,   200] loss: 1.857\n",
      "[40,   100] loss: 1.847\n",
      "[40,   200] loss: 1.865\n",
      "Finished training!\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAFNCAYAAADSGTgvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nX9EBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0dc5ccb4e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IP Net\n",
      "[1,   100] loss: 2.192\n",
      "[1,   200] loss: 2.045\n",
      "[2,   100] loss: 1.929\n",
      "[2,   200] loss: 1.915\n",
      "[3,   100] loss: 1.841\n",
      "[3,   200] loss: 1.807\n",
      "[4,   100] loss: 1.758\n",
      "[4,   200] loss: 1.737\n",
      "[5,   100] loss: 1.690\n",
      "[5,   200] loss: 1.689\n",
      "[6,   100] loss: 1.620\n",
      "[6,   200] loss: 1.619\n",
      "[7,   100] loss: 1.541\n",
      "[7,   200] loss: 1.546\n",
      "[8,   100] loss: 1.476\n",
      "[8,   200] loss: 1.487\n",
      "[9,   100] loss: 1.403\n",
      "[9,   200] loss: 1.432\n",
      "[10,   100] loss: 1.355\n",
      "[10,   200] loss: 1.385\n",
      "[11,   100] loss: 1.320\n",
      "[11,   200] loss: 1.327\n",
      "[12,   100] loss: 1.251\n",
      "[12,   200] loss: 1.289\n",
      "[13,   100] loss: 1.211\n",
      "[13,   200] loss: 1.229\n",
      "[14,   100] loss: 1.159\n",
      "[14,   200] loss: 1.190\n",
      "[15,   100] loss: 1.122\n",
      "[15,   200] loss: 1.139\n",
      "[16,   100] loss: 1.090\n",
      "[16,   200] loss: 1.117\n",
      "[17,   100] loss: 1.046\n",
      "[17,   200] loss: 1.052\n",
      "[18,   100] loss: 0.995\n",
      "[18,   200] loss: 1.031\n",
      "[19,   100] loss: 0.962\n",
      "[19,   200] loss: 0.974\n",
      "[20,   100] loss: 0.911\n",
      "[20,   200] loss: 0.954\n",
      "[21,   100] loss: 0.882\n",
      "[21,   200] loss: 0.912\n",
      "[22,   100] loss: 0.848\n",
      "[22,   200] loss: 0.878\n",
      "[23,   100] loss: 0.825\n",
      "[23,   200] loss: 0.857\n",
      "[24,   100] loss: 0.787\n",
      "[24,   200] loss: 0.814\n",
      "[25,   100] loss: 0.763\n",
      "[25,   200] loss: 0.794\n",
      "[26,   100] loss: 0.718\n",
      "[26,   200] loss: 0.771\n",
      "[27,   100] loss: 0.705\n",
      "[27,   200] loss: 0.707\n",
      "[28,   100] loss: 0.672\n",
      "[28,   200] loss: 0.691\n",
      "[29,   100] loss: 0.637\n",
      "[29,   200] loss: 0.681\n",
      "[30,   100] loss: 0.594\n",
      "[30,   200] loss: 0.643\n",
      "[31,   100] loss: 0.604\n",
      "[31,   200] loss: 0.632\n",
      "[32,   100] loss: 0.573\n",
      "[32,   200] loss: 0.617\n",
      "[33,   100] loss: 0.566\n",
      "[33,   200] loss: 0.580\n",
      "[34,   100] loss: 0.532\n",
      "[34,   200] loss: 0.561\n",
      "[35,   100] loss: 0.509\n",
      "[35,   200] loss: 0.541\n",
      "[36,   100] loss: 0.508\n",
      "[36,   200] loss: 0.528\n",
      "[37,   100] loss: 0.498\n",
      "[37,   200] loss: 0.515\n",
      "[38,   100] loss: 0.467\n",
      "[38,   200] loss: 0.522\n",
      "[39,   100] loss: 0.457\n",
      "[39,   200] loss: 0.494\n",
      "[40,   100] loss: 0.437\n",
      "[40,   200] loss: 0.473\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.300\n",
      "[1,   200] loss: 2.254\n",
      "[2,   100] loss: 2.271\n",
      "[2,   200] loss: 2.307\n",
      "[3,   100] loss: 2.280\n",
      "[3,   200] loss: 2.264\n",
      "[4,   100] loss: 2.201\n",
      "[4,   200] loss: 2.163\n",
      "[5,   100] loss: 2.125\n",
      "[5,   200] loss: 2.142\n",
      "[6,   100] loss: 2.131\n",
      "[6,   200] loss: 2.115\n",
      "[7,   100] loss: 2.130\n",
      "[7,   200] loss: 2.131\n",
      "[8,   100] loss: 2.119\n",
      "[8,   200] loss: 2.126\n",
      "[9,   100] loss: 2.110\n",
      "[9,   200] loss: 2.124\n",
      "[10,   100] loss: 2.110\n",
      "[10,   200] loss: 2.109\n",
      "[11,   100] loss: 2.095\n",
      "[11,   200] loss: 2.113\n",
      "[12,   100] loss: 2.089\n",
      "[12,   200] loss: 2.076\n",
      "[13,   100] loss: 2.075\n",
      "[13,   200] loss: 2.084\n",
      "[14,   100] loss: 2.076\n",
      "[14,   200] loss: 2.084\n",
      "[15,   100] loss: 2.090\n",
      "[15,   200] loss: 2.090\n",
      "[16,   100] loss: 2.075\n",
      "[16,   200] loss: 2.082\n",
      "[17,   100] loss: 2.068\n",
      "[17,   200] loss: 2.084\n",
      "[18,   100] loss: 2.096\n",
      "[18,   200] loss: 2.111\n",
      "[19,   100] loss: 2.100\n",
      "[19,   200] loss: 2.114\n",
      "[20,   100] loss: 2.114\n",
      "[20,   200] loss: 2.128\n",
      "[21,   100] loss: 2.127\n",
      "[21,   200] loss: 2.109\n",
      "[22,   100] loss: 2.118\n",
      "[22,   200] loss: 2.118\n",
      "[23,   100] loss: 2.120\n",
      "[23,   200] loss: 2.114\n",
      "[24,   100] loss: 2.109\n",
      "[24,   200] loss: 2.122\n",
      "[25,   100] loss: 2.122\n",
      "[25,   200] loss: 2.128\n",
      "[26,   100] loss: 2.139\n",
      "[26,   200] loss: 2.132\n",
      "[27,   100] loss: 2.113\n",
      "[27,   200] loss: 2.122\n",
      "[28,   100] loss: 2.134\n",
      "[28,   200] loss: 2.123\n",
      "[29,   100] loss: 2.125\n",
      "[29,   200] loss: 2.140\n",
      "[30,   100] loss: 2.112\n",
      "[30,   200] loss: 2.127\n",
      "[31,   100] loss: 2.134\n",
      "[31,   200] loss: 2.140\n",
      "[32,   100] loss: 2.135\n",
      "[32,   200] loss: 2.141\n",
      "[33,   100] loss: 2.130\n",
      "[33,   200] loss: 2.142\n",
      "[34,   100] loss: 2.142\n",
      "[34,   200] loss: 2.145\n",
      "[35,   100] loss: 2.144\n",
      "[35,   200] loss: 2.146\n",
      "[36,   100] loss: 2.159\n",
      "[36,   200] loss: 2.147\n",
      "[37,   100] loss: 2.133\n",
      "[37,   200] loss: 2.151\n",
      "[38,   100] loss: 2.135\n",
      "[38,   200] loss: 2.138\n",
      "[39,   100] loss: 2.156\n",
      "[39,   200] loss: 2.140\n",
      "[40,   100] loss: 2.143\n",
      "[40,   200] loss: 2.151\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.175\n",
      "[1,   200] loss: 2.016\n",
      "[2,   100] loss: 1.924\n",
      "[2,   200] loss: 1.879\n",
      "[3,   100] loss: 1.820\n",
      "[3,   200] loss: 1.792\n",
      "[4,   100] loss: 1.746\n",
      "[4,   200] loss: 1.728\n",
      "[5,   100] loss: 1.683\n",
      "[5,   200] loss: 1.670\n",
      "[6,   100] loss: 1.613\n",
      "[6,   200] loss: 1.599\n",
      "[7,   100] loss: 1.527\n",
      "[7,   200] loss: 1.527\n",
      "[8,   100] loss: 1.462\n",
      "[8,   200] loss: 1.474\n",
      "[9,   100] loss: 1.404\n",
      "[9,   200] loss: 1.418\n",
      "[10,   100] loss: 1.357\n",
      "[10,   200] loss: 1.374\n",
      "[11,   100] loss: 1.301\n",
      "[11,   200] loss: 1.324\n",
      "[12,   100] loss: 1.242\n",
      "[12,   200] loss: 1.282\n",
      "[13,   100] loss: 1.188\n",
      "[13,   200] loss: 1.234\n",
      "[14,   100] loss: 1.159\n",
      "[14,   200] loss: 1.164\n",
      "[15,   100] loss: 1.106\n",
      "[15,   200] loss: 1.127\n",
      "[16,   100] loss: 1.058\n",
      "[16,   200] loss: 1.107\n",
      "[17,   100] loss: 1.016\n",
      "[17,   200] loss: 1.051\n",
      "[18,   100] loss: 0.975\n",
      "[18,   200] loss: 0.997\n",
      "[19,   100] loss: 0.920\n",
      "[19,   200] loss: 0.969\n",
      "[20,   100] loss: 0.890\n",
      "[20,   200] loss: 0.940\n",
      "[21,   100] loss: 0.863\n",
      "[21,   200] loss: 0.876\n",
      "[22,   100] loss: 0.843\n",
      "[22,   200] loss: 0.866\n",
      "[23,   100] loss: 0.773\n",
      "[23,   200] loss: 0.827\n",
      "[24,   100] loss: 0.751\n",
      "[24,   200] loss: 0.809\n",
      "[25,   100] loss: 0.743\n",
      "[25,   200] loss: 0.773\n",
      "[26,   100] loss: 0.701\n",
      "[26,   200] loss: 0.735\n",
      "[27,   100] loss: 0.666\n",
      "[27,   200] loss: 0.699\n",
      "[28,   100] loss: 0.645\n",
      "[28,   200] loss: 0.672\n",
      "[29,   100] loss: 0.606\n",
      "[29,   200] loss: 0.656\n",
      "[30,   100] loss: 0.593\n",
      "[30,   200] loss: 0.629\n",
      "[31,   100] loss: 0.571\n",
      "[31,   200] loss: 0.606\n",
      "[32,   100] loss: 0.579\n",
      "[32,   200] loss: 0.575\n",
      "[33,   100] loss: 0.519\n",
      "[33,   200] loss: 0.553\n",
      "[34,   100] loss: 0.495\n",
      "[34,   200] loss: 0.539\n",
      "[35,   100] loss: 0.497\n",
      "[35,   200] loss: 0.511\n",
      "[36,   100] loss: 0.473\n",
      "[36,   200] loss: 0.492\n",
      "[37,   100] loss: 0.473\n",
      "[37,   200] loss: 0.495\n",
      "[38,   100] loss: 0.440\n",
      "[38,   200] loss: 0.468\n",
      "[39,   100] loss: 0.415\n",
      "[39,   200] loss: 0.462\n",
      "[40,   100] loss: 0.397\n",
      "[40,   200] loss: 0.448\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.296\n",
      "[1,   200] loss: 2.224\n",
      "[2,   100] loss: 2.188\n",
      "[2,   200] loss: 2.165\n",
      "[3,   100] loss: 2.182\n",
      "[3,   200] loss: 2.149\n",
      "[4,   100] loss: 2.151\n",
      "[4,   200] loss: 2.122\n",
      "[5,   100] loss: 2.133\n",
      "[5,   200] loss: 2.114\n",
      "[6,   100] loss: 2.092\n",
      "[6,   200] loss: 2.080\n",
      "[7,   100] loss: 2.067\n",
      "[7,   200] loss: 2.064\n",
      "[8,   100] loss: 2.036\n",
      "[8,   200] loss: 2.048\n",
      "[9,   100] loss: 2.054\n",
      "[9,   200] loss: 2.045\n",
      "[10,   100] loss: 2.053\n",
      "[10,   200] loss: 2.046\n",
      "[11,   100] loss: 2.053\n",
      "[11,   200] loss: 2.041\n",
      "[12,   100] loss: 2.029\n",
      "[12,   200] loss: 2.071\n",
      "[13,   100] loss: 2.041\n",
      "[13,   200] loss: 2.033\n",
      "[14,   100] loss: 2.033\n",
      "[14,   200] loss: 2.021\n",
      "[15,   100] loss: 2.038\n",
      "[15,   200] loss: 2.055\n",
      "[16,   100] loss: 2.037\n",
      "[16,   200] loss: 2.048\n",
      "[17,   100] loss: 2.045\n",
      "[17,   200] loss: 2.034\n",
      "[18,   100] loss: 2.026\n",
      "[18,   200] loss: 2.031\n",
      "[19,   100] loss: 2.028\n",
      "[19,   200] loss: 2.042\n",
      "[20,   100] loss: 2.014\n",
      "[20,   200] loss: 2.043\n",
      "[21,   100] loss: 2.010\n",
      "[21,   200] loss: 2.026\n",
      "[22,   100] loss: 2.028\n",
      "[22,   200] loss: 2.036\n",
      "[23,   100] loss: 2.011\n",
      "[23,   200] loss: 2.016\n",
      "[24,   100] loss: 2.029\n",
      "[24,   200] loss: 2.038\n",
      "[25,   100] loss: 2.034\n",
      "[25,   200] loss: 2.036\n",
      "[26,   100] loss: 2.033\n",
      "[26,   200] loss: 2.024\n",
      "[27,   100] loss: 2.031\n",
      "[27,   200] loss: 2.044\n",
      "[28,   100] loss: 2.029\n",
      "[28,   200] loss: 2.035\n",
      "[29,   100] loss: 2.015\n",
      "[29,   200] loss: 2.068\n",
      "[30,   100] loss: 2.027\n",
      "[30,   200] loss: 2.049\n",
      "[31,   100] loss: 2.034\n",
      "[31,   200] loss: 2.070\n",
      "[32,   100] loss: 2.059\n",
      "[32,   200] loss: 2.039\n",
      "[33,   100] loss: 2.022\n",
      "[33,   200] loss: 2.027\n",
      "[34,   100] loss: 2.040\n",
      "[34,   200] loss: 2.067\n",
      "[35,   100] loss: 2.044\n",
      "[35,   200] loss: 2.038\n",
      "[36,   100] loss: 2.029\n",
      "[36,   200] loss: 2.016\n",
      "[37,   100] loss: 2.024\n",
      "[37,   200] loss: 2.050\n",
      "[38,   100] loss: 2.030\n",
      "[38,   200] loss: 2.027\n",
      "[39,   100] loss: 2.031\n",
      "[39,   200] loss: 2.044\n",
      "[40,   100] loss: 2.030\n",
      "[40,   200] loss: 2.043\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.332\n",
      "[1,   200] loss: 2.295\n",
      "[2,   100] loss: 2.121\n",
      "[2,   200] loss: 2.040\n",
      "[3,   100] loss: 1.919\n",
      "[3,   200] loss: 1.880\n",
      "[4,   100] loss: 1.794\n",
      "[4,   200] loss: 1.779\n",
      "[5,   100] loss: 1.727\n",
      "[5,   200] loss: 1.728\n",
      "[6,   100] loss: 1.644\n",
      "[6,   200] loss: 1.611\n",
      "[7,   100] loss: 1.580\n",
      "[7,   200] loss: 1.564\n",
      "[8,   100] loss: 1.515\n",
      "[8,   200] loss: 1.504\n",
      "[9,   100] loss: 1.451\n",
      "[9,   200] loss: 1.457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   100] loss: 1.386\n",
      "[10,   200] loss: 1.396\n",
      "[11,   100] loss: 1.337\n",
      "[11,   200] loss: 1.352\n",
      "[12,   100] loss: 1.276\n",
      "[12,   200] loss: 1.302\n",
      "[13,   100] loss: 1.222\n",
      "[13,   200] loss: 1.241\n",
      "[14,   100] loss: 1.171\n",
      "[14,   200] loss: 1.203\n",
      "[15,   100] loss: 1.128\n",
      "[15,   200] loss: 1.155\n",
      "[16,   100] loss: 1.088\n",
      "[16,   200] loss: 1.115\n",
      "[17,   100] loss: 1.039\n",
      "[17,   200] loss: 1.061\n",
      "[18,   100] loss: 1.001\n",
      "[18,   200] loss: 1.036\n",
      "[19,   100] loss: 0.958\n",
      "[19,   200] loss: 1.004\n",
      "[20,   100] loss: 0.910\n",
      "[20,   200] loss: 0.947\n",
      "[21,   100] loss: 0.873\n",
      "[21,   200] loss: 0.929\n",
      "[22,   100] loss: 0.845\n",
      "[22,   200] loss: 0.870\n",
      "[23,   100] loss: 0.803\n",
      "[23,   200] loss: 0.855\n",
      "[24,   100] loss: 0.776\n",
      "[24,   200] loss: 0.812\n",
      "[25,   100] loss: 0.773\n",
      "[25,   200] loss: 0.796\n",
      "[26,   100] loss: 0.726\n",
      "[26,   200] loss: 0.748\n",
      "[27,   100] loss: 0.718\n",
      "[27,   200] loss: 0.733\n",
      "[28,   100] loss: 0.674\n",
      "[28,   200] loss: 0.708\n",
      "[29,   100] loss: 0.623\n",
      "[29,   200] loss: 0.689\n",
      "[30,   100] loss: 0.626\n",
      "[30,   200] loss: 0.650\n",
      "[31,   100] loss: 0.584\n",
      "[31,   200] loss: 0.646\n",
      "[32,   100] loss: 0.587\n",
      "[32,   200] loss: 0.624\n",
      "[33,   100] loss: 0.562\n",
      "[33,   200] loss: 0.593\n",
      "[34,   100] loss: 0.546\n",
      "[34,   200] loss: 0.571\n",
      "[35,   100] loss: 0.534\n",
      "[35,   200] loss: 0.557\n",
      "[36,   100] loss: 0.500\n",
      "[36,   200] loss: 0.548\n",
      "[37,   100] loss: 0.487\n",
      "[37,   200] loss: 0.548\n",
      "[38,   100] loss: 0.493\n",
      "[38,   200] loss: 0.540\n",
      "[39,   100] loss: 0.472\n",
      "[39,   200] loss: 0.514\n",
      "[40,   100] loss: 0.456\n",
      "[40,   200] loss: 0.482\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.269\n",
      "[1,   200] loss: 2.254\n",
      "[2,   100] loss: 2.264\n",
      "[2,   200] loss: 2.220\n",
      "[3,   100] loss: 2.241\n",
      "[3,   200] loss: 2.215\n",
      "[4,   100] loss: 2.157\n",
      "[4,   200] loss: 2.137\n",
      "[5,   100] loss: 2.138\n",
      "[5,   200] loss: 2.146\n",
      "[6,   100] loss: 2.132\n",
      "[6,   200] loss: 2.126\n",
      "[7,   100] loss: 2.117\n",
      "[7,   200] loss: 2.123\n",
      "[8,   100] loss: 2.129\n",
      "[8,   200] loss: 2.113\n",
      "[9,   100] loss: 2.125\n",
      "[9,   200] loss: 2.110\n",
      "[10,   100] loss: 2.099\n",
      "[10,   200] loss: 2.119\n",
      "[11,   100] loss: 2.122\n",
      "[11,   200] loss: 2.119\n",
      "[12,   100] loss: 2.109\n",
      "[12,   200] loss: 2.111\n",
      "[13,   100] loss: 2.113\n",
      "[13,   200] loss: 2.112\n",
      "[14,   100] loss: 2.136\n",
      "[14,   200] loss: 2.130\n",
      "[15,   100] loss: 2.109\n",
      "[15,   200] loss: 2.121\n",
      "[16,   100] loss: 2.111\n",
      "[16,   200] loss: 2.112\n",
      "[17,   100] loss: 2.108\n",
      "[17,   200] loss: 2.110\n",
      "[18,   100] loss: 2.113\n",
      "[18,   200] loss: 2.099\n",
      "[19,   100] loss: 2.105\n",
      "[19,   200] loss: 2.104\n",
      "[20,   100] loss: 2.114\n",
      "[20,   200] loss: 2.113\n",
      "[21,   100] loss: 2.115\n",
      "[21,   200] loss: 2.108\n",
      "[22,   100] loss: 2.106\n",
      "[22,   200] loss: 2.126\n",
      "[23,   100] loss: 2.105\n",
      "[23,   200] loss: 2.105\n",
      "[24,   100] loss: 2.126\n",
      "[24,   200] loss: 2.116\n",
      "[25,   100] loss: 2.116\n",
      "[25,   200] loss: 2.110\n",
      "[26,   100] loss: 2.111\n",
      "[26,   200] loss: 2.128\n",
      "[27,   100] loss: 2.123\n",
      "[27,   200] loss: 2.130\n",
      "[28,   100] loss: 2.125\n",
      "[28,   200] loss: 2.116\n",
      "[29,   100] loss: 2.125\n",
      "[29,   200] loss: 2.116\n",
      "[30,   100] loss: 2.116\n",
      "[30,   200] loss: 2.116\n",
      "[31,   100] loss: 2.117\n",
      "[31,   200] loss: 2.128\n",
      "[32,   100] loss: 2.123\n",
      "[32,   200] loss: 2.118\n",
      "[33,   100] loss: 2.119\n",
      "[33,   200] loss: 2.117\n",
      "[34,   100] loss: 2.141\n",
      "[34,   200] loss: 2.129\n",
      "[35,   100] loss: 2.128\n",
      "[35,   200] loss: 2.136\n",
      "[36,   100] loss: 2.139\n",
      "[36,   200] loss: 2.130\n",
      "[37,   100] loss: 2.128\n",
      "[37,   200] loss: 2.140\n",
      "[38,   100] loss: 2.127\n",
      "[38,   200] loss: 2.131\n",
      "[39,   100] loss: 2.150\n",
      "[39,   200] loss: 2.143\n",
      "[40,   100] loss: 2.142\n",
      "[40,   200] loss: 2.142\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.145\n",
      "[1,   200] loss: 1.998\n",
      "[2,   100] loss: 1.906\n",
      "[2,   200] loss: 1.891\n",
      "[3,   100] loss: 1.819\n",
      "[3,   200] loss: 1.792\n",
      "[4,   100] loss: 1.729\n",
      "[4,   200] loss: 1.710\n",
      "[5,   100] loss: 1.647\n",
      "[5,   200] loss: 1.612\n",
      "[6,   100] loss: 1.562\n",
      "[6,   200] loss: 1.560\n",
      "[7,   100] loss: 1.497\n",
      "[7,   200] loss: 1.491\n",
      "[8,   100] loss: 1.434\n",
      "[8,   200] loss: 1.480\n",
      "[9,   100] loss: 1.400\n",
      "[9,   200] loss: 1.410\n",
      "[10,   100] loss: 1.348\n",
      "[10,   200] loss: 1.343\n",
      "[11,   100] loss: 1.294\n",
      "[11,   200] loss: 1.318\n",
      "[12,   100] loss: 1.240\n",
      "[12,   200] loss: 1.265\n",
      "[13,   100] loss: 1.206\n",
      "[13,   200] loss: 1.227\n",
      "[14,   100] loss: 1.145\n",
      "[14,   200] loss: 1.201\n",
      "[15,   100] loss: 1.131\n",
      "[15,   200] loss: 1.146\n",
      "[16,   100] loss: 1.052\n",
      "[16,   200] loss: 1.127\n",
      "[17,   100] loss: 1.032\n",
      "[17,   200] loss: 1.073\n",
      "[18,   100] loss: 1.013\n",
      "[18,   200] loss: 1.045\n",
      "[19,   100] loss: 0.966\n",
      "[19,   200] loss: 1.008\n",
      "[20,   100] loss: 0.938\n",
      "[20,   200] loss: 0.960\n",
      "[21,   100] loss: 0.890\n",
      "[21,   200] loss: 0.938\n",
      "[22,   100] loss: 0.856\n",
      "[22,   200] loss: 0.904\n",
      "[23,   100] loss: 0.840\n",
      "[23,   200] loss: 0.887\n",
      "[24,   100] loss: 0.818\n",
      "[24,   200] loss: 0.847\n",
      "[25,   100] loss: 0.795\n",
      "[25,   200] loss: 0.805\n",
      "[26,   100] loss: 0.734\n",
      "[26,   200] loss: 0.795\n",
      "[27,   100] loss: 0.717\n",
      "[27,   200] loss: 0.773\n",
      "[28,   100] loss: 0.709\n",
      "[28,   200] loss: 0.717\n",
      "[29,   100] loss: 0.666\n",
      "[29,   200] loss: 0.705\n",
      "[30,   100] loss: 0.647\n",
      "[30,   200] loss: 0.663\n",
      "[31,   100] loss: 0.621\n",
      "[31,   200] loss: 0.653\n",
      "[32,   100] loss: 0.586\n",
      "[32,   200] loss: 0.629\n",
      "[33,   100] loss: 0.576\n",
      "[33,   200] loss: 0.623\n",
      "[34,   100] loss: 0.551\n",
      "[34,   200] loss: 0.609\n",
      "[35,   100] loss: 0.571\n",
      "[35,   200] loss: 0.579\n",
      "[36,   100] loss: 0.515\n",
      "[36,   200] loss: 0.559\n",
      "[37,   100] loss: 0.517\n",
      "[37,   200] loss: 0.533\n",
      "[38,   100] loss: 0.489\n",
      "[38,   200] loss: 0.549\n",
      "[39,   100] loss: 0.467\n",
      "[39,   200] loss: 0.515\n",
      "[40,   100] loss: 0.474\n",
      "[40,   200] loss: 0.491\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.323\n",
      "[1,   200] loss: 2.308\n",
      "[2,   100] loss: 2.274\n",
      "[2,   200] loss: 2.255\n",
      "[3,   100] loss: 2.255\n",
      "[3,   200] loss: 2.219\n",
      "[4,   100] loss: 2.191\n",
      "[4,   200] loss: 2.215\n",
      "[5,   100] loss: 2.191\n",
      "[5,   200] loss: 2.206\n",
      "[6,   100] loss: 2.194\n",
      "[6,   200] loss: 2.194\n",
      "[7,   100] loss: 2.141\n",
      "[7,   200] loss: 2.144\n",
      "[8,   100] loss: 2.110\n",
      "[8,   200] loss: 2.107\n",
      "[9,   100] loss: 2.101\n",
      "[9,   200] loss: 2.120\n",
      "[10,   100] loss: 2.079\n",
      "[10,   200] loss: 2.086\n",
      "[11,   100] loss: 2.094\n",
      "[11,   200] loss: 2.071\n",
      "[12,   100] loss: 2.115\n",
      "[12,   200] loss: 2.084\n",
      "[13,   100] loss: 2.083\n",
      "[13,   200] loss: 2.080\n",
      "[14,   100] loss: 2.078\n",
      "[14,   200] loss: 2.101\n",
      "[15,   100] loss: 2.065\n",
      "[15,   200] loss: 2.080\n",
      "[16,   100] loss: 2.088\n",
      "[16,   200] loss: 2.058\n",
      "[17,   100] loss: 2.066\n",
      "[17,   200] loss: 2.065\n",
      "[18,   100] loss: 2.065\n",
      "[18,   200] loss: 2.051\n",
      "[19,   100] loss: 2.046\n",
      "[19,   200] loss: 2.061\n",
      "[20,   100] loss: 2.064\n",
      "[20,   200] loss: 2.067\n",
      "[21,   100] loss: 2.056\n",
      "[21,   200] loss: 2.058\n",
      "[22,   100] loss: 2.042\n",
      "[22,   200] loss: 2.063\n",
      "[23,   100] loss: 2.071\n",
      "[23,   200] loss: 2.058\n",
      "[24,   100] loss: 2.078\n",
      "[24,   200] loss: 2.061\n",
      "[25,   100] loss: 2.082\n",
      "[25,   200] loss: 2.088\n",
      "[26,   100] loss: 2.065\n",
      "[26,   200] loss: 2.094\n",
      "[27,   100] loss: 2.075\n",
      "[27,   200] loss: 2.056\n",
      "[28,   100] loss: 2.082\n",
      "[28,   200] loss: 2.048\n",
      "[29,   100] loss: 2.077\n",
      "[29,   200] loss: 2.063\n",
      "[30,   100] loss: 2.078\n",
      "[30,   200] loss: 2.062\n",
      "[31,   100] loss: 2.068\n",
      "[31,   200] loss: 2.069\n",
      "[32,   100] loss: 2.058\n",
      "[32,   200] loss: 2.075\n",
      "[33,   100] loss: 2.080\n",
      "[33,   200] loss: 2.075\n",
      "[34,   100] loss: 2.073\n",
      "[34,   200] loss: 2.052\n",
      "[35,   100] loss: 2.066\n",
      "[35,   200] loss: 2.090\n",
      "[36,   100] loss: 2.089\n",
      "[36,   200] loss: 2.076\n",
      "[37,   100] loss: 2.095\n",
      "[37,   200] loss: 2.085\n",
      "[38,   100] loss: 2.081\n",
      "[38,   200] loss: 2.083\n",
      "[39,   100] loss: 2.084\n",
      "[39,   200] loss: 2.073\n",
      "[40,   100] loss: 2.067\n",
      "[40,   200] loss: 2.070\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.155\n",
      "[1,   200] loss: 2.033\n",
      "[2,   100] loss: 1.934\n",
      "[2,   200] loss: 1.897\n",
      "[3,   100] loss: 1.805\n",
      "[3,   200] loss: 1.754\n",
      "[4,   100] loss: 1.688\n",
      "[4,   200] loss: 1.677\n",
      "[5,   100] loss: 1.598\n",
      "[5,   200] loss: 1.602\n",
      "[6,   100] loss: 1.543\n",
      "[6,   200] loss: 1.532\n",
      "[7,   100] loss: 1.463\n",
      "[7,   200] loss: 1.488\n",
      "[8,   100] loss: 1.417\n",
      "[8,   200] loss: 1.427\n",
      "[9,   100] loss: 1.361\n",
      "[9,   200] loss: 1.374\n",
      "[10,   100] loss: 1.309\n",
      "[10,   200] loss: 1.305\n",
      "[11,   100] loss: 1.255\n",
      "[11,   200] loss: 1.265\n",
      "[12,   100] loss: 1.192\n",
      "[12,   200] loss: 1.230\n",
      "[13,   100] loss: 1.145\n",
      "[13,   200] loss: 1.191\n",
      "[14,   100] loss: 1.097\n",
      "[14,   200] loss: 1.140\n",
      "[15,   100] loss: 1.075\n",
      "[15,   200] loss: 1.081\n",
      "[16,   100] loss: 1.019\n",
      "[16,   200] loss: 1.062\n",
      "[17,   100] loss: 0.996\n",
      "[17,   200] loss: 1.026\n",
      "[18,   100] loss: 0.954\n",
      "[18,   200] loss: 0.991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19,   100] loss: 0.912\n",
      "[19,   200] loss: 0.964\n",
      "[20,   100] loss: 0.886\n",
      "[20,   200] loss: 0.907\n",
      "[21,   100] loss: 0.856\n",
      "[21,   200] loss: 0.892\n",
      "[22,   100] loss: 0.835\n",
      "[22,   200] loss: 0.859\n",
      "[23,   100] loss: 0.783\n",
      "[23,   200] loss: 0.844\n",
      "[24,   100] loss: 0.765\n",
      "[24,   200] loss: 0.778\n",
      "[25,   100] loss: 0.723\n",
      "[25,   200] loss: 0.755\n",
      "[26,   100] loss: 0.703\n",
      "[26,   200] loss: 0.741\n",
      "[27,   100] loss: 0.668\n",
      "[27,   200] loss: 0.713\n",
      "[28,   100] loss: 0.665\n",
      "[28,   200] loss: 0.671\n",
      "[29,   100] loss: 0.636\n",
      "[29,   200] loss: 0.676\n",
      "[30,   100] loss: 0.620\n",
      "[30,   200] loss: 0.640\n",
      "[31,   100] loss: 0.600\n",
      "[31,   200] loss: 0.617\n",
      "[32,   100] loss: 0.549\n",
      "[32,   200] loss: 0.579\n",
      "[33,   100] loss: 0.535\n",
      "[33,   200] loss: 0.567\n",
      "[34,   100] loss: 0.532\n",
      "[34,   200] loss: 0.539\n",
      "[35,   100] loss: 0.500\n",
      "[35,   200] loss: 0.535\n",
      "[36,   100] loss: 0.504\n",
      "[36,   200] loss: 0.523\n",
      "[37,   100] loss: 0.490\n",
      "[37,   200] loss: 0.505\n",
      "[38,   100] loss: 0.458\n",
      "[38,   200] loss: 0.505\n",
      "[39,   100] loss: 0.457\n",
      "[39,   200] loss: 0.487\n",
      "[40,   100] loss: 0.437\n",
      "[40,   200] loss: 0.487\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.347\n",
      "[1,   200] loss: 2.325\n",
      "[2,   100] loss: 2.321\n",
      "[2,   200] loss: 2.285\n",
      "[3,   100] loss: 2.306\n",
      "[3,   200] loss: 2.302\n",
      "[4,   100] loss: 2.269\n",
      "[4,   200] loss: 2.260\n",
      "[5,   100] loss: 2.254\n",
      "[5,   200] loss: 2.228\n",
      "[6,   100] loss: 2.188\n",
      "[6,   200] loss: 2.160\n",
      "[7,   100] loss: 2.136\n",
      "[7,   200] loss: 2.122\n",
      "[8,   100] loss: 2.112\n",
      "[8,   200] loss: 2.092\n",
      "[9,   100] loss: 2.090\n",
      "[9,   200] loss: 2.097\n",
      "[10,   100] loss: 2.097\n",
      "[10,   200] loss: 2.081\n",
      "[11,   100] loss: 2.113\n",
      "[11,   200] loss: 2.099\n",
      "[12,   100] loss: 2.090\n",
      "[12,   200] loss: 2.092\n",
      "[13,   100] loss: 2.080\n",
      "[13,   200] loss: 2.067\n",
      "[14,   100] loss: 2.078\n",
      "[14,   200] loss: 2.059\n",
      "[15,   100] loss: 2.080\n",
      "[15,   200] loss: 2.052\n",
      "[16,   100] loss: 2.076\n",
      "[16,   200] loss: 2.079\n",
      "[17,   100] loss: 2.063\n",
      "[17,   200] loss: 2.065\n",
      "[18,   100] loss: 2.052\n",
      "[18,   200] loss: 2.056\n",
      "[19,   100] loss: 2.067\n",
      "[19,   200] loss: 2.072\n",
      "[20,   100] loss: 2.051\n",
      "[20,   200] loss: 2.053\n",
      "[21,   100] loss: 2.082\n",
      "[21,   200] loss: 2.077\n",
      "[22,   100] loss: 2.054\n",
      "[22,   200] loss: 2.067\n",
      "[23,   100] loss: 2.055\n",
      "[23,   200] loss: 2.046\n",
      "[24,   100] loss: 2.067\n",
      "[24,   200] loss: 2.070\n",
      "[25,   100] loss: 2.051\n",
      "[25,   200] loss: 2.054\n",
      "[26,   100] loss: 2.037\n",
      "[26,   200] loss: 2.035\n",
      "[27,   100] loss: 2.059\n",
      "[27,   200] loss: 2.048\n",
      "[28,   100] loss: 2.042\n",
      "[28,   200] loss: 2.075\n",
      "[29,   100] loss: 2.050\n",
      "[29,   200] loss: 2.052\n",
      "[30,   100] loss: 2.043\n",
      "[30,   200] loss: 2.056\n",
      "[31,   100] loss: 2.032\n",
      "[31,   200] loss: 2.046\n",
      "[32,   100] loss: 2.045\n",
      "[32,   200] loss: 2.035\n",
      "[33,   100] loss: 2.057\n",
      "[33,   200] loss: 2.047\n",
      "[34,   100] loss: 2.044\n",
      "[34,   200] loss: 2.050\n",
      "[35,   100] loss: 2.040\n",
      "[35,   200] loss: 2.035\n",
      "[36,   100] loss: 2.029\n",
      "[36,   200] loss: 2.034\n",
      "[37,   100] loss: 2.037\n",
      "[37,   200] loss: 2.048\n",
      "[38,   100] loss: 2.029\n",
      "[38,   200] loss: 2.035\n",
      "[39,   100] loss: 2.034\n",
      "[39,   200] loss: 2.028\n",
      "[40,   100] loss: 2.037\n",
      "[40,   200] loss: 2.057\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.233\n",
      "[1,   200] loss: 2.140\n",
      "[2,   100] loss: 2.057\n",
      "[2,   200] loss: 1.988\n",
      "[3,   100] loss: 1.901\n",
      "[3,   200] loss: 1.846\n",
      "[4,   100] loss: 1.752\n",
      "[4,   200] loss: 1.736\n",
      "[5,   100] loss: 1.666\n",
      "[5,   200] loss: 1.633\n",
      "[6,   100] loss: 1.594\n",
      "[6,   200] loss: 1.578\n",
      "[7,   100] loss: 1.522\n",
      "[7,   200] loss: 1.521\n",
      "[8,   100] loss: 1.458\n",
      "[8,   200] loss: 1.478\n",
      "[9,   100] loss: 1.410\n",
      "[9,   200] loss: 1.412\n",
      "[10,   100] loss: 1.374\n",
      "[10,   200] loss: 1.382\n",
      "[11,   100] loss: 1.304\n",
      "[11,   200] loss: 1.322\n",
      "[12,   100] loss: 1.271\n",
      "[12,   200] loss: 1.280\n",
      "[13,   100] loss: 1.220\n",
      "[13,   200] loss: 1.248\n",
      "[14,   100] loss: 1.181\n",
      "[14,   200] loss: 1.205\n",
      "[15,   100] loss: 1.136\n",
      "[15,   200] loss: 1.164\n",
      "[16,   100] loss: 1.094\n",
      "[16,   200] loss: 1.112\n",
      "[17,   100] loss: 1.049\n",
      "[17,   200] loss: 1.092\n",
      "[18,   100] loss: 1.004\n",
      "[18,   200] loss: 1.037\n",
      "[19,   100] loss: 1.001\n",
      "[19,   200] loss: 1.013\n",
      "[20,   100] loss: 0.945\n",
      "[20,   200] loss: 0.980\n",
      "[21,   100] loss: 0.903\n",
      "[21,   200] loss: 0.943\n",
      "[22,   100] loss: 0.890\n",
      "[22,   200] loss: 0.931\n",
      "[23,   100] loss: 0.871\n",
      "[23,   200] loss: 0.903\n",
      "[24,   100] loss: 0.813\n",
      "[24,   200] loss: 0.845\n",
      "[25,   100] loss: 0.783\n",
      "[25,   200] loss: 0.819\n",
      "[26,   100] loss: 0.757\n",
      "[26,   200] loss: 0.811\n",
      "[27,   100] loss: 0.741\n",
      "[27,   200] loss: 0.756\n",
      "[28,   100] loss: 0.718\n",
      "[28,   200] loss: 0.749\n",
      "[29,   100] loss: 0.696\n",
      "[29,   200] loss: 0.722\n",
      "[30,   100] loss: 0.678\n",
      "[30,   200] loss: 0.703\n",
      "[31,   100] loss: 0.640\n",
      "[31,   200] loss: 0.691\n",
      "[32,   100] loss: 0.619\n",
      "[32,   200] loss: 0.661\n",
      "[33,   100] loss: 0.603\n",
      "[33,   200] loss: 0.635\n",
      "[34,   100] loss: 0.577\n",
      "[34,   200] loss: 0.607\n",
      "[35,   100] loss: 0.559\n",
      "[35,   200] loss: 0.600\n",
      "[36,   100] loss: 0.555\n",
      "[36,   200] loss: 0.587\n",
      "[37,   100] loss: 0.547\n",
      "[37,   200] loss: 0.579\n",
      "[38,   100] loss: 0.520\n",
      "[38,   200] loss: 0.568\n",
      "[39,   100] loss: 0.527\n",
      "[39,   200] loss: 0.558\n",
      "[40,   100] loss: 0.498\n",
      "[40,   200] loss: 0.531\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.283\n",
      "[1,   200] loss: 2.252\n",
      "[2,   100] loss: 2.237\n",
      "[2,   200] loss: 2.222\n",
      "[3,   100] loss: 2.189\n",
      "[3,   200] loss: 2.183\n",
      "[4,   100] loss: 2.218\n",
      "[4,   200] loss: 2.193\n",
      "[5,   100] loss: 2.176\n",
      "[5,   200] loss: 2.151\n",
      "[6,   100] loss: 2.122\n",
      "[6,   200] loss: 2.133\n",
      "[7,   100] loss: 2.135\n",
      "[7,   200] loss: 2.120\n",
      "[8,   100] loss: 2.101\n",
      "[8,   200] loss: 2.136\n",
      "[9,   100] loss: 2.142\n",
      "[9,   200] loss: 2.142\n",
      "[10,   100] loss: 2.117\n",
      "[10,   200] loss: 2.112\n",
      "[11,   100] loss: 2.098\n",
      "[11,   200] loss: 2.081\n",
      "[12,   100] loss: 2.077\n",
      "[12,   200] loss: 2.078\n",
      "[13,   100] loss: 2.081\n",
      "[13,   200] loss: 2.066\n",
      "[14,   100] loss: 2.045\n",
      "[14,   200] loss: 2.071\n",
      "[15,   100] loss: 2.073\n",
      "[15,   200] loss: 2.062\n",
      "[16,   100] loss: 2.060\n",
      "[16,   200] loss: 2.067\n",
      "[17,   100] loss: 2.068\n",
      "[17,   200] loss: 2.073\n",
      "[18,   100] loss: 2.079\n",
      "[18,   200] loss: 2.076\n",
      "[19,   100] loss: 2.073\n",
      "[19,   200] loss: 2.060\n",
      "[20,   100] loss: 2.070\n",
      "[20,   200] loss: 2.069\n",
      "[21,   100] loss: 2.042\n",
      "[21,   200] loss: 2.039\n",
      "[22,   100] loss: 2.041\n",
      "[22,   200] loss: 2.061\n",
      "[23,   100] loss: 2.036\n",
      "[23,   200] loss: 2.057\n",
      "[24,   100] loss: 2.051\n",
      "[24,   200] loss: 2.060\n",
      "[25,   100] loss: 2.053\n",
      "[25,   200] loss: 2.053\n",
      "[26,   100] loss: 2.046\n",
      "[26,   200] loss: 2.056\n",
      "[27,   100] loss: 2.039\n",
      "[27,   200] loss: 2.062\n",
      "[28,   100] loss: 2.060\n",
      "[28,   200] loss: 2.068\n",
      "[29,   100] loss: 2.051\n",
      "[29,   200] loss: 2.040\n",
      "[30,   100] loss: 2.045\n",
      "[30,   200] loss: 2.052\n",
      "[31,   100] loss: 2.055\n",
      "[31,   200] loss: 2.061\n",
      "[32,   100] loss: 2.045\n",
      "[32,   200] loss: 2.060\n",
      "[33,   100] loss: 2.049\n",
      "[33,   200] loss: 2.040\n",
      "[34,   100] loss: 2.066\n",
      "[34,   200] loss: 2.069\n",
      "[35,   100] loss: 2.056\n",
      "[35,   200] loss: 2.051\n",
      "[36,   100] loss: 2.057\n",
      "[36,   200] loss: 2.071\n",
      "[37,   100] loss: 2.077\n",
      "[37,   200] loss: 2.063\n",
      "[38,   100] loss: 2.054\n",
      "[38,   200] loss: 2.061\n",
      "[39,   100] loss: 2.055\n",
      "[39,   200] loss: 2.054\n",
      "[40,   100] loss: 2.064\n",
      "[40,   200] loss: 2.045\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.192\n",
      "[1,   200] loss: 2.006\n",
      "[2,   100] loss: 1.916\n",
      "[2,   200] loss: 1.888\n",
      "[3,   100] loss: 1.822\n",
      "[3,   200] loss: 1.786\n",
      "[4,   100] loss: 1.738\n",
      "[4,   200] loss: 1.726\n",
      "[5,   100] loss: 1.682\n",
      "[5,   200] loss: 1.668\n",
      "[6,   100] loss: 1.637\n",
      "[6,   200] loss: 1.616\n",
      "[7,   100] loss: 1.580\n",
      "[7,   200] loss: 1.571\n",
      "[8,   100] loss: 1.497\n",
      "[8,   200] loss: 1.505\n",
      "[9,   100] loss: 1.435\n",
      "[9,   200] loss: 1.447\n",
      "[10,   100] loss: 1.396\n",
      "[10,   200] loss: 1.392\n",
      "[11,   100] loss: 1.332\n",
      "[11,   200] loss: 1.366\n",
      "[12,   100] loss: 1.275\n",
      "[12,   200] loss: 1.325\n",
      "[13,   100] loss: 1.242\n",
      "[13,   200] loss: 1.262\n",
      "[14,   100] loss: 1.190\n",
      "[14,   200] loss: 1.232\n",
      "[15,   100] loss: 1.154\n",
      "[15,   200] loss: 1.188\n",
      "[16,   100] loss: 1.113\n",
      "[16,   200] loss: 1.140\n",
      "[17,   100] loss: 1.076\n",
      "[17,   200] loss: 1.105\n",
      "[18,   100] loss: 1.041\n",
      "[18,   200] loss: 1.061\n",
      "[19,   100] loss: 1.003\n",
      "[19,   200] loss: 1.041\n",
      "[20,   100] loss: 0.957\n",
      "[20,   200] loss: 1.002\n",
      "[21,   100] loss: 0.920\n",
      "[21,   200] loss: 0.953\n",
      "[22,   100] loss: 0.901\n",
      "[22,   200] loss: 0.929\n",
      "[23,   100] loss: 0.849\n",
      "[23,   200] loss: 0.908\n",
      "[24,   100] loss: 0.838\n",
      "[24,   200] loss: 0.863\n",
      "[25,   100] loss: 0.797\n",
      "[25,   200] loss: 0.836\n",
      "[26,   100] loss: 0.743\n",
      "[26,   200] loss: 0.792\n",
      "[27,   100] loss: 0.720\n",
      "[27,   200] loss: 0.774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28,   100] loss: 0.706\n",
      "[28,   200] loss: 0.736\n",
      "[29,   100] loss: 0.667\n",
      "[29,   200] loss: 0.719\n",
      "[30,   100] loss: 0.661\n",
      "[30,   200] loss: 0.681\n",
      "[31,   100] loss: 0.638\n",
      "[31,   200] loss: 0.663\n",
      "[32,   100] loss: 0.607\n",
      "[32,   200] loss: 0.629\n",
      "[33,   100] loss: 0.581\n",
      "[33,   200] loss: 0.617\n",
      "[34,   100] loss: 0.571\n",
      "[34,   200] loss: 0.592\n",
      "[35,   100] loss: 0.552\n",
      "[35,   200] loss: 0.575\n",
      "[36,   100] loss: 0.525\n",
      "[36,   200] loss: 0.542\n",
      "[37,   100] loss: 0.511\n",
      "[37,   200] loss: 0.535\n",
      "[38,   100] loss: 0.484\n",
      "[38,   200] loss: 0.524\n",
      "[39,   100] loss: 0.474\n",
      "[39,   200] loss: 0.506\n",
      "[40,   100] loss: 0.491\n",
      "[40,   200] loss: 0.508\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.344\n",
      "[1,   200] loss: 2.328\n",
      "[2,   100] loss: 2.317\n",
      "[2,   200] loss: 2.304\n",
      "[3,   100] loss: 2.302\n",
      "[3,   200] loss: 2.303\n",
      "[4,   100] loss: 2.307\n",
      "[4,   200] loss: 2.303\n",
      "[5,   100] loss: 2.305\n",
      "[5,   200] loss: 2.302\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[21,   100] loss: 2.303\n",
      "[21,   200] loss: 2.303\n",
      "[22,   100] loss: 2.303\n",
      "[22,   200] loss: 2.303\n",
      "[23,   100] loss: 2.303\n",
      "[23,   200] loss: 2.303\n",
      "[24,   100] loss: 2.303\n",
      "[24,   200] loss: 2.303\n",
      "[25,   100] loss: 2.303\n",
      "[25,   200] loss: 2.303\n",
      "[26,   100] loss: 2.303\n",
      "[26,   200] loss: 2.303\n",
      "[27,   100] loss: 2.303\n",
      "[27,   200] loss: 2.303\n",
      "[28,   100] loss: 2.303\n",
      "[28,   200] loss: 2.303\n",
      "[29,   100] loss: 2.303\n",
      "[29,   200] loss: 2.303\n",
      "[30,   100] loss: 2.303\n",
      "[30,   200] loss: 2.303\n",
      "[31,   100] loss: 2.303\n",
      "[31,   200] loss: 2.303\n",
      "[32,   100] loss: 2.303\n",
      "[32,   200] loss: 2.303\n",
      "[33,   100] loss: 2.303\n",
      "[33,   200] loss: 2.303\n",
      "[34,   100] loss: 2.303\n",
      "[34,   200] loss: 2.303\n",
      "[35,   100] loss: 2.303\n",
      "[35,   200] loss: 2.303\n",
      "[36,   100] loss: 2.303\n",
      "[36,   200] loss: 2.303\n",
      "[37,   100] loss: 2.303\n",
      "[37,   200] loss: 2.303\n",
      "[38,   100] loss: 2.303\n",
      "[38,   200] loss: 2.303\n",
      "[39,   100] loss: 2.303\n",
      "[39,   200] loss: 2.303\n",
      "[40,   100] loss: 2.303\n",
      "[40,   200] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.233\n",
      "[1,   200] loss: 2.105\n",
      "[2,   100] loss: 2.055\n",
      "[2,   200] loss: 2.003\n",
      "[3,   100] loss: 1.951\n",
      "[3,   200] loss: 1.891\n",
      "[4,   100] loss: 1.800\n",
      "[4,   200] loss: 1.749\n",
      "[5,   100] loss: 1.675\n",
      "[5,   200] loss: 1.660\n",
      "[6,   100] loss: 1.587\n",
      "[6,   200] loss: 1.596\n",
      "[7,   100] loss: 1.509\n",
      "[7,   200] loss: 1.526\n",
      "[8,   100] loss: 1.462\n",
      "[8,   200] loss: 1.461\n",
      "[9,   100] loss: 1.395\n",
      "[9,   200] loss: 1.407\n",
      "[10,   100] loss: 1.350\n",
      "[10,   200] loss: 1.353\n",
      "[11,   100] loss: 1.290\n",
      "[11,   200] loss: 1.314\n",
      "[12,   100] loss: 1.239\n",
      "[12,   200] loss: 1.281\n",
      "[13,   100] loss: 1.181\n",
      "[13,   200] loss: 1.204\n",
      "[14,   100] loss: 1.133\n",
      "[14,   200] loss: 1.179\n",
      "[15,   100] loss: 1.084\n",
      "[15,   200] loss: 1.132\n",
      "[16,   100] loss: 1.057\n",
      "[16,   200] loss: 1.087\n",
      "[17,   100] loss: 1.024\n",
      "[17,   200] loss: 1.062\n",
      "[18,   100] loss: 0.987\n",
      "[18,   200] loss: 1.023\n",
      "[19,   100] loss: 0.971\n",
      "[19,   200] loss: 0.971\n",
      "[20,   100] loss: 0.922\n",
      "[20,   200] loss: 0.941\n",
      "[21,   100] loss: 0.881\n",
      "[21,   200] loss: 0.906\n",
      "[22,   100] loss: 0.836\n",
      "[22,   200] loss: 0.888\n",
      "[23,   100] loss: 0.811\n",
      "[23,   200] loss: 0.858\n",
      "[24,   100] loss: 0.776\n",
      "[24,   200] loss: 0.824\n",
      "[25,   100] loss: 0.761\n",
      "[25,   200] loss: 0.787\n",
      "[26,   100] loss: 0.725\n",
      "[26,   200] loss: 0.764\n",
      "[27,   100] loss: 0.691\n",
      "[27,   200] loss: 0.729\n",
      "[28,   100] loss: 0.677\n",
      "[28,   200] loss: 0.688\n",
      "[29,   100] loss: 0.631\n",
      "[29,   200] loss: 0.687\n",
      "[30,   100] loss: 0.615\n",
      "[30,   200] loss: 0.660\n",
      "[31,   100] loss: 0.604\n",
      "[31,   200] loss: 0.615\n",
      "[32,   100] loss: 0.597\n",
      "[32,   200] loss: 0.610\n",
      "[33,   100] loss: 0.588\n",
      "[33,   200] loss: 0.585\n",
      "[34,   100] loss: 0.550\n",
      "[34,   200] loss: 0.561\n",
      "[35,   100] loss: 0.524\n",
      "[35,   200] loss: 0.562\n",
      "[36,   100] loss: 0.528\n",
      "[36,   200] loss: 0.543\n",
      "[37,   100] loss: 0.505\n",
      "[37,   200] loss: 0.519\n",
      "[38,   100] loss: 0.489\n",
      "[38,   200] loss: 0.513\n",
      "[39,   100] loss: 0.460\n",
      "[39,   200] loss: 0.504\n",
      "[40,   100] loss: 0.453\n",
      "[40,   200] loss: 0.490\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.326\n",
      "[1,   200] loss: 2.311\n",
      "[2,   100] loss: 2.295\n",
      "[2,   200] loss: 2.302\n",
      "[3,   100] loss: 2.306\n",
      "[3,   200] loss: 2.299\n",
      "[4,   100] loss: 2.287\n",
      "[4,   200] loss: 2.279\n",
      "[5,   100] loss: 2.278\n",
      "[5,   200] loss: 2.273\n",
      "[6,   100] loss: 2.261\n",
      "[6,   200] loss: 2.261\n",
      "[7,   100] loss: 2.249\n",
      "[7,   200] loss: 2.244\n",
      "[8,   100] loss: 2.244\n",
      "[8,   200] loss: 2.244\n",
      "[9,   100] loss: 2.235\n",
      "[9,   200] loss: 2.235\n",
      "[10,   100] loss: 2.231\n",
      "[10,   200] loss: 2.235\n",
      "[11,   100] loss: 2.234\n",
      "[11,   200] loss: 2.225\n",
      "[12,   100] loss: 2.227\n",
      "[12,   200] loss: 2.230\n",
      "[13,   100] loss: 2.229\n",
      "[13,   200] loss: 2.234\n",
      "[14,   100] loss: 2.240\n",
      "[14,   200] loss: 2.232\n",
      "[15,   100] loss: 2.224\n",
      "[15,   200] loss: 2.221\n",
      "[16,   100] loss: 2.216\n",
      "[16,   200] loss: 2.223\n",
      "[17,   100] loss: 2.222\n",
      "[17,   200] loss: 2.215\n",
      "[18,   100] loss: 2.223\n",
      "[18,   200] loss: 2.223\n",
      "[19,   100] loss: 2.222\n",
      "[19,   200] loss: 2.212\n",
      "[20,   100] loss: 2.221\n",
      "[20,   200] loss: 2.216\n",
      "[21,   100] loss: 2.216\n",
      "[21,   200] loss: 2.227\n",
      "[22,   100] loss: 2.219\n",
      "[22,   200] loss: 2.232\n",
      "[23,   100] loss: 2.222\n",
      "[23,   200] loss: 2.216\n",
      "[24,   100] loss: 2.215\n",
      "[24,   200] loss: 2.218\n",
      "[25,   100] loss: 2.216\n",
      "[25,   200] loss: 2.218\n",
      "[26,   100] loss: 2.211\n",
      "[26,   200] loss: 2.217\n",
      "[27,   100] loss: 2.213\n",
      "[27,   200] loss: 2.213\n",
      "[28,   100] loss: 2.210\n",
      "[28,   200] loss: 2.218\n",
      "[29,   100] loss: 2.220\n",
      "[29,   200] loss: 2.229\n",
      "[30,   100] loss: 2.203\n",
      "[30,   200] loss: 2.200\n",
      "[31,   100] loss: 2.220\n",
      "[31,   200] loss: 2.222\n",
      "[32,   100] loss: 2.227\n",
      "[32,   200] loss: 2.223\n",
      "[33,   100] loss: 2.224\n",
      "[33,   200] loss: 2.222\n",
      "[34,   100] loss: 2.226\n",
      "[34,   200] loss: 2.225\n",
      "[35,   100] loss: 2.224\n",
      "[35,   200] loss: 2.233\n",
      "[36,   100] loss: 2.229\n",
      "[36,   200] loss: 2.216\n",
      "[37,   100] loss: 2.215\n",
      "[37,   200] loss: 2.228\n",
      "[38,   100] loss: 2.227\n",
      "[38,   200] loss: 2.230\n",
      "[39,   100] loss: 2.213\n",
      "[39,   200] loss: 2.230\n",
      "[40,   100] loss: 2.221\n",
      "[40,   200] loss: 2.227\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.184\n",
      "[1,   200] loss: 2.022\n",
      "[2,   100] loss: 1.920\n",
      "[2,   200] loss: 1.893\n",
      "[3,   100] loss: 1.826\n",
      "[3,   200] loss: 1.787\n",
      "[4,   100] loss: 1.756\n",
      "[4,   200] loss: 1.749\n",
      "[5,   100] loss: 1.693\n",
      "[5,   200] loss: 1.708\n",
      "[6,   100] loss: 1.642\n",
      "[6,   200] loss: 1.641\n",
      "[7,   100] loss: 1.607\n",
      "[7,   200] loss: 1.574\n",
      "[8,   100] loss: 1.529\n",
      "[8,   200] loss: 1.504\n",
      "[9,   100] loss: 1.455\n",
      "[9,   200] loss: 1.464\n",
      "[10,   100] loss: 1.396\n",
      "[10,   200] loss: 1.405\n",
      "[11,   100] loss: 1.335\n",
      "[11,   200] loss: 1.360\n",
      "[12,   100] loss: 1.288\n",
      "[12,   200] loss: 1.312\n",
      "[13,   100] loss: 1.236\n",
      "[13,   200] loss: 1.261\n",
      "[14,   100] loss: 1.184\n",
      "[14,   200] loss: 1.220\n",
      "[15,   100] loss: 1.143\n",
      "[15,   200] loss: 1.173\n",
      "[16,   100] loss: 1.108\n",
      "[16,   200] loss: 1.130\n",
      "[17,   100] loss: 1.057\n",
      "[17,   200] loss: 1.091\n",
      "[18,   100] loss: 1.023\n",
      "[18,   200] loss: 1.067\n",
      "[19,   100] loss: 0.981\n",
      "[19,   200] loss: 1.032\n",
      "[20,   100] loss: 0.963\n",
      "[20,   200] loss: 0.992\n",
      "[21,   100] loss: 0.925\n",
      "[21,   200] loss: 0.947\n",
      "[22,   100] loss: 0.877\n",
      "[22,   200] loss: 0.917\n",
      "[23,   100] loss: 0.843\n",
      "[23,   200] loss: 0.874\n",
      "[24,   100] loss: 0.796\n",
      "[24,   200] loss: 0.868\n",
      "[25,   100] loss: 0.783\n",
      "[25,   200] loss: 0.806\n",
      "[26,   100] loss: 0.750\n",
      "[26,   200] loss: 0.786\n",
      "[27,   100] loss: 0.718\n",
      "[27,   200] loss: 0.767\n",
      "[28,   100] loss: 0.695\n",
      "[28,   200] loss: 0.729\n",
      "[29,   100] loss: 0.680\n",
      "[29,   200] loss: 0.705\n",
      "[30,   100] loss: 0.640\n",
      "[30,   200] loss: 0.659\n",
      "[31,   100] loss: 0.615\n",
      "[31,   200] loss: 0.648\n",
      "[32,   100] loss: 0.580\n",
      "[32,   200] loss: 0.622\n",
      "[33,   100] loss: 0.571\n",
      "[33,   200] loss: 0.609\n",
      "[34,   100] loss: 0.540\n",
      "[34,   200] loss: 0.583\n",
      "[35,   100] loss: 0.520\n",
      "[35,   200] loss: 0.560\n",
      "[36,   100] loss: 0.487\n",
      "[36,   200] loss: 0.557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37,   100] loss: 0.496\n",
      "[37,   200] loss: 0.539\n",
      "[38,   100] loss: 0.480\n",
      "[38,   200] loss: 0.508\n",
      "[39,   100] loss: 0.462\n",
      "[39,   200] loss: 0.500\n",
      "[40,   100] loss: 0.444\n",
      "[40,   200] loss: 0.489\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.308\n",
      "[1,   200] loss: 2.294\n",
      "[2,   100] loss: 2.253\n",
      "[2,   200] loss: 2.247\n",
      "[3,   100] loss: 2.235\n",
      "[3,   200] loss: 2.198\n",
      "[4,   100] loss: 2.193\n",
      "[4,   200] loss: 2.197\n",
      "[5,   100] loss: 2.168\n",
      "[5,   200] loss: 2.164\n",
      "[6,   100] loss: 2.165\n",
      "[6,   200] loss: 2.166\n",
      "[7,   100] loss: 2.144\n",
      "[7,   200] loss: 2.146\n",
      "[8,   100] loss: 2.142\n",
      "[8,   200] loss: 2.153\n",
      "[9,   100] loss: 2.162\n",
      "[9,   200] loss: 2.128\n",
      "[10,   100] loss: 2.133\n",
      "[10,   200] loss: 2.145\n",
      "[11,   100] loss: 2.123\n",
      "[11,   200] loss: 2.138\n",
      "[12,   100] loss: 2.131\n",
      "[12,   200] loss: 2.130\n",
      "[13,   100] loss: 2.141\n",
      "[13,   200] loss: 2.141\n",
      "[14,   100] loss: 2.135\n",
      "[14,   200] loss: 2.147\n",
      "[15,   100] loss: 2.135\n",
      "[15,   200] loss: 2.131\n",
      "[16,   100] loss: 2.145\n",
      "[16,   200] loss: 2.124\n",
      "[17,   100] loss: 2.130\n",
      "[17,   200] loss: 2.130\n",
      "[18,   100] loss: 2.131\n",
      "[18,   200] loss: 2.128\n",
      "[19,   100] loss: 2.123\n",
      "[19,   200] loss: 2.132\n",
      "[20,   100] loss: 2.123\n",
      "[20,   200] loss: 2.143\n",
      "[21,   100] loss: 2.158\n",
      "[21,   200] loss: 2.150\n",
      "[22,   100] loss: 2.139\n",
      "[22,   200] loss: 2.151\n",
      "[23,   100] loss: 2.140\n",
      "[23,   200] loss: 2.135\n",
      "[24,   100] loss: 2.128\n",
      "[24,   200] loss: 2.137\n",
      "[25,   100] loss: 2.143\n",
      "[25,   200] loss: 2.130\n",
      "[26,   100] loss: 2.131\n",
      "[26,   200] loss: 2.137\n",
      "[27,   100] loss: 2.133\n",
      "[27,   200] loss: 2.138\n",
      "[28,   100] loss: 2.136\n",
      "[28,   200] loss: 2.154\n",
      "[29,   100] loss: 2.134\n",
      "[29,   200] loss: 2.148\n",
      "[30,   100] loss: 2.138\n",
      "[30,   200] loss: 2.151\n",
      "[31,   100] loss: 2.143\n",
      "[31,   200] loss: 2.130\n",
      "[32,   100] loss: 2.147\n",
      "[32,   200] loss: 2.145\n",
      "[33,   100] loss: 2.151\n",
      "[33,   200] loss: 2.154\n",
      "[34,   100] loss: 2.137\n",
      "[34,   200] loss: 2.151\n",
      "[35,   100] loss: 2.148\n",
      "[35,   200] loss: 2.153\n",
      "[36,   100] loss: 2.153\n",
      "[36,   200] loss: 2.149\n",
      "[37,   100] loss: 2.157\n",
      "[37,   200] loss: 2.153\n",
      "[38,   100] loss: 2.146\n",
      "[38,   200] loss: 2.153\n",
      "[39,   100] loss: 2.139\n",
      "[39,   200] loss: 2.137\n",
      "[40,   100] loss: 2.148\n",
      "[40,   200] loss: 2.150\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.212\n",
      "[1,   200] loss: 2.062\n",
      "[2,   100] loss: 2.021\n",
      "[2,   200] loss: 1.979\n",
      "[3,   100] loss: 1.878\n",
      "[3,   200] loss: 1.840\n",
      "[4,   100] loss: 1.762\n",
      "[4,   200] loss: 1.769\n",
      "[5,   100] loss: 1.699\n",
      "[5,   200] loss: 1.653\n",
      "[6,   100] loss: 1.602\n",
      "[6,   200] loss: 1.599\n",
      "[7,   100] loss: 1.544\n",
      "[7,   200] loss: 1.539\n",
      "[8,   100] loss: 1.492\n",
      "[8,   200] loss: 1.487\n",
      "[9,   100] loss: 1.426\n",
      "[9,   200] loss: 1.443\n",
      "[10,   100] loss: 1.385\n",
      "[10,   200] loss: 1.379\n",
      "[11,   100] loss: 1.330\n",
      "[11,   200] loss: 1.334\n",
      "[12,   100] loss: 1.270\n",
      "[12,   200] loss: 1.299\n",
      "[13,   100] loss: 1.225\n",
      "[13,   200] loss: 1.264\n",
      "[14,   100] loss: 1.182\n",
      "[14,   200] loss: 1.215\n",
      "[15,   100] loss: 1.140\n",
      "[15,   200] loss: 1.174\n",
      "[16,   100] loss: 1.101\n",
      "[16,   200] loss: 1.119\n",
      "[17,   100] loss: 1.053\n",
      "[17,   200] loss: 1.095\n",
      "[18,   100] loss: 1.017\n",
      "[18,   200] loss: 1.057\n",
      "[19,   100] loss: 0.985\n",
      "[19,   200] loss: 1.021\n",
      "[20,   100] loss: 0.947\n",
      "[20,   200] loss: 0.979\n",
      "[21,   100] loss: 0.918\n",
      "[21,   200] loss: 0.953\n",
      "[22,   100] loss: 0.890\n",
      "[22,   200] loss: 0.916\n",
      "[23,   100] loss: 0.840\n",
      "[23,   200] loss: 0.895\n",
      "[24,   100] loss: 0.815\n",
      "[24,   200] loss: 0.848\n",
      "[25,   100] loss: 0.791\n",
      "[25,   200] loss: 0.821\n",
      "[26,   100] loss: 0.777\n",
      "[26,   200] loss: 0.779\n",
      "[27,   100] loss: 0.716\n",
      "[27,   200] loss: 0.760\n",
      "[28,   100] loss: 0.696\n",
      "[28,   200] loss: 0.745\n",
      "[29,   100] loss: 0.672\n",
      "[29,   200] loss: 0.698\n",
      "[30,   100] loss: 0.646\n",
      "[30,   200] loss: 0.675\n",
      "[31,   100] loss: 0.615\n",
      "[31,   200] loss: 0.638\n",
      "[32,   100] loss: 0.593\n",
      "[32,   200] loss: 0.636\n",
      "[33,   100] loss: 0.577\n",
      "[33,   200] loss: 0.619\n",
      "[34,   100] loss: 0.563\n",
      "[34,   200] loss: 0.599\n",
      "[35,   100] loss: 0.539\n",
      "[35,   200] loss: 0.578\n",
      "[36,   100] loss: 0.547\n",
      "[36,   200] loss: 0.566\n",
      "[37,   100] loss: 0.510\n",
      "[37,   200] loss: 0.538\n",
      "[38,   100] loss: 0.477\n",
      "[38,   200] loss: 0.527\n",
      "[39,   100] loss: 0.474\n",
      "[39,   200] loss: 0.523\n",
      "[40,   100] loss: 0.479\n",
      "[40,   200] loss: 0.485\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.294\n",
      "[1,   200] loss: 2.294\n",
      "[2,   100] loss: 2.283\n",
      "[2,   200] loss: 2.205\n",
      "[3,   100] loss: 2.174\n",
      "[3,   200] loss: 2.176\n",
      "[4,   100] loss: 2.128\n",
      "[4,   200] loss: 2.126\n",
      "[5,   100] loss: 2.133\n",
      "[5,   200] loss: 2.124\n",
      "[6,   100] loss: 2.105\n",
      "[6,   200] loss: 2.125\n",
      "[7,   100] loss: 2.127\n",
      "[7,   200] loss: 2.092\n",
      "[8,   100] loss: 2.086\n",
      "[8,   200] loss: 2.078\n",
      "[9,   100] loss: 2.084\n",
      "[9,   200] loss: 2.090\n",
      "[10,   100] loss: 2.075\n",
      "[10,   200] loss: 2.060\n",
      "[11,   100] loss: 2.083\n",
      "[11,   200] loss: 2.078\n",
      "[12,   100] loss: 2.067\n",
      "[12,   200] loss: 2.097\n",
      "[13,   100] loss: 2.058\n",
      "[13,   200] loss: 2.078\n",
      "[14,   100] loss: 2.059\n",
      "[14,   200] loss: 2.059\n",
      "[15,   100] loss: 2.068\n",
      "[15,   200] loss: 2.060\n",
      "[16,   100] loss: 2.041\n",
      "[16,   200] loss: 2.044\n",
      "[17,   100] loss: 2.037\n",
      "[17,   200] loss: 2.053\n",
      "[18,   100] loss: 2.046\n",
      "[18,   200] loss: 2.058\n",
      "[19,   100] loss: 2.034\n",
      "[19,   200] loss: 2.052\n",
      "[20,   100] loss: 2.031\n",
      "[20,   200] loss: 2.029\n",
      "[21,   100] loss: 2.023\n",
      "[21,   200] loss: 2.050\n",
      "[22,   100] loss: 2.030\n",
      "[22,   200] loss: 2.060\n",
      "[23,   100] loss: 2.050\n",
      "[23,   200] loss: 2.052\n",
      "[24,   100] loss: 2.057\n",
      "[24,   200] loss: 2.078\n",
      "[25,   100] loss: 2.066\n",
      "[25,   200] loss: 2.052\n",
      "[26,   100] loss: 2.045\n",
      "[26,   200] loss: 2.032\n",
      "[27,   100] loss: 2.058\n",
      "[27,   200] loss: 2.055\n",
      "[28,   100] loss: 2.051\n",
      "[28,   200] loss: 2.059\n",
      "[29,   100] loss: 2.076\n",
      "[29,   200] loss: 2.058\n",
      "[30,   100] loss: 2.062\n",
      "[30,   200] loss: 2.062\n",
      "[31,   100] loss: 2.063\n",
      "[31,   200] loss: 2.061\n",
      "[32,   100] loss: 2.044\n",
      "[32,   200] loss: 2.063\n",
      "[33,   100] loss: 2.065\n",
      "[33,   200] loss: 2.054\n",
      "[34,   100] loss: 2.076\n",
      "[34,   200] loss: 2.073\n",
      "[35,   100] loss: 2.036\n",
      "[35,   200] loss: 2.042\n",
      "[36,   100] loss: 2.046\n",
      "[36,   200] loss: 2.041\n",
      "[37,   100] loss: 2.035\n",
      "[37,   200] loss: 2.025\n",
      "[38,   100] loss: 2.041\n",
      "[38,   200] loss: 2.049\n",
      "[39,   100] loss: 2.040\n",
      "[39,   200] loss: 2.034\n",
      "[40,   100] loss: 2.047\n",
      "[40,   200] loss: 2.054\n",
      "Finished training!\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAFNCAYAAADSGTgvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKyIiIiIiIlXO/wH57jgP3B+iDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0e4005ae10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IP Net\n",
      "[1,   100] loss: 2.318\n",
      "[1,   200] loss: 2.241\n",
      "[2,   100] loss: 2.186\n",
      "[2,   200] loss: 2.147\n",
      "[3,   100] loss: 2.103\n",
      "[3,   200] loss: 2.104\n",
      "[4,   100] loss: 2.075\n",
      "[4,   200] loss: 2.069\n",
      "[5,   100] loss: 2.045\n",
      "[5,   200] loss: 2.039\n",
      "[6,   100] loss: 2.013\n",
      "[6,   200] loss: 2.008\n",
      "[7,   100] loss: 1.992\n",
      "[7,   200] loss: 1.996\n",
      "[8,   100] loss: 2.000\n",
      "[8,   200] loss: 2.002\n",
      "[9,   100] loss: 1.984\n",
      "[9,   200] loss: 1.968\n",
      "[10,   100] loss: 1.971\n",
      "[10,   200] loss: 1.958\n",
      "[11,   100] loss: 1.959\n",
      "[11,   200] loss: 1.933\n",
      "[12,   100] loss: 1.927\n",
      "[12,   200] loss: 1.933\n",
      "[13,   100] loss: 1.930\n",
      "[13,   200] loss: 1.924\n",
      "[14,   100] loss: 1.920\n",
      "[14,   200] loss: 1.910\n",
      "[15,   100] loss: 1.915\n",
      "[15,   200] loss: 1.945\n",
      "[16,   100] loss: 1.932\n",
      "[16,   200] loss: 1.940\n",
      "[17,   100] loss: 1.933\n",
      "[17,   200] loss: 1.940\n",
      "[18,   100] loss: 1.930\n",
      "[18,   200] loss: 1.929\n",
      "[19,   100] loss: 1.931\n",
      "[19,   200] loss: 1.913\n",
      "[20,   100] loss: 1.907\n",
      "[20,   200] loss: 1.916\n",
      "[21,   100] loss: 1.904\n",
      "[21,   200] loss: 1.932\n",
      "[22,   100] loss: 1.920\n",
      "[22,   200] loss: 1.928\n",
      "[23,   100] loss: 1.925\n",
      "[23,   200] loss: 1.935\n",
      "[24,   100] loss: 1.903\n",
      "[24,   200] loss: 1.913\n",
      "[25,   100] loss: 1.896\n",
      "[25,   200] loss: 1.899\n",
      "[26,   100] loss: 1.885\n",
      "[26,   200] loss: 1.892\n",
      "[27,   100] loss: 1.904\n",
      "[27,   200] loss: 1.888\n",
      "[28,   100] loss: 1.866\n",
      "[28,   200] loss: 1.882\n",
      "[29,   100] loss: 1.857\n",
      "[29,   200] loss: 1.876\n",
      "[30,   100] loss: 1.851\n",
      "[30,   200] loss: 1.850\n",
      "[31,   100] loss: 1.829\n",
      "[31,   200] loss: 1.850\n",
      "[32,   100] loss: 1.822\n",
      "[32,   200] loss: 1.921\n",
      "[33,   100] loss: 2.303\n",
      "[33,   200] loss: 2.303\n",
      "[34,   100] loss: 2.303\n",
      "[34,   200] loss: 2.303\n",
      "[35,   100] loss: 2.303\n",
      "[35,   200] loss: 2.303\n",
      "[36,   100] loss: 2.303\n",
      "[36,   200] loss: 2.303\n",
      "[37,   100] loss: 2.303\n",
      "[37,   200] loss: 2.303\n",
      "[38,   100] loss: 2.303\n",
      "[38,   200] loss: 2.303\n",
      "[39,   100] loss: 2.303\n",
      "[39,   200] loss: 2.303\n",
      "[40,   100] loss: 2.303\n",
      "[40,   200] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.388\n",
      "[1,   200] loss: 2.329\n",
      "[2,   100] loss: 2.301\n",
      "[2,   200] loss: 2.261\n",
      "[3,   100] loss: 2.241\n",
      "[3,   200] loss: 2.221\n",
      "[4,   100] loss: 2.226\n",
      "[4,   200] loss: 2.232\n",
      "[5,   100] loss: 2.202\n",
      "[5,   200] loss: 2.228\n",
      "[6,   100] loss: 2.204\n",
      "[6,   200] loss: 2.183\n",
      "[7,   100] loss: 2.208\n",
      "[7,   200] loss: 2.190\n",
      "[8,   100] loss: 2.211\n",
      "[8,   200] loss: 2.221\n",
      "[9,   100] loss: 2.205\n",
      "[9,   200] loss: 2.199\n",
      "[10,   100] loss: 2.200\n",
      "[10,   200] loss: 2.214\n",
      "[11,   100] loss: 2.209\n",
      "[11,   200] loss: 2.219\n",
      "[12,   100] loss: 2.231\n",
      "[12,   200] loss: 2.223\n",
      "[13,   100] loss: 2.233\n",
      "[13,   200] loss: 2.248\n",
      "[14,   100] loss: 2.240\n",
      "[14,   200] loss: 2.223\n",
      "[15,   100] loss: 2.236\n",
      "[15,   200] loss: 2.239\n",
      "[16,   100] loss: 2.244\n",
      "[16,   200] loss: 2.240\n",
      "[17,   100] loss: 2.243\n",
      "[17,   200] loss: 2.247\n",
      "[18,   100] loss: 2.231\n",
      "[18,   200] loss: 2.245\n",
      "[19,   100] loss: 2.235\n",
      "[19,   200] loss: 2.247\n",
      "[20,   100] loss: 2.239\n",
      "[20,   200] loss: 2.248\n",
      "[21,   100] loss: 2.236\n",
      "[21,   200] loss: 2.235\n",
      "[22,   100] loss: 2.235\n",
      "[22,   200] loss: 2.245\n",
      "[23,   100] loss: 2.242\n",
      "[23,   200] loss: 2.241\n",
      "[24,   100] loss: 2.248\n",
      "[24,   200] loss: 2.259\n",
      "[25,   100] loss: 2.234\n",
      "[25,   200] loss: 2.251\n",
      "[26,   100] loss: 2.248\n",
      "[26,   200] loss: 2.240\n",
      "[27,   100] loss: 2.241\n",
      "[27,   200] loss: 2.250\n",
      "[28,   100] loss: 2.264\n",
      "[28,   200] loss: 2.251\n",
      "[29,   100] loss: 2.245\n",
      "[29,   200] loss: 2.249\n",
      "[30,   100] loss: 2.244\n",
      "[30,   200] loss: 2.251\n",
      "[31,   100] loss: 2.241\n",
      "[31,   200] loss: 2.255\n",
      "[32,   100] loss: 2.225\n",
      "[32,   200] loss: 2.249\n",
      "[33,   100] loss: 2.242\n",
      "[33,   200] loss: 2.248\n",
      "[34,   100] loss: 2.264\n",
      "[34,   200] loss: 2.258\n",
      "[35,   100] loss: 2.250\n",
      "[35,   200] loss: 2.237\n",
      "[36,   100] loss: 2.236\n",
      "[36,   200] loss: 2.268\n",
      "[37,   100] loss: 2.245\n",
      "[37,   200] loss: 2.256\n",
      "[38,   100] loss: 2.251\n",
      "[38,   200] loss: 2.237\n",
      "[39,   100] loss: 2.272\n",
      "[39,   200] loss: 2.253\n",
      "[40,   100] loss: 2.243\n",
      "[40,   200] loss: 2.246\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.298\n",
      "[1,   200] loss: 2.161\n",
      "[2,   100] loss: 2.101\n",
      "[2,   200] loss: 2.093\n",
      "[3,   100] loss: 2.042\n",
      "[3,   200] loss: 2.030\n",
      "[4,   100] loss: 2.003\n",
      "[4,   200] loss: 2.015\n",
      "[5,   100] loss: 1.975\n",
      "[5,   200] loss: 1.963\n",
      "[6,   100] loss: 1.949\n",
      "[6,   200] loss: 1.954\n",
      "[7,   100] loss: 1.925\n",
      "[7,   200] loss: 1.934\n",
      "[8,   100] loss: 1.855\n",
      "[8,   200] loss: 1.844\n",
      "[9,   100] loss: 1.808\n",
      "[9,   200] loss: 1.787\n",
      "[10,   100] loss: 1.761\n",
      "[10,   200] loss: 1.756\n",
      "[11,   100] loss: 1.715\n",
      "[11,   200] loss: 1.732\n",
      "[12,   100] loss: 1.714\n",
      "[12,   200] loss: 1.698\n",
      "[13,   100] loss: 1.661\n",
      "[13,   200] loss: 1.675\n",
      "[14,   100] loss: 1.626\n",
      "[14,   200] loss: 1.655\n",
      "[15,   100] loss: 1.639\n",
      "[15,   200] loss: 1.631\n",
      "[16,   100] loss: 1.619\n",
      "[16,   200] loss: 1.657\n",
      "[17,   100] loss: 1.611\n",
      "[17,   200] loss: 1.622\n",
      "[18,   100] loss: 1.595\n",
      "[18,   200] loss: 1.630\n",
      "[19,   100] loss: 1.590\n",
      "[19,   200] loss: 1.607\n",
      "[20,   100] loss: 1.602\n",
      "[20,   200] loss: 1.624\n",
      "[21,   100] loss: 1.576\n",
      "[21,   200] loss: 1.571\n",
      "[22,   100] loss: 1.534\n",
      "[22,   200] loss: 1.547\n",
      "[23,   100] loss: 1.554\n",
      "[23,   200] loss: 1.529\n",
      "[24,   100] loss: 1.518\n",
      "[24,   200] loss: 1.525\n",
      "[25,   100] loss: 1.484\n",
      "[25,   200] loss: 1.480\n",
      "[26,   100] loss: 1.475\n",
      "[26,   200] loss: 1.493\n",
      "[27,   100] loss: 1.458\n",
      "[27,   200] loss: 1.493\n",
      "[28,   100] loss: 1.441\n",
      "[28,   200] loss: 1.491\n",
      "[29,   100] loss: 1.451\n",
      "[29,   200] loss: 1.457\n",
      "[30,   100] loss: 1.410\n",
      "[30,   200] loss: 1.434\n",
      "[31,   100] loss: 1.412\n",
      "[31,   200] loss: 1.468\n",
      "[32,   100] loss: 1.419\n",
      "[32,   200] loss: 1.444\n",
      "[33,   100] loss: 1.392\n",
      "[33,   200] loss: 1.416\n",
      "[34,   100] loss: 1.384\n",
      "[34,   200] loss: 1.422\n",
      "[35,   100] loss: 1.368\n",
      "[35,   200] loss: 1.416\n",
      "[36,   100] loss: 1.350\n",
      "[36,   200] loss: 1.383\n",
      "[37,   100] loss: 1.384\n",
      "[37,   200] loss: 1.387\n",
      "[38,   100] loss: 1.383\n",
      "[38,   200] loss: 1.363\n",
      "[39,   100] loss: 1.365\n",
      "[39,   200] loss: 1.375\n",
      "[40,   100] loss: 1.350\n",
      "[40,   200] loss: 1.372\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.346\n",
      "[1,   200] loss: 2.294\n",
      "[2,   100] loss: 2.233\n",
      "[2,   200] loss: 2.244\n",
      "[3,   100] loss: 2.226\n",
      "[3,   200] loss: 2.209\n",
      "[4,   100] loss: 2.180\n",
      "[4,   200] loss: 2.238\n",
      "[5,   100] loss: 2.214\n",
      "[5,   200] loss: 2.205\n",
      "[6,   100] loss: 2.199\n",
      "[6,   200] loss: 2.215\n",
      "[7,   100] loss: 2.207\n",
      "[7,   200] loss: 2.206\n",
      "[8,   100] loss: 2.193\n",
      "[8,   200] loss: 2.188\n",
      "[9,   100] loss: 2.201\n",
      "[9,   200] loss: 2.201\n",
      "[10,   100] loss: 2.203\n",
      "[10,   200] loss: 2.197\n",
      "[11,   100] loss: 2.226\n",
      "[11,   200] loss: 2.246\n",
      "[12,   100] loss: 2.241\n",
      "[12,   200] loss: 2.226\n",
      "[13,   100] loss: 2.231\n",
      "[13,   200] loss: 2.240\n",
      "[14,   100] loss: 2.245\n",
      "[14,   200] loss: 2.251\n",
      "[15,   100] loss: 2.241\n",
      "[15,   200] loss: 2.242\n",
      "[16,   100] loss: 2.238\n",
      "[16,   200] loss: 2.240\n",
      "[17,   100] loss: 2.235\n",
      "[17,   200] loss: 2.252\n",
      "[18,   100] loss: 2.238\n",
      "[18,   200] loss: 2.242\n",
      "[19,   100] loss: 2.249\n",
      "[19,   200] loss: 2.248\n",
      "[20,   100] loss: 2.251\n",
      "[20,   200] loss: 2.231\n",
      "[21,   100] loss: 2.235\n",
      "[21,   200] loss: 2.239\n",
      "[22,   100] loss: 2.235\n",
      "[22,   200] loss: 2.240\n",
      "[23,   100] loss: 2.236\n",
      "[23,   200] loss: 2.245\n",
      "[24,   100] loss: 2.243\n",
      "[24,   200] loss: 2.244\n",
      "[25,   100] loss: 2.237\n",
      "[25,   200] loss: 2.249\n",
      "[26,   100] loss: 2.253\n",
      "[26,   200] loss: 2.276\n",
      "[27,   100] loss: 2.242\n",
      "[27,   200] loss: 2.245\n",
      "[28,   100] loss: 2.255\n",
      "[28,   200] loss: 2.244\n",
      "[29,   100] loss: 2.243\n",
      "[29,   200] loss: 2.240\n",
      "[30,   100] loss: 2.253\n",
      "[30,   200] loss: 2.241\n",
      "[31,   100] loss: 2.238\n",
      "[31,   200] loss: 2.241\n",
      "[32,   100] loss: 2.237\n",
      "[32,   200] loss: 2.237\n",
      "[33,   100] loss: 2.273\n",
      "[33,   200] loss: 2.251\n",
      "[34,   100] loss: 2.240\n",
      "[34,   200] loss: 2.239\n",
      "[35,   100] loss: 2.261\n",
      "[35,   200] loss: 2.243\n",
      "[36,   100] loss: 2.243\n",
      "[36,   200] loss: 2.239\n",
      "[37,   100] loss: 2.238\n",
      "[37,   200] loss: 2.249\n",
      "[38,   100] loss: 2.244\n",
      "[38,   200] loss: 2.238\n",
      "[39,   100] loss: 2.243\n",
      "[39,   200] loss: 2.263\n",
      "[40,   100] loss: 2.235\n",
      "[40,   200] loss: 2.255\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.376\n",
      "[1,   200] loss: 2.252\n",
      "[2,   100] loss: 2.153\n",
      "[2,   200] loss: 2.113\n",
      "[3,   100] loss: 2.088\n",
      "[3,   200] loss: 2.065\n",
      "[4,   100] loss: 2.045\n",
      "[4,   200] loss: 2.023\n",
      "[5,   100] loss: 2.009\n",
      "[5,   200] loss: 2.008\n",
      "[6,   100] loss: 1.979\n",
      "[6,   200] loss: 1.987\n",
      "[7,   100] loss: 1.973\n",
      "[7,   200] loss: 1.947\n",
      "[8,   100] loss: 1.936\n",
      "[8,   200] loss: 1.929\n",
      "[9,   100] loss: 1.911\n",
      "[9,   200] loss: 1.921\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10,   100] loss: 1.903\n",
      "[10,   200] loss: 1.910\n",
      "[11,   100] loss: 1.884\n",
      "[11,   200] loss: 1.893\n",
      "[12,   100] loss: 1.892\n",
      "[12,   200] loss: 1.883\n",
      "[13,   100] loss: 1.855\n",
      "[13,   200] loss: 1.865\n",
      "[14,   100] loss: 1.854\n",
      "[14,   200] loss: 1.859\n",
      "[15,   100] loss: 1.832\n",
      "[15,   200] loss: 1.851\n",
      "[16,   100] loss: 1.860\n",
      "[16,   200] loss: 1.856\n",
      "[17,   100] loss: 1.821\n",
      "[17,   200] loss: 1.827\n",
      "[18,   100] loss: 1.803\n",
      "[18,   200] loss: 1.798\n",
      "[19,   100] loss: 1.777\n",
      "[19,   200] loss: 1.787\n",
      "[20,   100] loss: 1.797\n",
      "[20,   200] loss: 1.789\n",
      "[21,   100] loss: 1.780\n",
      "[21,   200] loss: 1.764\n",
      "[22,   100] loss: 1.738\n",
      "[22,   200] loss: 1.760\n",
      "[23,   100] loss: 1.765\n",
      "[23,   200] loss: 1.779\n",
      "[24,   100] loss: 1.757\n",
      "[24,   200] loss: 1.782\n",
      "[25,   100] loss: 1.771\n",
      "[25,   200] loss: 1.759\n",
      "[26,   100] loss: 1.741\n",
      "[26,   200] loss: 1.777\n",
      "[27,   100] loss: 1.752\n",
      "[27,   200] loss: 1.762\n",
      "[28,   100] loss: 1.725\n",
      "[28,   200] loss: 1.745\n",
      "[29,   100] loss: 1.724\n",
      "[29,   200] loss: 1.755\n",
      "[30,   100] loss: 1.733\n",
      "[30,   200] loss: 1.740\n",
      "[31,   100] loss: 1.722\n",
      "[31,   200] loss: 1.737\n",
      "[32,   100] loss: 1.709\n",
      "[32,   200] loss: 1.718\n",
      "[33,   100] loss: 1.692\n",
      "[33,   200] loss: 1.730\n",
      "[34,   100] loss: 1.703\n",
      "[34,   200] loss: 1.709\n",
      "[35,   100] loss: 1.691\n",
      "[35,   200] loss: 1.712\n",
      "[36,   100] loss: 1.675\n",
      "[36,   200] loss: 1.683\n",
      "[37,   100] loss: 1.664\n",
      "[37,   200] loss: 1.702\n",
      "[38,   100] loss: 1.687\n",
      "[38,   200] loss: 1.709\n",
      "[39,   100] loss: 1.678\n",
      "[39,   200] loss: 1.705\n",
      "[40,   100] loss: 1.681\n",
      "[40,   200] loss: 1.724\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.356\n",
      "[1,   200] loss: 2.341\n",
      "[2,   100] loss: 2.252\n",
      "[2,   200] loss: 2.229\n",
      "[3,   100] loss: 2.220\n",
      "[3,   200] loss: 2.178\n",
      "[4,   100] loss: 2.203\n",
      "[4,   200] loss: 2.203\n",
      "[5,   100] loss: 2.189\n",
      "[5,   200] loss: 2.179\n",
      "[6,   100] loss: 2.196\n",
      "[6,   200] loss: 2.180\n",
      "[7,   100] loss: 2.200\n",
      "[7,   200] loss: 2.195\n",
      "[8,   100] loss: 2.206\n",
      "[8,   200] loss: 2.200\n",
      "[9,   100] loss: 2.199\n",
      "[9,   200] loss: 2.207\n",
      "[10,   100] loss: 2.192\n",
      "[10,   200] loss: 2.201\n",
      "[11,   100] loss: 2.211\n",
      "[11,   200] loss: 2.238\n",
      "[12,   100] loss: 2.234\n",
      "[12,   200] loss: 2.234\n",
      "[13,   100] loss: 2.238\n",
      "[13,   200] loss: 2.230\n",
      "[14,   100] loss: 2.239\n",
      "[14,   200] loss: 2.243\n",
      "[15,   100] loss: 2.228\n",
      "[15,   200] loss: 2.227\n",
      "[16,   100] loss: 2.207\n",
      "[16,   200] loss: 2.227\n",
      "[17,   100] loss: 2.219\n",
      "[17,   200] loss: 2.237\n",
      "[18,   100] loss: 2.230\n",
      "[18,   200] loss: 2.229\n",
      "[19,   100] loss: 2.237\n",
      "[19,   200] loss: 2.235\n",
      "[20,   100] loss: 2.230\n",
      "[20,   200] loss: 2.235\n",
      "[21,   100] loss: 2.234\n",
      "[21,   200] loss: 2.229\n",
      "[22,   100] loss: 2.237\n",
      "[22,   200] loss: 2.230\n",
      "[23,   100] loss: 2.235\n",
      "[23,   200] loss: 2.238\n",
      "[24,   100] loss: 2.244\n",
      "[24,   200] loss: 2.236\n",
      "[25,   100] loss: 2.255\n",
      "[25,   200] loss: 2.249\n",
      "[26,   100] loss: 2.236\n",
      "[26,   200] loss: 2.247\n",
      "[27,   100] loss: 2.244\n",
      "[27,   200] loss: 2.245\n",
      "[28,   100] loss: 2.244\n",
      "[28,   200] loss: 2.261\n",
      "[29,   100] loss: 2.234\n",
      "[29,   200] loss: 2.234\n",
      "[30,   100] loss: 2.243\n",
      "[30,   200] loss: 2.246\n",
      "[31,   100] loss: 2.242\n",
      "[31,   200] loss: 2.257\n",
      "[32,   100] loss: 2.260\n",
      "[32,   200] loss: 2.247\n",
      "[33,   100] loss: 2.234\n",
      "[33,   200] loss: 2.249\n",
      "[34,   100] loss: 2.260\n",
      "[34,   200] loss: 2.257\n",
      "[35,   100] loss: 2.241\n",
      "[35,   200] loss: 2.252\n",
      "[36,   100] loss: 2.259\n",
      "[36,   200] loss: 2.253\n",
      "[37,   100] loss: 2.250\n",
      "[37,   200] loss: 2.245\n",
      "[38,   100] loss: 2.250\n",
      "[38,   200] loss: 2.247\n",
      "[39,   100] loss: 2.232\n",
      "[39,   200] loss: 2.236\n",
      "[40,   100] loss: 2.248\n",
      "[40,   200] loss: 2.259\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.303\n",
      "[1,   200] loss: 2.221\n",
      "[2,   100] loss: 2.157\n",
      "[2,   200] loss: 2.127\n",
      "[3,   100] loss: 2.075\n",
      "[3,   200] loss: 2.054\n",
      "[4,   100] loss: 2.030\n",
      "[4,   200] loss: 2.020\n",
      "[5,   100] loss: 2.001\n",
      "[5,   200] loss: 1.997\n",
      "[6,   100] loss: 1.974\n",
      "[6,   200] loss: 1.988\n",
      "[7,   100] loss: 1.965\n",
      "[7,   200] loss: 1.964\n",
      "[8,   100] loss: 1.945\n",
      "[8,   200] loss: 1.956\n",
      "[9,   100] loss: 1.934\n",
      "[9,   200] loss: 1.931\n",
      "[10,   100] loss: 1.922\n",
      "[10,   200] loss: 1.917\n",
      "[11,   100] loss: 1.895\n",
      "[11,   200] loss: 1.906\n",
      "[12,   100] loss: 1.889\n",
      "[12,   200] loss: 1.925\n",
      "[13,   100] loss: 1.894\n",
      "[13,   200] loss: 1.901\n",
      "[14,   100] loss: 1.888\n",
      "[14,   200] loss: 1.903\n",
      "[15,   100] loss: 1.977\n",
      "[15,   200] loss: 1.999\n",
      "[16,   100] loss: 1.995\n",
      "[16,   200] loss: 1.983\n",
      "[17,   100] loss: 1.948\n",
      "[17,   200] loss: 1.949\n",
      "[18,   100] loss: 1.941\n",
      "[18,   200] loss: 1.941\n",
      "[19,   100] loss: 1.947\n",
      "[19,   200] loss: 1.911\n",
      "[20,   100] loss: 1.914\n",
      "[20,   200] loss: 1.899\n",
      "[21,   100] loss: 1.933\n",
      "[21,   200] loss: 1.954\n",
      "[22,   100] loss: 1.942\n",
      "[22,   200] loss: 1.946\n",
      "[23,   100] loss: 1.955\n",
      "[23,   200] loss: 1.947\n",
      "[24,   100] loss: 1.892\n",
      "[24,   200] loss: 1.928\n",
      "[25,   100] loss: 1.965\n",
      "[25,   200] loss: 2.008\n",
      "[26,   100] loss: 1.961\n",
      "[26,   200] loss: 1.943\n",
      "[27,   100] loss: 1.901\n",
      "[27,   200] loss: 1.894\n",
      "[28,   100] loss: 1.897\n",
      "[28,   200] loss: 1.899\n",
      "[29,   100] loss: 1.891\n",
      "[29,   200] loss: 1.888\n",
      "[30,   100] loss: 1.853\n",
      "[30,   200] loss: 1.895\n",
      "[31,   100] loss: 1.860\n",
      "[31,   200] loss: 1.872\n",
      "[32,   100] loss: 1.873\n",
      "[32,   200] loss: 1.856\n",
      "[33,   100] loss: 1.837\n",
      "[33,   200] loss: 1.876\n",
      "[34,   100] loss: 1.847\n",
      "[34,   200] loss: 1.883\n",
      "[35,   100] loss: 1.884\n",
      "[35,   200] loss: 1.875\n",
      "[36,   100] loss: 1.865\n",
      "[36,   200] loss: 1.870\n",
      "[37,   100] loss: 1.868\n",
      "[37,   200] loss: 1.869\n",
      "[38,   100] loss: 1.859\n",
      "[38,   200] loss: 1.867\n",
      "[39,   100] loss: 1.853\n",
      "[39,   200] loss: 1.925\n",
      "[40,   100] loss: 1.874\n",
      "[40,   200] loss: 1.880\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.356\n",
      "[1,   200] loss: 2.330\n",
      "[2,   100] loss: 2.347\n",
      "[2,   200] loss: 2.301\n",
      "[3,   100] loss: 2.290\n",
      "[3,   200] loss: 2.280\n",
      "[4,   100] loss: 2.287\n",
      "[4,   200] loss: 2.295\n",
      "[5,   100] loss: 2.292\n",
      "[5,   200] loss: 2.302\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.302\n",
      "[7,   100] loss: 2.297\n",
      "[7,   200] loss: 2.291\n",
      "[8,   100] loss: 2.302\n",
      "[8,   200] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[21,   100] loss: 2.303\n",
      "[21,   200] loss: 2.303\n",
      "[22,   100] loss: 2.303\n",
      "[22,   200] loss: 2.303\n",
      "[23,   100] loss: 2.303\n",
      "[23,   200] loss: 2.303\n",
      "[24,   100] loss: 2.303\n",
      "[24,   200] loss: 2.303\n",
      "[25,   100] loss: 2.303\n",
      "[25,   200] loss: 2.303\n",
      "[26,   100] loss: 2.303\n",
      "[26,   200] loss: 2.303\n",
      "[27,   100] loss: 2.303\n",
      "[27,   200] loss: 2.303\n",
      "[28,   100] loss: 2.303\n",
      "[28,   200] loss: 2.303\n",
      "[29,   100] loss: 2.303\n",
      "[29,   200] loss: 2.303\n",
      "[30,   100] loss: 2.303\n",
      "[30,   200] loss: 2.303\n",
      "[31,   100] loss: 2.303\n",
      "[31,   200] loss: 2.303\n",
      "[32,   100] loss: 2.303\n",
      "[32,   200] loss: 2.303\n",
      "[33,   100] loss: 2.303\n",
      "[33,   200] loss: 2.303\n",
      "[34,   100] loss: 2.303\n",
      "[34,   200] loss: 2.303\n",
      "[35,   100] loss: 2.303\n",
      "[35,   200] loss: 2.303\n",
      "[36,   100] loss: 2.303\n",
      "[36,   200] loss: 2.303\n",
      "[37,   100] loss: 2.303\n",
      "[37,   200] loss: 2.303\n",
      "[38,   100] loss: 2.303\n",
      "[38,   200] loss: 2.303\n",
      "[39,   100] loss: 2.303\n",
      "[39,   200] loss: 2.303\n",
      "[40,   100] loss: 2.303\n",
      "[40,   200] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.236\n",
      "[1,   200] loss: 2.102\n",
      "[2,   100] loss: 2.050\n",
      "[2,   200] loss: 2.011\n",
      "[3,   100] loss: 1.975\n",
      "[3,   200] loss: 2.077\n",
      "[4,   100] loss: 2.253\n",
      "[4,   200] loss: 2.253\n",
      "[5,   100] loss: 2.245\n",
      "[5,   200] loss: 2.232\n",
      "[6,   100] loss: 2.225\n",
      "[6,   200] loss: 2.236\n",
      "[7,   100] loss: 2.212\n",
      "[7,   200] loss: 2.191\n",
      "[8,   100] loss: 2.195\n",
      "[8,   200] loss: 2.188\n",
      "[9,   100] loss: 2.218\n",
      "[9,   200] loss: 2.230\n",
      "[10,   100] loss: 2.223\n",
      "[10,   200] loss: 2.232\n",
      "[11,   100] loss: 2.298\n",
      "[11,   200] loss: 2.302\n",
      "[12,   100] loss: 2.302\n",
      "[12,   200] loss: 2.302\n",
      "[13,   100] loss: 2.299\n",
      "[13,   200] loss: 2.294\n",
      "[14,   100] loss: 2.282\n",
      "[14,   200] loss: 2.267\n",
      "[15,   100] loss: 2.299\n",
      "[15,   200] loss: 2.298\n",
      "[16,   100] loss: 2.295\n",
      "[16,   200] loss: 2.289\n",
      "[17,   100] loss: 2.289\n",
      "[17,   200] loss: 2.287\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[21,   100] loss: 2.303\n",
      "[21,   200] loss: 2.303\n",
      "[22,   100] loss: 2.303\n",
      "[22,   200] loss: 2.303\n",
      "[23,   100] loss: 2.303\n",
      "[23,   200] loss: 2.303\n",
      "[24,   100] loss: 2.303\n",
      "[24,   200] loss: 2.303\n",
      "[25,   100] loss: 2.303\n",
      "[25,   200] loss: 2.303\n",
      "[26,   100] loss: 2.303\n",
      "[26,   200] loss: 2.303\n",
      "[27,   100] loss: 2.303\n",
      "[27,   200] loss: 2.303\n",
      "[28,   100] loss: 2.303\n",
      "[28,   200] loss: 2.303\n",
      "[29,   100] loss: 2.303\n",
      "[29,   200] loss: 2.303\n",
      "[30,   100] loss: 2.303\n",
      "[30,   200] loss: 2.303\n",
      "[31,   100] loss: 2.303\n",
      "[31,   200] loss: 2.303\n",
      "[32,   100] loss: 2.303\n",
      "[32,   200] loss: 2.303\n",
      "[33,   100] loss: 2.303\n",
      "[33,   200] loss: 2.303\n",
      "[34,   100] loss: 2.303\n",
      "[34,   200] loss: 2.303\n",
      "[35,   100] loss: 2.303\n",
      "[35,   200] loss: 2.303\n",
      "[36,   100] loss: 2.303\n",
      "[36,   200] loss: 2.303\n",
      "[37,   100] loss: 2.303\n",
      "[37,   200] loss: 2.303\n",
      "[38,   100] loss: 2.303\n",
      "[38,   200] loss: 2.303\n",
      "[39,   100] loss: 2.303\n",
      "[39,   200] loss: 2.303\n",
      "[40,   100] loss: 2.303\n",
      "[40,   200] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.322\n",
      "[1,   200] loss: 2.301\n",
      "[2,   100] loss: 2.263\n",
      "[2,   200] loss: 2.255\n",
      "[3,   100] loss: 2.234\n",
      "[3,   200] loss: 2.237\n",
      "[4,   100] loss: 2.241\n",
      "[4,   200] loss: 2.238\n",
      "[5,   100] loss: 2.241\n",
      "[5,   200] loss: 2.221\n",
      "[6,   100] loss: 2.234\n",
      "[6,   200] loss: 2.224\n",
      "[7,   100] loss: 2.222\n",
      "[7,   200] loss: 2.230\n",
      "[8,   100] loss: 2.213\n",
      "[8,   200] loss: 2.235\n",
      "[9,   100] loss: 2.239\n",
      "[9,   200] loss: 2.233\n",
      "[10,   100] loss: 2.244\n",
      "[10,   200] loss: 2.252\n",
      "[11,   100] loss: 2.256\n",
      "[11,   200] loss: 2.257\n",
      "[12,   100] loss: 2.248\n",
      "[12,   200] loss: 2.244\n",
      "[13,   100] loss: 2.237\n",
      "[13,   200] loss: 2.232\n",
      "[14,   100] loss: 2.236\n",
      "[14,   200] loss: 2.234\n",
      "[15,   100] loss: 2.239\n",
      "[15,   200] loss: 2.237\n",
      "[16,   100] loss: 2.251\n",
      "[16,   200] loss: 2.243\n",
      "[17,   100] loss: 2.250\n",
      "[17,   200] loss: 2.255\n",
      "[18,   100] loss: 2.240\n",
      "[18,   200] loss: 2.240\n",
      "[19,   100] loss: 2.245\n",
      "[19,   200] loss: 2.244\n",
      "[20,   100] loss: 2.237\n",
      "[20,   200] loss: 2.242\n",
      "[21,   100] loss: 2.241\n",
      "[21,   200] loss: 2.245\n",
      "[22,   100] loss: 2.232\n",
      "[22,   200] loss: 2.237\n",
      "[23,   100] loss: 2.279\n",
      "[23,   200] loss: 2.257\n",
      "[24,   100] loss: 2.255\n",
      "[24,   200] loss: 2.272\n",
      "[25,   100] loss: 2.258\n",
      "[25,   200] loss: 2.275\n",
      "[26,   100] loss: 2.247\n",
      "[26,   200] loss: 2.249\n",
      "[27,   100] loss: 2.254\n",
      "[27,   200] loss: 2.240\n",
      "[28,   100] loss: 2.244\n",
      "[28,   200] loss: 2.247\n",
      "[29,   100] loss: 2.245\n",
      "[29,   200] loss: 2.269\n",
      "[30,   100] loss: 2.241\n",
      "[30,   200] loss: 2.255\n",
      "[31,   100] loss: 2.245\n",
      "[31,   200] loss: 2.244\n",
      "[32,   100] loss: 2.247\n",
      "[32,   200] loss: 2.248\n",
      "[33,   100] loss: 2.251\n",
      "[33,   200] loss: 2.254\n",
      "[34,   100] loss: 2.258\n",
      "[34,   200] loss: 2.243\n",
      "[35,   100] loss: 2.256\n",
      "[35,   200] loss: 2.267\n",
      "[36,   100] loss: 2.247\n",
      "[36,   200] loss: 2.251\n",
      "[37,   100] loss: 2.246\n",
      "[37,   200] loss: 2.257\n",
      "[38,   100] loss: 2.263\n",
      "[38,   200] loss: 2.246\n",
      "[39,   100] loss: 2.253\n",
      "[39,   200] loss: 2.239\n",
      "[40,   100] loss: 2.241\n",
      "[40,   200] loss: 2.249\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.315\n",
      "[1,   200] loss: 2.168\n",
      "[2,   100] loss: 2.119\n",
      "[2,   200] loss: 2.110\n",
      "[3,   100] loss: 2.085\n",
      "[3,   200] loss: 2.081\n",
      "[4,   100] loss: 2.059\n",
      "[4,   200] loss: 2.070\n",
      "[5,   100] loss: 2.139\n",
      "[5,   200] loss: 2.112\n",
      "[6,   100] loss: 2.129\n",
      "[6,   200] loss: 2.156\n",
      "[7,   100] loss: 2.200\n",
      "[7,   200] loss: 2.166\n",
      "[8,   100] loss: 2.160\n",
      "[8,   200] loss: 2.181\n",
      "[9,   100] loss: 2.167\n",
      "[9,   200] loss: 2.154\n",
      "[10,   100] loss: 2.208\n",
      "[10,   200] loss: 2.194\n",
      "[11,   100] loss: 2.168\n",
      "[11,   200] loss: 2.139\n",
      "[12,   100] loss: 2.156\n",
      "[12,   200] loss: 2.165\n",
      "[13,   100] loss: 2.186\n",
      "[13,   200] loss: 2.190\n",
      "[14,   100] loss: 2.192\n",
      "[14,   200] loss: 2.174\n",
      "[15,   100] loss: 2.211\n",
      "[15,   200] loss: 2.213\n",
      "[16,   100] loss: 2.150\n",
      "[16,   200] loss: 2.177\n",
      "[17,   100] loss: 2.163\n",
      "[17,   200] loss: 2.163\n",
      "[18,   100] loss: 2.136\n",
      "[18,   200] loss: 2.158\n",
      "[19,   100] loss: 2.215\n",
      "[19,   200] loss: 2.196\n",
      "[20,   100] loss: 2.120\n",
      "[20,   200] loss: 2.133\n",
      "[21,   100] loss: 2.107\n",
      "[21,   200] loss: 2.099\n",
      "[22,   100] loss: 2.085\n",
      "[22,   200] loss: 2.094\n",
      "[23,   100] loss: 2.100\n",
      "[23,   200] loss: 2.088\n",
      "[24,   100] loss: 2.076\n",
      "[24,   200] loss: 2.076\n",
      "[25,   100] loss: 2.054\n",
      "[25,   200] loss: 2.056\n",
      "[26,   100] loss: 2.062\n",
      "[26,   200] loss: 2.052\n",
      "[27,   100] loss: 2.041\n",
      "[27,   200] loss: 2.057\n",
      "[28,   100] loss: 2.033\n",
      "[28,   200] loss: 2.039\n",
      "[29,   100] loss: 2.016\n",
      "[29,   200] loss: 2.044\n",
      "[30,   100] loss: 2.068\n",
      "[30,   200] loss: 2.072\n",
      "[31,   100] loss: 2.044\n",
      "[31,   200] loss: 2.049\n",
      "[32,   100] loss: 2.024\n",
      "[32,   200] loss: 2.038\n",
      "[33,   100] loss: 2.031\n",
      "[33,   200] loss: 2.133\n",
      "[34,   100] loss: 2.303\n",
      "[34,   200] loss: 2.303\n",
      "[35,   100] loss: 2.303\n",
      "[35,   200] loss: 2.303\n",
      "[36,   100] loss: 2.303\n",
      "[36,   200] loss: 2.303\n",
      "[37,   100] loss: 2.303\n",
      "[37,   200] loss: 2.303\n",
      "[38,   100] loss: 2.303\n",
      "[38,   200] loss: 2.303\n",
      "[39,   100] loss: 2.303\n",
      "[39,   200] loss: 2.303\n",
      "[40,   100] loss: 2.303\n",
      "[40,   200] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.341\n",
      "[1,   200] loss: 2.307\n",
      "[2,   100] loss: 2.299\n",
      "[2,   200] loss: 2.283\n",
      "[3,   100] loss: 2.265\n",
      "[3,   200] loss: 2.242\n",
      "[4,   100] loss: 2.208\n",
      "[4,   200] loss: 2.208\n",
      "[5,   100] loss: 2.205\n",
      "[5,   200] loss: 2.211\n",
      "[6,   100] loss: 2.203\n",
      "[6,   200] loss: 2.204\n",
      "[7,   100] loss: 2.208\n",
      "[7,   200] loss: 2.200\n",
      "[8,   100] loss: 2.212\n",
      "[8,   200] loss: 2.209\n",
      "[9,   100] loss: 2.236\n",
      "[9,   200] loss: 2.211\n",
      "[10,   100] loss: 2.208\n",
      "[10,   200] loss: 2.215\n",
      "[11,   100] loss: 2.241\n",
      "[11,   200] loss: 2.229\n",
      "[12,   100] loss: 2.229\n",
      "[12,   200] loss: 2.243\n",
      "[13,   100] loss: 2.242\n",
      "[13,   200] loss: 2.234\n",
      "[14,   100] loss: 2.238\n",
      "[14,   200] loss: 2.231\n",
      "[15,   100] loss: 2.258\n",
      "[15,   200] loss: 2.246\n",
      "[16,   100] loss: 2.256\n",
      "[16,   200] loss: 2.254\n",
      "[17,   100] loss: 2.242\n",
      "[17,   200] loss: 2.258\n",
      "[18,   100] loss: 2.280\n",
      "[18,   200] loss: 2.253\n",
      "[19,   100] loss: 2.244\n",
      "[19,   200] loss: 2.247\n",
      "[20,   100] loss: 2.229\n",
      "[20,   200] loss: 2.244\n",
      "[21,   100] loss: 2.230\n",
      "[21,   200] loss: 2.235\n",
      "[22,   100] loss: 2.228\n",
      "[22,   200] loss: 2.255\n",
      "[23,   100] loss: 2.277\n",
      "[23,   200] loss: 2.238\n",
      "[24,   100] loss: 2.241\n",
      "[24,   200] loss: 2.267\n",
      "[25,   100] loss: 2.250\n",
      "[25,   200] loss: 2.233\n",
      "[26,   100] loss: 2.247\n",
      "[26,   200] loss: 2.244\n",
      "[27,   100] loss: 2.257\n",
      "[27,   200] loss: 2.256\n",
      "[28,   100] loss: 2.267\n",
      "[28,   200] loss: 2.239\n",
      "[29,   100] loss: 2.247\n",
      "[29,   200] loss: 2.257\n",
      "[30,   100] loss: 2.259\n",
      "[30,   200] loss: 2.253\n",
      "[31,   100] loss: 2.281\n",
      "[31,   200] loss: 2.268\n",
      "[32,   100] loss: 2.246\n",
      "[32,   200] loss: 2.252\n",
      "[33,   100] loss: 2.249\n",
      "[33,   200] loss: 2.262\n",
      "[34,   100] loss: 2.284\n",
      "[34,   200] loss: 2.243\n",
      "[35,   100] loss: 2.241\n",
      "[35,   200] loss: 2.239\n",
      "[36,   100] loss: 2.253\n",
      "[36,   200] loss: 2.253\n",
      "[37,   100] loss: 2.252\n",
      "[37,   200] loss: 2.245\n",
      "[38,   100] loss: 2.243\n",
      "[38,   200] loss: 2.263\n",
      "[39,   100] loss: 2.236\n",
      "[39,   200] loss: 2.245\n",
      "[40,   100] loss: 2.270\n",
      "[40,   200] loss: 2.274\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.240\n",
      "[1,   200] loss: 2.118\n",
      "[2,   100] loss: 2.017\n",
      "[2,   200] loss: 1.975\n",
      "[3,   100] loss: 1.935\n",
      "[3,   200] loss: 2.006\n",
      "[4,   100] loss: 2.119\n",
      "[4,   200] loss: 2.094\n",
      "[5,   100] loss: 2.025\n",
      "[5,   200] loss: 2.183\n",
      "[6,   100] loss: 2.137\n",
      "[6,   200] loss: 2.125\n",
      "[7,   100] loss: 2.057\n",
      "[7,   200] loss: 2.023\n",
      "[8,   100] loss: 2.000\n",
      "[8,   200] loss: 1.986\n",
      "[9,   100] loss: 1.998\n",
      "[9,   200] loss: 2.005\n",
      "[10,   100] loss: 1.990\n",
      "[10,   200] loss: 1.996\n",
      "[11,   100] loss: 2.016\n",
      "[11,   200] loss: 2.019\n",
      "[12,   100] loss: 2.021\n",
      "[12,   200] loss: 2.013\n",
      "[13,   100] loss: 2.032\n",
      "[13,   200] loss: 2.026\n",
      "[14,   100] loss: 2.052\n",
      "[14,   200] loss: 2.030\n",
      "[15,   100] loss: 2.058\n",
      "[15,   200] loss: 2.067\n",
      "[16,   100] loss: 2.048\n",
      "[16,   200] loss: 2.104\n",
      "[17,   100] loss: 2.058\n",
      "[17,   200] loss: 2.133\n",
      "[18,   100] loss: 2.185\n",
      "[18,   200] loss: 2.140\n",
      "[19,   100] loss: 2.215\n",
      "[19,   200] loss: 2.210\n",
      "[20,   100] loss: 2.224\n",
      "[20,   200] loss: 2.222\n",
      "[21,   100] loss: 2.212\n",
      "[21,   200] loss: 2.210\n",
      "[22,   100] loss: 2.199\n",
      "[22,   200] loss: 2.197\n",
      "[23,   100] loss: 2.200\n",
      "[23,   200] loss: 2.199\n",
      "[24,   100] loss: 2.196\n",
      "[24,   200] loss: 2.195\n",
      "[25,   100] loss: 2.209\n",
      "[25,   200] loss: 2.247\n",
      "[26,   100] loss: 2.260\n",
      "[26,   200] loss: 2.269\n",
      "[27,   100] loss: 2.239\n",
      "[27,   200] loss: 2.243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28,   100] loss: 2.245\n",
      "[28,   200] loss: 2.255\n",
      "[29,   100] loss: 2.270\n",
      "[29,   200] loss: 2.265\n",
      "[30,   100] loss: 2.266\n",
      "[30,   200] loss: 2.259\n",
      "[31,   100] loss: 2.263\n",
      "[31,   200] loss: 2.290\n",
      "[32,   100] loss: 2.303\n",
      "[32,   200] loss: 2.303\n",
      "[33,   100] loss: 2.303\n",
      "[33,   200] loss: 2.303\n",
      "[34,   100] loss: 2.303\n",
      "[34,   200] loss: 2.303\n",
      "[35,   100] loss: 2.303\n",
      "[35,   200] loss: 2.303\n",
      "[36,   100] loss: 2.303\n",
      "[36,   200] loss: 2.303\n",
      "[37,   100] loss: 2.303\n",
      "[37,   200] loss: 2.303\n",
      "[38,   100] loss: 2.303\n",
      "[38,   200] loss: 2.303\n",
      "[39,   100] loss: 2.303\n",
      "[39,   200] loss: 2.303\n",
      "[40,   100] loss: 2.303\n",
      "[40,   200] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.362\n",
      "[1,   200] loss: 2.328\n",
      "[2,   100] loss: 2.333\n",
      "[2,   200] loss: 2.278\n",
      "[3,   100] loss: 2.278\n",
      "[3,   200] loss: 2.285\n",
      "[4,   100] loss: 2.274\n",
      "[4,   200] loss: 2.286\n",
      "[5,   100] loss: 2.298\n",
      "[5,   200] loss: 2.303\n",
      "[6,   100] loss: 2.292\n",
      "[6,   200] loss: 2.290\n",
      "[7,   100] loss: 2.297\n",
      "[7,   200] loss: 2.301\n",
      "[8,   100] loss: 2.302\n",
      "[8,   200] loss: 2.292\n",
      "[9,   100] loss: 2.291\n",
      "[9,   200] loss: 2.294\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[21,   100] loss: 2.303\n",
      "[21,   200] loss: 2.303\n",
      "[22,   100] loss: 2.303\n",
      "[22,   200] loss: 2.303\n",
      "[23,   100] loss: 2.303\n",
      "[23,   200] loss: 2.303\n",
      "[24,   100] loss: 2.303\n",
      "[24,   200] loss: 2.303\n",
      "[25,   100] loss: 2.303\n",
      "[25,   200] loss: 2.303\n",
      "[26,   100] loss: 2.303\n",
      "[26,   200] loss: 2.303\n",
      "[27,   100] loss: 2.303\n",
      "[27,   200] loss: 2.303\n",
      "[28,   100] loss: 2.303\n",
      "[28,   200] loss: 2.303\n",
      "[29,   100] loss: 2.303\n",
      "[29,   200] loss: 2.303\n",
      "[30,   100] loss: 2.303\n",
      "[30,   200] loss: 2.303\n",
      "[31,   100] loss: 2.303\n",
      "[31,   200] loss: 2.303\n",
      "[32,   100] loss: 2.303\n",
      "[32,   200] loss: 2.303\n",
      "[33,   100] loss: 2.303\n",
      "[33,   200] loss: 2.303\n",
      "[34,   100] loss: 2.303\n",
      "[34,   200] loss: 2.303\n",
      "[35,   100] loss: 2.303\n",
      "[35,   200] loss: 2.303\n",
      "[36,   100] loss: 2.303\n",
      "[36,   200] loss: 2.303\n",
      "[37,   100] loss: 2.303\n",
      "[37,   200] loss: 2.303\n",
      "[38,   100] loss: 2.303\n",
      "[38,   200] loss: 2.303\n",
      "[39,   100] loss: 2.303\n",
      "[39,   200] loss: 2.303\n",
      "[40,   100] loss: 2.303\n",
      "[40,   200] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.299\n",
      "[1,   200] loss: 2.100\n",
      "[2,   100] loss: 1.997\n",
      "[2,   200] loss: 1.928\n",
      "[3,   100] loss: 2.087\n",
      "[3,   200] loss: 2.311\n",
      "[4,   100] loss: 2.303\n",
      "[4,   200] loss: 2.303\n",
      "[5,   100] loss: 2.303\n",
      "[5,   200] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[21,   100] loss: 2.303\n",
      "[21,   200] loss: 2.303\n",
      "[22,   100] loss: 2.303\n",
      "[22,   200] loss: 2.303\n",
      "[23,   100] loss: 2.303\n",
      "[23,   200] loss: 2.303\n",
      "[24,   100] loss: 2.324\n",
      "[24,   200] loss: 2.303\n",
      "[25,   100] loss: 2.303\n",
      "[25,   200] loss: 2.303\n",
      "[26,   100] loss: 2.303\n",
      "[26,   200] loss: 2.303\n",
      "[27,   100] loss: 2.303\n",
      "[27,   200] loss: 2.303\n",
      "[28,   100] loss: 2.303\n",
      "[28,   200] loss: 2.303\n",
      "[29,   100] loss: 2.303\n",
      "[29,   200] loss: 2.303\n",
      "[30,   100] loss: 2.303\n",
      "[30,   200] loss: 2.303\n",
      "[31,   100] loss: 2.303\n",
      "[31,   200] loss: 2.303\n",
      "[32,   100] loss: 2.303\n",
      "[32,   200] loss: 2.303\n",
      "[33,   100] loss: 2.303\n",
      "[33,   200] loss: 2.303\n",
      "[34,   100] loss: 2.303\n",
      "[34,   200] loss: 2.303\n",
      "[35,   100] loss: 2.303\n",
      "[35,   200] loss: 2.303\n",
      "[36,   100] loss: 2.303\n",
      "[36,   200] loss: 2.303\n",
      "[37,   100] loss: 2.303\n",
      "[37,   200] loss: 2.303\n",
      "[38,   100] loss: 2.303\n",
      "[38,   200] loss: 2.303\n",
      "[39,   100] loss: 2.303\n",
      "[39,   200] loss: 2.303\n",
      "[40,   100] loss: 2.303\n",
      "[40,   200] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.351\n",
      "[1,   200] loss: 2.304\n",
      "[2,   100] loss: 2.260\n",
      "[2,   200] loss: 2.231\n",
      "[3,   100] loss: 2.194\n",
      "[3,   200] loss: 2.192\n",
      "[4,   100] loss: 2.215\n",
      "[4,   200] loss: 2.221\n",
      "[5,   100] loss: 2.227\n",
      "[5,   200] loss: 2.210\n",
      "[6,   100] loss: 2.203\n",
      "[6,   200] loss: 2.194\n",
      "[7,   100] loss: 2.195\n",
      "[7,   200] loss: 2.201\n",
      "[8,   100] loss: 2.210\n",
      "[8,   200] loss: 2.224\n",
      "[9,   100] loss: 2.225\n",
      "[9,   200] loss: 2.227\n",
      "[10,   100] loss: 2.239\n",
      "[10,   200] loss: 2.222\n",
      "[11,   100] loss: 2.228\n",
      "[11,   200] loss: 2.235\n",
      "[12,   100] loss: 2.234\n",
      "[12,   200] loss: 2.244\n",
      "[13,   100] loss: 2.246\n",
      "[13,   200] loss: 2.256\n",
      "[14,   100] loss: 2.240\n",
      "[14,   200] loss: 2.238\n",
      "[15,   100] loss: 2.238\n",
      "[15,   200] loss: 2.248\n",
      "[16,   100] loss: 2.249\n",
      "[16,   200] loss: 2.244\n",
      "[17,   100] loss: 2.256\n",
      "[17,   200] loss: 2.245\n",
      "[18,   100] loss: 2.238\n",
      "[18,   200] loss: 2.237\n",
      "[19,   100] loss: 2.244\n",
      "[19,   200] loss: 2.248\n",
      "[20,   100] loss: 2.241\n",
      "[20,   200] loss: 2.241\n",
      "[21,   100] loss: 2.238\n",
      "[21,   200] loss: 2.238\n",
      "[22,   100] loss: 2.250\n",
      "[22,   200] loss: 2.269\n",
      "[23,   100] loss: 2.247\n",
      "[23,   200] loss: 2.234\n",
      "[24,   100] loss: 2.244\n",
      "[24,   200] loss: 2.235\n",
      "[25,   100] loss: 2.242\n",
      "[25,   200] loss: 2.242\n",
      "[26,   100] loss: 2.250\n",
      "[26,   200] loss: 2.247\n",
      "[27,   100] loss: 2.238\n",
      "[27,   200] loss: 2.244\n",
      "[28,   100] loss: 2.242\n",
      "[28,   200] loss: 2.240\n",
      "[29,   100] loss: 2.239\n",
      "[29,   200] loss: 2.243\n",
      "[30,   100] loss: 2.241\n",
      "[30,   200] loss: 2.249\n",
      "[31,   100] loss: 2.253\n",
      "[31,   200] loss: 2.251\n",
      "[32,   100] loss: 2.258\n",
      "[32,   200] loss: 2.264\n",
      "[33,   100] loss: 2.234\n",
      "[33,   200] loss: 2.246\n",
      "[34,   100] loss: 2.243\n",
      "[34,   200] loss: 2.249\n",
      "[35,   100] loss: 2.246\n",
      "[35,   200] loss: 2.250\n",
      "[36,   100] loss: 2.234\n",
      "[36,   200] loss: 2.243\n",
      "[37,   100] loss: 2.241\n",
      "[37,   200] loss: 2.254\n",
      "[38,   100] loss: 2.250\n",
      "[38,   200] loss: 2.239\n",
      "[39,   100] loss: 2.241\n",
      "[39,   200] loss: 2.247\n",
      "[40,   100] loss: 2.241\n",
      "[40,   200] loss: 2.237\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.206\n",
      "[1,   200] loss: 2.072\n",
      "[2,   100] loss: 2.007\n",
      "[2,   200] loss: 1.976\n",
      "[3,   100] loss: 2.084\n",
      "[3,   200] loss: 2.158\n",
      "[4,   100] loss: 2.224\n",
      "[4,   200] loss: 2.242\n",
      "[5,   100] loss: 2.301\n",
      "[5,   200] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[8,   100] loss: 2.304\n",
      "[8,   200] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[21,   100] loss: 2.303\n",
      "[21,   200] loss: 2.303\n",
      "[22,   100] loss: 2.303\n",
      "[22,   200] loss: 2.303\n",
      "[23,   100] loss: 2.303\n",
      "[23,   200] loss: 2.303\n",
      "[24,   100] loss: 2.303\n",
      "[24,   200] loss: 2.303\n",
      "[25,   100] loss: 2.303\n",
      "[25,   200] loss: 2.303\n",
      "[26,   100] loss: 2.303\n",
      "[26,   200] loss: 2.303\n",
      "[27,   100] loss: 2.303\n",
      "[27,   200] loss: 2.303\n",
      "[28,   100] loss: 2.303\n",
      "[28,   200] loss: 2.303\n",
      "[29,   100] loss: 2.303\n",
      "[29,   200] loss: 2.303\n",
      "[30,   100] loss: 2.303\n",
      "[30,   200] loss: 2.303\n",
      "[31,   100] loss: 2.303\n",
      "[31,   200] loss: 2.303\n",
      "[32,   100] loss: 2.303\n",
      "[32,   200] loss: 2.303\n",
      "[33,   100] loss: 2.303\n",
      "[33,   200] loss: 2.303\n",
      "[34,   100] loss: 2.303\n",
      "[34,   200] loss: 2.303\n",
      "[35,   100] loss: 2.303\n",
      "[35,   200] loss: 2.303\n",
      "[36,   100] loss: 2.303\n",
      "[36,   200] loss: 2.303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37,   100] loss: 2.303\n",
      "[37,   200] loss: 2.303\n",
      "[38,   100] loss: 2.303\n",
      "[38,   200] loss: 2.303\n",
      "[39,   100] loss: 2.303\n",
      "[39,   200] loss: 2.303\n",
      "[40,   100] loss: 2.303\n",
      "[40,   200] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.344\n",
      "[1,   200] loss: 2.312\n",
      "[2,   100] loss: 2.313\n",
      "[2,   200] loss: 2.301\n",
      "[3,   100] loss: 2.302\n",
      "[3,   200] loss: 2.303\n",
      "[4,   100] loss: 2.303\n",
      "[4,   200] loss: 2.303\n",
      "[5,   100] loss: 2.303\n",
      "[5,   200] loss: 2.303\n",
      "[6,   100] loss: 2.303\n",
      "[6,   200] loss: 2.303\n",
      "[7,   100] loss: 2.303\n",
      "[7,   200] loss: 2.303\n",
      "[8,   100] loss: 2.303\n",
      "[8,   200] loss: 2.303\n",
      "[9,   100] loss: 2.303\n",
      "[9,   200] loss: 2.303\n",
      "[10,   100] loss: 2.303\n",
      "[10,   200] loss: 2.303\n",
      "[11,   100] loss: 2.303\n",
      "[11,   200] loss: 2.303\n",
      "[12,   100] loss: 2.303\n",
      "[12,   200] loss: 2.303\n",
      "[13,   100] loss: 2.303\n",
      "[13,   200] loss: 2.303\n",
      "[14,   100] loss: 2.303\n",
      "[14,   200] loss: 2.303\n",
      "[15,   100] loss: 2.303\n",
      "[15,   200] loss: 2.303\n",
      "[16,   100] loss: 2.303\n",
      "[16,   200] loss: 2.303\n",
      "[17,   100] loss: 2.303\n",
      "[17,   200] loss: 2.303\n",
      "[18,   100] loss: 2.303\n",
      "[18,   200] loss: 2.303\n",
      "[19,   100] loss: 2.303\n",
      "[19,   200] loss: 2.303\n",
      "[20,   100] loss: 2.303\n",
      "[20,   200] loss: 2.303\n",
      "[21,   100] loss: 2.303\n",
      "[21,   200] loss: 2.303\n",
      "[22,   100] loss: 2.303\n",
      "[22,   200] loss: 2.303\n",
      "[23,   100] loss: 2.303\n",
      "[23,   200] loss: 2.303\n",
      "[24,   100] loss: 2.303\n",
      "[24,   200] loss: 2.303\n",
      "[25,   100] loss: 2.303\n",
      "[25,   200] loss: 2.303\n",
      "[26,   100] loss: 2.303\n",
      "[26,   200] loss: 2.303\n",
      "[27,   100] loss: 2.303\n",
      "[27,   200] loss: 2.303\n",
      "[28,   100] loss: 2.303\n",
      "[28,   200] loss: 2.303\n",
      "[29,   100] loss: 2.303\n",
      "[29,   200] loss: 2.303\n",
      "[30,   100] loss: 2.303\n",
      "[30,   200] loss: 2.303\n",
      "[31,   100] loss: 2.303\n",
      "[31,   200] loss: 2.303\n",
      "[32,   100] loss: 2.303\n",
      "[32,   200] loss: 2.303\n",
      "[33,   100] loss: 2.303\n",
      "[33,   200] loss: 2.303\n",
      "[34,   100] loss: 2.303\n",
      "[34,   200] loss: 2.303\n",
      "[35,   100] loss: 2.303\n",
      "[35,   200] loss: 2.303\n",
      "[36,   100] loss: 2.303\n",
      "[36,   200] loss: 2.303\n",
      "[37,   100] loss: 2.303\n",
      "[37,   200] loss: 2.303\n",
      "[38,   100] loss: 2.303\n",
      "[38,   200] loss: 2.303\n",
      "[39,   100] loss: 2.303\n",
      "[39,   200] loss: 2.303\n",
      "[40,   100] loss: 2.303\n",
      "[40,   200] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 2.265\n",
      "[1,   200] loss: 2.155\n",
      "[2,   100] loss: 2.122\n",
      "[2,   200] loss: 2.104\n",
      "[3,   100] loss: 2.074\n",
      "[3,   200] loss: 2.055\n",
      "[4,   100] loss: 2.032\n",
      "[4,   200] loss: 2.057\n",
      "[5,   100] loss: 2.022\n",
      "[5,   200] loss: 2.017\n",
      "[6,   100] loss: 1.998\n",
      "[6,   200] loss: 2.019\n",
      "[7,   100] loss: 2.000\n",
      "[7,   200] loss: 2.010\n",
      "[8,   100] loss: 1.999\n",
      "[8,   200] loss: 1.995\n",
      "[9,   100] loss: 1.990\n",
      "[9,   200] loss: 1.992\n",
      "[10,   100] loss: 1.993\n",
      "[10,   200] loss: 2.018\n",
      "[11,   100] loss: 2.040\n",
      "[11,   200] loss: 2.033\n",
      "[12,   100] loss: 2.035\n",
      "[12,   200] loss: 2.053\n",
      "[13,   100] loss: 2.116\n",
      "[13,   200] loss: 2.119\n",
      "[14,   100] loss: 2.080\n",
      "[14,   200] loss: 2.071\n",
      "[15,   100] loss: 2.064\n",
      "[15,   200] loss: 2.058\n",
      "[16,   100] loss: 2.038\n",
      "[16,   200] loss: 2.053\n",
      "[17,   100] loss: 2.031\n",
      "[17,   200] loss: 2.027\n",
      "[18,   100] loss: 2.010\n",
      "[18,   200] loss: 2.017\n",
      "[19,   100] loss: 2.019\n",
      "[19,   200] loss: 2.045\n",
      "[20,   100] loss: 2.023\n",
      "[20,   200] loss: 2.031\n",
      "[21,   100] loss: 2.032\n",
      "[21,   200] loss: 2.041\n",
      "[22,   100] loss: 2.029\n",
      "[22,   200] loss: 2.040\n",
      "[23,   100] loss: 2.027\n",
      "[23,   200] loss: 2.021\n",
      "[24,   100] loss: 2.038\n",
      "[24,   200] loss: 2.030\n",
      "[25,   100] loss: 2.017\n",
      "[25,   200] loss: 2.010\n",
      "[26,   100] loss: 1.989\n",
      "[26,   200] loss: 2.021\n",
      "[27,   100] loss: 1.998\n",
      "[27,   200] loss: 2.008\n",
      "[28,   100] loss: 2.022\n",
      "[28,   200] loss: 2.017\n",
      "[29,   100] loss: 2.011\n",
      "[29,   200] loss: 2.033\n",
      "[30,   100] loss: 2.019\n",
      "[30,   200] loss: 2.030\n",
      "[31,   100] loss: 2.025\n",
      "[31,   200] loss: 2.031\n",
      "[32,   100] loss: 2.012\n",
      "[32,   200] loss: 2.037\n",
      "[33,   100] loss: 2.279\n",
      "[33,   200] loss: 2.303\n",
      "[34,   100] loss: 2.303\n",
      "[34,   200] loss: 2.303\n",
      "[35,   100] loss: 2.303\n",
      "[35,   200] loss: 2.303\n",
      "[36,   100] loss: 2.303\n",
      "[36,   200] loss: 2.303\n",
      "[37,   100] loss: 2.303\n",
      "[37,   200] loss: 2.303\n",
      "[38,   100] loss: 2.303\n",
      "[38,   200] loss: 2.303\n",
      "[39,   100] loss: 2.303\n",
      "[39,   200] loss: 2.303\n",
      "[40,   100] loss: 2.303\n",
      "[40,   200] loss: 2.303\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.352\n",
      "[1,   200] loss: 2.301\n",
      "[2,   100] loss: 2.272\n",
      "[2,   200] loss: 2.235\n",
      "[3,   100] loss: 2.241\n",
      "[3,   200] loss: 2.225\n",
      "[4,   100] loss: 2.211\n",
      "[4,   200] loss: 2.198\n",
      "[5,   100] loss: 2.217\n",
      "[5,   200] loss: 2.207\n",
      "[6,   100] loss: 2.207\n",
      "[6,   200] loss: 2.214\n",
      "[7,   100] loss: 2.205\n",
      "[7,   200] loss: 2.228\n",
      "[8,   100] loss: 2.222\n",
      "[8,   200] loss: 2.231\n",
      "[9,   100] loss: 2.224\n",
      "[9,   200] loss: 2.224\n",
      "[10,   100] loss: 2.238\n",
      "[10,   200] loss: 2.251\n",
      "[11,   100] loss: 2.256\n",
      "[11,   200] loss: 2.241\n",
      "[12,   100] loss: 2.216\n",
      "[12,   200] loss: 2.229\n",
      "[13,   100] loss: 2.253\n",
      "[13,   200] loss: 2.244\n",
      "[14,   100] loss: 2.236\n",
      "[14,   200] loss: 2.226\n",
      "[15,   100] loss: 2.244\n",
      "[15,   200] loss: 2.246\n",
      "[16,   100] loss: 2.234\n",
      "[16,   200] loss: 2.242\n",
      "[17,   100] loss: 2.235\n",
      "[17,   200] loss: 2.246\n",
      "[18,   100] loss: 2.246\n",
      "[18,   200] loss: 2.237\n",
      "[19,   100] loss: 2.250\n",
      "[19,   200] loss: 2.249\n",
      "[20,   100] loss: 2.253\n",
      "[20,   200] loss: 2.250\n",
      "[21,   100] loss: 2.252\n",
      "[21,   200] loss: 2.256\n",
      "[22,   100] loss: 2.258\n",
      "[22,   200] loss: 2.275\n",
      "[23,   100] loss: 2.266\n",
      "[23,   200] loss: 2.237\n",
      "[24,   100] loss: 2.254\n",
      "[24,   200] loss: 2.250\n",
      "[25,   100] loss: 2.245\n",
      "[25,   200] loss: 2.246\n",
      "[26,   100] loss: 2.245\n",
      "[26,   200] loss: 2.287\n",
      "[27,   100] loss: 2.257\n",
      "[27,   200] loss: 2.257\n",
      "[28,   100] loss: 2.244\n",
      "[28,   200] loss: 2.238\n",
      "[29,   100] loss: 2.244\n",
      "[29,   200] loss: 2.244\n",
      "[30,   100] loss: 2.247\n",
      "[30,   200] loss: 2.248\n",
      "[31,   100] loss: 2.245\n",
      "[31,   200] loss: 2.270\n",
      "[32,   100] loss: 2.250\n",
      "[32,   200] loss: 2.251\n",
      "[33,   100] loss: 2.254\n",
      "[33,   200] loss: 2.247\n",
      "[34,   100] loss: 2.243\n",
      "[34,   200] loss: 2.263\n",
      "[35,   100] loss: 2.251\n",
      "[35,   200] loss: 2.257\n",
      "[36,   100] loss: 2.241\n",
      "[36,   200] loss: 2.253\n",
      "[37,   100] loss: 2.253\n",
      "[37,   200] loss: 2.239\n",
      "[38,   100] loss: 2.247\n",
      "[38,   200] loss: 2.245\n",
      "[39,   100] loss: 2.257\n",
      "[39,   200] loss: 2.241\n",
      "[40,   100] loss: 2.286\n",
      "[40,   200] loss: 2.265\n",
      "Finished training!\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAFNCAYAAADSGTgvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWKwnEQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0dbfbdfa58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAYERSIZE = 300\n",
    "\n",
    "test_runs = 10\n",
    "epochs = 40\n",
    "\n",
    "int_lr = 0.3\n",
    "syn_lr = 0.003\n",
    "\n",
    "seed = random.randint(0, 1000000)\n",
    "\n",
    "#Train IP Model\n",
    "torch.manual_seed(seed)\n",
    "IPnet = CDNet(LAYERSIZE, IP, eta=int_lr)\n",
    "IPnet = IPnet.to(device)\n",
    "\n",
    "optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "print(\"Training IP Net\")\n",
    "ip_losses = train_deep_model(IPnet, optimizer1, seed, epochs)\n",
    "\n",
    "\n",
    "#Train Standard Model\n",
    "torch.manual_seed(seed)\n",
    "net = CDNet(LAYERSIZE, NN, eta=int_lr)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "print(\"Training Standard Net\")\n",
    "standard_losses = train_deep_model(net, optimizer2, seed, epochs)\n",
    "\n",
    "for i in range(test_runs-1):\n",
    "    seed = random.randint(0, 1000000)\n",
    "    \n",
    "    #Train IP Model\n",
    "    torch.manual_seed(seed)\n",
    "    IPnet = CDNet(LAYERSIZE, IP, eta=int_lr)\n",
    "    IPnet = IPnet.to(device)\n",
    "\n",
    "    optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training IP Net\")\n",
    "    ip_losses += train_deep_model(IPnet, optimizer1, seed, epochs)\n",
    "\n",
    "\n",
    "    #Train Standard Model\n",
    "    torch.manual_seed(seed)\n",
    "    net = CDNet(LAYERSIZE, NN, eta=int_lr)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "    print(\"Training Standard Net\")\n",
    "    standard_losses += train_deep_model(net, optimizer2, seed, epochs)\n",
    "    \n",
    "ip_losses = ip_losses/test_runs\n",
    "standard_losses = standard_losses/test_runs\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.ylim([-0.1, 3])\n",
    "plt.title(\"Learning curves for deep networks\")\n",
    "plt.plot(ip_losses[0], ip_losses[1], label=\"IP\")\n",
    "# plt.plot(bn_losses[0], bn_losses[1], label=\"BN\")\n",
    "plt.plot(standard_losses[0], standard_losses[1], label=\"Standard\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "int_lr = 0.3\n",
    "syn_lr = 0.006\n",
    "\n",
    "seed = random.randint(0, 1000000)\n",
    "\n",
    "#Train IP Model\n",
    "torch.manual_seed(seed)\n",
    "IPnet = CDNet(LAYERSIZE, IP, eta=int_lr)\n",
    "IPnet = IPnet.to(device)\n",
    "\n",
    "optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "print(\"Training IP Net\")\n",
    "ip_losses = train_deep_model(IPnet, optimizer1, seed, epochs)\n",
    "\n",
    "\n",
    "#Train Standard Model\n",
    "torch.manual_seed(seed)\n",
    "net = CDNet(LAYERSIZE, NN, eta=int_lr)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "print(\"Training Standard Net\")\n",
    "standard_losses = train_deep_model(net, optimizer2, seed, epochs)\n",
    "\n",
    "for i in range(test_runs-1):\n",
    "    seed = random.randint(0, 1000000)\n",
    "    \n",
    "    #Train IP Model\n",
    "    torch.manual_seed(seed)\n",
    "    IPnet = CDNet(LAYERSIZE, IP, eta=int_lr)\n",
    "    IPnet = IPnet.to(device)\n",
    "\n",
    "    optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training IP Net\")\n",
    "    ip_losses += train_deep_model(IPnet, optimizer1, seed, epochs)\n",
    "\n",
    "\n",
    "    #Train Standard Model\n",
    "    torch.manual_seed(seed)\n",
    "    net = CDNet(LAYERSIZE, NN, eta=int_lr)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "    print(\"Training Standard Net\")\n",
    "    standard_losses += train_deep_model(net, optimizer2, seed, epochs)\n",
    "    \n",
    "ip_losses = ip_losses/test_runs\n",
    "standard_losses = standard_losses/test_runs\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.ylim([-0.1, 3])\n",
    "plt.title(\"Learning curves for deep networks\")\n",
    "plt.plot(ip_losses[0], ip_losses[1], label=\"IP\")\n",
    "# plt.plot(bn_losses[0], bn_losses[1], label=\"BN\")\n",
    "plt.plot(standard_losses[0], standard_losses[1], label=\"Standard\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "int_lr = 0.3\n",
    "syn_lr = 0.01\n",
    "\n",
    "seed = random.randint(0, 1000000)\n",
    "\n",
    "#Train IP Model\n",
    "torch.manual_seed(seed)\n",
    "IPnet = CDNet(LAYERSIZE, IP, eta=int_lr)\n",
    "IPnet = IPnet.to(device)\n",
    "\n",
    "optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "print(\"Training IP Net\")\n",
    "ip_losses = train_deep_model(IPnet, optimizer1, seed, epochs)\n",
    "\n",
    "\n",
    "#Train Standard Model\n",
    "torch.manual_seed(seed)\n",
    "net = CDNet(LAYERSIZE, NN, eta=int_lr)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "print(\"Training Standard Net\")\n",
    "standard_losses = train_deep_model(net, optimizer2, seed, epochs)\n",
    "\n",
    "for i in range(test_runs-1):\n",
    "    seed = random.randint(0, 1000000)\n",
    "    \n",
    "    #Train IP Model\n",
    "    torch.manual_seed(seed)\n",
    "    IPnet = CDNet(LAYERSIZE, IP, eta=int_lr)\n",
    "    IPnet = IPnet.to(device)\n",
    "\n",
    "    optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training IP Net\")\n",
    "    ip_losses += train_deep_model(IPnet, optimizer1, seed, epochs)\n",
    "\n",
    "\n",
    "    #Train Standard Model\n",
    "    torch.manual_seed(seed)\n",
    "    net = CDNet(LAYERSIZE, NN, eta=int_lr)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "    print(\"Training Standard Net\")\n",
    "    standard_losses += train_deep_model(net, optimizer2, seed, epochs)\n",
    "    \n",
    "ip_losses = ip_losses/test_runs\n",
    "standard_losses = standard_losses/test_runs\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "plt.ylim([-0.1, 3])\n",
    "plt.title(\"Learning curves for deep networks\")\n",
    "plt.plot(ip_losses[0], ip_losses[1], label=\"IP\")\n",
    "# plt.plot(bn_losses[0], bn_losses[1], label=\"BN\")\n",
    "plt.plot(standard_losses[0], standard_losses[1], label=\"Standard\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
