{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as LR\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total training batch number: 300\n",
      "==>>> total testing batch number: 50\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "print('==>>> total training batch number: {}'.format(len(trainloader)))\n",
    "print('==>>> total testing batch number: {}'.format(len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, layersize, eta=None):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "    def update(self, u, v, eta=None):\n",
    "        pass\n",
    "    \n",
    "class BN(nn.Module):\n",
    "    def __init__(self, layersize, eta=None):\n",
    "        super(BN, self).__init__()\n",
    "        self.gain = nn.Parameter(torch.ones(layersize))\n",
    "        self.bias = nn.Parameter(torch.zeros(layersize))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        beta = x.mean(0, keepdim=True)\n",
    "        alpha = ((x-beta)**2).mean(0, keepdim=True).sqrt()\n",
    "\n",
    "        # Normalize\n",
    "        nx = (x-beta)/alpha\n",
    "\n",
    "        # Adjust using learned parameters\n",
    "        o = self.gain*nx + self.bias\n",
    "        return o\n",
    "\n",
    "    def update(self, u, v, eta=None):\n",
    "        pass\n",
    "\n",
    "class IP(nn.Module):\n",
    "    def __init__(self, layersize, eta=1):\n",
    "        super(IP, self).__init__()\n",
    "        self.eta = eta\n",
    "        \n",
    "        # gain/bias are the learned output distribution params\n",
    "        self.gain = nn.Parameter(torch.ones(layersize))\n",
    "        self.bias = nn.Parameter(torch.zeros(layersize))\n",
    "        \n",
    "        # Alpha and beta are the ip normalization parameters\n",
    "        self.register_buffer('alpha', torch.ones(layersize))\n",
    "        self.register_buffer('beta', torch.zeros(layersize))\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Normalize\n",
    "        nx = (x-self.beta)/self.alpha\n",
    "\n",
    "        # Adjust using learned parameters\n",
    "        o = self.gain*nx + self.bias\n",
    "        return  o\n",
    "        \n",
    "    def update(self, u, v, eta=None):\n",
    "\n",
    "        if (eta is None):\n",
    "            eta = self.eta\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            Eu = u.mean(0, keepdim=True)\n",
    "            Euu = (u**2).mean(0, keepdim=True)\n",
    "            Ev = v.mean(0, keepdim=True)\n",
    "            Evv = (v**2).mean(0, keepdim=True)\n",
    "            Euv = (u*v).mean(0, keepdim=True)\n",
    "\n",
    "        self.alpha = (1-eta)*self.alpha + eta * (2*(Euv))\n",
    "        self.beta = (1-eta)*self.beta + eta * (2*Ev)\n",
    "        \n",
    "        self.eta = eta * 0.99\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, layersize, norm=None, eta=1):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Dense Layers\n",
    "        self.fc1 = nn.Linear(28*28, layersize)\n",
    "        self.fc2 = nn.Linear(layersize, layersize)\n",
    "        self.fc3 = nn.Linear(layersize, 10)\n",
    "        \n",
    "        # Normalization Layers\n",
    "        self.n1 = norm(layersize, eta)\n",
    "        self.n2 = norm(layersize, eta)\n",
    "        \n",
    "    def forward(self, x, eta=None):\n",
    "        x = x.view(-1, 28*28)\n",
    "        u1 = self.fc1(x)\n",
    "        v1 = F.tanh(self.n1(u1))\n",
    "        u2 = self.fc2(v1)\n",
    "        v2 = F.tanh(self.n2(u2))\n",
    "        # Note you should not normalize after the last linear layer (you delete info)\n",
    "        o = F.relu(self.fc3(v2))\n",
    "        \n",
    "        # Lets do the updates to the normalizations\n",
    "        self.n1.update(u1, v1, eta)\n",
    "        self.n2.update(u2, v2, eta)\n",
    "        \n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_deep_model(network, optimization, seed):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    loss_tracker = []\n",
    "    episode = 1\n",
    "    \n",
    "    for epoch in range(20):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimization.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            y = network(inputs)\n",
    "            loss = criterion(y, labels)\n",
    "            loss.backward()\n",
    "            optimization.step()\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                      (epoch + 1, i + 1, running_loss / 100))\n",
    "                running_loss = 0.0\n",
    "            \n",
    "            loss_tracker.append([episode,loss.item()])\n",
    "            episode += 1\n",
    "            \n",
    "    print(\"Finished training!\\n\")\n",
    "    return(np.transpose(loss_tracker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IP Net\n",
      "[1,   100] loss: 0.467\n",
      "[1,   200] loss: 0.215\n",
      "[1,   300] loss: 0.195\n",
      "[2,   100] loss: 0.147\n",
      "[2,   200] loss: 0.149\n",
      "[2,   300] loss: 0.144\n",
      "[3,   100] loss: 0.121\n",
      "[3,   200] loss: 0.118\n",
      "[3,   300] loss: 0.112\n",
      "[4,   100] loss: 0.093\n",
      "[4,   200] loss: 0.102\n",
      "[4,   300] loss: 0.115\n",
      "[5,   100] loss: 0.089\n",
      "[5,   200] loss: 0.105\n",
      "[5,   300] loss: 0.103\n",
      "[6,   100] loss: 0.091\n",
      "[6,   200] loss: 0.080\n",
      "[6,   300] loss: 0.089\n",
      "[7,   100] loss: 0.085\n",
      "[7,   200] loss: 0.084\n",
      "[7,   300] loss: 0.086\n",
      "[8,   100] loss: 0.070\n",
      "[8,   200] loss: 0.071\n",
      "[8,   300] loss: 0.082\n",
      "[9,   100] loss: 0.065\n",
      "[9,   200] loss: 0.073\n",
      "[9,   300] loss: 0.076\n",
      "[10,   100] loss: 0.059\n",
      "[10,   200] loss: 0.068\n",
      "[10,   300] loss: 0.080\n",
      "[11,   100] loss: 0.052\n",
      "[11,   200] loss: 0.064\n",
      "[11,   300] loss: 0.069\n",
      "[12,   100] loss: 0.056\n",
      "[12,   200] loss: 0.070\n",
      "[12,   300] loss: 0.072\n",
      "[13,   100] loss: 0.046\n",
      "[13,   200] loss: 0.055\n",
      "[13,   300] loss: 0.066\n",
      "[14,   100] loss: 0.048\n",
      "[14,   200] loss: 0.060\n",
      "[14,   300] loss: 0.056\n",
      "[15,   100] loss: 0.053\n",
      "[15,   200] loss: 0.058\n",
      "[15,   300] loss: 0.057\n",
      "[16,   100] loss: 0.050\n",
      "[16,   200] loss: 0.047\n",
      "[16,   300] loss: 0.070\n",
      "[17,   100] loss: 0.064\n",
      "[17,   200] loss: 0.060\n",
      "[17,   300] loss: 0.055\n",
      "[18,   100] loss: 0.047\n",
      "[18,   200] loss: 0.052\n",
      "[18,   300] loss: 0.060\n",
      "[19,   100] loss: 0.049\n",
      "[19,   200] loss: 0.050\n",
      "[19,   300] loss: 0.048\n",
      "[20,   100] loss: 0.038\n",
      "[20,   200] loss: 0.043\n",
      "[20,   300] loss: 0.048\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 0.522\n",
      "[1,   200] loss: 0.293\n",
      "[1,   300] loss: 0.281\n",
      "[2,   100] loss: 0.260\n",
      "[2,   200] loss: 0.253\n",
      "[2,   300] loss: 0.252\n",
      "[3,   100] loss: 0.235\n",
      "[3,   200] loss: 0.238\n",
      "[3,   300] loss: 0.239\n",
      "[4,   100] loss: 0.231\n",
      "[4,   200] loss: 0.235\n",
      "[4,   300] loss: 0.253\n",
      "[5,   100] loss: 0.248\n",
      "[5,   200] loss: 0.250\n",
      "[5,   300] loss: 0.211\n",
      "[6,   100] loss: 0.224\n",
      "[6,   200] loss: 0.228\n",
      "[6,   300] loss: 0.230\n",
      "[7,   100] loss: 0.238\n",
      "[7,   200] loss: 0.248\n",
      "[7,   300] loss: 0.242\n",
      "[8,   100] loss: 0.227\n",
      "[8,   200] loss: 0.215\n",
      "[8,   300] loss: 0.223\n",
      "[9,   100] loss: 0.219\n",
      "[9,   200] loss: 0.218\n",
      "[9,   300] loss: 0.216\n",
      "[10,   100] loss: 0.217\n",
      "[10,   200] loss: 0.221\n",
      "[10,   300] loss: 0.235\n",
      "[11,   100] loss: 0.206\n",
      "[11,   200] loss: 0.249\n",
      "[11,   300] loss: 0.237\n",
      "[12,   100] loss: 0.235\n",
      "[12,   200] loss: 0.229\n",
      "[12,   300] loss: 0.243\n",
      "[13,   100] loss: 0.220\n",
      "[13,   200] loss: 0.225\n",
      "[13,   300] loss: 0.227\n",
      "[14,   100] loss: 0.230\n",
      "[14,   200] loss: 0.218\n",
      "[14,   300] loss: 0.234\n",
      "[15,   100] loss: 0.237\n",
      "[15,   200] loss: 0.219\n",
      "[15,   300] loss: 0.232\n",
      "[16,   100] loss: 0.225\n",
      "[16,   200] loss: 0.220\n",
      "[16,   300] loss: 0.244\n",
      "[17,   100] loss: 0.225\n",
      "[17,   200] loss: 0.207\n",
      "[17,   300] loss: 0.227\n",
      "[18,   100] loss: 0.209\n",
      "[18,   200] loss: 0.229\n",
      "[18,   300] loss: 0.234\n",
      "[19,   100] loss: 0.210\n",
      "[19,   200] loss: 0.231\n",
      "[19,   300] loss: 0.230\n",
      "[20,   100] loss: 0.219\n",
      "[20,   200] loss: 0.211\n",
      "[20,   300] loss: 0.226\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.460\n",
      "[1,   200] loss: 0.217\n",
      "[1,   300] loss: 0.187\n",
      "[2,   100] loss: 0.152\n",
      "[2,   200] loss: 0.146\n",
      "[2,   300] loss: 0.147\n",
      "[3,   100] loss: 0.119\n",
      "[3,   200] loss: 0.138\n",
      "[3,   300] loss: 0.122\n",
      "[4,   100] loss: 0.097\n",
      "[4,   200] loss: 0.104\n",
      "[4,   300] loss: 0.100\n",
      "[5,   100] loss: 0.083\n",
      "[5,   200] loss: 0.086\n",
      "[5,   300] loss: 0.102\n",
      "[6,   100] loss: 0.086\n",
      "[6,   200] loss: 0.082\n",
      "[6,   300] loss: 0.088\n",
      "[7,   100] loss: 0.071\n",
      "[7,   200] loss: 0.086\n",
      "[7,   300] loss: 0.085\n",
      "[8,   100] loss: 0.065\n",
      "[8,   200] loss: 0.078\n",
      "[8,   300] loss: 0.082\n",
      "[9,   100] loss: 0.053\n",
      "[9,   200] loss: 0.073\n",
      "[9,   300] loss: 0.071\n",
      "[10,   100] loss: 0.062\n",
      "[10,   200] loss: 0.065\n",
      "[10,   300] loss: 0.074\n",
      "[11,   100] loss: 0.053\n",
      "[11,   200] loss: 0.068\n",
      "[11,   300] loss: 0.066\n",
      "[12,   100] loss: 0.051\n",
      "[12,   200] loss: 0.054\n",
      "[12,   300] loss: 0.071\n",
      "[13,   100] loss: 0.054\n",
      "[13,   200] loss: 0.060\n",
      "[13,   300] loss: 0.064\n",
      "[14,   100] loss: 0.048\n",
      "[14,   200] loss: 0.050\n",
      "[14,   300] loss: 0.064\n",
      "[15,   100] loss: 0.041\n",
      "[15,   200] loss: 0.051\n",
      "[15,   300] loss: 0.074\n",
      "[16,   100] loss: 0.054\n",
      "[16,   200] loss: 0.060\n",
      "[16,   300] loss: 0.059\n",
      "[17,   100] loss: 0.041\n",
      "[17,   200] loss: 0.055\n",
      "[17,   300] loss: 0.050\n",
      "[18,   100] loss: 0.032\n",
      "[18,   200] loss: 0.043\n",
      "[18,   300] loss: 0.061\n",
      "[19,   100] loss: 0.044\n",
      "[19,   200] loss: 0.048\n",
      "[19,   300] loss: 0.052\n",
      "[20,   100] loss: 0.043\n",
      "[20,   200] loss: 0.050\n",
      "[20,   300] loss: 0.047\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 0.507\n",
      "[1,   200] loss: 0.310\n",
      "[1,   300] loss: 0.268\n",
      "[2,   100] loss: 0.250\n",
      "[2,   200] loss: 0.250\n",
      "[2,   300] loss: 0.247\n",
      "[3,   100] loss: 0.236\n",
      "[3,   200] loss: 0.230\n",
      "[3,   300] loss: 0.257\n",
      "[4,   100] loss: 0.242\n",
      "[4,   200] loss: 0.249\n",
      "[4,   300] loss: 0.231\n",
      "[5,   100] loss: 0.230\n",
      "[5,   200] loss: 0.232\n",
      "[5,   300] loss: 0.244\n",
      "[6,   100] loss: 0.243\n",
      "[6,   200] loss: 0.238\n",
      "[6,   300] loss: 0.228\n",
      "[7,   100] loss: 0.230\n",
      "[7,   200] loss: 0.240\n",
      "[7,   300] loss: 0.233\n",
      "[8,   100] loss: 0.228\n",
      "[8,   200] loss: 0.244\n",
      "[8,   300] loss: 0.242\n",
      "[9,   100] loss: 0.240\n",
      "[9,   200] loss: 0.235\n",
      "[9,   300] loss: 0.229\n",
      "[10,   100] loss: 0.237\n",
      "[10,   200] loss: 0.217\n",
      "[10,   300] loss: 0.225\n",
      "[11,   100] loss: 0.207\n",
      "[11,   200] loss: 0.227\n",
      "[11,   300] loss: 0.226\n",
      "[12,   100] loss: 0.221\n",
      "[12,   200] loss: 0.230\n",
      "[12,   300] loss: 0.233\n",
      "[13,   100] loss: 0.241\n",
      "[13,   200] loss: 0.256\n",
      "[13,   300] loss: 0.225\n",
      "[14,   100] loss: 0.238\n",
      "[14,   200] loss: 0.228\n",
      "[14,   300] loss: 0.235\n",
      "[15,   100] loss: 0.227\n",
      "[15,   200] loss: 0.231\n",
      "[15,   300] loss: 0.222\n",
      "[16,   100] loss: 0.209\n",
      "[16,   200] loss: 0.229\n",
      "[16,   300] loss: 0.225\n",
      "[17,   100] loss: 0.221\n",
      "[17,   200] loss: 0.229\n",
      "[17,   300] loss: 0.212\n",
      "[18,   100] loss: 0.226\n",
      "[18,   200] loss: 0.214\n",
      "[18,   300] loss: 0.231\n",
      "[19,   100] loss: 0.223\n",
      "[19,   200] loss: 0.238\n",
      "[19,   300] loss: 0.249\n",
      "[20,   100] loss: 0.234\n",
      "[20,   200] loss: 0.215\n",
      "[20,   300] loss: 0.217\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.466\n",
      "[1,   200] loss: 0.221\n",
      "[1,   300] loss: 0.194\n",
      "[2,   100] loss: 0.160\n",
      "[2,   200] loss: 0.150\n",
      "[2,   300] loss: 0.156\n",
      "[3,   100] loss: 0.120\n",
      "[3,   200] loss: 0.117\n",
      "[3,   300] loss: 0.123\n",
      "[4,   100] loss: 0.102\n",
      "[4,   200] loss: 0.106\n",
      "[4,   300] loss: 0.103\n",
      "[5,   100] loss: 0.079\n",
      "[5,   200] loss: 0.085\n",
      "[5,   300] loss: 0.096\n",
      "[6,   100] loss: 0.075\n",
      "[6,   200] loss: 0.082\n",
      "[6,   300] loss: 0.098\n",
      "[7,   100] loss: 0.072\n",
      "[7,   200] loss: 0.087\n",
      "[7,   300] loss: 0.081\n",
      "[8,   100] loss: 0.063\n",
      "[8,   200] loss: 0.065\n",
      "[8,   300] loss: 0.074\n",
      "[9,   100] loss: 0.057\n",
      "[9,   200] loss: 0.064\n",
      "[9,   300] loss: 0.071\n",
      "[10,   100] loss: 0.051\n",
      "[10,   200] loss: 0.071\n",
      "[10,   300] loss: 0.081\n",
      "[11,   100] loss: 0.052\n",
      "[11,   200] loss: 0.061\n",
      "[11,   300] loss: 0.069\n",
      "[12,   100] loss: 0.048\n",
      "[12,   200] loss: 0.061\n",
      "[12,   300] loss: 0.057\n",
      "[13,   100] loss: 0.048\n",
      "[13,   200] loss: 0.058\n",
      "[13,   300] loss: 0.056\n",
      "[14,   100] loss: 0.050\n",
      "[14,   200] loss: 0.059\n",
      "[14,   300] loss: 0.058\n",
      "[15,   100] loss: 0.052\n",
      "[15,   200] loss: 0.049\n",
      "[15,   300] loss: 0.058\n",
      "[16,   100] loss: 0.039\n",
      "[16,   200] loss: 0.047\n",
      "[16,   300] loss: 0.050\n",
      "[17,   100] loss: 0.048\n",
      "[17,   200] loss: 0.054\n",
      "[17,   300] loss: 0.057\n",
      "[18,   100] loss: 0.047\n",
      "[18,   200] loss: 0.060\n",
      "[18,   300] loss: 0.061\n",
      "[19,   100] loss: 0.035\n",
      "[19,   200] loss: 0.047\n",
      "[19,   300] loss: 0.062\n",
      "[20,   100] loss: 0.045\n",
      "[20,   200] loss: 0.044\n",
      "[20,   300] loss: 0.053\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 0.531\n",
      "[1,   200] loss: 0.280\n",
      "[1,   300] loss: 0.284\n",
      "[2,   100] loss: 0.258\n",
      "[2,   200] loss: 0.252\n",
      "[2,   300] loss: 0.264\n",
      "[3,   100] loss: 0.251\n",
      "[3,   200] loss: 0.248\n",
      "[3,   300] loss: 0.250\n",
      "[4,   100] loss: 0.227\n",
      "[4,   200] loss: 0.253\n",
      "[4,   300] loss: 0.236\n",
      "[5,   100] loss: 0.230\n",
      "[5,   200] loss: 0.227\n",
      "[5,   300] loss: 0.230\n",
      "[6,   100] loss: 0.227\n",
      "[6,   200] loss: 0.234\n",
      "[6,   300] loss: 0.241\n",
      "[7,   100] loss: 0.218\n",
      "[7,   200] loss: 0.218\n",
      "[7,   300] loss: 0.223\n",
      "[8,   100] loss: 0.219\n",
      "[8,   200] loss: 0.234\n",
      "[8,   300] loss: 0.230\n",
      "[9,   100] loss: 0.235\n",
      "[9,   200] loss: 0.239\n",
      "[9,   300] loss: 0.243\n",
      "[10,   100] loss: 0.230\n",
      "[10,   200] loss: 0.230\n",
      "[10,   300] loss: 0.233\n",
      "[11,   100] loss: 0.226\n",
      "[11,   200] loss: 0.251\n",
      "[11,   300] loss: 0.232\n",
      "[12,   100] loss: 0.216\n",
      "[12,   200] loss: 0.220\n",
      "[12,   300] loss: 0.221\n",
      "[13,   100] loss: 0.222\n",
      "[13,   200] loss: 0.246\n",
      "[13,   300] loss: 0.223\n",
      "[14,   100] loss: 0.224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14,   200] loss: 0.224\n",
      "[14,   300] loss: 0.227\n",
      "[15,   100] loss: 0.218\n",
      "[15,   200] loss: 0.244\n",
      "[15,   300] loss: 0.226\n",
      "[16,   100] loss: 0.236\n",
      "[16,   200] loss: 0.255\n",
      "[16,   300] loss: 0.218\n",
      "[17,   100] loss: 0.233\n",
      "[17,   200] loss: 0.241\n",
      "[17,   300] loss: 0.246\n",
      "[18,   100] loss: 0.239\n",
      "[18,   200] loss: 0.254\n",
      "[18,   300] loss: 0.250\n",
      "[19,   100] loss: 0.234\n",
      "[19,   200] loss: 0.212\n",
      "[19,   300] loss: 0.241\n",
      "[20,   100] loss: 0.214\n",
      "[20,   200] loss: 0.213\n",
      "[20,   300] loss: 0.204\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.701\n",
      "[1,   200] loss: 0.249\n",
      "[1,   300] loss: 0.192\n",
      "[2,   100] loss: 0.154\n",
      "[2,   200] loss: 0.152\n",
      "[2,   300] loss: 0.144\n",
      "[3,   100] loss: 0.115\n",
      "[3,   200] loss: 0.120\n",
      "[3,   300] loss: 0.117\n",
      "[4,   100] loss: 0.104\n",
      "[4,   200] loss: 0.106\n",
      "[4,   300] loss: 0.113\n",
      "[5,   100] loss: 0.083\n",
      "[5,   200] loss: 0.088\n",
      "[5,   300] loss: 0.097\n",
      "[6,   100] loss: 0.077\n",
      "[6,   200] loss: 0.076\n",
      "[6,   300] loss: 0.095\n",
      "[7,   100] loss: 0.078\n",
      "[7,   200] loss: 0.079\n",
      "[7,   300] loss: 0.079\n",
      "[8,   100] loss: 0.059\n",
      "[8,   200] loss: 0.066\n",
      "[8,   300] loss: 0.077\n",
      "[9,   100] loss: 0.061\n",
      "[9,   200] loss: 0.066\n",
      "[9,   300] loss: 0.073\n",
      "[10,   100] loss: 0.071\n",
      "[10,   200] loss: 0.071\n",
      "[10,   300] loss: 0.076\n",
      "[11,   100] loss: 0.056\n",
      "[11,   200] loss: 0.072\n",
      "[11,   300] loss: 0.065\n",
      "[12,   100] loss: 0.045\n",
      "[12,   200] loss: 0.057\n",
      "[12,   300] loss: 0.063\n",
      "[13,   100] loss: 0.052\n",
      "[13,   200] loss: 0.057\n",
      "[13,   300] loss: 0.060\n",
      "[14,   100] loss: 0.043\n",
      "[14,   200] loss: 0.052\n",
      "[14,   300] loss: 0.063\n",
      "[15,   100] loss: 0.043\n",
      "[15,   200] loss: 0.051\n",
      "[15,   300] loss: 0.051\n",
      "[16,   100] loss: 0.039\n",
      "[16,   200] loss: 0.044\n",
      "[16,   300] loss: 0.048\n",
      "[17,   100] loss: 0.046\n",
      "[17,   200] loss: 0.050\n",
      "[17,   300] loss: 0.051\n",
      "[18,   100] loss: 0.036\n",
      "[18,   200] loss: 0.046\n",
      "[18,   300] loss: 0.051\n",
      "[19,   100] loss: 0.042\n",
      "[19,   200] loss: 0.037\n",
      "[19,   300] loss: 0.054\n",
      "[20,   100] loss: 0.039\n",
      "[20,   200] loss: 0.046\n",
      "[20,   300] loss: 0.054\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 0.817\n",
      "[1,   200] loss: 0.460\n",
      "[1,   300] loss: 0.279\n",
      "[2,   100] loss: 0.278\n",
      "[2,   200] loss: 0.263\n",
      "[2,   300] loss: 0.252\n",
      "[3,   100] loss: 0.254\n",
      "[3,   200] loss: 0.245\n",
      "[3,   300] loss: 0.231\n",
      "[4,   100] loss: 0.251\n",
      "[4,   200] loss: 0.245\n",
      "[4,   300] loss: 0.241\n",
      "[5,   100] loss: 0.221\n",
      "[5,   200] loss: 0.259\n",
      "[5,   300] loss: 0.229\n",
      "[6,   100] loss: 0.218\n",
      "[6,   200] loss: 0.235\n",
      "[6,   300] loss: 0.237\n",
      "[7,   100] loss: 0.214\n",
      "[7,   200] loss: 0.225\n",
      "[7,   300] loss: 0.256\n",
      "[8,   100] loss: 0.246\n",
      "[8,   200] loss: 0.246\n",
      "[8,   300] loss: 0.244\n",
      "[9,   100] loss: 0.233\n",
      "[9,   200] loss: 0.222\n",
      "[9,   300] loss: 0.229\n",
      "[10,   100] loss: 0.222\n",
      "[10,   200] loss: 0.221\n",
      "[10,   300] loss: 0.225\n",
      "[11,   100] loss: 0.223\n",
      "[11,   200] loss: 0.228\n",
      "[11,   300] loss: 0.227\n",
      "[12,   100] loss: 0.219\n",
      "[12,   200] loss: 0.205\n",
      "[12,   300] loss: 0.227\n",
      "[13,   100] loss: 0.219\n",
      "[13,   200] loss: 0.229\n",
      "[13,   300] loss: 0.229\n",
      "[14,   100] loss: 0.222\n",
      "[14,   200] loss: 0.241\n",
      "[14,   300] loss: 0.241\n",
      "[15,   100] loss: 0.229\n",
      "[15,   200] loss: 0.271\n",
      "[15,   300] loss: 0.238\n",
      "[16,   100] loss: 0.241\n",
      "[16,   200] loss: 0.235\n",
      "[16,   300] loss: 0.229\n",
      "[17,   100] loss: 0.215\n",
      "[17,   200] loss: 0.225\n",
      "[17,   300] loss: 0.210\n",
      "[18,   100] loss: 0.211\n",
      "[18,   200] loss: 0.205\n",
      "[18,   300] loss: 0.224\n",
      "[19,   100] loss: 0.223\n",
      "[19,   200] loss: 0.238\n",
      "[19,   300] loss: 0.226\n",
      "[20,   100] loss: 0.213\n",
      "[20,   200] loss: 0.212\n",
      "[20,   300] loss: 0.226\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.497\n",
      "[1,   200] loss: 0.206\n",
      "[1,   300] loss: 0.192\n",
      "[2,   100] loss: 0.170\n",
      "[2,   200] loss: 0.157\n",
      "[2,   300] loss: 0.140\n",
      "[3,   100] loss: 0.120\n",
      "[3,   200] loss: 0.118\n",
      "[3,   300] loss: 0.135\n",
      "[4,   100] loss: 0.098\n",
      "[4,   200] loss: 0.107\n",
      "[4,   300] loss: 0.114\n",
      "[5,   100] loss: 0.091\n",
      "[5,   200] loss: 0.095\n",
      "[5,   300] loss: 0.107\n",
      "[6,   100] loss: 0.075\n",
      "[6,   200] loss: 0.091\n",
      "[6,   300] loss: 0.092\n",
      "[7,   100] loss: 0.068\n",
      "[7,   200] loss: 0.082\n",
      "[7,   300] loss: 0.088\n",
      "[8,   100] loss: 0.078\n",
      "[8,   200] loss: 0.072\n",
      "[8,   300] loss: 0.074\n",
      "[9,   100] loss: 0.059\n",
      "[9,   200] loss: 0.072\n",
      "[9,   300] loss: 0.082\n",
      "[10,   100] loss: 0.058\n",
      "[10,   200] loss: 0.076\n",
      "[10,   300] loss: 0.068\n",
      "[11,   100] loss: 0.050\n",
      "[11,   200] loss: 0.064\n",
      "[11,   300] loss: 0.068\n",
      "[12,   100] loss: 0.063\n",
      "[12,   200] loss: 0.062\n",
      "[12,   300] loss: 0.064\n",
      "[13,   100] loss: 0.058\n",
      "[13,   200] loss: 0.050\n",
      "[13,   300] loss: 0.066\n",
      "[14,   100] loss: 0.051\n",
      "[14,   200] loss: 0.059\n",
      "[14,   300] loss: 0.062\n",
      "[15,   100] loss: 0.044\n",
      "[15,   200] loss: 0.057\n",
      "[15,   300] loss: 0.061\n",
      "[16,   100] loss: 0.044\n",
      "[16,   200] loss: 0.055\n",
      "[16,   300] loss: 0.066\n",
      "[17,   100] loss: 0.039\n",
      "[17,   200] loss: 0.053\n",
      "[17,   300] loss: 0.058\n",
      "[18,   100] loss: 0.045\n",
      "[18,   200] loss: 0.051\n",
      "[18,   300] loss: 0.070\n",
      "[19,   100] loss: 0.044\n",
      "[19,   200] loss: 0.045\n",
      "[19,   300] loss: 0.056\n",
      "[20,   100] loss: 0.038\n",
      "[20,   200] loss: 0.038\n",
      "[20,   300] loss: 0.053\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 0.511\n",
      "[1,   200] loss: 0.269\n",
      "[1,   300] loss: 0.275\n",
      "[2,   100] loss: 0.254\n",
      "[2,   200] loss: 0.251\n",
      "[2,   300] loss: 0.240\n",
      "[3,   100] loss: 0.253\n",
      "[3,   200] loss: 0.231\n",
      "[3,   300] loss: 0.254\n",
      "[4,   100] loss: 0.247\n",
      "[4,   200] loss: 0.248\n",
      "[4,   300] loss: 0.238\n",
      "[5,   100] loss: 0.240\n",
      "[5,   200] loss: 0.225\n",
      "[5,   300] loss: 0.242\n",
      "[6,   100] loss: 0.227\n",
      "[6,   200] loss: 0.223\n",
      "[6,   300] loss: 0.245\n",
      "[7,   100] loss: 0.233\n",
      "[7,   200] loss: 0.235\n",
      "[7,   300] loss: 0.236\n",
      "[8,   100] loss: 0.231\n",
      "[8,   200] loss: 0.231\n",
      "[8,   300] loss: 0.232\n",
      "[9,   100] loss: 0.240\n",
      "[9,   200] loss: 0.220\n",
      "[9,   300] loss: 0.229\n",
      "[10,   100] loss: 0.250\n",
      "[10,   200] loss: 0.236\n",
      "[10,   300] loss: 0.241\n",
      "[11,   100] loss: 0.219\n",
      "[11,   200] loss: 0.224\n",
      "[11,   300] loss: 0.217\n",
      "[12,   100] loss: 0.218\n",
      "[12,   200] loss: 0.230\n",
      "[12,   300] loss: 0.251\n",
      "[13,   100] loss: 0.223\n",
      "[13,   200] loss: 0.218\n",
      "[13,   300] loss: 0.228\n",
      "[14,   100] loss: 0.214\n",
      "[14,   200] loss: 0.220\n",
      "[14,   300] loss: 0.230\n",
      "[15,   100] loss: 0.227\n",
      "[15,   200] loss: 0.221\n",
      "[15,   300] loss: 0.237\n",
      "[16,   100] loss: 0.212\n",
      "[16,   200] loss: 0.199\n",
      "[16,   300] loss: 0.235\n",
      "[17,   100] loss: 0.218\n",
      "[17,   200] loss: 0.223\n",
      "[17,   300] loss: 0.198\n",
      "[18,   100] loss: 0.213\n",
      "[18,   200] loss: 0.214\n",
      "[18,   300] loss: 0.235\n",
      "[19,   100] loss: 0.219\n",
      "[19,   200] loss: 0.222\n",
      "[19,   300] loss: 0.220\n",
      "[20,   100] loss: 0.199\n",
      "[20,   200] loss: 0.218\n",
      "[20,   300] loss: 0.223\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.694\n",
      "[1,   200] loss: 0.459\n",
      "[1,   300] loss: 0.407\n",
      "[2,   100] loss: 0.393\n",
      "[2,   200] loss: 0.375\n",
      "[2,   300] loss: 0.363\n",
      "[3,   100] loss: 0.346\n",
      "[3,   200] loss: 0.353\n",
      "[3,   300] loss: 0.357\n",
      "[4,   100] loss: 0.318\n",
      "[4,   200] loss: 0.335\n",
      "[4,   300] loss: 0.343\n",
      "[5,   100] loss: 0.305\n",
      "[5,   200] loss: 0.322\n",
      "[5,   300] loss: 0.335\n",
      "[6,   100] loss: 0.312\n",
      "[6,   200] loss: 0.308\n",
      "[6,   300] loss: 0.322\n",
      "[7,   100] loss: 0.307\n",
      "[7,   200] loss: 0.312\n",
      "[7,   300] loss: 0.309\n",
      "[8,   100] loss: 0.296\n",
      "[8,   200] loss: 0.307\n",
      "[8,   300] loss: 0.319\n",
      "[9,   100] loss: 0.285\n",
      "[9,   200] loss: 0.308\n",
      "[9,   300] loss: 0.307\n",
      "[10,   100] loss: 0.292\n",
      "[10,   200] loss: 0.287\n",
      "[10,   300] loss: 0.303\n",
      "[11,   100] loss: 0.285\n",
      "[11,   200] loss: 0.296\n",
      "[11,   300] loss: 0.297\n",
      "[12,   100] loss: 0.290\n",
      "[12,   200] loss: 0.300\n",
      "[12,   300] loss: 0.291\n",
      "[13,   100] loss: 0.276\n",
      "[13,   200] loss: 0.287\n",
      "[13,   300] loss: 0.292\n",
      "[14,   100] loss: 0.278\n",
      "[14,   200] loss: 0.290\n",
      "[14,   300] loss: 0.279\n",
      "[15,   100] loss: 0.280\n",
      "[15,   200] loss: 0.279\n",
      "[15,   300] loss: 0.277\n",
      "[16,   100] loss: 0.275\n",
      "[16,   200] loss: 0.288\n",
      "[16,   300] loss: 0.287\n",
      "[17,   100] loss: 0.279\n",
      "[17,   200] loss: 0.264\n",
      "[17,   300] loss: 0.287\n",
      "[18,   100] loss: 0.266\n",
      "[18,   200] loss: 0.278\n",
      "[18,   300] loss: 0.282\n",
      "[19,   100] loss: 0.270\n",
      "[19,   200] loss: 0.287\n",
      "[19,   300] loss: 0.302\n",
      "[20,   100] loss: 0.263\n",
      "[20,   200] loss: 0.277\n",
      "[20,   300] loss: 0.282\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 0.713\n",
      "[1,   200] loss: 0.507\n",
      "[1,   300] loss: 0.495\n",
      "[2,   100] loss: 0.464\n",
      "[2,   200] loss: 0.471\n",
      "[2,   300] loss: 0.453\n",
      "[3,   100] loss: 0.459\n",
      "[3,   200] loss: 0.481\n",
      "[3,   300] loss: 0.476\n",
      "[4,   100] loss: 0.451\n",
      "[4,   200] loss: 0.464\n",
      "[4,   300] loss: 0.459\n",
      "[5,   100] loss: 0.423\n",
      "[5,   200] loss: 0.450\n",
      "[5,   300] loss: 0.453\n",
      "[6,   100] loss: 0.442\n",
      "[6,   200] loss: 0.445\n",
      "[6,   300] loss: 0.442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7,   100] loss: 0.434\n",
      "[7,   200] loss: 0.430\n",
      "[7,   300] loss: 0.445\n",
      "[8,   100] loss: 0.442\n",
      "[8,   200] loss: 0.439\n",
      "[8,   300] loss: 0.462\n",
      "[9,   100] loss: 0.428\n",
      "[9,   200] loss: 0.448\n",
      "[9,   300] loss: 0.442\n",
      "[10,   100] loss: 0.436\n",
      "[10,   200] loss: 0.428\n",
      "[10,   300] loss: 0.455\n",
      "[11,   100] loss: 0.440\n",
      "[11,   200] loss: 0.447\n",
      "[11,   300] loss: 0.440\n",
      "[12,   100] loss: 0.433\n",
      "[12,   200] loss: 0.447\n",
      "[12,   300] loss: 0.434\n",
      "[13,   100] loss: 0.428\n",
      "[13,   200] loss: 0.422\n",
      "[13,   300] loss: 0.418\n",
      "[14,   100] loss: 0.412\n",
      "[14,   200] loss: 0.430\n",
      "[14,   300] loss: 0.423\n",
      "[15,   100] loss: 0.430\n",
      "[15,   200] loss: 0.428\n",
      "[15,   300] loss: 0.425\n",
      "[16,   100] loss: 0.430\n",
      "[16,   200] loss: 0.445\n",
      "[16,   300] loss: 0.440\n",
      "[17,   100] loss: 0.443\n",
      "[17,   200] loss: 0.431\n",
      "[17,   300] loss: 0.470\n",
      "[18,   100] loss: 0.432\n",
      "[18,   200] loss: 0.447\n",
      "[18,   300] loss: 0.440\n",
      "[19,   100] loss: 0.423\n",
      "[19,   200] loss: 0.432\n",
      "[19,   300] loss: 0.430\n",
      "[20,   100] loss: 0.422\n",
      "[20,   200] loss: 0.431\n",
      "[20,   300] loss: 0.451\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.516\n",
      "[1,   200] loss: 0.220\n",
      "[1,   300] loss: 0.203\n",
      "[2,   100] loss: 0.149\n",
      "[2,   200] loss: 0.165\n",
      "[2,   300] loss: 0.139\n",
      "[3,   100] loss: 0.121\n",
      "[3,   200] loss: 0.130\n",
      "[3,   300] loss: 0.120\n",
      "[4,   100] loss: 0.094\n",
      "[4,   200] loss: 0.100\n",
      "[4,   300] loss: 0.113\n",
      "[5,   100] loss: 0.081\n",
      "[5,   200] loss: 0.103\n",
      "[5,   300] loss: 0.087\n",
      "[6,   100] loss: 0.071\n",
      "[6,   200] loss: 0.087\n",
      "[6,   300] loss: 0.092\n",
      "[7,   100] loss: 0.070\n",
      "[7,   200] loss: 0.077\n",
      "[7,   300] loss: 0.076\n",
      "[8,   100] loss: 0.062\n",
      "[8,   200] loss: 0.075\n",
      "[8,   300] loss: 0.081\n",
      "[9,   100] loss: 0.062\n",
      "[9,   200] loss: 0.074\n",
      "[9,   300] loss: 0.075\n",
      "[10,   100] loss: 0.050\n",
      "[10,   200] loss: 0.058\n",
      "[10,   300] loss: 0.068\n",
      "[11,   100] loss: 0.046\n",
      "[11,   200] loss: 0.074\n",
      "[11,   300] loss: 0.069\n",
      "[12,   100] loss: 0.053\n",
      "[12,   200] loss: 0.061\n",
      "[12,   300] loss: 0.072\n",
      "[13,   100] loss: 0.055\n",
      "[13,   200] loss: 0.062\n",
      "[13,   300] loss: 0.064\n",
      "[14,   100] loss: 0.049\n",
      "[14,   200] loss: 0.055\n",
      "[14,   300] loss: 0.065\n",
      "[15,   100] loss: 0.053\n",
      "[15,   200] loss: 0.055\n",
      "[15,   300] loss: 0.056\n",
      "[16,   100] loss: 0.046\n",
      "[16,   200] loss: 0.054\n",
      "[16,   300] loss: 0.065\n",
      "[17,   100] loss: 0.042\n",
      "[17,   200] loss: 0.040\n",
      "[17,   300] loss: 0.055\n",
      "[18,   100] loss: 0.040\n",
      "[18,   200] loss: 0.043\n",
      "[18,   300] loss: 0.059\n",
      "[19,   100] loss: 0.042\n",
      "[19,   200] loss: 0.046\n",
      "[19,   300] loss: 0.060\n",
      "[20,   100] loss: 0.046\n",
      "[20,   200] loss: 0.052\n",
      "[20,   300] loss: 0.041\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 0.628\n",
      "[1,   200] loss: 0.303\n",
      "[1,   300] loss: 0.297\n",
      "[2,   100] loss: 0.274\n",
      "[2,   200] loss: 0.263\n",
      "[2,   300] loss: 0.235\n",
      "[3,   100] loss: 0.235\n",
      "[3,   200] loss: 0.245\n",
      "[3,   300] loss: 0.251\n",
      "[4,   100] loss: 0.239\n",
      "[4,   200] loss: 0.246\n",
      "[4,   300] loss: 0.252\n",
      "[5,   100] loss: 0.241\n",
      "[5,   200] loss: 0.233\n",
      "[5,   300] loss: 0.235\n",
      "[6,   100] loss: 0.236\n",
      "[6,   200] loss: 0.223\n",
      "[6,   300] loss: 0.243\n",
      "[7,   100] loss: 0.230\n",
      "[7,   200] loss: 0.225\n",
      "[7,   300] loss: 0.224\n",
      "[8,   100] loss: 0.204\n",
      "[8,   200] loss: 0.241\n",
      "[8,   300] loss: 0.235\n",
      "[9,   100] loss: 0.217\n",
      "[9,   200] loss: 0.225\n",
      "[9,   300] loss: 0.230\n",
      "[10,   100] loss: 0.209\n",
      "[10,   200] loss: 0.243\n",
      "[10,   300] loss: 0.230\n",
      "[11,   100] loss: 0.241\n",
      "[11,   200] loss: 0.233\n",
      "[11,   300] loss: 0.224\n",
      "[12,   100] loss: 0.236\n",
      "[12,   200] loss: 0.249\n",
      "[12,   300] loss: 0.244\n",
      "[13,   100] loss: 0.220\n",
      "[13,   200] loss: 0.232\n",
      "[13,   300] loss: 0.238\n",
      "[14,   100] loss: 0.230\n",
      "[14,   200] loss: 0.221\n",
      "[14,   300] loss: 0.236\n",
      "[15,   100] loss: 0.220\n",
      "[15,   200] loss: 0.221\n",
      "[15,   300] loss: 0.224\n",
      "[16,   100] loss: 0.200\n",
      "[16,   200] loss: 0.207\n",
      "[16,   300] loss: 0.215\n",
      "[17,   100] loss: 0.223\n",
      "[17,   200] loss: 0.211\n",
      "[17,   300] loss: 0.212\n",
      "[18,   100] loss: 0.214\n",
      "[18,   200] loss: 0.204\n",
      "[18,   300] loss: 0.219\n",
      "[19,   100] loss: 0.211\n",
      "[19,   200] loss: 0.232\n",
      "[19,   300] loss: 0.249\n",
      "[20,   100] loss: 0.226\n",
      "[20,   200] loss: 0.237\n",
      "[20,   300] loss: 0.227\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.544\n",
      "[1,   200] loss: 0.234\n",
      "[1,   300] loss: 0.195\n",
      "[2,   100] loss: 0.160\n",
      "[2,   200] loss: 0.150\n",
      "[2,   300] loss: 0.140\n",
      "[3,   100] loss: 0.116\n",
      "[3,   200] loss: 0.129\n",
      "[3,   300] loss: 0.125\n",
      "[4,   100] loss: 0.101\n",
      "[4,   200] loss: 0.110\n",
      "[4,   300] loss: 0.116\n",
      "[5,   100] loss: 0.096\n",
      "[5,   200] loss: 0.101\n",
      "[5,   300] loss: 0.092\n",
      "[6,   100] loss: 0.084\n",
      "[6,   200] loss: 0.084\n",
      "[6,   300] loss: 0.095\n",
      "[7,   100] loss: 0.076\n",
      "[7,   200] loss: 0.092\n",
      "[7,   300] loss: 0.091\n",
      "[8,   100] loss: 0.063\n",
      "[8,   200] loss: 0.074\n",
      "[8,   300] loss: 0.085\n",
      "[9,   100] loss: 0.090\n",
      "[9,   200] loss: 0.073\n",
      "[9,   300] loss: 0.070\n",
      "[10,   100] loss: 0.061\n",
      "[10,   200] loss: 0.068\n",
      "[10,   300] loss: 0.083\n",
      "[11,   100] loss: 0.064\n",
      "[11,   200] loss: 0.066\n",
      "[11,   300] loss: 0.079\n",
      "[12,   100] loss: 0.061\n",
      "[12,   200] loss: 0.069\n",
      "[12,   300] loss: 0.062\n",
      "[13,   100] loss: 0.050\n",
      "[13,   200] loss: 0.067\n",
      "[13,   300] loss: 0.065\n",
      "[14,   100] loss: 0.046\n",
      "[14,   200] loss: 0.062\n",
      "[14,   300] loss: 0.077\n",
      "[15,   100] loss: 0.048\n",
      "[15,   200] loss: 0.054\n",
      "[15,   300] loss: 0.065\n",
      "[16,   100] loss: 0.039\n",
      "[16,   200] loss: 0.045\n",
      "[16,   300] loss: 0.068\n",
      "[17,   100] loss: 0.053\n",
      "[17,   200] loss: 0.060\n",
      "[17,   300] loss: 0.063\n",
      "[18,   100] loss: 0.048\n",
      "[18,   200] loss: 0.050\n",
      "[18,   300] loss: 0.064\n",
      "[19,   100] loss: 0.045\n",
      "[19,   200] loss: 0.052\n",
      "[19,   300] loss: 0.062\n",
      "[20,   100] loss: 0.045\n",
      "[20,   200] loss: 0.050\n",
      "[20,   300] loss: 0.059\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 0.554\n",
      "[1,   200] loss: 0.307\n",
      "[1,   300] loss: 0.275\n",
      "[2,   100] loss: 0.242\n",
      "[2,   200] loss: 0.267\n",
      "[2,   300] loss: 0.268\n",
      "[3,   100] loss: 0.228\n",
      "[3,   200] loss: 0.264\n",
      "[3,   300] loss: 0.241\n",
      "[4,   100] loss: 0.215\n",
      "[4,   200] loss: 0.243\n",
      "[4,   300] loss: 0.260\n",
      "[5,   100] loss: 0.245\n",
      "[5,   200] loss: 0.254\n",
      "[5,   300] loss: 0.252\n",
      "[6,   100] loss: 0.231\n",
      "[6,   200] loss: 0.243\n",
      "[6,   300] loss: 0.254\n",
      "[7,   100] loss: 0.231\n",
      "[7,   200] loss: 0.231\n",
      "[7,   300] loss: 0.244\n",
      "[8,   100] loss: 0.221\n",
      "[8,   200] loss: 0.239\n",
      "[8,   300] loss: 0.256\n",
      "[9,   100] loss: 0.242\n",
      "[9,   200] loss: 0.239\n",
      "[9,   300] loss: 0.231\n",
      "[10,   100] loss: 0.226\n",
      "[10,   200] loss: 0.252\n",
      "[10,   300] loss: 0.233\n",
      "[11,   100] loss: 0.240\n",
      "[11,   200] loss: 0.266\n",
      "[11,   300] loss: 0.237\n",
      "[12,   100] loss: 0.235\n",
      "[12,   200] loss: 0.233\n",
      "[12,   300] loss: 0.230\n",
      "[13,   100] loss: 0.210\n",
      "[13,   200] loss: 0.217\n",
      "[13,   300] loss: 0.212\n",
      "[14,   100] loss: 0.206\n",
      "[14,   200] loss: 0.232\n",
      "[14,   300] loss: 0.235\n",
      "[15,   100] loss: 0.214\n",
      "[15,   200] loss: 0.192\n",
      "[15,   300] loss: 0.205\n",
      "[16,   100] loss: 0.221\n",
      "[16,   200] loss: 0.229\n",
      "[16,   300] loss: 0.225\n",
      "[17,   100] loss: 0.210\n",
      "[17,   200] loss: 0.224\n",
      "[17,   300] loss: 0.230\n",
      "[18,   100] loss: 0.207\n",
      "[18,   200] loss: 0.210\n",
      "[18,   300] loss: 0.223\n",
      "[19,   100] loss: 0.203\n",
      "[19,   200] loss: 0.223\n",
      "[19,   300] loss: 0.240\n",
      "[20,   100] loss: 0.208\n",
      "[20,   200] loss: 0.201\n",
      "[20,   300] loss: 0.219\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.470\n",
      "[1,   200] loss: 0.224\n",
      "[1,   300] loss: 0.205\n",
      "[2,   100] loss: 0.151\n",
      "[2,   200] loss: 0.150\n",
      "[2,   300] loss: 0.153\n",
      "[3,   100] loss: 0.121\n",
      "[3,   200] loss: 0.129\n",
      "[3,   300] loss: 0.121\n",
      "[4,   100] loss: 0.098\n",
      "[4,   200] loss: 0.108\n",
      "[4,   300] loss: 0.122\n",
      "[5,   100] loss: 0.087\n",
      "[5,   200] loss: 0.105\n",
      "[5,   300] loss: 0.099\n",
      "[6,   100] loss: 0.078\n",
      "[6,   200] loss: 0.076\n",
      "[6,   300] loss: 0.088\n",
      "[7,   100] loss: 0.069\n",
      "[7,   200] loss: 0.088\n",
      "[7,   300] loss: 0.085\n",
      "[8,   100] loss: 0.067\n",
      "[8,   200] loss: 0.066\n",
      "[8,   300] loss: 0.082\n",
      "[9,   100] loss: 0.066\n",
      "[9,   200] loss: 0.077\n",
      "[9,   300] loss: 0.073\n",
      "[10,   100] loss: 0.056\n",
      "[10,   200] loss: 0.068\n",
      "[10,   300] loss: 0.066\n",
      "[11,   100] loss: 0.056\n",
      "[11,   200] loss: 0.068\n",
      "[11,   300] loss: 0.075\n",
      "[12,   100] loss: 0.056\n",
      "[12,   200] loss: 0.066\n",
      "[12,   300] loss: 0.069\n",
      "[13,   100] loss: 0.047\n",
      "[13,   200] loss: 0.050\n",
      "[13,   300] loss: 0.060\n",
      "[14,   100] loss: 0.045\n",
      "[14,   200] loss: 0.058\n",
      "[14,   300] loss: 0.072\n",
      "[15,   100] loss: 0.059\n",
      "[15,   200] loss: 0.055\n",
      "[15,   300] loss: 0.055\n",
      "[16,   100] loss: 0.046\n",
      "[16,   200] loss: 0.057\n",
      "[16,   300] loss: 0.056\n",
      "[17,   100] loss: 0.052\n",
      "[17,   200] loss: 0.053\n",
      "[17,   300] loss: 0.044\n",
      "[18,   100] loss: 0.044\n",
      "[18,   200] loss: 0.045\n",
      "[18,   300] loss: 0.054\n",
      "[19,   100] loss: 0.052\n",
      "[19,   200] loss: 0.052\n",
      "[19,   300] loss: 0.062\n",
      "[20,   100] loss: 0.039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20,   200] loss: 0.047\n",
      "[20,   300] loss: 0.046\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 0.591\n",
      "[1,   200] loss: 0.286\n",
      "[1,   300] loss: 0.306\n",
      "[2,   100] loss: 0.245\n",
      "[2,   200] loss: 0.260\n",
      "[2,   300] loss: 0.272\n",
      "[3,   100] loss: 0.258\n",
      "[3,   200] loss: 0.267\n",
      "[3,   300] loss: 0.261\n",
      "[4,   100] loss: 0.246\n",
      "[4,   200] loss: 0.239\n",
      "[4,   300] loss: 0.262\n",
      "[5,   100] loss: 0.249\n",
      "[5,   200] loss: 0.253\n",
      "[5,   300] loss: 0.249\n",
      "[6,   100] loss: 0.235\n",
      "[6,   200] loss: 0.221\n",
      "[6,   300] loss: 0.238\n",
      "[7,   100] loss: 0.223\n",
      "[7,   200] loss: 0.235\n",
      "[7,   300] loss: 0.221\n",
      "[8,   100] loss: 0.239\n",
      "[8,   200] loss: 0.213\n",
      "[8,   300] loss: 0.231\n",
      "[9,   100] loss: 0.217\n",
      "[9,   200] loss: 0.249\n",
      "[9,   300] loss: 0.236\n",
      "[10,   100] loss: 0.226\n",
      "[10,   200] loss: 0.234\n",
      "[10,   300] loss: 0.236\n",
      "[11,   100] loss: 0.223\n",
      "[11,   200] loss: 0.245\n",
      "[11,   300] loss: 0.243\n",
      "[12,   100] loss: 0.233\n",
      "[12,   200] loss: 0.239\n",
      "[12,   300] loss: 0.218\n",
      "[13,   100] loss: 0.224\n",
      "[13,   200] loss: 0.225\n",
      "[13,   300] loss: 0.251\n",
      "[14,   100] loss: 0.237\n",
      "[14,   200] loss: 0.238\n",
      "[14,   300] loss: 0.240\n",
      "[15,   100] loss: 0.220\n",
      "[15,   200] loss: 0.221\n",
      "[15,   300] loss: 0.216\n",
      "[16,   100] loss: 0.204\n",
      "[16,   200] loss: 0.228\n",
      "[16,   300] loss: 0.237\n",
      "[17,   100] loss: 0.232\n",
      "[17,   200] loss: 0.229\n",
      "[17,   300] loss: 0.220\n",
      "[18,   100] loss: 0.219\n",
      "[18,   200] loss: 0.215\n",
      "[18,   300] loss: 0.231\n",
      "[19,   100] loss: 0.233\n",
      "[19,   200] loss: 0.223\n",
      "[19,   300] loss: 0.234\n",
      "[20,   100] loss: 0.218\n",
      "[20,   200] loss: 0.232\n",
      "[20,   300] loss: 0.228\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 0.579\n",
      "[1,   200] loss: 0.230\n",
      "[1,   300] loss: 0.215\n",
      "[2,   100] loss: 0.175\n",
      "[2,   200] loss: 0.160\n",
      "[2,   300] loss: 0.162\n",
      "[3,   100] loss: 0.134\n",
      "[3,   200] loss: 0.149\n",
      "[3,   300] loss: 0.150\n",
      "[4,   100] loss: 0.112\n",
      "[4,   200] loss: 0.119\n",
      "[4,   300] loss: 0.118\n",
      "[5,   100] loss: 0.095\n",
      "[5,   200] loss: 0.114\n",
      "[5,   300] loss: 0.109\n",
      "[6,   100] loss: 0.087\n",
      "[6,   200] loss: 0.100\n",
      "[6,   300] loss: 0.096\n",
      "[7,   100] loss: 0.081\n",
      "[7,   200] loss: 0.096\n",
      "[7,   300] loss: 0.097\n",
      "[8,   100] loss: 0.073\n",
      "[8,   200] loss: 0.088\n",
      "[8,   300] loss: 0.099\n",
      "[9,   100] loss: 0.074\n",
      "[9,   200] loss: 0.082\n",
      "[9,   300] loss: 0.078\n",
      "[10,   100] loss: 0.069\n",
      "[10,   200] loss: 0.077\n",
      "[10,   300] loss: 0.092\n",
      "[11,   100] loss: 0.073\n",
      "[11,   200] loss: 0.070\n",
      "[11,   300] loss: 0.082\n",
      "[12,   100] loss: 0.073\n",
      "[12,   200] loss: 0.068\n",
      "[12,   300] loss: 0.073\n",
      "[13,   100] loss: 0.066\n",
      "[13,   200] loss: 0.073\n",
      "[13,   300] loss: 0.062\n",
      "[14,   100] loss: 0.058\n",
      "[14,   200] loss: 0.057\n",
      "[14,   300] loss: 0.071\n",
      "[15,   100] loss: 0.059\n",
      "[15,   200] loss: 0.078\n",
      "[15,   300] loss: 0.074\n",
      "[16,   100] loss: 0.054\n",
      "[16,   200] loss: 0.065\n",
      "[16,   300] loss: 0.068\n",
      "[17,   100] loss: 0.057\n",
      "[17,   200] loss: 0.057\n",
      "[17,   300] loss: 0.065\n",
      "[18,   100] loss: 0.054\n",
      "[18,   200] loss: 0.063\n",
      "[18,   300] loss: 0.070\n",
      "[19,   100] loss: 0.060\n",
      "[19,   200] loss: 0.057\n",
      "[19,   300] loss: 0.069\n",
      "[20,   100] loss: 0.053\n",
      "[20,   200] loss: 0.055\n",
      "[20,   300] loss: 0.057\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.409\n",
      "[1,   200] loss: 1.302\n",
      "[1,   300] loss: 1.288\n",
      "[2,   100] loss: 1.277\n",
      "[2,   200] loss: 1.278\n",
      "[2,   300] loss: 1.287\n",
      "[3,   100] loss: 1.257\n",
      "[3,   200] loss: 1.259\n",
      "[3,   300] loss: 1.299\n",
      "[4,   100] loss: 1.257\n",
      "[4,   200] loss: 1.272\n",
      "[4,   300] loss: 1.256\n",
      "[5,   100] loss: 1.257\n",
      "[5,   200] loss: 1.279\n",
      "[5,   300] loss: 1.275\n",
      "[6,   100] loss: 1.273\n",
      "[6,   200] loss: 1.262\n",
      "[6,   300] loss: 1.273\n",
      "[7,   100] loss: 1.263\n",
      "[7,   200] loss: 1.255\n",
      "[7,   300] loss: 1.257\n",
      "[8,   100] loss: 1.255\n",
      "[8,   200] loss: 1.248\n",
      "[8,   300] loss: 1.258\n",
      "[9,   100] loss: 1.258\n",
      "[9,   200] loss: 1.260\n",
      "[9,   300] loss: 1.276\n",
      "[10,   100] loss: 1.269\n",
      "[10,   200] loss: 1.252\n",
      "[10,   300] loss: 1.258\n",
      "[11,   100] loss: 1.264\n",
      "[11,   200] loss: 1.276\n",
      "[11,   300] loss: 1.282\n",
      "[12,   100] loss: 1.264\n",
      "[12,   200] loss: 1.253\n",
      "[12,   300] loss: 1.265\n",
      "[13,   100] loss: 1.256\n",
      "[13,   200] loss: 1.250\n",
      "[13,   300] loss: 1.253\n",
      "[14,   100] loss: 1.264\n",
      "[14,   200] loss: 1.270\n",
      "[14,   300] loss: 1.254\n",
      "[15,   100] loss: 1.254\n",
      "[15,   200] loss: 1.257\n",
      "[15,   300] loss: 1.258\n",
      "[16,   100] loss: 1.252\n",
      "[16,   200] loss: 1.248\n",
      "[16,   300] loss: 1.257\n",
      "[17,   100] loss: 1.261\n",
      "[17,   200] loss: 1.255\n",
      "[17,   300] loss: 1.246\n",
      "[18,   100] loss: 1.256\n",
      "[18,   200] loss: 1.253\n",
      "[18,   300] loss: 1.246\n",
      "[19,   100] loss: 1.254\n",
      "[19,   200] loss: 1.255\n",
      "[19,   300] loss: 1.246\n",
      "[20,   100] loss: 1.256\n",
      "[20,   200] loss: 1.250\n",
      "[20,   300] loss: 1.253\n",
      "Finished training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAYERSIZE = 50\n",
    "\n",
    "test_runs = 10\n",
    "\n",
    "int_lr = 0.3\n",
    "syn_lr = 0.03\n",
    "\n",
    "seed = random.randint(0, 1000000)\n",
    "\n",
    "#Train IP Model\n",
    "torch.manual_seed(seed)\n",
    "IPnet = Net(LAYERSIZE, IP, eta=int_lr)\n",
    "IPnet = IPnet.to(device)\n",
    "\n",
    "optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "print(\"Training IP Net\")\n",
    "ip_losses = train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "#Train Standard Model\n",
    "torch.manual_seed(seed)\n",
    "net = Net(LAYERSIZE, NN, eta=int_lr)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "print(\"Training Standard Net\")\n",
    "standard_losses = train_deep_model(net, optimizer2, seed)\n",
    "\n",
    "for i in range(test_runs-1):\n",
    "    seed = random.randint(0, 1000000)\n",
    "    \n",
    "    #Train IP Model\n",
    "    torch.manual_seed(seed)\n",
    "    IPnet = Net(LAYERSIZE, IP, eta=int_lr)\n",
    "    IPnet = IPnet.to(device)\n",
    "\n",
    "    optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training IP Net\")\n",
    "    ip_losses += train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "    #Train Standard Model\n",
    "    torch.manual_seed(seed)\n",
    "    net = Net(LAYERSIZE, NN, eta=int_lr)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "    print(\"Training Standard Net\")\n",
    "    standard_losses += train_deep_model(net, optimizer2, seed)\n",
    "    \n",
    "ip_losses = ip_losses/test_runs\n",
    "standard_losses = standard_losses/test_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAFNCAYAAADSGTgvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nP7zi0BdfqyemAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f28cb3471d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.ylim([-0.1, 3])\n",
    "plt.title(\"Learning curves for single-layer networks\")\n",
    "plt.plot(ip_losses[0], ip_losses[1], label=\"IP\")\n",
    "# plt.plot(bn_losses[0], bn_losses[1], label=\"BN\")\n",
    "plt.plot(standard_losses[0], standard_losses[1], label=\"Standard\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the standard network on the 10000 test images: 58.0000 %\n",
      "Accuracy of the IP network on the 10000 test images: 96.4900 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        y = net(images)\n",
    "        _, predicted = torch.max(y.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the standard network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        y = IPnet(images)\n",
    "        _, predicted = torch.max(y.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the IP network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CNet(nn.Module):\n",
    "    def __init__(self, layersize, norm=None, eta=1):\n",
    "        super(CNet, self).__init__()\n",
    "        \n",
    "        # Dense Layers\n",
    "        self.fc1 = nn.Linear(3*32*32, layersize)\n",
    "        self.fc2 = nn.Linear(layersize, layersize)\n",
    "        self.fc3 = nn.Linear(layersize, 10)\n",
    "        \n",
    "        # Normalization Layers\n",
    "        self.n1 = norm(layersize, eta)\n",
    "        self.n2 = norm(layersize, eta)\n",
    "        \n",
    "    def forward(self, x, eta=None):\n",
    "        x = x.view(-1, 3*32*32)\n",
    "        u1 = self.fc1(x)\n",
    "        v1 = F.tanh(self.n1(u1))\n",
    "        u2 = self.fc2(v1)\n",
    "        v2 = F.tanh(self.n2(u2))\n",
    "        # Note you should not normalize after the last linear layer (you delete info)\n",
    "        o = F.relu(self.fc3(v2))\n",
    "        \n",
    "        # Lets do the updates to the normalizations\n",
    "        self.n1.update(u1, v1, eta)\n",
    "        self.n2.update(u2, v2, eta)\n",
    "        \n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batchSize = 200\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchSize,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IP Net\n",
      "[1,   100] loss: 1.926\n",
      "[1,   200] loss: 1.756\n",
      "[2,   100] loss: 1.607\n",
      "[2,   200] loss: 1.547\n",
      "[3,   100] loss: 1.461\n",
      "[3,   200] loss: 1.460\n",
      "[4,   100] loss: 1.364\n",
      "[4,   200] loss: 1.400\n",
      "[5,   100] loss: 1.305\n",
      "[5,   200] loss: 1.329\n",
      "[6,   100] loss: 1.248\n",
      "[6,   200] loss: 1.263\n",
      "[7,   100] loss: 1.189\n",
      "[7,   200] loss: 1.228\n",
      "[8,   100] loss: 1.141\n",
      "[8,   200] loss: 1.191\n",
      "[9,   100] loss: 1.099\n",
      "[9,   200] loss: 1.142\n",
      "[10,   100] loss: 1.060\n",
      "[10,   200] loss: 1.099\n",
      "[11,   100] loss: 1.015\n",
      "[11,   200] loss: 1.066\n",
      "[12,   100] loss: 0.983\n",
      "[12,   200] loss: 1.025\n",
      "[13,   100] loss: 0.945\n",
      "[13,   200] loss: 1.008\n",
      "[14,   100] loss: 0.907\n",
      "[14,   200] loss: 0.966\n",
      "[15,   100] loss: 0.882\n",
      "[15,   200] loss: 0.937\n",
      "[16,   100] loss: 0.862\n",
      "[16,   200] loss: 0.897\n",
      "[17,   100] loss: 0.825\n",
      "[17,   200] loss: 0.875\n",
      "[18,   100] loss: 0.790\n",
      "[18,   200] loss: 0.844\n",
      "[19,   100] loss: 0.783\n",
      "[19,   200] loss: 0.824\n",
      "[20,   100] loss: 0.756\n",
      "[20,   200] loss: 0.799\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.019\n",
      "[1,   200] loss: 1.906\n",
      "[2,   100] loss: 1.853\n",
      "[2,   200] loss: 1.837\n",
      "[3,   100] loss: 1.809\n",
      "[3,   200] loss: 1.817\n",
      "[4,   100] loss: 1.790\n",
      "[4,   200] loss: 1.793\n",
      "[5,   100] loss: 1.773\n",
      "[5,   200] loss: 1.775\n",
      "[6,   100] loss: 1.759\n",
      "[6,   200] loss: 1.767\n",
      "[7,   100] loss: 1.748\n",
      "[7,   200] loss: 1.763\n",
      "[8,   100] loss: 1.754\n",
      "[8,   200] loss: 1.772\n",
      "[9,   100] loss: 1.733\n",
      "[9,   200] loss: 1.741\n",
      "[10,   100] loss: 1.729\n",
      "[10,   200] loss: 1.739\n",
      "[11,   100] loss: 1.727\n",
      "[11,   200] loss: 1.740\n",
      "[12,   100] loss: 1.730\n",
      "[12,   200] loss: 1.716\n",
      "[13,   100] loss: 1.710\n",
      "[13,   200] loss: 1.727\n",
      "[14,   100] loss: 1.698\n",
      "[14,   200] loss: 1.720\n",
      "[15,   100] loss: 1.699\n",
      "[15,   200] loss: 1.724\n",
      "[16,   100] loss: 1.718\n",
      "[16,   200] loss: 1.719\n",
      "[17,   100] loss: 1.702\n",
      "[17,   200] loss: 1.700\n",
      "[18,   100] loss: 1.688\n",
      "[18,   200] loss: 1.703\n",
      "[19,   100] loss: 1.697\n",
      "[19,   200] loss: 1.712\n",
      "[20,   100] loss: 1.677\n",
      "[20,   200] loss: 1.699\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.902\n",
      "[1,   200] loss: 1.745\n",
      "[2,   100] loss: 1.592\n",
      "[2,   200] loss: 1.559\n",
      "[3,   100] loss: 1.462\n",
      "[3,   200] loss: 1.452\n",
      "[4,   100] loss: 1.383\n",
      "[4,   200] loss: 1.372\n",
      "[5,   100] loss: 1.296\n",
      "[5,   200] loss: 1.329\n",
      "[6,   100] loss: 1.241\n",
      "[6,   200] loss: 1.276\n",
      "[7,   100] loss: 1.202\n",
      "[7,   200] loss: 1.217\n",
      "[8,   100] loss: 1.148\n",
      "[8,   200] loss: 1.193\n",
      "[9,   100] loss: 1.097\n",
      "[9,   200] loss: 1.163\n",
      "[10,   100] loss: 1.063\n",
      "[10,   200] loss: 1.103\n",
      "[11,   100] loss: 1.026\n",
      "[11,   200] loss: 1.056\n",
      "[12,   100] loss: 0.987\n",
      "[12,   200] loss: 1.024\n",
      "[13,   100] loss: 0.945\n",
      "[13,   200] loss: 1.003\n",
      "[14,   100] loss: 0.924\n",
      "[14,   200] loss: 0.971\n",
      "[15,   100] loss: 0.902\n",
      "[15,   200] loss: 0.936\n",
      "[16,   100] loss: 0.845\n",
      "[16,   200] loss: 0.891\n",
      "[17,   100] loss: 0.822\n",
      "[17,   200] loss: 0.884\n",
      "[18,   100] loss: 0.797\n",
      "[18,   200] loss: 0.854\n",
      "[19,   100] loss: 0.762\n",
      "[19,   200] loss: 0.812\n",
      "[20,   100] loss: 0.739\n",
      "[20,   200] loss: 0.793\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.960\n",
      "[1,   200] loss: 1.886\n",
      "[2,   100] loss: 1.828\n",
      "[2,   200] loss: 1.831\n",
      "[3,   100] loss: 1.812\n",
      "[3,   200] loss: 1.809\n",
      "[4,   100] loss: 1.783\n",
      "[4,   200] loss: 1.780\n",
      "[5,   100] loss: 1.758\n",
      "[5,   200] loss: 1.788\n",
      "[6,   100] loss: 1.760\n",
      "[6,   200] loss: 1.776\n",
      "[7,   100] loss: 1.763\n",
      "[7,   200] loss: 1.762\n",
      "[8,   100] loss: 1.749\n",
      "[8,   200] loss: 1.771\n",
      "[9,   100] loss: 1.728\n",
      "[9,   200] loss: 1.763\n",
      "[10,   100] loss: 1.723\n",
      "[10,   200] loss: 1.748\n",
      "[11,   100] loss: 1.728\n",
      "[11,   200] loss: 1.738\n",
      "[12,   100] loss: 1.728\n",
      "[12,   200] loss: 1.741\n",
      "[13,   100] loss: 1.709\n",
      "[13,   200] loss: 1.728\n",
      "[14,   100] loss: 1.709\n",
      "[14,   200] loss: 1.722\n",
      "[15,   100] loss: 1.715\n",
      "[15,   200] loss: 1.711\n",
      "[16,   100] loss: 1.707\n",
      "[16,   200] loss: 1.711\n",
      "[17,   100] loss: 1.707\n",
      "[17,   200] loss: 1.720\n",
      "[18,   100] loss: 1.699\n",
      "[18,   200] loss: 1.707\n",
      "[19,   100] loss: 1.695\n",
      "[19,   200] loss: 1.715\n",
      "[20,   100] loss: 1.692\n",
      "[20,   200] loss: 1.710\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.922\n",
      "[1,   200] loss: 1.743\n",
      "[2,   100] loss: 1.604\n",
      "[2,   200] loss: 1.545\n",
      "[3,   100] loss: 1.469\n",
      "[3,   200] loss: 1.453\n",
      "[4,   100] loss: 1.368\n",
      "[4,   200] loss: 1.393\n",
      "[5,   100] loss: 1.366\n",
      "[5,   200] loss: 1.369\n",
      "[6,   100] loss: 1.298\n",
      "[6,   200] loss: 1.313\n",
      "[7,   100] loss: 1.233\n",
      "[7,   200] loss: 1.246\n",
      "[8,   100] loss: 1.190\n",
      "[8,   200] loss: 1.215\n",
      "[9,   100] loss: 1.137\n",
      "[9,   200] loss: 1.175\n",
      "[10,   100] loss: 1.109\n",
      "[10,   200] loss: 1.129\n",
      "[11,   100] loss: 1.061\n",
      "[11,   200] loss: 1.100\n",
      "[12,   100] loss: 1.023\n",
      "[12,   200] loss: 1.080\n",
      "[13,   100] loss: 1.001\n",
      "[13,   200] loss: 1.039\n",
      "[14,   100] loss: 0.963\n",
      "[14,   200] loss: 0.995\n",
      "[15,   100] loss: 0.922\n",
      "[15,   200] loss: 0.962\n",
      "[16,   100] loss: 0.896\n",
      "[16,   200] loss: 0.947\n",
      "[17,   100] loss: 0.877\n",
      "[17,   200] loss: 0.910\n",
      "[18,   100] loss: 0.839\n",
      "[18,   200] loss: 0.882\n",
      "[19,   100] loss: 0.800\n",
      "[19,   200] loss: 0.860\n",
      "[20,   100] loss: 0.765\n",
      "[20,   200] loss: 0.830\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.980\n",
      "[1,   200] loss: 1.882\n",
      "[2,   100] loss: 1.848\n",
      "[2,   200] loss: 1.833\n",
      "[3,   100] loss: 1.815\n",
      "[3,   200] loss: 1.819\n",
      "[4,   100] loss: 1.783\n",
      "[4,   200] loss: 1.806\n",
      "[5,   100] loss: 1.774\n",
      "[5,   200] loss: 1.786\n",
      "[6,   100] loss: 1.768\n",
      "[6,   200] loss: 1.776\n",
      "[7,   100] loss: 1.766\n",
      "[7,   200] loss: 1.772\n",
      "[8,   100] loss: 1.748\n",
      "[8,   200] loss: 1.776\n",
      "[9,   100] loss: 1.746\n",
      "[9,   200] loss: 1.749\n",
      "[10,   100] loss: 1.731\n",
      "[10,   200] loss: 1.746\n",
      "[11,   100] loss: 1.723\n",
      "[11,   200] loss: 1.741\n",
      "[12,   100] loss: 1.729\n",
      "[12,   200] loss: 1.745\n",
      "[13,   100] loss: 1.724\n",
      "[13,   200] loss: 1.732\n",
      "[14,   100] loss: 1.720\n",
      "[14,   200] loss: 1.734\n",
      "[15,   100] loss: 1.712\n",
      "[15,   200] loss: 1.713\n",
      "[16,   100] loss: 1.713\n",
      "[16,   200] loss: 1.718\n",
      "[17,   100] loss: 1.714\n",
      "[17,   200] loss: 1.719\n",
      "[18,   100] loss: 1.713\n",
      "[18,   200] loss: 1.705\n",
      "[19,   100] loss: 1.700\n",
      "[19,   200] loss: 1.699\n",
      "[20,   100] loss: 1.681\n",
      "[20,   200] loss: 1.701\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.918\n",
      "[1,   200] loss: 1.739\n",
      "[2,   100] loss: 1.581\n",
      "[2,   200] loss: 1.556\n",
      "[3,   100] loss: 1.453\n",
      "[3,   200] loss: 1.454\n",
      "[4,   100] loss: 1.360\n",
      "[4,   200] loss: 1.433\n",
      "[5,   100] loss: 1.323\n",
      "[5,   200] loss: 1.344\n",
      "[6,   100] loss: 1.270\n",
      "[6,   200] loss: 1.276\n",
      "[7,   100] loss: 1.214\n",
      "[7,   200] loss: 1.228\n",
      "[8,   100] loss: 1.159\n",
      "[8,   200] loss: 1.203\n",
      "[9,   100] loss: 1.117\n",
      "[9,   200] loss: 1.162\n",
      "[10,   100] loss: 1.092\n",
      "[10,   200] loss: 1.110\n",
      "[11,   100] loss: 1.039\n",
      "[11,   200] loss: 1.075\n",
      "[12,   100] loss: 0.996\n",
      "[12,   200] loss: 1.045\n",
      "[13,   100] loss: 0.963\n",
      "[13,   200] loss: 1.003\n",
      "[14,   100] loss: 0.938\n",
      "[14,   200] loss: 0.990\n",
      "[15,   100] loss: 0.887\n",
      "[15,   200] loss: 0.958\n",
      "[16,   100] loss: 0.864\n",
      "[16,   200] loss: 0.909\n",
      "[17,   100] loss: 0.824\n",
      "[17,   200] loss: 0.882\n",
      "[18,   100] loss: 0.815\n",
      "[18,   200] loss: 0.868\n",
      "[19,   100] loss: 0.773\n",
      "[19,   200] loss: 0.831\n",
      "[20,   100] loss: 0.767\n",
      "[20,   200] loss: 0.815\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.978\n",
      "[1,   200] loss: 1.883\n",
      "[2,   100] loss: 1.843\n",
      "[2,   200] loss: 1.835\n",
      "[3,   100] loss: 1.804\n",
      "[3,   200] loss: 1.815\n",
      "[4,   100] loss: 1.788\n",
      "[4,   200] loss: 1.804\n",
      "[5,   100] loss: 1.766\n",
      "[5,   200] loss: 1.779\n",
      "[6,   100] loss: 1.766\n",
      "[6,   200] loss: 1.773\n",
      "[7,   100] loss: 1.761\n",
      "[7,   200] loss: 1.748\n",
      "[8,   100] loss: 1.735\n",
      "[8,   200] loss: 1.758\n",
      "[9,   100] loss: 1.741\n",
      "[9,   200] loss: 1.749\n",
      "[10,   100] loss: 1.741\n",
      "[10,   200] loss: 1.735\n",
      "[11,   100] loss: 1.725\n",
      "[11,   200] loss: 1.728\n",
      "[12,   100] loss: 1.706\n",
      "[12,   200] loss: 1.733\n",
      "[13,   100] loss: 1.703\n",
      "[13,   200] loss: 1.730\n",
      "[14,   100] loss: 1.700\n",
      "[14,   200] loss: 1.730\n",
      "[15,   100] loss: 1.699\n",
      "[15,   200] loss: 1.729\n",
      "[16,   100] loss: 1.707\n",
      "[16,   200] loss: 1.720\n",
      "[17,   100] loss: 1.682\n",
      "[17,   200] loss: 1.722\n",
      "[18,   100] loss: 1.700\n",
      "[18,   200] loss: 1.715\n",
      "[19,   100] loss: 1.698\n",
      "[19,   200] loss: 1.713\n",
      "[20,   100] loss: 1.703\n",
      "[20,   200] loss: 1.707\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.906\n",
      "[1,   200] loss: 1.735\n",
      "[2,   100] loss: 1.591\n",
      "[2,   200] loss: 1.547\n",
      "[3,   100] loss: 1.453\n",
      "[3,   200] loss: 1.448\n",
      "[4,   100] loss: 1.359\n",
      "[4,   200] loss: 1.394\n",
      "[5,   100] loss: 1.296\n",
      "[5,   200] loss: 1.331\n",
      "[6,   100] loss: 1.234\n",
      "[6,   200] loss: 1.267\n",
      "[7,   100] loss: 1.186\n",
      "[7,   200] loss: 1.235\n",
      "[8,   100] loss: 1.142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8,   200] loss: 1.161\n",
      "[9,   100] loss: 1.092\n",
      "[9,   200] loss: 1.131\n",
      "[10,   100] loss: 1.040\n",
      "[10,   200] loss: 1.104\n",
      "[11,   100] loss: 1.007\n",
      "[11,   200] loss: 1.061\n",
      "[12,   100] loss: 0.977\n",
      "[12,   200] loss: 1.018\n",
      "[13,   100] loss: 0.943\n",
      "[13,   200] loss: 0.982\n",
      "[14,   100] loss: 0.880\n",
      "[14,   200] loss: 0.967\n",
      "[15,   100] loss: 0.866\n",
      "[15,   200] loss: 0.909\n",
      "[16,   100] loss: 0.831\n",
      "[16,   200] loss: 0.873\n",
      "[17,   100] loss: 0.805\n",
      "[17,   200] loss: 0.853\n",
      "[18,   100] loss: 0.775\n",
      "[18,   200] loss: 0.813\n",
      "[19,   100] loss: 0.748\n",
      "[19,   200] loss: 0.798\n",
      "[20,   100] loss: 0.710\n",
      "[20,   200] loss: 0.771\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.970\n",
      "[1,   200] loss: 1.883\n",
      "[2,   100] loss: 1.835\n",
      "[2,   200] loss: 1.834\n",
      "[3,   100] loss: 1.799\n",
      "[3,   200] loss: 1.803\n",
      "[4,   100] loss: 1.786\n",
      "[4,   200] loss: 1.796\n",
      "[5,   100] loss: 1.765\n",
      "[5,   200] loss: 1.796\n",
      "[6,   100] loss: 1.773\n",
      "[6,   200] loss: 1.768\n",
      "[7,   100] loss: 1.740\n",
      "[7,   200] loss: 1.773\n",
      "[8,   100] loss: 1.749\n",
      "[8,   200] loss: 1.753\n",
      "[9,   100] loss: 1.743\n",
      "[9,   200] loss: 1.744\n",
      "[10,   100] loss: 1.722\n",
      "[10,   200] loss: 1.733\n",
      "[11,   100] loss: 1.721\n",
      "[11,   200] loss: 1.727\n",
      "[12,   100] loss: 1.712\n",
      "[12,   200] loss: 1.733\n",
      "[13,   100] loss: 1.710\n",
      "[13,   200] loss: 1.725\n",
      "[14,   100] loss: 1.696\n",
      "[14,   200] loss: 1.732\n",
      "[15,   100] loss: 1.712\n",
      "[15,   200] loss: 1.708\n",
      "[16,   100] loss: 1.699\n",
      "[16,   200] loss: 1.707\n",
      "[17,   100] loss: 1.706\n",
      "[17,   200] loss: 1.722\n",
      "[18,   100] loss: 1.703\n",
      "[18,   200] loss: 1.698\n",
      "[19,   100] loss: 1.703\n",
      "[19,   200] loss: 1.712\n",
      "[20,   100] loss: 1.684\n",
      "[20,   200] loss: 1.709\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.921\n",
      "[1,   200] loss: 1.726\n",
      "[2,   100] loss: 1.603\n",
      "[2,   200] loss: 1.563\n",
      "[3,   100] loss: 1.461\n",
      "[3,   200] loss: 1.463\n",
      "[4,   100] loss: 1.369\n",
      "[4,   200] loss: 1.386\n",
      "[5,   100] loss: 1.308\n",
      "[5,   200] loss: 1.324\n",
      "[6,   100] loss: 1.249\n",
      "[6,   200] loss: 1.280\n",
      "[7,   100] loss: 1.181\n",
      "[7,   200] loss: 1.232\n",
      "[8,   100] loss: 1.157\n",
      "[8,   200] loss: 1.168\n",
      "[9,   100] loss: 1.113\n",
      "[9,   200] loss: 1.137\n",
      "[10,   100] loss: 1.069\n",
      "[10,   200] loss: 1.095\n",
      "[11,   100] loss: 1.029\n",
      "[11,   200] loss: 1.067\n",
      "[12,   100] loss: 0.996\n",
      "[12,   200] loss: 1.021\n",
      "[13,   100] loss: 0.939\n",
      "[13,   200] loss: 1.020\n",
      "[14,   100] loss: 0.913\n",
      "[14,   200] loss: 0.962\n",
      "[15,   100] loss: 0.889\n",
      "[15,   200] loss: 0.927\n",
      "[16,   100] loss: 0.851\n",
      "[16,   200] loss: 0.883\n",
      "[17,   100] loss: 0.828\n",
      "[17,   200] loss: 0.874\n",
      "[18,   100] loss: 0.792\n",
      "[18,   200] loss: 0.855\n",
      "[19,   100] loss: 0.761\n",
      "[19,   200] loss: 0.814\n",
      "[20,   100] loss: 0.743\n",
      "[20,   200] loss: 0.777\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 2.000\n",
      "[1,   200] loss: 1.876\n",
      "[2,   100] loss: 1.858\n",
      "[2,   200] loss: 1.836\n",
      "[3,   100] loss: 1.804\n",
      "[3,   200] loss: 1.820\n",
      "[4,   100] loss: 1.801\n",
      "[4,   200] loss: 1.798\n",
      "[5,   100] loss: 1.780\n",
      "[5,   200] loss: 1.793\n",
      "[6,   100] loss: 1.770\n",
      "[6,   200] loss: 1.785\n",
      "[7,   100] loss: 1.748\n",
      "[7,   200] loss: 1.775\n",
      "[8,   100] loss: 1.748\n",
      "[8,   200] loss: 1.745\n",
      "[9,   100] loss: 1.752\n",
      "[9,   200] loss: 1.741\n",
      "[10,   100] loss: 1.741\n",
      "[10,   200] loss: 1.744\n",
      "[11,   100] loss: 1.747\n",
      "[11,   200] loss: 1.749\n",
      "[12,   100] loss: 1.736\n",
      "[12,   200] loss: 1.735\n",
      "[13,   100] loss: 1.719\n",
      "[13,   200] loss: 1.742\n",
      "[14,   100] loss: 1.728\n",
      "[14,   200] loss: 1.723\n",
      "[15,   100] loss: 1.711\n",
      "[15,   200] loss: 1.717\n",
      "[16,   100] loss: 1.720\n",
      "[16,   200] loss: 1.711\n",
      "[17,   100] loss: 1.713\n",
      "[17,   200] loss: 1.718\n",
      "[18,   100] loss: 1.715\n",
      "[18,   200] loss: 1.720\n",
      "[19,   100] loss: 1.701\n",
      "[19,   200] loss: 1.718\n",
      "[20,   100] loss: 1.686\n",
      "[20,   200] loss: 1.706\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.933\n",
      "[1,   200] loss: 1.740\n",
      "[2,   100] loss: 1.576\n",
      "[2,   200] loss: 1.561\n",
      "[3,   100] loss: 1.458\n",
      "[3,   200] loss: 1.455\n",
      "[4,   100] loss: 1.381\n",
      "[4,   200] loss: 1.358\n",
      "[5,   100] loss: 1.297\n",
      "[5,   200] loss: 1.318\n",
      "[6,   100] loss: 1.237\n",
      "[6,   200] loss: 1.258\n",
      "[7,   100] loss: 1.200\n",
      "[7,   200] loss: 1.203\n",
      "[8,   100] loss: 1.148\n",
      "[8,   200] loss: 1.164\n",
      "[9,   100] loss: 1.097\n",
      "[9,   200] loss: 1.127\n",
      "[10,   100] loss: 1.064\n",
      "[10,   200] loss: 1.094\n",
      "[11,   100] loss: 1.019\n",
      "[11,   200] loss: 1.046\n",
      "[12,   100] loss: 0.961\n",
      "[12,   200] loss: 1.021\n",
      "[13,   100] loss: 0.940\n",
      "[13,   200] loss: 0.988\n",
      "[14,   100] loss: 0.896\n",
      "[14,   200] loss: 0.970\n",
      "[15,   100] loss: 0.878\n",
      "[15,   200] loss: 0.920\n",
      "[16,   100] loss: 0.859\n",
      "[16,   200] loss: 0.891\n",
      "[17,   100] loss: 0.806\n",
      "[17,   200] loss: 0.867\n",
      "[18,   100] loss: 0.802\n",
      "[18,   200] loss: 0.826\n",
      "[19,   100] loss: 0.744\n",
      "[19,   200] loss: 0.817\n",
      "[20,   100] loss: 0.749\n",
      "[20,   200] loss: 0.759\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.985\n",
      "[1,   200] loss: 1.886\n",
      "[2,   100] loss: 1.826\n",
      "[2,   200] loss: 1.826\n",
      "[3,   100] loss: 1.806\n",
      "[3,   200] loss: 1.806\n",
      "[4,   100] loss: 1.798\n",
      "[4,   200] loss: 1.787\n",
      "[5,   100] loss: 1.772\n",
      "[5,   200] loss: 1.801\n",
      "[6,   100] loss: 1.765\n",
      "[6,   200] loss: 1.780\n",
      "[7,   100] loss: 1.762\n",
      "[7,   200] loss: 1.756\n",
      "[8,   100] loss: 1.743\n",
      "[8,   200] loss: 1.763\n",
      "[9,   100] loss: 1.748\n",
      "[9,   200] loss: 1.755\n",
      "[10,   100] loss: 1.734\n",
      "[10,   200] loss: 1.739\n",
      "[11,   100] loss: 1.727\n",
      "[11,   200] loss: 1.733\n",
      "[12,   100] loss: 1.713\n",
      "[12,   200] loss: 1.737\n",
      "[13,   100] loss: 1.714\n",
      "[13,   200] loss: 1.744\n",
      "[14,   100] loss: 1.689\n",
      "[14,   200] loss: 1.743\n",
      "[15,   100] loss: 1.710\n",
      "[15,   200] loss: 1.715\n",
      "[16,   100] loss: 1.700\n",
      "[16,   200] loss: 1.712\n",
      "[17,   100] loss: 1.689\n",
      "[17,   200] loss: 1.719\n",
      "[18,   100] loss: 1.703\n",
      "[18,   200] loss: 1.702\n",
      "[19,   100] loss: 1.695\n",
      "[19,   200] loss: 1.705\n",
      "[20,   100] loss: 1.698\n",
      "[20,   200] loss: 1.684\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.923\n",
      "[1,   200] loss: 1.753\n",
      "[2,   100] loss: 1.593\n",
      "[2,   200] loss: 1.572\n",
      "[3,   100] loss: 1.473\n",
      "[3,   200] loss: 1.463\n",
      "[4,   100] loss: 1.417\n",
      "[4,   200] loss: 1.450\n",
      "[5,   100] loss: 1.360\n",
      "[5,   200] loss: 1.372\n",
      "[6,   100] loss: 1.285\n",
      "[6,   200] loss: 1.310\n",
      "[7,   100] loss: 1.234\n",
      "[7,   200] loss: 1.265\n",
      "[8,   100] loss: 1.207\n",
      "[8,   200] loss: 1.209\n",
      "[9,   100] loss: 1.147\n",
      "[9,   200] loss: 1.182\n",
      "[10,   100] loss: 1.107\n",
      "[10,   200] loss: 1.166\n",
      "[11,   100] loss: 1.063\n",
      "[11,   200] loss: 1.109\n",
      "[12,   100] loss: 1.038\n",
      "[12,   200] loss: 1.079\n",
      "[13,   100] loss: 1.001\n",
      "[13,   200] loss: 1.056\n",
      "[14,   100] loss: 0.974\n",
      "[14,   200] loss: 1.008\n",
      "[15,   100] loss: 0.934\n",
      "[15,   200] loss: 0.997\n",
      "[16,   100] loss: 0.915\n",
      "[16,   200] loss: 0.950\n",
      "[17,   100] loss: 0.866\n",
      "[17,   200] loss: 0.911\n",
      "[18,   100] loss: 0.836\n",
      "[18,   200] loss: 0.898\n",
      "[19,   100] loss: 0.804\n",
      "[19,   200] loss: 0.867\n",
      "[20,   100] loss: 0.788\n",
      "[20,   200] loss: 0.820\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.983\n",
      "[1,   200] loss: 1.897\n",
      "[2,   100] loss: 1.840\n",
      "[2,   200] loss: 1.848\n",
      "[3,   100] loss: 1.809\n",
      "[3,   200] loss: 1.810\n",
      "[4,   100] loss: 1.789\n",
      "[4,   200] loss: 1.798\n",
      "[5,   100] loss: 1.776\n",
      "[5,   200] loss: 1.791\n",
      "[6,   100] loss: 1.759\n",
      "[6,   200] loss: 1.764\n",
      "[7,   100] loss: 1.752\n",
      "[7,   200] loss: 1.770\n",
      "[8,   100] loss: 1.761\n",
      "[8,   200] loss: 1.757\n",
      "[9,   100] loss: 1.743\n",
      "[9,   200] loss: 1.752\n",
      "[10,   100] loss: 1.740\n",
      "[10,   200] loss: 1.752\n",
      "[11,   100] loss: 1.729\n",
      "[11,   200] loss: 1.747\n",
      "[12,   100] loss: 1.725\n",
      "[12,   200] loss: 1.739\n",
      "[13,   100] loss: 1.717\n",
      "[13,   200] loss: 1.741\n",
      "[14,   100] loss: 1.710\n",
      "[14,   200] loss: 1.714\n",
      "[15,   100] loss: 1.715\n",
      "[15,   200] loss: 1.722\n",
      "[16,   100] loss: 1.691\n",
      "[16,   200] loss: 1.724\n",
      "[17,   100] loss: 1.705\n",
      "[17,   200] loss: 1.706\n",
      "[18,   100] loss: 1.680\n",
      "[18,   200] loss: 1.716\n",
      "[19,   100] loss: 1.702\n",
      "[19,   200] loss: 1.707\n",
      "[20,   100] loss: 1.706\n",
      "[20,   200] loss: 1.707\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.906\n",
      "[1,   200] loss: 1.734\n",
      "[2,   100] loss: 1.582\n",
      "[2,   200] loss: 1.546\n",
      "[3,   100] loss: 1.452\n",
      "[3,   200] loss: 1.436\n",
      "[4,   100] loss: 1.360\n",
      "[4,   200] loss: 1.390\n",
      "[5,   100] loss: 1.357\n",
      "[5,   200] loss: 1.355\n",
      "[6,   100] loss: 1.270\n",
      "[6,   200] loss: 1.270\n",
      "[7,   100] loss: 1.208\n",
      "[7,   200] loss: 1.219\n",
      "[8,   100] loss: 1.154\n",
      "[8,   200] loss: 1.179\n",
      "[9,   100] loss: 1.104\n",
      "[9,   200] loss: 1.158\n",
      "[10,   100] loss: 1.068\n",
      "[10,   200] loss: 1.109\n",
      "[11,   100] loss: 1.034\n",
      "[11,   200] loss: 1.069\n",
      "[12,   100] loss: 0.986\n",
      "[12,   200] loss: 1.033\n",
      "[13,   100] loss: 0.959\n",
      "[13,   200] loss: 0.989\n",
      "[14,   100] loss: 0.913\n",
      "[14,   200] loss: 0.960\n",
      "[15,   100] loss: 0.885\n",
      "[15,   200] loss: 0.932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16,   100] loss: 0.856\n",
      "[16,   200] loss: 0.911\n",
      "[17,   100] loss: 0.818\n",
      "[17,   200] loss: 0.869\n",
      "[18,   100] loss: 0.785\n",
      "[18,   200] loss: 0.842\n",
      "[19,   100] loss: 0.772\n",
      "[19,   200] loss: 0.801\n",
      "[20,   100] loss: 0.739\n",
      "[20,   200] loss: 0.782\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.977\n",
      "[1,   200] loss: 1.872\n",
      "[2,   100] loss: 1.819\n",
      "[2,   200] loss: 1.816\n",
      "[3,   100] loss: 1.808\n",
      "[3,   200] loss: 1.805\n",
      "[4,   100] loss: 1.774\n",
      "[4,   200] loss: 1.794\n",
      "[5,   100] loss: 1.776\n",
      "[5,   200] loss: 1.785\n",
      "[6,   100] loss: 1.770\n",
      "[6,   200] loss: 1.763\n",
      "[7,   100] loss: 1.753\n",
      "[7,   200] loss: 1.765\n",
      "[8,   100] loss: 1.762\n",
      "[8,   200] loss: 1.755\n",
      "[9,   100] loss: 1.749\n",
      "[9,   200] loss: 1.752\n",
      "[10,   100] loss: 1.723\n",
      "[10,   200] loss: 1.743\n",
      "[11,   100] loss: 1.737\n",
      "[11,   200] loss: 1.733\n",
      "[12,   100] loss: 1.715\n",
      "[12,   200] loss: 1.727\n",
      "[13,   100] loss: 1.728\n",
      "[13,   200] loss: 1.739\n",
      "[14,   100] loss: 1.712\n",
      "[14,   200] loss: 1.719\n",
      "[15,   100] loss: 1.730\n",
      "[15,   200] loss: 1.721\n",
      "[16,   100] loss: 1.713\n",
      "[16,   200] loss: 1.722\n",
      "[17,   100] loss: 1.711\n",
      "[17,   200] loss: 1.720\n",
      "[18,   100] loss: 1.703\n",
      "[18,   200] loss: 1.708\n",
      "[19,   100] loss: 1.703\n",
      "[19,   200] loss: 1.712\n",
      "[20,   100] loss: 1.697\n",
      "[20,   200] loss: 1.707\n",
      "Finished training!\n",
      "\n",
      "Training IP Net\n",
      "[1,   100] loss: 1.910\n",
      "[1,   200] loss: 1.736\n",
      "[2,   100] loss: 1.581\n",
      "[2,   200] loss: 1.556\n",
      "[3,   100] loss: 1.457\n",
      "[3,   200] loss: 1.458\n",
      "[4,   100] loss: 1.443\n",
      "[4,   200] loss: 1.459\n",
      "[5,   100] loss: 1.393\n",
      "[5,   200] loss: 1.372\n",
      "[6,   100] loss: 1.298\n",
      "[6,   200] loss: 1.312\n",
      "[7,   100] loss: 1.240\n",
      "[7,   200] loss: 1.276\n",
      "[8,   100] loss: 1.207\n",
      "[8,   200] loss: 1.224\n",
      "[9,   100] loss: 1.153\n",
      "[9,   200] loss: 1.203\n",
      "[10,   100] loss: 1.118\n",
      "[10,   200] loss: 1.156\n",
      "[11,   100] loss: 1.084\n",
      "[11,   200] loss: 1.103\n",
      "[12,   100] loss: 1.032\n",
      "[12,   200] loss: 1.083\n",
      "[13,   100] loss: 1.000\n",
      "[13,   200] loss: 1.052\n",
      "[14,   100] loss: 0.971\n",
      "[14,   200] loss: 1.017\n",
      "[15,   100] loss: 0.943\n",
      "[15,   200] loss: 0.991\n",
      "[16,   100] loss: 0.902\n",
      "[16,   200] loss: 0.956\n",
      "[17,   100] loss: 0.879\n",
      "[17,   200] loss: 0.932\n",
      "[18,   100] loss: 0.840\n",
      "[18,   200] loss: 0.886\n",
      "[19,   100] loss: 0.821\n",
      "[19,   200] loss: 0.866\n",
      "[20,   100] loss: 0.778\n",
      "[20,   200] loss: 0.852\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net\n",
      "[1,   100] loss: 1.969\n",
      "[1,   200] loss: 1.888\n",
      "[2,   100] loss: 1.824\n",
      "[2,   200] loss: 1.832\n",
      "[3,   100] loss: 1.798\n",
      "[3,   200] loss: 1.815\n",
      "[4,   100] loss: 1.795\n",
      "[4,   200] loss: 1.783\n",
      "[5,   100] loss: 1.759\n",
      "[5,   200] loss: 1.770\n",
      "[6,   100] loss: 1.751\n",
      "[6,   200] loss: 1.762\n",
      "[7,   100] loss: 1.766\n",
      "[7,   200] loss: 1.764\n",
      "[8,   100] loss: 1.755\n",
      "[8,   200] loss: 1.761\n",
      "[9,   100] loss: 1.748\n",
      "[9,   200] loss: 1.747\n",
      "[10,   100] loss: 1.737\n",
      "[10,   200] loss: 1.741\n",
      "[11,   100] loss: 1.731\n",
      "[11,   200] loss: 1.742\n",
      "[12,   100] loss: 1.719\n",
      "[12,   200] loss: 1.738\n",
      "[13,   100] loss: 1.726\n",
      "[13,   200] loss: 1.743\n",
      "[14,   100] loss: 1.715\n",
      "[14,   200] loss: 1.734\n",
      "[15,   100] loss: 1.704\n",
      "[15,   200] loss: 1.731\n",
      "[16,   100] loss: 1.708\n",
      "[16,   200] loss: 1.708\n",
      "[17,   100] loss: 1.693\n",
      "[17,   200] loss: 1.709\n",
      "[18,   100] loss: 1.703\n",
      "[18,   200] loss: 1.720\n",
      "[19,   100] loss: 1.696\n",
      "[19,   200] loss: 1.698\n",
      "[20,   100] loss: 1.687\n",
      "[20,   200] loss: 1.713\n",
      "Finished training!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAYERSIZE = 150\n",
    "\n",
    "test_runs = 10\n",
    "\n",
    "int_lr = 0.3\n",
    "syn_lr = 0.01\n",
    "\n",
    "seed = random.randint(0, 1000000)\n",
    "\n",
    "#Train IP Model\n",
    "torch.manual_seed(seed)\n",
    "IPnet = CNet(LAYERSIZE, IP, eta=int_lr)\n",
    "IPnet = IPnet.to(device)\n",
    "\n",
    "optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "print(\"Training IP Net\")\n",
    "ip_losses = train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "#Train Standard Model\n",
    "torch.manual_seed(seed)\n",
    "net = CNet(LAYERSIZE, NN, eta=int_lr)\n",
    "net = net.to(device)\n",
    "\n",
    "optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "print(\"Training Standard Net\")\n",
    "standard_losses = train_deep_model(net, optimizer2, seed)\n",
    "\n",
    "for i in range(test_runs-1):\n",
    "    seed = random.randint(0, 1000000)\n",
    "    \n",
    "    #Train IP Model\n",
    "    torch.manual_seed(seed)\n",
    "    IPnet = CNet(LAYERSIZE, IP, eta=int_lr)\n",
    "    IPnet = IPnet.to(device)\n",
    "\n",
    "    optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training IP Net\")\n",
    "    ip_losses += train_deep_model(IPnet, optimizer1, seed)\n",
    "\n",
    "\n",
    "    #Train Standard Model\n",
    "    torch.manual_seed(seed)\n",
    "    net = CNet(LAYERSIZE, NN, eta=int_lr)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "    print(\"Training Standard Net\")\n",
    "    standard_losses += train_deep_model(net, optimizer2, seed)\n",
    "    \n",
    "ip_losses = ip_losses/test_runs\n",
    "standard_losses = standard_losses/test_runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAFNCAYAAADSGTgvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWSIiIiIiIrI6DGaJiIiIiIjI6vw/uN5FSK978MAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f091b45ce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16, 5))\n",
    "plt.ylim([-0.1, 3])\n",
    "plt.title(\"Learning curves for single-layer networks\")\n",
    "plt.plot(ip_losses[0], ip_losses[1], label=\"IP\")\n",
    "# plt.plot(bn_losses[0], bn_losses[1], label=\"BN\")\n",
    "plt.plot(standard_losses[0], standard_losses[1], label=\"Standard\")\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the standard network on the 10000 test images: 38.9400 %\n",
      "Accuracy of the IP network on the 10000 test images: 49.2800 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        y = net(images)\n",
    "        _, predicted = torch.max(y.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the standard network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        y = IPnet(images)\n",
    "        _, predicted = torch.max(y.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the IP network on the 10000 test images: %.4f %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
