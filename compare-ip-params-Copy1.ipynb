{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.optim.lr_scheduler as LR\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self, layersize, eta=None):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "    \n",
    "    def update(self, u, v, eta=None):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "class Adam(nn.Module):\n",
    "    def __init__(self, param, betas=(0.9, 0.999), eps=1e-8):\n",
    "        super(Adam, self).__init__()\n",
    "\n",
    "        self.register_buffer('beta1', torch.tensor(betas[0]))\n",
    "        self.register_buffer('beta2', torch.tensor(betas[1]))\n",
    "        self.register_buffer('eps', torch.tensor(eps))\n",
    "\n",
    "        self.register_buffer('m', torch.zeros_like(param))\n",
    "        self.register_buffer('v', torch.zeros_like(param))\n",
    "        self.register_buffer('t', torch.tensor(0.0))\n",
    "\n",
    "    def forward(self, g):\n",
    "        self.m = self.beta1 * self.m + (1-self.beta1) * g\n",
    "        self.v = self.beta2 * self.v + (1-self.beta2) * g**2\n",
    "        self.t += 1\n",
    "\n",
    "        m_hat = self.m/(1 - self.beta1**self.t)\n",
    "        v_hat = self.v/(1 - self.beta2**self.t)\n",
    "\n",
    "        return m_hat / (torch.sqrt(v_hat) + self.eps)\n",
    "\n",
    "    \n",
    "class BN(nn.Module):\n",
    "    def __init__(self, layersize, eta=None):\n",
    "        super(BN, self).__init__()\n",
    "        self.gain = nn.Parameter(torch.ones(layersize))\n",
    "        self.bias = nn.Parameter(torch.zeros(layersize))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        beta = x.mean(0, keepdim=True)\n",
    "        alpha = ((x-beta)**2).mean(0, keepdim=True).sqrt()\n",
    "\n",
    "        # Normalize\n",
    "        nx = (x-beta)/alpha\n",
    "\n",
    "        # Adjust using learned parameters\n",
    "        o = self.gain*nx + self.bias\n",
    "        return o\n",
    "\n",
    "    def update(self, u, v, eta=None):\n",
    "        pass\n",
    "\n",
    "class IP(nn.Module):\n",
    "    def __init__(self, layersize, eta=1):\n",
    "        super(IP, self).__init__()\n",
    "        self.eta = eta\n",
    "        \n",
    "        # gain/bias are the learned output distribution params\n",
    "#         self.gain = nn.Parameter(torch.ones(layersize))\n",
    "#         self.bias = nn.Parameter(torch.zeros(layersize))\n",
    "        \n",
    "        # Alpha and beta are the ip normalization parameters\n",
    "        self.register_buffer('alpha', torch.ones(layersize))\n",
    "        self.register_buffer('beta', torch.zeros(layersize))\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Normalize\n",
    "        nx = (x-self.beta)/self.alpha\n",
    "\n",
    "        return  nx\n",
    "        \n",
    "    def update(self, u, v, eta=None):\n",
    "\n",
    "        if (eta is None):\n",
    "            eta = self.eta\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            Ev = v.mean(0, keepdim=True)\n",
    "            Euv = (u*v).mean(0, keepdim=True)\n",
    "\n",
    "        self.alpha = (1-eta)*self.alpha + eta * 2*Euv\n",
    "        self.beta = (1-eta)*self.beta + eta * (Ev)\n",
    "\n",
    "\n",
    "class inc_BN(nn.Module):\n",
    "    def __init__(self, layersize, eta=1):\n",
    "        super(inc_BN, self).__init__()\n",
    "        self.eta = eta\n",
    "        \n",
    "        # gain/bias are the learned output distribution params\n",
    "        self.gain = nn.Parameter(torch.ones(layersize))\n",
    "        self.bias = nn.Parameter(torch.zeros(layersize))\n",
    "        \n",
    "        # Alpha and beta are the ip normalization parameters\n",
    "        self.register_buffer('alpha', torch.ones(layersize))\n",
    "        self.register_buffer('beta', torch.zeros(layersize))\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Normalize\n",
    "        nx = (x-self.beta)/self.alpha\n",
    "\n",
    "        # Adjust using learned parameters\n",
    "        o = self.gain*nx + self.bias\n",
    "        return o\n",
    "        \n",
    "    def update(self, u, v, eta=None):\n",
    "\n",
    "        if (eta is None):\n",
    "            eta = self.eta\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            Eu = u.mean(0, keepdim=True)\n",
    "            Euu = (u**2).mean(0, keepdim=True)\n",
    "\n",
    "        self.alpha = (1-eta)*self.alpha + eta * (torch.sqrt((Euu - Eu**2)))\n",
    "        self.beta = (1-eta)*self.beta + eta * (Eu)\n",
    "        \n",
    "#         self.eta = eta * 0.998\n",
    "        \n",
    "class og_IP(nn.Module):\n",
    "    def __init__(self, layersize, eta=1):\n",
    "        super(og_IP, self).__init__()\n",
    "        self.eta = eta\n",
    "        \n",
    "        # gain/bias are the learned output distribution params\n",
    "        self.gain = nn.Parameter(torch.ones(layersize))\n",
    "        self.bias = nn.Parameter(torch.zeros(layersize))\n",
    "        \n",
    "        # Alpha and beta are the ip normalization parameters\n",
    "        self.register_buffer('alpha', torch.ones(layersize))\n",
    "        self.register_buffer('beta', torch.zeros(layersize))\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Normalize\n",
    "        nx = self.alpha*x + self.beta\n",
    "        \n",
    "        return nx\n",
    "        \n",
    "    def update(self, u, v, eta=None):\n",
    "\n",
    "        if (eta is None):\n",
    "            eta = self.eta\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            Ev = v.mean(0, keepdim=True)\n",
    "            Euv = (u*v).mean(0, keepdim=True)\n",
    "\n",
    "        self.alpha = self.alpha + eta * (1/self.alpha -2*Euv)\n",
    "        self.beta = self.beta + eta * (-2*Ev)\n",
    "        \n",
    "#         self.eta = eta * 0.998\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, layersize, norm=None, eta=1):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        # Dense Layers\n",
    "        self.fc1 = nn.Linear(28*28, layersize)\n",
    "        self.fc2 = nn.Linear(layersize, layersize)\n",
    "        self.fc3 = nn.Linear(layersize, 10)\n",
    "        \n",
    "        # Normalization Layers\n",
    "        self.n1 = norm(layersize, eta)\n",
    "        self.n2 = norm(layersize, eta)\n",
    "        \n",
    "    def forward(self, x, eta=None):\n",
    "        x = x.view(-1, 28*28)\n",
    "        u1 = self.fc1(x)\n",
    "        v1 = F.tanh(self.n1(u1))\n",
    "        u2 = self.fc2(v1)\n",
    "        v2 = F.tanh(self.n2(u2))\n",
    "        # Note you should not normalize after the last linear layer (you delete info)\n",
    "        o = F.relu(self.fc3(v2))\n",
    "        \n",
    "        # Lets do the updates to the normalizations\n",
    "        self.n1.update(u1, v1, eta)\n",
    "        self.n2.update(u2, v2, eta)\n",
    "        \n",
    "        return o\n",
    "\n",
    "class DNet(nn.Module):\n",
    "    def __init__(self, layersize, norm=None, eta=1):\n",
    "        super(DNet, self).__init__()\n",
    "        \n",
    "        # Dense Layers\n",
    "        self.fc1 = nn.Linear(28*28, layersize)\n",
    "        self.fc2 = nn.Linear(layersize, layersize)\n",
    "        self.fc3 = nn.Linear(layersize, layersize)\n",
    "        self.fc4 = nn.Linear(layersize, layersize)\n",
    "        self.fc5 = nn.Linear(layersize, layersize)\n",
    "        self.fc6 = nn.Linear(layersize, layersize)\n",
    "        self.fc7 = nn.Linear(layersize, layersize)\n",
    "        self.fc8 = nn.Linear(layersize, layersize)\n",
    "        self.fc9 = nn.Linear(layersize, 10)\n",
    "        \n",
    "        # Normalization Layers\n",
    "        self.n1 = norm(layersize, eta)\n",
    "        self.n2 = norm(layersize, eta)\n",
    "        self.n3 = norm(layersize, eta)\n",
    "        self.n4 = norm(layersize, eta)\n",
    "        self.n5 = norm(layersize, eta)\n",
    "        self.n6 = norm(layersize, eta)\n",
    "        self.n7 = norm(layersize, eta)\n",
    "        self.n8 = norm(layersize, eta)\n",
    "        \n",
    "    def forward(self, x, eta=None):\n",
    "        x = x.view(-1, 28*28)\n",
    "        u1 = self.fc1(x)\n",
    "        v1 = F.tanh(self.n1(u1))\n",
    "        u2 = self.fc2(v1)\n",
    "        v2 = F.tanh(self.n2(u2))\n",
    "        u3 = self.fc3(v2)\n",
    "        v3 = F.tanh(self.n3(u3))\n",
    "        u4 = self.fc4(v3)\n",
    "        v4 = F.tanh(self.n4(u4))\n",
    "        u5 = self.fc5(v4)\n",
    "        v5 = F.tanh(self.n5(u5))\n",
    "        u6 = self.fc6(v5)\n",
    "        v6 = F.tanh(self.n6(u6))\n",
    "        u7 = self.fc7(v6)\n",
    "        v7 = F.tanh(self.n7(u7))\n",
    "        u8 = self.fc8(v7)\n",
    "        v8 = F.tanh(self.n8(u8))\n",
    "        # Note you should not normalize after the last linear layer (you delete info)\n",
    "        o = F.relu(self.fc9(v8))\n",
    "        \n",
    "        # Lets do the updates to the normalizations\n",
    "        self.n1.update(u1, v1, eta)\n",
    "        self.n2.update(u2, v2, eta)\n",
    "        self.n3.update(u3, v3, eta)\n",
    "        self.n4.update(u4, v4, eta)\n",
    "        self.n5.update(u5, v5, eta)\n",
    "        self.n6.update(u6, v6, eta)\n",
    "        self.n7.update(u7, v7, eta)\n",
    "        self.n8.update(u8, v8, eta)\n",
    "        \n",
    "        \n",
    "        return o\n",
    "    \n",
    "class CDNet(nn.Module):\n",
    "    def __init__(self, layersize, norm=None, eta=1):\n",
    "        super(CDNet, self).__init__()\n",
    "        \n",
    "        # Dense Layers\n",
    "        self.fc1 = nn.Linear(3*32*32, layersize)\n",
    "        self.fc2 = nn.Linear(layersize, layersize)\n",
    "        self.fc3 = nn.Linear(layersize, layersize)\n",
    "        self.fc4 = nn.Linear(layersize, layersize)\n",
    "        self.fc5 = nn.Linear(layersize, layersize)\n",
    "        self.fc6 = nn.Linear(layersize, layersize)\n",
    "        self.fc7 = nn.Linear(layersize, layersize)\n",
    "        self.fc8 = nn.Linear(layersize, layersize)\n",
    "        self.fc9 = nn.Linear(layersize, 10)\n",
    "        \n",
    "        # Normalization Layers\n",
    "        self.n1 = norm(layersize, eta)\n",
    "        self.n2 = norm(layersize, eta)\n",
    "        self.n3 = norm(layersize, eta)\n",
    "        self.n4 = norm(layersize, eta)\n",
    "        self.n5 = norm(layersize, eta)\n",
    "        self.n6 = norm(layersize, eta)\n",
    "        self.n7 = norm(layersize, eta)\n",
    "        self.n8 = norm(layersize, eta)\n",
    "        \n",
    "    def forward(self, x, eta=None):\n",
    "        x = x.view(-1, 3*32*32)\n",
    "        u1 = self.fc1(x)\n",
    "        v1 = F.tanh(self.n1(u1))\n",
    "        u2 = self.fc2(v1)\n",
    "        v2 = F.tanh(self.n2(u2))\n",
    "        u3 = self.fc3(v2)\n",
    "        v3 = F.tanh(self.n3(u3))\n",
    "        u4 = self.fc4(v3)\n",
    "        v4 = F.tanh(self.n4(u4))\n",
    "        u5 = self.fc5(v4)\n",
    "        v5 = F.tanh(self.n5(u5))\n",
    "        u6 = self.fc6(v5)\n",
    "        v6 = F.tanh(self.n6(u6))\n",
    "        u7 = self.fc7(v6)\n",
    "        v7 = F.tanh(self.n7(u7))\n",
    "        u8 = self.fc8(v7)\n",
    "        v8 = F.tanh(self.n8(u8))\n",
    "        # Note you should not normalize after the last linear layer (you delete info)\n",
    "        o = F.relu(self.fc9(v8))\n",
    "        \n",
    "        # Lets do the updates to the normalizations\n",
    "        self.n1.update(u1, v1, eta)\n",
    "        self.n2.update(u2, v2, eta)\n",
    "        self.n3.update(u3, v3, eta)\n",
    "        self.n4.update(u4, v4, eta)\n",
    "        self.n5.update(u5, v5, eta)\n",
    "        self.n6.update(u6, v6, eta)\n",
    "        self.n7.update(u7, v7, eta)\n",
    "        self.n8.update(u8, v8, eta)\n",
    "        \n",
    "        \n",
    "        return o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_deep_model(network, optimization, seed, epochs):\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    torch.manual_seed(seed)\n",
    "    \n",
    "    loss_tracker = []\n",
    "    episode = 1\n",
    "    \n",
    "    for epoch in range(epochs):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "        i = 0\n",
    "\n",
    "        for i, data in enumerate(trainloader):\n",
    "            # get the inputs\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimization.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            y = network(inputs)\n",
    "            loss = criterion(y, labels)\n",
    "            loss.backward()\n",
    "            optimization.step()\n",
    "\n",
    "            # update statistics\n",
    "            running_loss += loss.item()\n",
    "            i += 0\n",
    "            \n",
    "            loss_tracker.append([episode,loss.item()])\n",
    "            episode += 1\n",
    "            \n",
    "        print('[%d] loss: %.3f' %\n",
    "                      (epoch + 1,running_loss / i))\n",
    "            \n",
    "    print(\"Finished training!\\n\")\n",
    "    return(np.transpose(loss_tracker))\n",
    "\n",
    "\n",
    "def run_mnist_experiment(int_lr, syn_lr, epochs, test_runs):\n",
    "    seed = random.randint(0, 1000000)\n",
    "\n",
    "    #Train IP Model\n",
    "    torch.manual_seed(seed)\n",
    "    IPnet = DNet(LAYERSIZE, IP, eta=int_lr)\n",
    "    IPnet = IPnet.to(device)\n",
    "\n",
    "    optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training IP Net. Run %d\" % (1))\n",
    "    ip_losses = train_deep_model(IPnet, optimizer1, seed, epochs)\n",
    "\n",
    "    #Train Incremental BN\n",
    "    torch.manual_seed(seed)\n",
    "    BNnet = DNet(LAYERSIZE, inc_BN, eta=int_lr)\n",
    "    BNnet = BNnet.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(BNnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training Incremental BN. Run %d\" % (1))\n",
    "    bn_losses = train_deep_model(BNnet, optimizer, seed, epochs)\n",
    "          \n",
    "    #Train Deep OG IP\n",
    "    torch.manual_seed(seed)\n",
    "    DOGnet = DNet(LAYERSIZE, og_IP, eta=int_lr)\n",
    "    DOGnet = DOGnet.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(DOGnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training Infomax Net. Run %d\" % (1))\n",
    "    og_losses = train_deep_model(DOGnet, optimizer, seed, epochs)\n",
    "    \n",
    "    #Train Standard Model\n",
    "    torch.manual_seed(seed)\n",
    "    net = DNet(LAYERSIZE, NN, eta=int_lr)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "    print(\"Training Standard Net. Run 1\")\n",
    "    standard_losses = train_deep_model(net, optimizer2, seed, epochs)\n",
    "\n",
    "    for i in range(test_runs-1):\n",
    "        seed = random.randint(0, 1000000)\n",
    "\n",
    "        #Train IP Model\n",
    "        torch.manual_seed(seed)\n",
    "        IPnet = DNet(LAYERSIZE, IP, eta=int_lr)\n",
    "        IPnet = IPnet.to(device)\n",
    "\n",
    "        optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "        print(\"Training IP Net. Run %d\" % (i+2))\n",
    "        ip_losses += train_deep_model(IPnet, optimizer1, seed, epochs)\n",
    "\n",
    "\n",
    "        #Train Incremental BN\n",
    "        torch.manual_seed(seed)\n",
    "        BNnet = DNet(LAYERSIZE, inc_BN, eta=int_lr)\n",
    "        BNnet = BNnet.to(device)\n",
    "\n",
    "        optimizer = optim.Adam(BNnet.parameters(), lr=syn_lr)\n",
    "        print(\"Training Incremental BN. Run %d\" % (i+2))\n",
    "        bn_losses += train_deep_model(BNnet, optimizer, seed, epochs)\n",
    "              \n",
    "        #Train Deep OG IP\n",
    "        torch.manual_seed(seed)\n",
    "        DOGnet = DNet(LAYERSIZE, og_IP, eta=int_lr)\n",
    "        DOGnet = DOGnet.to(device)\n",
    "\n",
    "        optimizer = optim.Adam(DOGnet.parameters(), lr=syn_lr)\n",
    "        print(\"Training Infomax Net. Run %d\" % (i+2))\n",
    "        og_losses += train_deep_model(DOGnet, optimizer, seed, epochs)\n",
    "        \n",
    "        #Train Standard Model\n",
    "        torch.manual_seed(seed)\n",
    "        net = DNet(LAYERSIZE, NN, eta=int_lr)\n",
    "        net = net.to(device)\n",
    "\n",
    "        optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "        print(\"Training Standard Net. Run %d\" % (i+2))\n",
    "        standard_losses += train_deep_model(net, optimizer2, seed, epochs)\n",
    "\n",
    "    ip_losses = ip_losses/test_runs\n",
    "    bn_losses = bn_losses/test_runs\n",
    "    og_losses = og_losses/test_runs\n",
    "    standard_losses = standard_losses/test_runs\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.ylim([-0.1, 3])\n",
    "#     plt.title(\"Learning curves for deep networks\")\n",
    "    plt.plot(ip_losses[0], ip_losses[1], label=\"IP\")\n",
    "    plt.plot(standard_losses[0], standard_losses[1], label=\"Standard\")\n",
    "    plt.plot(bn_losses[0], bn_losses[1], label=\"BN\")\n",
    "    plt.plot(og_losses[0], og_losses[1], label=\"Infomax\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def run_cifar_experiment(int_lr, syn_lr, epochs, test_runs):\n",
    "    seed = random.randint(0, 1000000)\n",
    "\n",
    "    #Train IP Model\n",
    "    torch.manual_seed(seed)\n",
    "    IPnet = CDNet(LAYERSIZE, IP, eta=int_lr)\n",
    "    IPnet = IPnet.to(device)\n",
    "\n",
    "    optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training IP Net. Run %d\" % (1))\n",
    "    ip_losses = train_deep_model(IPnet, optimizer1, seed, epochs)\n",
    "\n",
    "    #Train Incremental BN\n",
    "    torch.manual_seed(seed)\n",
    "    BNnet = CDNet(LAYERSIZE, inc_BN, eta=int_lr)\n",
    "    BNnet = BNnet.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(BNnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training Incremental BN. Run %d\" % (1))\n",
    "    bn_losses = train_deep_model(BNnet, optimizer, seed, epochs)\n",
    "          \n",
    "    #Train Deep OG IP\n",
    "    torch.manual_seed(seed)\n",
    "    DOGnet = CDNet(LAYERSIZE, og_IP, eta=int_lr)\n",
    "    DOGnet = DOGnet.to(device)\n",
    "\n",
    "    optimizer = optim.Adam(DOGnet.parameters(), lr=syn_lr)\n",
    "    print(\"Training Infomax Net. Run %d\" % (1))\n",
    "    og_losses = train_deep_model(DOGnet, optimizer, seed, epochs)\n",
    "    \n",
    "    #Train Standard Model\n",
    "    torch.manual_seed(seed)\n",
    "    net = CDNet(LAYERSIZE, NN, eta=int_lr)\n",
    "    net = net.to(device)\n",
    "\n",
    "    optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "    print(\"Training Standard Net. Run 1\")\n",
    "    standard_losses = train_deep_model(net, optimizer2, seed, epochs)\n",
    "\n",
    "    for i in range(test_runs-1):\n",
    "        seed = random.randint(0, 1000000)\n",
    "\n",
    "        #Train IP Model\n",
    "        torch.manual_seed(seed)\n",
    "        IPnet = CDNet(LAYERSIZE, IP, eta=int_lr)\n",
    "        IPnet = IPnet.to(device)\n",
    "\n",
    "        optimizer1 = optim.Adam(IPnet.parameters(), lr=syn_lr)\n",
    "        print(\"Training IP Net. Run %d\" % (i+2))\n",
    "        ip_losses += train_deep_model(IPnet, optimizer1, seed, epochs)\n",
    "\n",
    "\n",
    "        #Train Incremental BN\n",
    "        torch.manual_seed(seed)\n",
    "        BNnet = CDNet(LAYERSIZE, inc_BN, eta=int_lr)\n",
    "        BNnet = BNnet.to(device)\n",
    "\n",
    "        optimizer = optim.Adam(BNnet.parameters(), lr=syn_lr)\n",
    "        print(\"Training Incremental BN. Run %d\" % (i+2))\n",
    "        bn_losses += train_deep_model(BNnet, optimizer, seed, epochs)\n",
    "              \n",
    "        #Train Deep OG IP\n",
    "        torch.manual_seed(seed)\n",
    "        DOGnet = CDNet(LAYERSIZE, og_IP, eta=int_lr)\n",
    "        DOGnet = DOGnet.to(device)\n",
    "\n",
    "        optimizer = optim.Adam(DOGnet.parameters(), lr=syn_lr)\n",
    "        print(\"Training Infomax Net. Run %d\" % (i+2))\n",
    "        og_losses += train_deep_model(DOGnet, optimizer, seed, epochs)\n",
    "        \n",
    "        #Train Standard Model\n",
    "        torch.manual_seed(seed)\n",
    "        net = CDNet(LAYERSIZE, NN, eta=int_lr)\n",
    "        net = net.to(device)\n",
    "\n",
    "        optimizer2 = optim.Adam(net.parameters(), lr=syn_lr)\n",
    "        print(\"Training Standard Net. Run %d\" % (i+2))\n",
    "        standard_losses += train_deep_model(net, optimizer2, seed, epochs)\n",
    "\n",
    "    ip_losses = ip_losses/test_runs\n",
    "    bn_losses = bn_losses/test_runs\n",
    "    og_losses = og_losses/test_runs\n",
    "    standard_losses = standard_losses/test_runs\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.ylim([-0.1, 3])\n",
    "    plt.plot(ip_losses[0], ip_losses[1], label=\"IP\")\n",
    "    plt.plot(standard_losses[0], standard_losses[1], label=\"Standard\")\n",
    "    plt.plot(bn_losses[0], bn_losses[1], label=\"BN\")\n",
    "    plt.plot(og_losses[0], og_losses[1], label=\"Infomax\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==>>> total training batch number: 300\n",
      "==>>> total testing batch number: 50\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.ToTensor()\n",
    "\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "batch_size = 200\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "print('==>>> total training batch number: {}'.format(len(trainloader)))\n",
    "print('==>>> total testing batch number: {}'.format(len(testloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IP Net. Run 1\n",
      "[1] loss: 0.633\n",
      "[2] loss: 0.311\n",
      "[3] loss: 0.236\n",
      "[4] loss: 0.195\n",
      "[5] loss: 0.169\n",
      "[6] loss: 0.150\n",
      "[7] loss: 0.138\n",
      "[8] loss: 0.126\n",
      "[9] loss: 0.118\n",
      "[10] loss: 0.111\n",
      "[11] loss: 0.103\n",
      "[12] loss: 0.097\n",
      "[13] loss: 0.093\n",
      "[14] loss: 0.089\n",
      "[15] loss: 0.086\n",
      "[16] loss: 0.080\n",
      "[17] loss: 0.079\n",
      "[18] loss: 0.076\n",
      "[19] loss: 0.072\n",
      "[20] loss: 0.066\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 1\n",
      "[1] loss: 0.689\n",
      "[2] loss: 0.316\n",
      "[3] loss: 0.231\n",
      "[4] loss: 0.185\n",
      "[5] loss: 0.160\n",
      "[6] loss: 0.135\n",
      "[7] loss: 0.122\n",
      "[8] loss: 0.107\n",
      "[9] loss: 0.099\n",
      "[10] loss: 0.090\n",
      "[11] loss: 0.083\n",
      "[12] loss: 0.076\n",
      "[13] loss: 0.070\n",
      "[14] loss: 0.064\n",
      "[15] loss: 0.059\n",
      "[16] loss: 0.057\n",
      "[17] loss: 0.051\n",
      "[18] loss: 0.048\n",
      "[19] loss: 0.046\n",
      "[20] loss: 0.045\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 1\n",
      "[1] loss: 1.708\n",
      "[2] loss: 1.847\n",
      "[3] loss: 2.101\n",
      "[4] loss: 2.196\n",
      "[5] loss: 2.129\n",
      "[6] loss: 1.860\n",
      "[7] loss: 1.889\n",
      "[8] loss: 2.178\n",
      "[9] loss: 2.259\n",
      "[10] loss: 2.321\n",
      "[11] loss: 2.312\n",
      "[12] loss: 2.314\n",
      "[13] loss: 2.312\n",
      "[14] loss: 2.314\n",
      "[15] loss: 2.311\n",
      "[16] loss: 2.311\n",
      "[17] loss: 2.311\n",
      "[18] loss: 2.311\n",
      "[19] loss: 2.311\n",
      "[20] loss: 2.311\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 1\n",
      "[1] loss: 1.360\n",
      "[2] loss: 0.410\n",
      "[3] loss: 0.241\n",
      "[4] loss: 0.184\n",
      "[5] loss: 0.150\n",
      "[6] loss: 0.134\n",
      "[7] loss: 0.116\n",
      "[8] loss: 0.102\n",
      "[9] loss: 0.094\n",
      "[10] loss: 0.091\n",
      "[11] loss: 0.087\n",
      "[12] loss: 0.081\n",
      "[13] loss: 0.078\n",
      "[14] loss: 0.073\n",
      "[15] loss: 0.065\n",
      "[16] loss: 0.065\n",
      "[17] loss: 0.060\n",
      "[18] loss: 0.065\n",
      "[19] loss: 0.058\n",
      "[20] loss: 0.054\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 2\n",
      "[1] loss: 0.575\n",
      "[2] loss: 0.256\n",
      "[3] loss: 0.202\n",
      "[4] loss: 0.174\n",
      "[5] loss: 0.151\n",
      "[6] loss: 0.137\n",
      "[7] loss: 0.128\n",
      "[8] loss: 0.118\n",
      "[9] loss: 0.107\n",
      "[10] loss: 0.101\n",
      "[11] loss: 0.093\n",
      "[12] loss: 0.090\n",
      "[13] loss: 0.085\n",
      "[14] loss: 0.081\n",
      "[15] loss: 0.073\n",
      "[16] loss: 0.074\n",
      "[17] loss: 0.070\n",
      "[18] loss: 0.065\n",
      "[19] loss: 0.064\n",
      "[20] loss: 0.062\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 2\n",
      "[1] loss: 0.719\n",
      "[2] loss: 0.313\n",
      "[3] loss: 0.220\n",
      "[4] loss: 0.179\n",
      "[5] loss: 0.149\n",
      "[6] loss: 0.134\n",
      "[7] loss: 0.117\n",
      "[8] loss: 0.105\n",
      "[9] loss: 0.094\n",
      "[10] loss: 0.085\n",
      "[11] loss: 0.080\n",
      "[12] loss: 0.075\n",
      "[13] loss: 0.069\n",
      "[14] loss: 0.063\n",
      "[15] loss: 0.058\n",
      "[16] loss: 0.055\n",
      "[17] loss: 0.051\n",
      "[18] loss: 0.046\n",
      "[19] loss: 0.046\n",
      "[20] loss: 0.043\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 2\n",
      "[1] loss: 1.082\n",
      "[2] loss: 0.851\n",
      "[3] loss: 1.615\n",
      "[4] loss: 1.921\n",
      "[5] loss: 2.089\n",
      "[6] loss: 2.167\n",
      "[7] loss: 2.265\n",
      "[8] loss: 2.153\n",
      "[9] loss: 2.200\n",
      "[10] loss: 2.321\n",
      "[11] loss: 2.321\n",
      "[12] loss: 2.317\n",
      "[13] loss: 2.312\n",
      "[14] loss: 2.311\n",
      "[15] loss: 2.311\n",
      "[16] loss: 2.311\n",
      "[17] loss: 2.311\n",
      "[18] loss: 2.311\n",
      "[19] loss: 2.311\n",
      "[20] loss: 2.311\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 2\n",
      "[1] loss: 0.660\n",
      "[2] loss: 0.240\n",
      "[3] loss: 0.185\n",
      "[4] loss: 0.155\n",
      "[5] loss: 0.137\n",
      "[6] loss: 0.119\n",
      "[7] loss: 0.111\n",
      "[8] loss: 0.099\n",
      "[9] loss: 0.095\n",
      "[10] loss: 0.089\n",
      "[11] loss: 0.083\n",
      "[12] loss: 0.077\n",
      "[13] loss: 0.075\n",
      "[14] loss: 0.074\n",
      "[15] loss: 0.074\n",
      "[16] loss: 0.062\n",
      "[17] loss: 0.064\n",
      "[18] loss: 0.062\n",
      "[19] loss: 0.061\n",
      "[20] loss: 0.061\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 3\n",
      "[1] loss: 0.490\n",
      "[2] loss: 0.242\n",
      "[3] loss: 0.193\n",
      "[4] loss: 0.168\n",
      "[5] loss: 0.147\n",
      "[6] loss: 0.129\n",
      "[7] loss: 0.121\n",
      "[8] loss: 0.109\n",
      "[9] loss: 0.103\n",
      "[10] loss: 0.097\n",
      "[11] loss: 0.090\n",
      "[12] loss: 0.085\n",
      "[13] loss: 0.080\n",
      "[14] loss: 0.077\n",
      "[15] loss: 0.072\n",
      "[16] loss: 0.069\n",
      "[17] loss: 0.067\n",
      "[18] loss: 0.064\n",
      "[19] loss: 0.061\n",
      "[20] loss: 0.059\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 3\n",
      "[1] loss: 0.547\n",
      "[2] loss: 0.292\n",
      "[3] loss: 0.223\n",
      "[4] loss: 0.179\n",
      "[5] loss: 0.147\n",
      "[6] loss: 0.128\n",
      "[7] loss: 0.116\n",
      "[8] loss: 0.105\n",
      "[9] loss: 0.091\n",
      "[10] loss: 0.085\n",
      "[11] loss: 0.077\n",
      "[12] loss: 0.072\n",
      "[13] loss: 0.067\n",
      "[14] loss: 0.063\n",
      "[15] loss: 0.057\n",
      "[16] loss: 0.056\n",
      "[17] loss: 0.053\n",
      "[18] loss: 0.046\n",
      "[19] loss: 0.045\n",
      "[20] loss: 0.039\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 3\n",
      "[1] loss: 0.922\n",
      "[2] loss: 0.617\n",
      "[3] loss: 0.834\n",
      "[4] loss: 2.162\n",
      "[5] loss: 2.345\n",
      "[6] loss: 2.335\n",
      "[7] loss: 2.314\n",
      "[8] loss: 2.318\n",
      "[9] loss: 2.312\n",
      "[10] loss: 2.312\n",
      "[11] loss: 2.311\n",
      "[12] loss: 2.311\n",
      "[13] loss: 2.311\n",
      "[14] loss: 2.310\n",
      "[15] loss: 2.311\n",
      "[16] loss: 2.311\n",
      "[17] loss: 2.310\n",
      "[18] loss: 2.310\n",
      "[19] loss: 2.310\n",
      "[20] loss: 2.310\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 3\n",
      "[1] loss: 0.728\n",
      "[2] loss: 0.254\n",
      "[3] loss: 0.193\n",
      "[4] loss: 0.167\n",
      "[5] loss: 0.149\n",
      "[6] loss: 0.132\n",
      "[7] loss: 0.117\n",
      "[8] loss: 0.107\n",
      "[9] loss: 0.102\n",
      "[10] loss: 0.096\n",
      "[11] loss: 0.094\n",
      "[12] loss: 0.082\n",
      "[13] loss: 0.082\n",
      "[14] loss: 0.078\n",
      "[15] loss: 0.071\n",
      "[16] loss: 0.065\n",
      "[17] loss: 0.073\n",
      "[18] loss: 0.066\n",
      "[19] loss: 0.063\n",
      "[20] loss: 0.063\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 4\n",
      "[1] loss: 0.520\n",
      "[2] loss: 0.246\n",
      "[3] loss: 0.198\n",
      "[4] loss: 0.172\n",
      "[5] loss: 0.154\n",
      "[6] loss: 0.139\n",
      "[7] loss: 0.127\n",
      "[8] loss: 0.116\n",
      "[9] loss: 0.106\n",
      "[10] loss: 0.100\n",
      "[11] loss: 0.094\n",
      "[12] loss: 0.086\n",
      "[13] loss: 0.081\n",
      "[14] loss: 0.079\n",
      "[15] loss: 0.074\n",
      "[16] loss: 0.070\n",
      "[17] loss: 0.067\n",
      "[18] loss: 0.063\n",
      "[19] loss: 0.060\n",
      "[20] loss: 0.061\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 4\n",
      "[1] loss: 0.628\n",
      "[2] loss: 0.303\n",
      "[3] loss: 0.229\n",
      "[4] loss: 0.183\n",
      "[5] loss: 0.155\n",
      "[6] loss: 0.132\n",
      "[7] loss: 0.118\n",
      "[8] loss: 0.106\n",
      "[9] loss: 0.097\n",
      "[10] loss: 0.090\n",
      "[11] loss: 0.080\n",
      "[12] loss: 0.076\n",
      "[13] loss: 0.070\n",
      "[14] loss: 0.065\n",
      "[15] loss: 0.064\n",
      "[16] loss: 0.055\n",
      "[17] loss: 0.052\n",
      "[18] loss: 0.052\n",
      "[19] loss: 0.049\n",
      "[20] loss: 0.046\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 4\n",
      "[1] loss: 0.847\n",
      "[2] loss: 0.546\n",
      "[3] loss: 0.681\n",
      "[4] loss: 1.622\n",
      "[5] loss: 2.109\n",
      "[6] loss: 2.170\n",
      "[7] loss: 2.051\n",
      "[8] loss: 2.161\n",
      "[9] loss: 2.272\n",
      "[10] loss: 2.326\n",
      "[11] loss: 2.320\n",
      "[12] loss: 2.313\n",
      "[13] loss: 2.312\n",
      "[14] loss: 2.311\n",
      "[15] loss: 2.311\n",
      "[16] loss: 2.300\n",
      "[17] loss: 2.306\n",
      "[18] loss: 2.309\n",
      "[19] loss: 2.310\n",
      "[20] loss: 2.311\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 4\n",
      "[1] loss: 1.160\n",
      "[2] loss: 0.357\n",
      "[3] loss: 0.238\n",
      "[4] loss: 0.190\n",
      "[5] loss: 0.163\n",
      "[6] loss: 0.142\n",
      "[7] loss: 0.126\n",
      "[8] loss: 0.119\n",
      "[9] loss: 0.110\n",
      "[10] loss: 0.105\n",
      "[11] loss: 0.096\n",
      "[12] loss: 0.089\n",
      "[13] loss: 0.081\n",
      "[14] loss: 0.080\n",
      "[15] loss: 0.075\n",
      "[16] loss: 0.072\n",
      "[17] loss: 0.066\n",
      "[18] loss: 0.063\n",
      "[19] loss: 0.067\n",
      "[20] loss: 0.065\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 5\n",
      "[1] loss: 0.587\n",
      "[2] loss: 0.263\n",
      "[3] loss: 0.206\n",
      "[4] loss: 0.178\n",
      "[5] loss: 0.152\n",
      "[6] loss: 0.141\n",
      "[7] loss: 0.129\n",
      "[8] loss: 0.119\n",
      "[9] loss: 0.110\n",
      "[10] loss: 0.107\n",
      "[11] loss: 0.100\n",
      "[12] loss: 0.093\n",
      "[13] loss: 0.087\n",
      "[14] loss: 0.086\n",
      "[15] loss: 0.081\n",
      "[16] loss: 0.077\n",
      "[17] loss: 0.073\n",
      "[18] loss: 0.070\n",
      "[19] loss: 0.066\n",
      "[20] loss: 0.066\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 5\n",
      "[1] loss: 0.746\n",
      "[2] loss: 0.336\n",
      "[3] loss: 0.254\n",
      "[4] loss: 0.208\n",
      "[5] loss: 0.174\n",
      "[6] loss: 0.151\n",
      "[7] loss: 0.129\n",
      "[8] loss: 0.119\n",
      "[9] loss: 0.108\n",
      "[10] loss: 0.098\n",
      "[11] loss: 0.092\n",
      "[12] loss: 0.086\n",
      "[13] loss: 0.077\n",
      "[14] loss: 0.076\n",
      "[15] loss: 0.069\n",
      "[16] loss: 0.063\n",
      "[17] loss: 0.061\n",
      "[18] loss: 0.057\n",
      "[19] loss: 0.052\n",
      "[20] loss: 0.049\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 5\n",
      "[1] loss: 1.605\n",
      "[2] loss: 1.582\n",
      "[3] loss: 2.079\n",
      "[4] loss: 2.117\n",
      "[5] loss: 2.345\n",
      "[6] loss: 2.317\n",
      "[7] loss: 2.312\n",
      "[8] loss: 2.312\n",
      "[9] loss: 2.312\n",
      "[10] loss: 2.311\n",
      "[11] loss: 2.312\n",
      "[12] loss: 2.312\n",
      "[13] loss: 2.311\n",
      "[14] loss: 2.310\n",
      "[15] loss: 2.311\n",
      "[16] loss: 2.310\n",
      "[17] loss: 2.311\n",
      "[18] loss: 2.311\n",
      "[19] loss: 2.311\n",
      "[20] loss: 2.311\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 5\n",
      "[1] loss: 2.146\n",
      "[2] loss: 2.170\n",
      "[3] loss: 2.173\n",
      "[4] loss: 2.291\n",
      "[5] loss: 2.191\n",
      "[6] loss: 2.177\n",
      "[7] loss: 2.164\n",
      "[8] loss: 2.178\n",
      "[9] loss: 2.155\n",
      "[10] loss: 2.150\n",
      "[11] loss: 2.165\n",
      "[12] loss: 2.270\n",
      "[13] loss: 2.309\n",
      "[14] loss: 2.309\n",
      "[15] loss: 2.309\n",
      "[16] loss: 2.310\n",
      "[17] loss: 2.309\n",
      "[18] loss: 2.309\n",
      "[19] loss: 2.309\n",
      "[20] loss: 2.309\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 6\n",
      "[1] loss: 0.730\n",
      "[2] loss: 0.346\n",
      "[3] loss: 0.203\n",
      "[4] loss: 0.170\n",
      "[5] loss: 0.148\n",
      "[6] loss: 0.132\n",
      "[7] loss: 0.121\n",
      "[8] loss: 0.111\n",
      "[9] loss: 0.102\n",
      "[10] loss: 0.095\n",
      "[11] loss: 0.090\n",
      "[12] loss: 0.083\n",
      "[13] loss: 0.078\n",
      "[14] loss: 0.076\n",
      "[15] loss: 0.069\n",
      "[16] loss: 0.068\n",
      "[17] loss: 0.062\n",
      "[18] loss: 0.061\n",
      "[19] loss: 0.060\n",
      "[20] loss: 0.055\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 6\n",
      "[1] loss: 0.567\n",
      "[2] loss: 0.267\n",
      "[3] loss: 0.206\n",
      "[4] loss: 0.170\n",
      "[5] loss: 0.144\n",
      "[6] loss: 0.123\n",
      "[7] loss: 0.112\n",
      "[8] loss: 0.095\n",
      "[9] loss: 0.087\n",
      "[10] loss: 0.080\n",
      "[11] loss: 0.070\n",
      "[12] loss: 0.065\n",
      "[13] loss: 0.060\n",
      "[14] loss: 0.055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15] loss: 0.052\n",
      "[16] loss: 0.049\n",
      "[17] loss: 0.045\n",
      "[18] loss: 0.046\n",
      "[19] loss: 0.039\n",
      "[20] loss: 0.040\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 6\n",
      "[1] loss: 1.007\n",
      "[2] loss: 0.885\n",
      "[3] loss: 1.251\n",
      "[4] loss: 1.938\n",
      "[5] loss: 2.061\n",
      "[6] loss: 2.155\n",
      "[7] loss: 2.176\n",
      "[8] loss: 1.998\n",
      "[9] loss: 2.325\n",
      "[10] loss: 2.331\n",
      "[11] loss: 2.318\n",
      "[12] loss: 2.312\n",
      "[13] loss: 2.313\n",
      "[14] loss: 2.311\n",
      "[15] loss: 2.311\n",
      "[16] loss: 2.310\n",
      "[17] loss: 2.311\n",
      "[18] loss: 2.310\n",
      "[19] loss: 2.311\n",
      "[20] loss: 2.311\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 6\n",
      "[1] loss: 1.006\n",
      "[2] loss: 0.505\n",
      "[3] loss: 0.428\n",
      "[4] loss: 0.326\n",
      "[5] loss: 0.161\n",
      "[6] loss: 0.132\n",
      "[7] loss: 0.124\n",
      "[8] loss: 0.114\n",
      "[9] loss: 0.104\n",
      "[10] loss: 0.093\n",
      "[11] loss: 0.087\n",
      "[12] loss: 0.081\n",
      "[13] loss: 0.074\n",
      "[14] loss: 0.075\n",
      "[15] loss: 0.078\n",
      "[16] loss: 0.071\n",
      "[17] loss: 0.067\n",
      "[18] loss: 0.060\n",
      "[19] loss: 0.061\n",
      "[20] loss: 0.060\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 7\n",
      "[1] loss: 0.514\n",
      "[2] loss: 0.236\n",
      "[3] loss: 0.190\n",
      "[4] loss: 0.158\n",
      "[5] loss: 0.142\n",
      "[6] loss: 0.127\n",
      "[7] loss: 0.116\n",
      "[8] loss: 0.108\n",
      "[9] loss: 0.101\n",
      "[10] loss: 0.095\n",
      "[11] loss: 0.088\n",
      "[12] loss: 0.085\n",
      "[13] loss: 0.080\n",
      "[14] loss: 0.077\n",
      "[15] loss: 0.073\n",
      "[16] loss: 0.070\n",
      "[17] loss: 0.065\n",
      "[18] loss: 0.064\n",
      "[19] loss: 0.059\n",
      "[20] loss: 0.058\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 7\n",
      "[1] loss: 0.621\n",
      "[2] loss: 0.301\n",
      "[3] loss: 0.223\n",
      "[4] loss: 0.181\n",
      "[5] loss: 0.152\n",
      "[6] loss: 0.130\n",
      "[7] loss: 0.114\n",
      "[8] loss: 0.104\n",
      "[9] loss: 0.092\n",
      "[10] loss: 0.088\n",
      "[11] loss: 0.078\n",
      "[12] loss: 0.075\n",
      "[13] loss: 0.066\n",
      "[14] loss: 0.063\n",
      "[15] loss: 0.062\n",
      "[16] loss: 0.056\n",
      "[17] loss: 0.051\n",
      "[18] loss: 0.048\n",
      "[19] loss: 0.046\n",
      "[20] loss: 0.042\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 7\n",
      "[1] loss: 1.002\n",
      "[2] loss: 0.820\n",
      "[3] loss: 1.589\n",
      "[4] loss: 2.312\n",
      "[5] loss: 2.235\n",
      "[6] loss: 2.308\n",
      "[7] loss: 2.327\n",
      "[8] loss: 2.317\n",
      "[9] loss: 2.316\n",
      "[10] loss: 2.312\n",
      "[11] loss: 2.312\n",
      "[12] loss: 2.312\n",
      "[13] loss: 2.311\n",
      "[14] loss: 2.310\n",
      "[15] loss: 2.311\n",
      "[16] loss: 2.311\n",
      "[17] loss: 2.311\n",
      "[18] loss: 2.310\n",
      "[19] loss: 2.310\n",
      "[20] loss: 2.310\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 7\n",
      "[1] loss: 0.774\n",
      "[2] loss: 0.271\n",
      "[3] loss: 0.198\n",
      "[4] loss: 0.160\n",
      "[5] loss: 0.143\n",
      "[6] loss: 0.120\n",
      "[7] loss: 0.108\n",
      "[8] loss: 0.097\n",
      "[9] loss: 0.089\n",
      "[10] loss: 0.089\n",
      "[11] loss: 0.080\n",
      "[12] loss: 0.075\n",
      "[13] loss: 0.070\n",
      "[14] loss: 0.069\n",
      "[15] loss: 0.069\n",
      "[16] loss: 0.066\n",
      "[17] loss: 0.060\n",
      "[18] loss: 0.057\n",
      "[19] loss: 0.060\n",
      "[20] loss: 0.055\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 8\n",
      "[1] loss: 0.475\n",
      "[2] loss: 0.225\n",
      "[3] loss: 0.180\n",
      "[4] loss: 0.154\n",
      "[5] loss: 0.137\n",
      "[6] loss: 0.127\n",
      "[7] loss: 0.113\n",
      "[8] loss: 0.105\n",
      "[9] loss: 0.098\n",
      "[10] loss: 0.094\n",
      "[11] loss: 0.088\n",
      "[12] loss: 0.085\n",
      "[13] loss: 0.081\n",
      "[14] loss: 0.077\n",
      "[15] loss: 0.073\n",
      "[16] loss: 0.068\n",
      "[17] loss: 0.068\n",
      "[18] loss: 0.065\n",
      "[19] loss: 0.061\n",
      "[20] loss: 0.058\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 8\n",
      "[1] loss: 0.522\n",
      "[2] loss: 0.262\n",
      "[3] loss: 0.202\n",
      "[4] loss: 0.166\n",
      "[5] loss: 0.140\n",
      "[6] loss: 0.123\n",
      "[7] loss: 0.110\n",
      "[8] loss: 0.098\n",
      "[9] loss: 0.089\n",
      "[10] loss: 0.082\n",
      "[11] loss: 0.073\n",
      "[12] loss: 0.068\n",
      "[13] loss: 0.065\n",
      "[14] loss: 0.061\n",
      "[15] loss: 0.058\n",
      "[16] loss: 0.050\n",
      "[17] loss: 0.051\n",
      "[18] loss: 0.046\n",
      "[19] loss: 0.046\n",
      "[20] loss: 0.042\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 8\n",
      "[1] loss: 0.864\n",
      "[2] loss: 0.708\n",
      "[3] loss: 1.310\n",
      "[4] loss: 2.125\n",
      "[5] loss: 2.302\n",
      "[6] loss: 2.385\n",
      "[7] loss: 2.326\n",
      "[8] loss: 2.320\n",
      "[9] loss: 2.314\n",
      "[10] loss: 2.312\n",
      "[11] loss: 2.312\n",
      "[12] loss: 2.311\n",
      "[13] loss: 2.311\n",
      "[14] loss: 2.311\n",
      "[15] loss: 2.311\n",
      "[16] loss: 2.310\n",
      "[17] loss: 2.311\n",
      "[18] loss: 2.311\n",
      "[19] loss: 2.310\n",
      "[20] loss: 2.311\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 8\n",
      "[1] loss: 0.724\n",
      "[2] loss: 0.285\n",
      "[3] loss: 0.205\n",
      "[4] loss: 0.163\n",
      "[5] loss: 0.134\n",
      "[6] loss: 0.118\n",
      "[7] loss: 0.103\n",
      "[8] loss: 0.101\n",
      "[9] loss: 0.089\n",
      "[10] loss: 0.083\n",
      "[11] loss: 0.077\n",
      "[12] loss: 0.071\n",
      "[13] loss: 0.065\n",
      "[14] loss: 0.072\n",
      "[15] loss: 0.065\n",
      "[16] loss: 0.064\n",
      "[17] loss: 0.063\n",
      "[18] loss: 0.057\n",
      "[19] loss: 0.052\n",
      "[20] loss: 0.054\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 9\n",
      "[1] loss: 0.553\n",
      "[2] loss: 0.253\n",
      "[3] loss: 0.199\n",
      "[4] loss: 0.170\n",
      "[5] loss: 0.154\n",
      "[6] loss: 0.136\n",
      "[7] loss: 0.125\n",
      "[8] loss: 0.115\n",
      "[9] loss: 0.108\n",
      "[10] loss: 0.100\n",
      "[11] loss: 0.095\n",
      "[12] loss: 0.092\n",
      "[13] loss: 0.087\n",
      "[14] loss: 0.082\n",
      "[15] loss: 0.077\n",
      "[16] loss: 0.073\n",
      "[17] loss: 0.072\n",
      "[18] loss: 0.068\n",
      "[19] loss: 0.066\n",
      "[20] loss: 0.063\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 9\n",
      "[1] loss: 0.645\n",
      "[2] loss: 0.315\n",
      "[3] loss: 0.234\n",
      "[4] loss: 0.186\n",
      "[5] loss: 0.156\n",
      "[6] loss: 0.133\n",
      "[7] loss: 0.120\n",
      "[8] loss: 0.109\n",
      "[9] loss: 0.099\n",
      "[10] loss: 0.088\n",
      "[11] loss: 0.081\n",
      "[12] loss: 0.074\n",
      "[13] loss: 0.069\n",
      "[14] loss: 0.065\n",
      "[15] loss: 0.060\n",
      "[16] loss: 0.055\n",
      "[17] loss: 0.052\n",
      "[18] loss: 0.047\n",
      "[19] loss: 0.049\n",
      "[20] loss: 0.044\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 9\n",
      "[1] loss: 1.728\n",
      "[2] loss: 2.014\n",
      "[3] loss: 1.992\n",
      "[4] loss: 2.039\n",
      "[5] loss: 2.020\n",
      "[6] loss: 1.992\n",
      "[7] loss: 2.044\n",
      "[8] loss: 2.165\n",
      "[9] loss: 2.237\n",
      "[10] loss: 2.323\n",
      "[11] loss: 2.317\n",
      "[12] loss: 2.313\n",
      "[13] loss: 2.312\n",
      "[14] loss: 2.310\n",
      "[15] loss: 2.310\n",
      "[16] loss: 2.311\n",
      "[17] loss: 2.311\n",
      "[18] loss: 2.311\n",
      "[19] loss: 2.310\n",
      "[20] loss: 2.310\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 9\n",
      "[1] loss: 0.927\n",
      "[2] loss: 0.371\n",
      "[3] loss: 0.237\n",
      "[4] loss: 0.178\n",
      "[5] loss: 0.148\n",
      "[6] loss: 0.129\n",
      "[7] loss: 0.113\n",
      "[8] loss: 0.105\n",
      "[9] loss: 0.098\n",
      "[10] loss: 0.093\n",
      "[11] loss: 0.089\n",
      "[12] loss: 0.080\n",
      "[13] loss: 0.079\n",
      "[14] loss: 0.073\n",
      "[15] loss: 0.072\n",
      "[16] loss: 0.067\n",
      "[17] loss: 0.063\n",
      "[18] loss: 0.071\n",
      "[19] loss: 0.058\n",
      "[20] loss: 0.057\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 10\n",
      "[1] loss: 0.456\n",
      "[2] loss: 0.213\n",
      "[3] loss: 0.171\n",
      "[4] loss: 0.148\n",
      "[5] loss: 0.133\n",
      "[6] loss: 0.118\n",
      "[7] loss: 0.110\n",
      "[8] loss: 0.099\n",
      "[9] loss: 0.095\n",
      "[10] loss: 0.090\n",
      "[11] loss: 0.084\n",
      "[12] loss: 0.080\n",
      "[13] loss: 0.077\n",
      "[14] loss: 0.073\n",
      "[15] loss: 0.069\n",
      "[16] loss: 0.065\n",
      "[17] loss: 0.062\n",
      "[18] loss: 0.060\n",
      "[19] loss: 0.058\n",
      "[20] loss: 0.056\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 10\n",
      "[1] loss: 0.489\n",
      "[2] loss: 0.259\n",
      "[3] loss: 0.206\n",
      "[4] loss: 0.175\n",
      "[5] loss: 0.147\n",
      "[6] loss: 0.130\n",
      "[7] loss: 0.118\n",
      "[8] loss: 0.103\n",
      "[9] loss: 0.095\n",
      "[10] loss: 0.084\n",
      "[11] loss: 0.079\n",
      "[12] loss: 0.076\n",
      "[13] loss: 0.067\n",
      "[14] loss: 0.063\n",
      "[15] loss: 0.057\n",
      "[16] loss: 0.055\n",
      "[17] loss: 0.053\n",
      "[18] loss: 0.048\n",
      "[19] loss: 0.045\n",
      "[20] loss: 0.042\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 10\n",
      "[1] loss: 0.840\n",
      "[2] loss: 0.665\n",
      "[3] loss: 1.150\n",
      "[4] loss: 2.118\n",
      "[5] loss: 2.194\n",
      "[6] loss: 2.198\n",
      "[7] loss: 2.278\n",
      "[8] loss: 2.284\n",
      "[9] loss: 2.277\n",
      "[10] loss: 2.319\n",
      "[11] loss: 2.314\n",
      "[12] loss: 2.312\n",
      "[13] loss: 2.311\n",
      "[14] loss: 2.311\n",
      "[15] loss: 2.310\n",
      "[16] loss: 2.310\n",
      "[17] loss: 2.311\n",
      "[18] loss: 2.311\n",
      "[19] loss: 2.310\n",
      "[20] loss: 2.310\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 10\n",
      "[1] loss: 0.918\n",
      "[2] loss: 0.321\n",
      "[3] loss: 0.220\n",
      "[4] loss: 0.178\n",
      "[5] loss: 0.142\n",
      "[6] loss: 0.126\n",
      "[7] loss: 0.111\n",
      "[8] loss: 0.103\n",
      "[9] loss: 0.097\n",
      "[10] loss: 0.089\n",
      "[11] loss: 0.082\n",
      "[12] loss: 0.076\n",
      "[13] loss: 0.072\n",
      "[14] loss: 0.074\n",
      "[15] loss: 0.066\n",
      "[16] loss: 0.064\n",
      "[17] loss: 0.061\n",
      "[18] loss: 0.059\n",
      "[19] loss: 0.061\n",
      "[20] loss: 0.059\n",
      "Finished training!\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAHkCAYAAAAnwrYvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzs3Xd8VFX+//HXmUkPPYQm0ksAqYIiFrBhWde+q6jrqsta\ndm3r/my79q9l17JrW9dFce1d1wp2UFFEERGBgIBSAqGHhPRk5vz+mMlkkkwmM8lMJpl5Px8PHrnl\n3HM/GZTPnHPPPcdYaxEREZH2zxHrAERERCQylNRFRETihJK6iIhInFBSFxERiRNK6iIiInFCSV1E\nRCRORC2pG2PSjDFfG2O+N8asMMbcGqCMMcY8aIxZa4xZZoyZEK14RERE4l1SFOuuAI6w1hYbY5KB\nBcaYudbar/zKHAcM9f45EPi396eIiIiEKWotdetR7N1N9v6pP9PNScDT3rJfAV2MMb2jFZOIiEg8\ni+ozdWOM0xizFNgOfGitXVSvyD7AJr/9PO8xERERCVM0u9+x1rqAccaYLsD/jDH7WWuXh1uPMeZC\n4EKAzMzM/XNyciIcqYiISNv17bff7rTWZjdVLqpJvYa1do8xZh5wLOCf1DcD+/rt9/Ueq3/9LGAW\nwMSJE+3ixYujGK2IiEjbYozZEEq5aI5+z/a20DHGpANHA6vqFXsLONc7Cn4yUGitzY9WTCIiIvEs\nmi313sBTxhgnni8PL1tr3zHGXAxgrX0UmAMcD6wFSoHzoxiPiIhIXItaUrfWLgPGBzj+qN+2Bf4Y\nrRhEREQSSas8UxcRkfhXVVVFXl4e5eXlsQ6l3UpLS6Nv374kJyc363oldRERiYi8vDw6duzIgAED\nMMbEOpx2x1rLrl27yMvLY+DAgc2qQ3O/i4hIRJSXl5OVlaWE3kzGGLKyslrU06GkLiIiEaOE3jIt\n/fyU1EVEJG506NABgPXr15Oens64ceMYOXIkF198MW63O8bRRZ+SuoiIxKXBgwezdOlSli1bxsqV\nK3njjTdiHVLUKamLiEhcS0pKYsqUKaxduzbWoUSdRr+LiEjE3fr2ClZuKYponSP7dOLmX44K+7rS\n0lI+/vhjbrvttojG0xYpqYuISFxat24d48aNwxjDSSedxHHHHRfrkKJOSV1ERCKuOS3qSKt5pp5I\n9ExdREQkTiipi4iIxAkldRERiRvFxcUADBgwgOXLl8c4mtanpC4iIhInlNRFRETihJK6iIhInFBS\nFxERiRNK6iIiInFCSV1ERCROKKmLiEhcueOOOxg1ahRjxoxh3LhxLFq0iPvvv5/S0tKI3WPAgAHs\n3Lmz2dfPnz+fE044IWLx1NA0sSIiEjcWLlzIO++8w5IlS0hNTWXnzp1UVlZyxhlncM4555CRkRGT\nuFwuF06nM+r3UUtdRETiRn5+Pt27dyc1NRWA7t278+qrr7JlyxYOP/xwDj/8cAAuueQSJk6cyKhR\no7j55pt91w8YMICbb76ZCRMmMHr0aFatWgXArl27mD59OqNGjWLmzJlYa33XnHzyyey///6MGjWK\nWbNm+Y536NCBP//5z4wdO5aFCxfy3nvvkZOTw4QJE3j99dej8vurpS4iIpE39zrY+kNk6+w1Go77\nW9Ai06dP57bbbmPYsGEcddRRnHHGGVx++eX84x//YN68eXTv3h3wdNF369YNl8vFkUceybJlyxgz\nZgzg+SKwZMkSHnnkEe69914ef/xxbr31Vg455BBuuukm3n33XWbPnu275xNPPEG3bt0oKytj0qRJ\nnHbaaWRlZVFSUsKBBx7IfffdR3l5OUOHDuWTTz5hyJAhnHHGGZH9bLzUUhcRkbjRoUMHvv32W2bN\nmkV2djZnnHEGTz75ZINyL7/8MhMmTGD8+PGsWLGClStX+s6deuqpAOy///6sX78egM8++4xzzjkH\ngF/84hd07drVV/7BBx9k7NixTJ48mU2bNrFmzRoAnE4np512GgCrVq1i4MCBDB06FGOMr65IU0td\nREQir4kWdTQ5nU6mTZvGtGnTGD16NE899VSd8z///DP33nsv33zzDV27duW8886jvLzcd76m697p\ndFJdXR30XvPnz+ejjz5i4cKFZGRkMG3aNF9daWlprfIc3Z9a6iIiEjdWr17taykDLF26lP79+9Ox\nY0f27t0LQFFREZmZmXTu3Jlt27Yxd+7cJus97LDDeP755wGYO3cuBQUFABQWFtK1a1cyMjJYtWoV\nX331VcDrc3JyWL9+PevWrQPghRdeaNHv2Ri11EVEJG4UFxdz2WWXsWfPHpKSkhgyZAizZs3ihRde\n4Nhjj6VPnz7MmzeP8ePHk5OTw7777svBBx/cZL0333wzM2bMYNSoUUyZMoV+/foBcOyxx/Loo48y\nYsQIhg8fzuTJkwNen5aWxqxZs/jFL35BRkYGhx56qO9LRiQZ/xF87cHEiRPt4sWLYx2GiIjUk5ub\ny4gRI2IdRrsX6HM0xnxrrZ3Y1LXqfhcREYkTSuoiIiJxQkldREQkTiipi4iIxAkldRERkTihpC4i\nIhInlNRFRCRuOJ1Oxo0bx9ixY5kwYQJffvklAOvXr8cYw0MPPeQre+mllwacQrY9U1IXEZG4kZ6e\nztKlS/n++++56667uP76633nevTowQMPPEBlZWUMI4wuJXUREYlLRUVFdRZeyc7O5sgjj2wwF3w8\n0TSxIiIScX//+u+s2r0qonXmdMvh2gOuDVqmrKyMcePGUV5eTn5+Pp988kmd89deey3HHXccF1xw\nQURjayuU1EVEJG7UdL8DLFy4kHPPPZfly5f7zg8aNIgDDzzQtzhLvFFSFxGRiGuqRd0aDjroIHbu\n3MmOHTvqHP/LX/7C6aefztSpU2MUWfTombqIiMSlVatW4XK5yMrKqnM8JyeHkSNH8vbbb8cosuhR\nS11EROJGzTN1AGstTz31FE6ns0G5v/71r4wfP761w4s6JXUREYkbLpcr4PEBAwbUebY+duxY3G53\na4XVatT9LiIiEieU1EVEROKEkrqIiEicUFIXERGJE0rqIiIicUJJXUREJE4oqYuISNzo0KFDk2U+\n//xzRo0axbhx4ygrK2uFqFqPkrqIiCSU5557juuvv56lS5eSnp4e63AiSkldRETizvz585k2bRqn\nn346OTk5nH322Vhrefzxx3n55Ze58cYbfceuvvpq9ttvP0aPHs1LL73ku37q1KmcdNJJDBo0iOuu\nu47nnnuOAw44gNGjR7Nu3ToA3n77bQ488EDGjx/PUUcdxbZt2wC44ooruO222wB4//33Oeyww1pl\nshvNKCciIhG39c47qciN7NKrqSNy6PWXv4Rc/rvvvmPFihX06dOHgw8+mC+++IKZM2eyYMECTjjh\nBE4//XRee+01li5dyvfff8/OnTuZNGkShx12GADff/89ubm5dOvWjUGDBjFz5ky+/vprHnjgAR56\n6CHuv/9+DjnkEL766iuMMTz++OPcfffd3Hfffdx1111MmjSJQw89lMsvv5w5c+bgcES/Ha2kLiIi\ncemAAw6gb9++AIwbN47169dzyCGH1CmzYMECZsyYgdPppGfPnkydOpVvvvmGTp06MWnSJHr37g3A\n4MGDmT59OgCjR49m3rx5AOTl5XHGGWeQn59PZWUlAwcOBCAjI4PHHnuMww47jH/+858MHjy4VX5n\nJXUREYm4cFrU0ZKamurbdjqdVFdXN/t6h8Ph23c4HL66LrvsMq666ipOPPFE5s+fzy233OK75ocf\nfiArK4stW7a04LcIj56pi4hIwjr00EN56aWXcLlc7Nixg88++4wDDjgg5OsLCwvZZ599AHjqqad8\nxzds2MB9993Hd999x9y5c1m0aFHEYw9ESV1ERBLWKaecwpgxYxg7dixHHHEEd999N7169Qr5+ltu\nuYVf/epX7L///nTv3h3wLPn6u9/9jnvvvZc+ffowe/ZsZs6cSXl5ebR+DR9jrY36TSJp4sSJdvHi\nxbEOQ0RE6snNzWXEiBGxDqPdC/Q5GmO+tdZObOpatdRFRETihJK6iIhInFBSFxERiRNRS+rGmH2N\nMfOMMSuNMSuMMVcEKDPNGFNojFnq/XNTtOIREZHoa2/jtNqaln5+0XxPvRr4s7V2iTGmI/CtMeZD\na+3KeuU+t9aeEMU4RESkFaSlpbFr1y6ysrIwxsQ6nHbHWsuuXbtIS0trdh1RS+rW2nwg37u91xiT\nC+wD1E/qIiISB/r27UteXh47duyIdSjtVlpamm8WvOZolRnljDEDgPFAoLfvpxhjlgGbgf9nrV3R\nGjGJiEhkJScn+6ZJldiIelI3xnQAXgOutNYW1Tu9BOhnrS02xhwPvAEMDVDHhcCFAP369YtyxCIi\nIu1TVEe/G2OS8ST056y1r9c/b60tstYWe7fnAMnGmO4Bys2y1k601k7Mzs6OZsgiIiLtVjRHvxtg\nNpBrrf1HI2V6ecthjDnAG8+uaMUkIiISz6LZ/X4w8BvgB2PMUu+xvwD9AKy1jwKnA5cYY6qBMuBM\nq/chREREmiWao98XAEHfabDWPgw8HK0YREREEolmlBMREYkTSuoiIiJxQkldREQkTiipi4iIxAkl\ndRERkTihpC4iIhInlNRFRETihJK6iIhInFBSFxERiRNK6iIiInFCSV1iwlqLpvkXEYksJXWJiVUj\nRrLp4otjHUa7VP8LUcVPP/PjQVOoys+PYVQi0hYoqUuzWWup3rmz2deXfPpZBKNJHGuPOJK1h031\n7e956SVcBQUUvfd+DKMSkbZASV2abfcTT7DmkEOp3LAh1qEklOr8fKp37PDtF33wAQDukpJYhSQi\nbYSSujRb8ecLAKjasiXGkSS2am+3e/G8eWz72981VkEkgSmpS7PsnT+f0q++inUYcctWVZE7chR7\nXnst5GvKV6xg95NPUr19exQjE5G2TEldmiXv4ktiHUJccxUXg9vN9rvvCfvaHQ88SOWGDdiqqojE\nsuE357Ll2usiUpeIRJeSukgbV5mXR+XGjQ2O/3jwIdjq6gbHC19/nXXHHMv6GWd5vhwAtrKS3JwR\nlH73HZWbNpGbM4KSRV+HdP/Sb76h8M03W/ZLiEirUFKXiLHWUvjmm7grKhqec7nYds89dQZ4hWvX\nE/8lN2dE3D8zzs0ZwdbbbvPtrzvqaNZNPwZXYWGdz9a1axfb7vpbo/WUL1/OjxMnUfDiixS89DIA\nG2acxbqjpwOwaeZMcnNGULFmje/LQXVBAVXbtmGtpTIvD+t2++orW7oUV2Ehez/+mNyRo6jctCn8\n322/0eRddlnY14lIaJJiHYDEj5IFC9hy7XV0W7mSntdfX+dc6aJF7J79BJVr17Hvfx5tVv3b777b\ns2EtGNPScENS8tUiwJI5eXJE67VVVbiKi0nq2jXg+b1z32tw7McDJ5M2ZkydYwXPPdfkvbbecmuj\nMQD89MsTm6wDYP2ZM+rsF771FmnDh1Py9df0vOYaypcvJ//mWxjwwvM4MjIAzyDKsuXL6TR9uqe3\nobqavR9+5KvDXVnJ3vc/IH3sGFL69aN81SocGRmk9OsXUkytwVoL1dWY5OTaY1VVuMvLcXbsGMPI\n2g/rclHyxRdkHnooppX+301UaqlLxLj37gWgalvDgVrW5WnxReo5b2vZeN55bDzv/IjXm3/DDaw5\naArW5fIdcxWXULFmTdDrypcti3gszbXzoYfJu/QyCp5+hlX7jWb9mTOoWL2a1RP2Z8/r/6Ns2TLW\nHnEkmy+/goIXX2Td9GN81+bmjGDPa6+xesxYtlx9NeumH0Nuzgh+PvkU1k0/hg3n/Iadjz5K2YoV\nbLvrb6w79jg2X30NFT/9zM5H/1OnBwGgfOVKKvPyqN65k8qNG6nesYPSb77xvebnrqwkd8RIfvrl\nL3EVFbHn1Vcp+fJLXEVFnsl8XC6qd+5k93PPse2eeyhbtozSxYsB2PHP+1k1egzuykpPXWVlbLr4\nEn6cdIDv/v69R3s/+qj2vqWldWJ1l5aSmzOCXf99sk78JQsXsmrceFxFRQDsfv55fjzkUCrzNrPj\noYcp/vRT36OUYCrWrcNdWYmrsLDReQsKXnrZ81n/+gzyb7yxQb0Fr7xCZV4eu2bPjkjPmKuoiFWj\n9mPThRdRPG8erj17qN69m8J33vWVqfk7aImd//43ez/6qOmCEVKxdi3u0lIAdjz4IKXffttq9w7G\ntLeuzIkTJ9rF3v/ZWurbj19hzfMPMup31zN6yvERqTNR5OaM8G33vuN2upx2GkVz57L5T1eRMXEi\n/Z99pk754gVfsGnmTDKnTKHfE7N9149YlRv2PXNWLMc4nWHHXJWfT1J2NiYp9A6q5sQZUr2j9gOX\ni5wflmGSk6neuZM1hxzaoJyzc2dchYURvbe0vv7PP8eGs84OqawjMzPonAOpI0dQsdLz36OjUyeS\ne/agYs1aet5wA9tuv71u2eHDqVi9mg5HHUnxRx+T9fuZ7Hrs8YD1po0dQ/n3Db80djzmGDImjGfX\n7CfoetYMdv7rEWxVFanDhpHSvz9dfnU6rsJCtlx9DRmTJ5PSrx97Xn6ZHtdcU9u7FqI+995L5U/r\nsFVVFH3wAb1uuBFbVUXKvn0p/e47XLt2kTFpEs4uXShdsoSKtWtJ6duXyvXrKXj+BQD2/c+jpA4d\nSsW6dVSsXo2rsJAOhx/OjgceBCD7yiso/eoriubMxaSn4yooIH38OGxFJVhLxqRJmNQUtt50MwCd\nTz4ZV2EhxfPm0fHoo6hcv4FOxx9XW99VV7HjH/8AYNDcOZQs+AKTmkKXX/0qor0SxphvrbUTmyyX\nyEn93UevZ9D9b7Du0uM54dL7IlJnovBP6uBJekXvvc/mK6/07furTeoHse/jj7Nq5KiA5UK5Z87y\nH8JKzADVu3ezZsrBdP3Nb+j117+Efc+IJ/URI8FaX1IvW7GC9aed3qCckrpI+zT4o49I6btPxOoL\nNakndPd7WpbnA68qbP5Up+LHEeRbqd+pwtdfb179Nd96m/FFtGLVKgAKnnmGPW+8QcnChU1es/X2\nO8K+T8hqfgffz0aKBRjdHkmD5s4BIKlXLwD2uf/+gOWcnTvT+6676P6HS+qUF5HAIpnQw5HQA+Uc\n6Z5BSo7K0hhHEh+MI7TviNW7C3zbFWvXkjpkSHg38kvq1QUFFLzwAt0vvjjo/Tde8Dvfdv51nkF8\nTbW+C559Nuj5Xf99koo1a+hzZ/OTv8Xzfafo7bcCno/01K85uStZNWIkHaZNo+vZZ5E6cCAjVuV6\nnmlWVOBIS8Mx6z+kjx9P9Y4dbJw5k+ot+QxbVDvRUPbll3tid7koW7aMyg0byL/uenrecAMdph5G\n2ZIlbLn2Onpcdy1dTj6Z3c8+x86HH6bb+edTuXEjxR9/TJcZZ7LnhRcBSBk0iM4nnUTZkiV0PulE\nOh53HMYYrLWeOe3feZfOJ58EbjflK1dSXVBA6pChFL3zNsn9+tHhkEMomjOX5N69SM3JoXrbNjIm\nT6bwf2+QPn4cKfvui3W7qVi1inTvQMOyFSuozs8n87DDqPx5PaWLFpExaSIp/ftjXS4caWlYa3GX\nlFC+bBnp++9P4f/eoGjOHMq++45OJ/6SPn//uyfOqipce/ZQungxW/56A1RV0efuv5MyYACVmzbR\nYepUXAUFJPfqRXluLtblJn0/T0+Vq7iY8pUrcaRnkLxPH4zD4et+L1uxgk2/m8ng99/zxGUtRW+/\nTeaUKSR1717735C17P3gQ1L69yMtJwfwPGpypKdj0tPB5aJy0yZ+PunkBv89DHz9NSrWrAk4D0HK\nkMEMeuMNij/7jMxDDsGRkhLwvylXYSEYQ9n3y9j0+9+T1Ls3+9x3H2mjRrJ67DhfuQGvvIxJSuLn\nU06tvcegQQye8y6u4mIcGRkh/xsSDutyYcvLcWRmYqurMUlJ7J0/n7Rhw0jKzvY0FpzOOl3l1lqq\n8/NJ7tMHgLIfllO1aSMdDj8cd3Exzqwsz0yOycnYyipsVSWpAwdGPPbmSOju9/kfvE7Py//K6tNz\nOPn2/0WkzkQRqPt97yefkPeHP/r2/RV/8QWbfufpfs+YfJDvGZR/d/iOf/2LtOHD6XjUUYHvWdNl\nvex7jPcfmLwrrmTv++/T74nZZE6ZEnK8NTFaa6nauJGU/v2DXhPoC0BLuuZrrh32zdc4O3bk51/9\nmvIffgi7nnD0f/45MiZM8AzcMiaiz/vcFRU4UlObLGfdbnC5MMnJlK9aRUq/fr6R8u2FrayEpKSo\nJKDWUPPfXv3uYet2U/r1N2DdpI8ZgyMzMyr3r9q6lb0ffUy3c0IbYyAe6n4PgbPmHyFXdLs4E1Fl\nXl7A4/W/RJbnriQ3ZwSb/vBH32jq+iObG9Tht+2umVylmSNnC555lnXHHEuZd1R59c6dlC5Z0qBc\nZd5m3OXljdaTd9nl5OaMwFVUxO6nn/Zt+2Kurg5Yb8Gzz3rqDfboIkwmI4Ph3y8lZ+UKnNmeFl33\nP/6RjAkTPOcdjoi/VhRKQvfd2/tqWFpOTrtL6AAmJaXdJnTwfAkdsSq3QfewcTjInHwgmQcdFLWE\nDpDcq5cSehS13/8yI8CZlO7ZUFKPuHVHHU356h99+74kYqFq82bf8bLFntdAij/5xHds91NPe4q6\n3azefyIFr7zivbbec+gIKFu6FIDKjZ6JVNb/+gw2nHU2W/+v7ijidUcdRd4fLw1YR9GcOez98ENP\nPevXs/tZz7vjG8+/gNycEZQtXcq2O+9kw1lns9Y78UuNHQ88yOpx4wOOOm6O4d8uZtgXC3CkpmIc\nDoZ9/jn9nphN90u0dr1IIkjopJ7kbTHUvEMtwbnLy4MP3KqXbKs2+U1t6tcy3PPSS0HvU3OdrajA\nXVLC1htvwlVc+2y5Ys1aqryLlpR88UWj9bj27KHghRcafc82N2cE5bmernN3SQkVa9f6VpwLNKlL\nY/fafNWffdsbzj6HKu+UruUrVgCeSVtqXrepasYsbKEa9PZbODIzcaSn1zmeOWVK2G8LiEj7lND/\npzuTvQM/3C2b9CBRrB43nvTx48n+05UhlQ/4ZSmcVrZfN7ytqvRtrz/d8+pXr1tvbVC2autWXHv2\nkJaTw5br/0LxvHkNZmHzV/nzzwBsvfnm0OMKIpTJdfb8742I3Ku+1KFDo1KviLQfCZ7UvdM+KqmH\nrOy779h47m9DKxzgc3XtLQpQsK6alrV/CzvQM2D/ROwuKwNg7bTDARi+7HuK580DPM/NI6Vq82ZM\nWhpJWVnNriO/3hS6IiKRktDd78k1LfUWTk8oHvUH12z+01UNytTMhBWM9U7H6d9SL/k6+Ipim6/8\nU539vEv+4NsufCNyLeO1Rx7FmoMPiVh9zZV58MEMX1I7LaWp1+UuIokpoZO6s+Y5YxOjraVp1QUF\n7Px3w4VacnNGsPeTec1bgMXv72Xz5Vc0Wdz3ZYDgz9ojoXpnbCcs6nXjDTgyMsi+yvPFSaOJRQQS\nPKn7WupK6i225qAplC5aFPDcrsceC/o6WAPeLwBNvdpW36oxY8Mq3xLrZ5zVavfylzZypGfD+xl1\nv/D35Kxc4UvuIpLYEvqZenJSMpWgpB5t1rJr1mMhFy989TW6/vrXJPfuHcWgWiaao9gb0/+Zp0nu\n35+9739QZ7Kc9vzOtIhEVkIndV/3u1VSj6aypUtJHdFwRrdgtt99DxkHHNB0wQTR69ZbyZg0CYBu\nvzknxtGISFuV2End4Vm+07SzqXITQenixb71rAW6nvHrWIcgIu1AQvfbqaXeivTFKWz7Phb6IwsR\nEVBL3bPhVsKR1pc5ZQolX37Z4Hife++levt2Ohwa+1fnRKR9Seyk7mupK6lHXYIORux0wgkUvfNO\nwHNZF11UJ6lnX3kFnU89leQePXzH+vz9bwFXkBMRCSShk7rDO2rYqPs96ip+/LHpQnGo2/nnNZrU\n00fvR9YlF5N54IGkDBxEcs8eDcp0PumkaIcoInEkoZ+pJzmduKHuWp7SKgZ/+EGsQ4iq5H08y1oG\na2WbtDR6XHEFmZMnB0zoIiLhSuik7jQOrNHod4DS776jevfugOdcxSXk33JLRO9n/Nbf7v23uyJa\nd1vQ8ZhjGLEqF2eHDo2W0fvlIhJpCf2vSk1ST9Rn6u6SEvbOnw/Ahhlnsf6MMwOW2/3EE+x5Mfhy\nqf66XXBBk2X8k12Xk08Oue42SwlaRNqAhP6XyOEwuBO4pZ5/443kXXwJFT95lh9tbJa0ijVrwqs4\nlEFxEVzfO33i/iGVy5x6WMQXPkkZMACAIR9/VDem8eN82yYtrcF1/Z5+KqJxiIhAgg+UM8Z4WuoJ\n+kpb5foNALhLS33H8i6/gt533I6zY0cK33oLjGHvhx+GV3EIAw9NUhImJaXOIixNGfjmG5R++y3b\nbvs/37E+991L51/8gtycpmes6/vPf5J/yy0UvfU2AJmHHUrJZ58HvcbZvTuuIIu3DHr3HVxFRSR1\n7crAt97EVlWRlJ1dZwT78G++xrVnD8ULviBj0iRMcrKeoYtIVCR0UgdwO0jYgXI2wC++94MPSB83\njqwLzmfLNdc2q15Hh45NljEOB0M//yyspJ42fDhpw4f7kvqIVbXLuCb17En1tm3B48rI8K3L3vtv\nd9Hl5JMDfhlI6tGD6u3bARi24POgXxiM00lS166e+IYNC1wmOZmk7Gy6nBIHjxlEpE1L+KRuDZhE\nzeo16q+KGuIyqfs88ACFb71F8ccf1zmePi601dKcnTuHVK6+vv96mLIffqh7sJmPUFKHDvU9Xuj7\n70fAQscjDmfXk09S9O6cxmN45BHfCHcRkbYioZ+pg7eRnqivqXvzYNn33zfr8k7HTKfP3/8WoN4m\nEqzT2eBQ+rhxAQoG1vHII+lx5ZXh3bM+b/Fet9zs2TCGjocfTscjDgcg67zzGPjKy41ennnIwaQN\nD9wyFxGJlYRP6ok8UK5GxarVdQ+E0FDP9iZVE6BVb91uHBkZjV476O23GhwzyclB75fcr1/Q89b7\nd1h/UNqQzz6ts599+eVkHnwwHY8+2nPAO6gvfcKEoPUDZB56aJNlRERiKeGTug2tpzkuuYuLAXDU\nf5c6hO+20VNqAAAgAElEQVQ43S++CGg8GaeNHdPotSkDBzY41lRS7Xb2WcED8ibnIR/VDurrcfXV\ndQasgWdSmH6zH8fZIdOzv+++AHQ69tjg9QP9HptF7zvvxNmtGyaCo/dFRCIl4f9lSuT31H2vsNX7\n/d2lJSHXYVJSGPDySxQvWEDVho0UvvkmyT170vehh/hx4qTA1wRo3Wdfdikdpx+NLStjwzm/8R3v\n/8zTvnXEg6p5jc7vffGUwYMA6HLGGZQtWxbwsuRevRj+3ZKAr53V6PH//ux7n7/LqafQ5dRTmo5H\nRCQGlNTV/d7wS02YH0f6mDGkjxmDu6KCzqecQtqIpl8vq88kJZE+alSD4yEldMDZPQvXnj0Y/+f1\n3t+r9623BL3W0cS761kzZ5I1c2ZIcYiIxFLCd7+7DQn7Sluj3G7cJY231rMuuTjgcUdqKpmTDwxa\nddezmuhGp3nriPd7/HHP+/WdO5Nx0OSwrxcRiQcJn9StkjrW5aqzX/7jalbvP7HR8il99w2p3o7H\nNf2cOpDmrCOe3KsXXU47DQBHinde+QT/exWRxKOkru53Cp55ps5++cqVQcubpIavpAXS8fDDmx1T\nS2RM8nwh0XvkIpJolNSNUYsuXM7QhmJ0PvHElt0mK6tZ13W74AIGf/C+3iMXkYSjgXI1LXVrQ55J\nLe418SXHpAR/pzwShi78EkdKSrOuNQ4HKU281y4iEo8SPqm7wZPE3K6QW6Dxrjo/P+j5UEekBxZa\nt0jNfOoiIhI6db8bAAOu0BcWSWRDPp2vhCsi0kYpqRswFnBVxDqU9qGFgwo7n3RShAIREZH6opbU\njTH7GmPmGWNWGmNWGGOuCFDGGGMeNMasNcYsM8Y0PQF3hPkGyrmqWvvW7VMLknrvO24nfWxoK7iJ\niEj4otlSrwb+bK0dCUwG/miMGVmvzHHAUO+fC4F/RzGegHyTz6j7PTRhJvWUwYNrL612BSkpIiIt\nFbWkbq3Nt9Yu8W7vBXKB+i8OnwQ8bT2+AroYY3pHK6aAcfq635XUm9LxmGNI6h3eX8/gd9+h2+8u\nANAiKCIiUdYq/8oaYwYA44FF9U7tA2zy28/zHgs+/DqCapO6ut+b0veB+5t1Xfall+Ls2InOJ7Xs\nvXUREQku6gPljDEdgNeAK621Rc2s40JjzGJjzOIdO3ZEND53zbvp1RooFy2O9HS6X3yRWuoiIlEW\n1aRujEnGk9Cfs9a+HqDIZsB/IvG+3mN1WGtnWWsnWmsnZmdnRzRGX0vd6nmviIi0b9Ec/W6A2UCu\ntfYfjRR7CzjXOwp+MlBorW21rneoWdDFeCafSSDuCvVMiIjEm2j2hx4M/Ab4wRiz1HvsL0A/AGvt\no8Ac4HhgLVAKnB/FeAKyxnha6u7q1r51TNjqairWriWpe/dYhyIiIhEWtaRurV0ABJ1M3VprgT9G\nK4ZQ+F5pS5Ckvv2f/2T37Cfo/8zTsQ5FREQiTDPKGeP55pEgSb38+2UAVO/cGeNIREQk0pTUfS31\nxHqm3tLpXkVEpO1RUsckZFK3SuoiInFHSb3mlbYE6X73UU4XEYk7CZ/UfZPPJEpSr/l967XUG5v+\ntdPxx5E6fHi0oxIRkQhI+Cm+ErWlXrW17nQAJjk5YLmMgw6iz913g9vdGmGJiEgLJHxL3bf0qk2s\npLXjvrrzAfW89prABa3FJCVhUlJaISoREWkJJfVEa6k3MkDO2bUbHadPb+VgREQkkhI+qbuNwViT\nMEm9dPHiRs/1ffCBhgc1oE5EpN1I+KTu635PkKTeFEfnznUP6NU3EZF2Q0m9Zka5Hz+IdSix5R0U\n3+eO2+sczjxocgyCERGR5lBSr1nQZfW7sQ4lppydOgHg6NChzvGU/v1jEY6IiDSDknrNNLEJLnXw\nYABMamqMIxERkeZK+KTurmmpCwDp48bFOgQREWkmJXWHA4cbGDsj1qG0CcYYsi68MNZhiIhIMyR8\nUq92OHC4DSSnxzqUNsOkeiaaybrk4hhHIiIi4Uj4pO5yGhwu4vaVtrzLr2D9jLPCuiZj/HjPzwkT\nohGSiIhEScLP/e52GE/3e5zObb73g/Bf1cucMoVhXy3E2aVLFCISEZFoSfiWuu899ThtqftzV1aG\nXFYJXUSk/Un4pE7N6HfrinUkEWf9eh+stex9//2A5TKnHtZaIYmISBQlfPe79c6kxvbcmMYRDeXL\nlvm2i955ly1XN1yJbdiir3DWnxpWRETapYRvqVvjwFgL25bHOpSIs9W1jxQq1q4NWEYJXUQkfiR8\nUqdm6dV45LcYi0lK+E4ZEZG4l/BJvd/WUlKrDO74e6SO9V9hzZnwf9UiInEv4f+lH75xLwBVxXHY\nkvXL6caYxsuJiEhciMNM1gJuFzicsY4iIgpefJGqbdt8+649hTGMRkREWoOSuj9XVdwk9a233Fpn\nf/dTT8UoEhERaS0J3/2+OTsD8I4pc1fFNhgREZEWSPik/s7U/p4Ni6elLiIi0k4lfFJ3OzwfgXWb\nhJgq1l/3yy+LdQgiIhJBSuoOz6hwm4At9ew//CHWIYiISAQlfFK33pY6bqNn6iIi0q4lfFL3db9b\niJcZaOpMOiMiIgkj4ZO6dfo9U4+T7ve9H30U6xBERCQGEj6p17TUiaNX2qq3bY91CCIiEgNK6k6/\n7vc4aamHwqSnxzoEERGJsIRP6jUzyCXaK22O1NRYhyAiIhGW8End7fQudBJPLfVQBsppgRcRkbij\npF6npR4nST0EHadPj3UIIiISYQmf1K3/K22uOOl+b+LVvMwpB9HrxhtaKRgREWktSurO+Bv9Xrlh\nQ9Dzjo6dMElaoE9EJN4oqft3v8+/K8bRRIZ1u4Ofj5ceCRERqUNJ3b/7Pf/72AYTIXtefCnWIYiI\nSAwoqfsmn9FocBERad+U1J013e8xDqQ1aWp4EZG4lPBJHbXURUQkTiR8Uq9pqVcUJsHAw2IcTSvR\nKm4iInFJSd2b1AvXZ0DnfjGORkREpPkSPqn7ut8Blj4buzhERERaKOGTuknAOdC7nXN2rEMQEZEo\nSPiknmScsQ6h1Tk6dox1CCIiEgUJn9RT/aZLtQnzTD3xeidERBJBwid1p8Ovpd59WOwCaVUa/S4i\nEo8SPqk7jN9HsOaj2AUiIiLSQkrq7fCZuruigtycEex57bWwrksZMjhKEYmISFuQ8End6ddSt+72\n8azZtXs3ADseejis60xyimdDk8+IiMSlhE/q/t3vhevTYxiJiIhIyyip+3W/t7sGbJgB+97Jb3e/\nqIiIhCLhk7p/93v76HwHwpwwZ8gnHzPonbfB7/U9ERGJP0rq7XCgXLiS+/QhdcgQUvp53sN3ZGbG\nOCIREYmGhG+61Xmlrb0Jsxu992230un440kdMiRKAYmISCy144wWGXWeqQO4qmIWS8gCdL9XrFlD\n6TffBL3MkZFBxyMOj1ZUIiISY1FL6saYJ4wx240xyxs5P80YU2iMWer9c1O0YgnG6TCs2se7nWzB\numMRRov99MsT2fCbc2MdhoiIxFA0W+pPAsc2UeZza+0475/bohhLoxzGydNHelrrVWVOcLtiEUaz\nVG/fTtXWrXWOWY1sFxFJWCEldWPMYGNMqnd7mjHmcmNMl2DXWGs/A3ZHIMaochonyd48vuP7Tu2u\npb52Wt3u9N1PPBGjSEREJNZCbam/BriMMUOAWcC+wPMRuP8UY8wyY8xcY8yoxgoZYy40xiw2xize\nsWNHBG5by2mcuP0/BdseWuqNv9K2/Z57WzEOERFpS0JN6m5rbTVwCvCQtfZqoHcL770E6GetHQM8\nBLzRWEFr7Sxr7URr7cTs7OwW3rYup3FQZ3bYdtH9HnoXu7Nz5yjGISIibUmoSb3KGDMD+C3wjvdY\ncktubK0tstYWe7fnAMnGmO4tqbM5HA5n3aSeF3wEeZsQxnPzYYu+imIgIiLSloSa1M8HDgLusNb+\nbIwZCDzTkhsbY3oZ77ylxpgDvLHsakmdzZFkHFj/pO5Mae0QwqfBcCIiEkBIk89Ya1cClwMYY7oC\nHa21fw92jTHmBWAa0N0YkwfcjLd1b619FDgduMQYUw2UAWfaGAzddjqcdTuz85fC4Db+Lne9j8lV\nXByjQEREpC0JKakbY+YDJ3rLfwtsN8Z8Ya29qrFrrLUzgtVprX0YCG/t0ChwOpx1x511bOlQgeiw\n1rLl2mvpeuYMknv1rHPOVVAQo6hERKQtCXWa2M7W2iJjzEzgaWvtzcaYZdEMrLUkOZxszvI70EYH\nyrmLiih6622K3nqbDkceWfdke57qVkREIibUbJBkjOkN/JragXJxIck4qUz2a6q31ffU/aaGLf74\n48ZOiYhIAgs1qd8GvA+ss9Z+Y4wZBKyJXlitx+mo9xG01ffUg2Xu+r+DiIgkpFAHyr0CvOK3/xNw\nWrSCak1JjnpLr7bR7vegSV1NdRERIfRpYvsaY/7nXaBluzHmNWNM32gH1xrqJ3V3ZWWMImmKkrqI\niAQXar/tf4G3gD7eP297j7V7Dbrfd7bNpwpB87beWxcREUJP6tnW2v9aa6u9f54EIjtfa4w06H7/\nZnZsAmmBbXfeFfB430ceaeVIREQklkJN6ruMMecYY5zeP+cQg9nfoiHJ1Evqwbq5YyhYY3zvBx8E\nPN7xiDY+iY6IiERUqEn9Ajyvs20F8vHMBndelGJqVUnOekm9zfZkhxmYnrOLiCSckJK6tXaDtfZE\na222tbaHtfZk4nT0e5vN6eGq/2VFRETiXktecG50itj2JLn+M/U2mNVdxcVsPPe3YV1j9O66iEjC\nCXWa2EDion/XWT+ptzH5N95ExZo1lK9cGd6FaqmLiCScliT1NtimDV+D7veMHjGKJLA9r7zSdKEA\net96S2QDERGRNi9oUjfG7CVw8jZAelQiamXJjvofQXy0cDMmTYp1CCIi0sqCJnVrbcfWCiRWnI56\nTxHcVbEJJNLa+GMFERGJvIQfTZVUf0CZqzo2gUSYcSb8X62ISMJJ+H/56yd162qjC7qESwPlREQS\nTsIndYc3qZd2zPAciJuWupK6iEiiSfikXjP6fdFxB3oOVFeA2x3DiCJEz9RFRBJOwid1p3c6Vesd\nL+d2GezWZTGMKDL0TF1EJPEk/L/8Nc/U9121EYCf5vRg539fjmVIEaHudxGRxJPwSd3pbdF237zT\nd6zw4y9jFU7kKKmLiCQcJXVv93t1sn8SjIPJ8jT3u4hIwkn4f/lrBsq9ekxP37F4mNTeaOlVEZGE\nk/BJHeNpla9z/lh7zFUeo2BERESaL+GTeucUz0y4nZL28R2r2lEYq3BapOdNN8Y6BBERiaGET+oO\nhwN3RTYZybWrs1m3p+t61+zZVPz0c6xCC1v6mLGxDkFERGIo4ZO6h4Nq6k4P6y4tZfs997LhnHNi\nFBPsfvrpoOf3uf+fdQ/oMbqISEJTUgcMTqrrjXi3bs++uzw2z9eLP/2UbXfeFZN7i4hI+6SkDjjq\nt9SNpea1NltZiW3laWMr1q1j00UXN1nOJNVdOVcj3kVEEpuSOmCMg2rcfvuA9bbcq6vZdvvtrRqP\nq6gopHIdpk2j2wUX0Oeee3BmZZEyYAAp/fvT6fjjohyhiIi0RUlNF4l/DuOkqk5LHTZffoVvt+Dl\nV+h1002tF5ANbfIbk5REz2uuBqDzL08AYPD770UtLBERadvUUsfzTN1tahOpdRlKFi6sPd/a3doh\nJnURERF/SuqAwYEr2NSwrZjUK376iQ1nx27EvYiItF9K6gA4sMbVdLFWUPbdd7EOQURE2ikldTwt\n9cKMIK1xjSoXEZF2QAPlAGMduE2Q19YilNRtVRXVuwtI7lk7e11uzgg6n3oqfe68w1uo6efp2Vde\nQVKPnk2WExGRxKKWOoCBakqCnI9MUt96222snToVd2lpneOFr7/u267avr3JejodfzxdTj0lIjGJ\niEj8UFIHypOXU8muRs/bsjKstbgrKihfubLZ99n70cdABGap0+h4EREJQEndT9bFjc/iVvL552z8\n7Xn8fOppIbWmA3GXlQFQtmQJe954I2CZ6h07mqyntWe4ExGR9kFJ3U/WJRc1es5dUkLZ0qWe7eIg\nXfVBWG8LPe/Sy8i/7vqAZfa88GKT9SRlZTXr/iIiEt+U1IHKXYcA4A71XfUYDYbvdPzx5KxYjrNT\np9gEICIibZpGvwPWleH5GaRM/k03+7YjNcOcq7g4rPL7/OO+iNxXRETik1rq4F2VDWyQtO4OcZGV\ncFSsWVNnf+vtdzRaNvvPV0X8/iIiEl+U1IHU7A8BWF3wY6ved8OMs3zbFevWUfDss42W7f7737dG\nSCIi0o4pqfvZWb4zZvfW9LAiItJSSup+gnW/1xGFaWOLPvgg4nWKiEhiUVKvI7Rkvfejj3zbtqoq\naNmCF19kz2uvBy0jIiISCUrqQGfnvgB0SuscUvnt99wLgKu4hFWjx7DzsccaLbv1llvJ/+tfWx6k\niIhIE5TUgXEdZgCQkZQR1nXuEs8rabufehrrduMuad6kNCIiIpGgpA4kOzyv61fbaoYtXhz6hS7P\nGuzu4mK233sfq/ef6FusZe9HH5GbM8JX1DYxX3v5isbnlM+6pPHpa0VERGpo8hnA6XACUO1y4eyQ\nGdI12+/7ByVffgl4pn8tfPNNANylpTgyMih859065UsWLAhan2tX4wvKJHXTtLAiItI0JXVqW+pV\n3pZ3p+GpFK2uCHrNriDP0YEGK6lt+v2FzY4vbeSIpguJiEjCU/c7kOT0tNQrXdUA9D62W7Pryrvi\nSs9GhJZHHbrwSzL23z8idYmISHxTUqe2pV7p9iR1x9hT6Do0vEFvNd3nZd9+6zlgI7M8alLXrhGp\nR0RE4p+SOpDk8HwMVdWepM5Bl7aooV2+alWTA+NEREQiTc/UgaSaZ+puzzN1jCEl09Xs+jZdeBGu\ngoIWxTRozhxsZfDn+iIiIv6U1IFkZ01Sr/Yd6za8mO3fd6Q5i6dXb9/e4phSBw1scR0iIpJY1P0O\nJHtfadtWss13zDig54TIL7cqIiISLUrqQLJ39Pu/l98b40hERESaT0md2slnRERE2rOoJXVjzBPG\nmO3GmOWNnDfGmAeNMWuNMcuMMROiFUtTXH7P0v2lZ1W2ciQiIiLNF82W+pPAsUHOHwcM9f65EPh3\nFGMJau7yLQGPp2dV0WN8YStHIyIi0jxRS+rW2s+A3UGKnAQ8bT2+AroYY3pHK55gThm/T6PnHEl6\n31xERNqHWD5T3wfY5Lef5z3WgDHmQmPMYmPM4h07dkQ8kN6dNGubiIi0f+1ioJy1dpa1dqK1dmJ2\ndnbE6++V0afhwRP+GfH7iIiIRFMsk/pmYF+//b7eY63OYQJMMDPxAgA69Clv5WhERESaJ5ZJ/S3g\nXO8o+MlAobU2PxaBBEzqXsnpbkacGXggnYiISFsStWlijTEvANOA7saYPOBmIBnAWvsoMAc4HlgL\nlALnRyuWpjhC+WpjTMSWU60v48ADKV20KCp1i4hI4ohaUrfWzmjivAX+GK37h8MZpKVeo///XcSG\nGx6Nyv0zJk5UUhcRkRZrFwPlos2EkNTNZ/8XlXsPXfglmYccHJW6RUQksSipAw4D7upMeqUNrnvi\n1Mejfu+krl1JHToUAJOSAkDm1MOifl8REYk/WnoVcDoMjqQStpavq3siMyui9+n/wvNUrP6RvZ98\nTPYf/oCjQwfvGW9PgdPJ8CXf+pK7iIhIOJTUCTL6PSnNt+lMcQPQYepUij/9tE6xIZ98zNojjmzy\nPhnjx5Mxfjxdzzyj3hnPADxjDI6MjNADFxER8aOk7lW1ZzzOzJ/rHux3kG8zpYOLgc/PJnW/ib6W\ndG7OCACS+wSYvCYcNaPqQxqGLyIiEpiyCFDpcmNtCph6q7UZAwdd6ttNq17R7K7xff5xX6PnHKmp\nAHQ9++xm1S0iIgJqqQPgcltwJ2NMgKVWM/yeq+d/3+x7dDr++EbPmZQUclau8HyJEBERaSa11IGh\nPTpgbQrGWYWtP8FMdk7ttnU3uDapT9MLy/V95JEmyxiHI6RX60RERBqjljqeAWoZSem4sFS6K0l1\nptaeHHp07faW7+pcN/jDD3B27gzAgNdeJalLF6p3F7D+V7+qUy599H5Ri11ERKSGWupeDs8MtpRX\n11vAxZlcu719ZZ1TKfvui7NTJwDSR40ieZ99SB+9HwPffJOOxx3rK9eg9S8iIhIFSupeTjyt87Lq\nshbXlTZ8GH3/6bd0q3K6iIi0AiV1L4dppKVe3y2dYeVbIdU5aO4cuv/hDyT1iPwa8CIiIvUpqXs5\ncALgDjAYroGlz4VUZ+rAgWRffpkGwImISKtQUvdypWwE4MMNHzZd+Mf3ohyNiIhI+JTUvVxJeQB8\nueXLhiedmotdRETaPiV1L+Ptfq+21Q1PHvu3Vo5GREQkfErqXsb7Slu1O0BSn3hBK0cjIiISPiV1\nr24VJwJw4uATG54MNNBN756LiEgbo6Tu9eMWz0+HCfEjcQWYJ15ERCSGlNS9rPXMmFvlqgpc4Ldv\n191f+3GUIxIREQmPknoNb1KvdDfSAh94WN39F2fAlqVRDkpERCR0SupeR+f0AYK01AFSO9XdnzUV\n1n8RxahERERCp6Tu1b1jOlhH4y11gN+80fDY7p+iF5SIiEgYlNS9UpM8H0VxZXHjhXqPhe7D6h3U\nKHgREWkblNS9UpIcYNy8uPrFxgs5k+DcN+se06ttIiLSRiipe6U4Q/woMrLq7r93PbhDWARGREQk\nypTUvWq635tUfx74qhLYsCDyAYmIiIRJSd3L4QhxeVRj4JcP1D2mLngREWkDlNS93lmWH3rhIUfV\n3V/2cmSDERERaQYldS9rLdad1LyLlz4b2WBERESaQUndKzM1ierikaTaXiEUzo5+QCIiImFqZtM0\n/mSkODF2LxVma9OFk1KjH5CIiEiY1FL3ykhxkpT5c+gXpHaOXjAiIiLNoKTuNaxnR9/2jtIdTV9w\nzqt196u1FKuIiMSWkrrXRVMH+7Zv+OKGEK6o9wqcO8hCMCIiIq1ASd0rLclBdbFnXveg87/X6Dao\n7v7mJVGISkREJHRK6l5JTgc1rW+XdTV9QWa96WKfOiHyQYmIiIRBSd2Pw3g+jhW7VjSvgmBrsYuI\niESZkroflzvEqWJr/GFR3f2510YuGBERkTApqfuzYSb1Hjl19xfPhtLdkYtHREQkDErqfqoKpoR/\n0XH31N3/98GRCUZERCRMSup+XKWDmy7UlL1boLyo5fWIiIiESUm9Ed9t/y7EkgGWXf3k9ojGIiIi\nEgol9UacO/fc0Ar2ndjwWEkIM9KJiIhEmJJ6S+2zf8NjNe+5a9CciIi0IiX1aFj5Jix9Ae4eCMte\njnU0IiKSIJTU63FV9IhMRW9c7Pn586eRqU9ERKQJSur1udIjW1+AcXQiIiLRoKReT8WOo3zbVZGY\n9nXps7D525bXIyIi0gQldT/nHzwAd0Vv3/7BL0ZoIhlNHysiIq1ASd1PstOBtbUfSVl1WWgXXvRZ\nEwXCnH5WRESkGZTUG2jGR9J7LNxUEPlQREREwqCk7mfmoQPB1v1I1u1ZR2lVadMXOxyNJ/aiLXqu\nLiIiUaek7qdHx7QGSf3kN0/minlXhFaBo5GPsygPHjsCCjfXHst9B/Zua2akIiIiDSmpN9DwI1mU\nvyhAuWbYm+/5WVUOL50NT58UmXpFRERQUg+g4aA2G87L5n/8BrKGBj739Mmw+Amwbs9+wc/NiE9E\nRCQwJfUGWjhSPXsYnPNa4HOVe+GdP8HOHz37VjPTiIhI5CipB+CuzGpZBaaJLwazpnp+uirqHq+u\n9HTNi4iINIOSej0HDuxGdenAllXidoVe9r+/gFfO82z/6wC4o2fL7i0iIglLSb2emYcOCnj8g/Uf\nsKN0B8/nPt90JSaMj3XDAljxP88rb3rGLiIiLZAU6wDamgMHdaO6aD9Suiyuc/zexffSM6MnS3cs\n5ZB9DqFfp36NV9K1P0y/Az74a+g3fuyIZkYsIiLiEdWWujHmWGPMamPMWmPMdQHOTzPGFBpjlnr/\n3BTNeEKR4nTgKslpcDy/JJ+iyiIA38+gplwKvcZEOjwREZFGRS2pG2OcwL+A44CRwAxjzMgART+3\n1o7z/rktWvGEKtnp+UhK11/c4NxPhT8BcNfXd4VW2W/fal4QFXuhdHfzrhURkYQVzZb6AcBaa+1P\n1tpK4EWgzc+24nR4Rq67ygY0WmZH6Y7QKkvv2rwg7uoLdw+EeXd69t0uKNjQvLpERCRhRDOp7wNs\n8tvP8x6rb4oxZpkxZq4xZlQU44kYd83kMaHoFOhXDtGnf/f8nH8XPDBGiV1ERIKK9UC5JUA/a22x\nMeZ44A2gwXRsxpgLgQsB+vULMkCtldhwJo25aqXn58618PD+4d/syRNg/eee7eJt4KqELUthzK/C\nr0tEROJaNFvqm4F9/fb7eo/5WGuLrLXF3u05QLIxpnv9iqy1s6y1E621E7Ozs6MYcl17c+8MeNxN\nGC31Gk1NSNOYmoQOnhno/nUgvD6zeXWJiEhci2ZS/wYYaowZaIxJAc4E6owcM8b0MsaT7YwxB3jj\n2RXFmEIyICvDuxX44wmr+71GaqfmB1TjielgG5nYpmJv3VXgAqksgbnXQmUIS8mKiEi7E7Wkbq2t\nBi4F3gdygZettSuMMRcbY2qGlp8OLDfGfA88CJxpw+rbjo5JA7oFPb+7fDfXfHpNeMm9QzZc9Dlc\nux7+vBqGHduyIO8fA/ePrt1/7Ej4Z6CXC/ws/BcsehS++lfL7i0iIm1SVN9Tt9bOsdYOs9YOttbe\n4T32qLX2Ue/2w9baUdbasdbaydbaL6MZT6gcfl3lVYWB3zWfu34uRRUhvK/ur/cYz4j4jr3grJfg\nlsLmB7lnA+zZCLd2hQfGwc7V3uN+YxOrK2HZK7ULx9RMX+uqbljfK+d7vhiIiEi7FeuBcm1SZmrt\nx8CvxXgAACAASURBVFK+5SySOy+LYTRNsO6608vev1/DMikZkJwBa96vvaa+Fa/XbldXgDOl+eMA\nREQkJjT3ewB/nj6szn713oYzzAFct+A6TnnzFIori5t/szFnen72Owj6TGh+PcG8eBY8czJs+c6z\nb91QshPcAZJ7RTHc3gP+1r+2hb9nE3zzeHRiExGRiFFSDyAzNYkP/nSYb78s79yA5b7Y/AVr96zl\ninlXNP9mh/0/6LkfnPk8zHih+fWEo3gr3DMYnjjGs7/Q7xn77nWenxWFsH4BlOyCp06Ad//s2a5x\nS2f4MOaz+oqIiB91vzdiWM+OfnvBv/v8sPOH5t+o+1C45Iva/UHT4Kf5za8vFNtWeH7mfQ3/mQr5\nS2vP/af2ywxPnVD3ul1rITOr9tn8Fw/A0TGf2VdERLzUUg9Rybo/tc6NJnnfQZ96bfTuUdMND3UT\nelNWv+v56aqKbDwiIhIRSuohclf2bPRcWXVZ5G404peeUfGH/wWub+K989b2xQNQvAPcAUbPi4hI\nzCmph6F003mNnpv781xuXXhrZG+Y2qHu/kWfwbDjInuPcN07BMJ9lU9ERFqFknoQT5w3sc6+qziH\n0g2/C1j2ms+u4dUfX418EL3H+W2PhZMfifw9wvWPEbXbbpen9S4iIjGnpB7EETkNu9yDLckaFRe8\nD799B65c7tnP6AZ//rH2/JUtGKQXCbd187TeSxqZ3XfPxtpX40REJKqU1MNlg78wMPqp0ZF9xp6c\nBgMPhS5+a+N07AknPQK/fRu69IvMvPItVbyt4bG8bz1T2X77ZMNzfx8In9/n2d65tnZEvoiINJuS\nehMunjq43hFD8dqrg16zu3x39AKqMf5sGOh9/WxSvVXbbimE6Xd4tjv0in4sULv2u7/Niz0/37my\n4bmy3fCx93W4h/eHf0+B0lb43ERE4piSehOuPXZ4g2O2qnMMIgniyJvgxl1wyULPT4Apl8I5r8Of\nlrdODCvf8ExIs/Erz0Q1C/8Fc6+pPf/yubD6PXj0UE+5Gv6JfNW7ntb9CzNge27rxC0iEkeU1Jtg\nAs5/HrwL/tjXjuWyTy7jx4Ifg5aLGGPAmQQ9R3p+1hhyJDiTa/dPfRz+ug2o9zsdfy/c4DfY7bqN\ncOj/g79uDT+WJ47xTCn7/l/qHl/5JrxwBmytN4/+3QNrt3evg8ePgNVz4JHJMOcagirc3LB1v3db\n7TP8ir3hx9+UXes8f0RE2iDTBlY6DcvEiRPt4sWLW/Weg/8yB5e77ufUccR1IV276KxFZCRnNF0w\nmkp3Q3K650+NJc949kefXnts4b+gaAscc0ftMVc1vHcdpGTCF/e3Xsz+rsqFTn0825Ul4EiGty6F\nZS95jtWsdrdlKcyaCkOOhgMvhudOg/PnQv8pkYulppchnBX2NnwJ378Iv3xAi+SISLMYY7611k5s\nqpymiQ3Bp1dPY3NBGWfM+qrBueIfb6DDsNsbvXbOz3M4fdjpjZ5vFRkB1oef8JuGxw76Y8NjziT4\nxb2eZB+rpP7MKfC7D6B0Fzw4vuH5WzrDUbd6VpYDWPth7VK0y16Cnz+DwUfAvgeEfs9F/4GOvWHk\niZ4lbPO/hw1fNH1dIP/1zi1wwv1QvgdW/A+M0/OFKiWzeXWKiASglnoYvlm/m189uhCA1N6vYpyl\nlOedS3q//5CU+XPQa++fdj9H9DuCKncV+z+7P5eOu5SLxl7UGmFHVlWZ59n3fqfBrV1iHU14mmpd\nf/ecZy7+fQ+o+9w/kHNegyFHhXhfb10nPgw/vger3qk997uP4N2rPF9a/HtSRET8hNpS1zP1MAzv\nVbvIS0X+6ZR7V2+r3jumyWuvnH8lY54eQ3GVZ5nW2ctns60kwGtgbV1Nl70xnpZne1O625Nk37u+\n9tjquZ6eiDf/ALOPhm0rm67n2dNgfSMt9wX3w5PexXD8l7dd+Yant8Hf7KM84wy2hDEHf2OsrV1s\np73b/VPrzm9QUQyFea13P5EoUVIPQ6e0ZJbfekyD41UFB1Kx4+iQ6nhx1YuAZ774o14NsaXXVk08\nH06bHesoQrdthSdZAHz1iCe5PzQRXjiz7ix5/z4otPqK6s3N76ry1PnRzbD+c3j8aHjA7wvf2v/f\n3nmHR1WsDfw3u5ueEJKQkAAhIXSkSxFERREQEBXligpiQ+zl2j6sV6xYr92rggUbShERUARp0pv0\n0FsSCElISNtk63x/zGazmx5IKMn8nidPzs6ZM2fOS9h3zjtvWQRHVpc91ldXwfZZ5d9r7eeQvtu7\nzZLnXVznpzEqGdDehbDvr6o9w5nCYVP5CKpC0jq1zfLrg5X3LcyG3FNw6CzJl1fBfy84tWvTd8Pc\nx7wXcEXkHK26Y6WUsOhFyDp8avPQnB0cNrVFd46glXo18TWWJTID1owBFB4fWun1n2751OvziF9H\nMG7BOP44+AeO8/Etq9NZ9heoDp/2hckDvNtO7D318WbdrVLkpm6DnGOw9n/e55PXQXZS1cebcUfZ\n7U4n/P4kfNxLOd1Z81Xo4OtN4eVG8L9+ajFRZNb/fiR8dz38+oBaxOxdWHY5X1uBGgfg7Tbwy73q\neOvParyihEDmTHi/i2rLz/AeI+uQWqwUsfYzNabDrpwDnU4VpfByI5WPYN9fapxfH4ST5cgmwxU1\nsvk7df2mqepL05ypoiiyDqnFWG6q+v1OW1j+loe8HCoKoiRfXAHf31j2PY+7MjO+GKqiJpxONb7T\nqZS2rbDs63JT1b/LhimQdVA9t5RqjBdD1WLxw+6w9I2y5+RJ5gFY8V+YdkvF/SrCYa871przhfe7\nwiuRZ3sWbvSeejWRUtLi6fnlnHUS0v6Zcs5VTo/GPRjSYgg3ti3ni+dc5cshcGSVd9tFD8Caj8u/\n5uJH4PBqGP6eil1vfzWM/BqkQymA+kyznnDDZAiLV1/QG76E+U+c/rgvZEHiHKV0B05USn/bdBj8\nWnEI4l2L4NvrwKq2iZhwBCY1Lx7jzj+hee/izy9FqKp9Rf4KRf4DV05UFouBL6vFwdZpZc/pPydL\nRwRs/Bp+e8R7nPbD1d+LOaPUEG6u/Rg6j1JJjVZ9AE8egKAIdS55owqXBLh3JYQngMMCeWnwxQCw\nlgh/vOI5WOzhANt2GAx4XmVvDG2q2vb8CT/8q/z5lEVJvw67RUWd9Bynnu2Dburf/ZEt6rzDBl8N\nVQ6VB5aotrh+yqcjOxkiWnrL78VQaNYLxi30vo8lV239hMV7tzudkLoFmnRTW0Ah0eqnLMyZYPKD\n/HQlt1UfqgXmrWVYmOxWMBjVT20i5alHlKRsBP+GSoblsW0GzLzLOwKnJKcSEXMKVHVPXSv1UyR+\nwrwy26sa6lYR2247y/ncTwW7RXmf56Qor3GDUf3HtuTAN9dAmkca2PFL1ZdIeVTmpFZfGP4B/Pbw\n2Z6FNw2bwwPrVfrirEPqDR7g4X8gKBJeb6Y+d7wBts+sfLzBr0Of+4s/p25TlofTIaIVnNinFivS\nqawbu8tbiJ/K+K1h0Cuw8Svl+FgdrnoDLrq3+LPn33r8JWrbBlTNh3WfQ5Pu8Oezpcdp2FzVVQiM\ngMj2cPHD8IPHy0CT7nD3YqXwpCx2an0xWylyh0UtGCa50k8nXK4WDT6B8Owx1XZkjVo4dBqptkSm\nDFTnbWbvufQcB8PeUb4oUe2V8n8rQZ27f61Kce0bBIdWwNfD4Il9EOx6s131kbJmDXypeJFiyVVz\n9m8AexepapX7/lIJtQwmeKc9jJwCv/+f+n55sorbOqDG3vkr+IWohFhFMvFESvX385GH/hwzS+X9\nKAut1E+Pc02p90mIYPWBYueneqvUK+KjXsUhZlD5H/+yt2BJ+WGCXoxfpmLTi4i9CJJKhx5qapgh\nb3pnDDwdGndUStJggm+urpkxz3WGvg3dxsCrtZjG+bl0tbjeswCm3azaOlynHDYroqTVZeRX5W8N\nVYWGcfDoVvi8Pxz9B0Z9ryxznvco4rbf4Jvh6ji6k1rkeVJkAYy6oPhFoeT3SUEWBISpRUl4Aqz+\nCIx+0KyH98KniKcOeof9/jxWKX5PxsyEtF3KqpJ7FO5doeZnNcNrMarP/WvVOPMeg6smQWizKouo\nKmilXsvsSs3BZpc0aejPha8U7ylqpV4Gm3+A2fcpRRDXV/1nqIyi/+wXXA87Spj3xsyElgPU/m5w\npNqbfa+jOjchqfjtA1Tq3Nn3qjhzjUZTOZ3+pd6cPZ1HT5enDhZnj2zeVyn1kJhTXyw0alPsezH0\nbVj5gbIATr0Gjp9Cauz+zyiLUfqe4m2aSufQ1vtlxZPmfeDOalpxKkEr9TOIlyneYMHgk0FQwoc4\n7YEYTObyLywHf6M/68esZ8q2KRiEgeEth9MooJ7tM+emqlV9drLaT77gemUCzEkuO0Z85xxlUmt5\nORTmqOuS18GFtyszY3n79LfPUybFLy4vbnsuDZLXq9V9bM/iBcbzJ+DliJp9zrsWqbA2jUZTt3j2\nuNqmqiF0RrkziK/JgNXu5J7LEvhs2QGclhisWb2wZfUFKTAG78G/cdl78GVR6Cik0zfFb7Pvbny3\n7r29V0ZINLQdohQ7qD3azqNU/vjoMvICdLim+Ni/Afh3ULnwQeW/H/WdCvkCGPKWMn067aovKCey\nl8LUsckP4kvs63Yfq7LrPZuqvL2LxjodPB25NBpN3cJhrVGlXlV0SFsN8PdTlzP3oX48MaioopsB\nS+r1OC3ROK2NsWVeUiP3+Xn3zyw5sqRGxjpvaNINnjmmzHVtr1L7Z8FR1R+n/XB4PkOZ6nrcCb6B\nxQodwFDBf4UXs+GaD9WxT4Aaq48rhrpRG7VgMLgK59yzHC5/Vu1nxvVTeeiLeHQ7XPmi8vh+MbtY\nod+zvOz7hjb3/vzA+tJ9et6tfg95U2013DxNOZ9dMKL856kOV75YM+OcCkWyM3l8McZdXHzcvA/c\nvUTJevDrp36fEZ9Du6th7JxTH6MqnO0aEJozi19I5X1qAW1+r2Fqyyt+0chF7mQ1Zb21WxwWUvJS\n8BE+xDaILXVeUwW2z1QOMjdOrbxv2i74pDc8sA4i2yrvf0suBJVh5i/IAlNAxav2XfPU9VmHYP9i\n6D9BKa2Z41T8+YQktQgp2gp4bBek7VShZz+PhXF/KUcgTzydkAwmVeRm9Uflz6HlANjvkbTmmg+V\nhcKSq3wSvh5WqVhK8WJ28TyiOiivbqOP8oco8oMoi74Pw6CXiz+f2K8SxNz6i0rl+8930P6aYi9q\nUCFveakq/n72fd7jjV8GDZqqbZWweOVIZfJT2zQxJSw/B5aqUL/wlvDXROXtfmIvCAM8vkfVAAiL\nhzWfKs/wtETlAW4zq1wIfg288x9c+SIERSlL08sR4BtSOoSuLAb8BzpeD4GNVOjY9hlw0f0qzNFh\ngdfKCbEqj/Lu2/dhFQIY2hyyj1RvzCIufQqWv3lq19Y2nf6l/j1BLbQPr6j9e3a5BUZ8Wnm/aqD3\n1M8SWflWur28sFR7YPyHGANSyrii+rzb/126R3XnjfVv0CK0BRdEXMADfxUXY6l3pvr6xMkkFabk\n6VlbcBICysjD76nUL/s/uPwZFc4khHIy8gmA2ferMKrBr0Pve1SYVtthKqSnxSVlj3f9ZJg1zvvc\ngBeUwnFYAaG2KJpfpGJ7C3OUovUPLV7Y2ApKe35Htof0RHX8zNHTK3azfaaaR0AYLHtTeVUbq7nb\nKCXkHlPPsPEbtSVTUUxzSaxm7y0eUCFcrQcqC8/az9S20rHNKjfB32+rxYLRF7qOrjzGe/8SlVOg\niEe3QWgsLJ0EyyZ5923aA8Ytgi0/qsVQdhIc/Bsi20BCf9XHblXJmUqWRy5JZDu1QIm7GL4cpNr+\nc1ItPKz5ypImZbH1q6SHe3iC+nv85R7ocZcqJBUWD8vfhqWvqT4J/dXi6tpPoPONLqfYxmr+v95P\nhdz4rVpId71FLZJDY+HVxmrbbvxSJdcja5T8cpLVArEiBr1aHFY4/P3iHAoAVzyvfi/2WID6h6r8\nDjWMVupnkcMn8rnsraU0CwsgOasAgIDYKZiCi1fvTms4Bt/M8oY4LeZcN4cWoS2wOCx8vvVz7u50\nN/6mM7+3oznLJP4GKZvUW2RITNlbDLmp6kvtkscrT+KRskm9sXe/Tb3Bdh6lYpBXfgCXPaXewKvD\npm9VCV3/hnD9F9BmkFIAMV3hnmXVG0vjjZRwcBnEX1rx1lJZ7F2oshKCd7Khle+rkLiwuOK+mQch\nc3/FxY0Sf4OQJtDsQu/2why1cCtavFjz4YPu6g23ZQUe6PsXq1S6AWEw/TZoPUjFwPd7TIXClpXQ\nqDykhPRdsODZYitVSIyyUrW4VFlzQCXbsRWoZ5dSVaxc8jo8uF4tsH//P7joPmXFuWBErZjetVI/\nixzKyKf/20tpHh7IL/f3Jc9ip/+7vxHc5lUs6QOxZvTHN2IpflELsWRcju1kT4Jb1azpqnd0b+JD\n4/lp90882v1R7up0V42Or9HUCLYCZdYu+vKE08sSpqkZzJnq36Yoe965iNOhFhq9xqsENaeLOVNZ\nSWpirFpAV2k7iwT4qpVnu+gQIoL9iIsIYny/LuQmTsKaMQAwgihaTAmkLZz8/f+u0TmsTV3LT7t/\nAmBL+hbeXP8maeY0Rs8bTUZBBak2NZoziU+At0IHrdDPBQLDz22FDuoN/5LHak4JB4afswq9OuiQ\ntlqgcQN/fri7N12aFe9zPjW4HYMviOb6T1SOdHtOZ/wiF2HPVZWhnNbGSKcJYbDX+HyWJCmP+eP5\nx9masZUZe2Zwb5d7K7lKo9FoNOcb+k29lujbshFBfsVrJqNB0L15GD+MU/tTTmsUuYmTcBZ6roZr\n9w3lz8N/uu4i+OPQH+zNKrtCWa41l3RzernjSCnZnLaZ823rRqPRaOo6WqmfYfq2asSDl7cq85y0\nNyizvab5aPNHPLnsSa6fc727be7Wo3y7RtVxHjJrCFdMV44qUspSynv2vtnc+vutLDxc2stfo9Fo\nNGcPbX4/CzwxuC0fLSldWch8+G6MQftx5LcGaSC4TRWLmpwmSblJPDxjEU5bKAuznifbogokJJ5I\n5NWFi9mYuYDE++ew4NACTAYT+0/uByAlr2ZC9DQajUZTM2jv97PEk9O3MH1jcoV9hCkbn7DV+DVa\n6m6z57XBFLynlmenGNdpHJO3TQZgRKsR/LLvFwB6RfdiXeo6AFo2bMm0oTPx96nluskajUZTj9He\n7+c4jRuouPFruzZhWCdVuq9vywgeuLw4uYW0h2LN8I7/LEi684zNccq2Ke7jIoUOuBU6wP6T++n5\nQ1dSc3LO2Lw0Go1GUzZaqZ8lerVQ9XvH9onj49HdSXzpKqbe2YvHB7b17ihN5CZ6Z4cyJ90OQO7u\nF7Bm9q21OUqqbsVJTD/Mh3/tZV3KTo7lHavSNXaHk/cW7SHfojz+f979M+tTy8hvrtFoNJoqoc3v\nZ5FCm6NMs/XS3Wn4mYzc/MUad5sxcB9OWxjS5l3Vy+CfQlCLD8u9h/nIHQQ2/6rmJl0O4xM+5Z3f\njxHS9iUANt+6mZVHVzJ151RuaH0DjQIa0SmiO53eeYlHLrmMyIh0ktMa8NHCdNpHxrPzaK47P/7C\nkQuJDoqu6HYajUZTr9AZ5eoAN362mr3Hc7mqYzQ/rksi0NeI2eooo6cTcBLS/jl3iy27K4XHRoD0\nO+1iMlXh+pj/MOvYRPfnQXGD3CF0RXw38A/GLLyq1LW27C6YGmxFuBLytAvryI/Dvsdk1IYkjUaj\nAa3U6ywFVgd9Jv3FSbONr+/oye1fFZurhU8GQjhwWht7XVOk1PMPPExQwgdndL6ngqMwmn9F/5eJ\n16oqXjaHE59yFPy+rH0E+gTSJLiJO/TO7pTl9tdoNJrzEe0oV0cJ8DW6U9R0ahrK+meLHemkrVEp\nhf7ydUoxOm0hOC1NsKQPOFNTPWWM/qn8tSsNgJSTBbR+9ncenjWbRYcXAfBnYhIPLnqUg9kHGTFn\nBINnDmZD6gZaPD2fFk/Pp/Wzv7P3eC5bjyYzZ/8cMgszOZ5/vMr3X7kvgxd+3Y7Zqvb6Z/+TQvyE\neZw0WzmeU8jxnMKaf2iNRqOpAXSc+nnIjT1i+Wz5AYL8TBWGkh18fShCCF6Y9yTSEQCALacrfpF/\nlXvNuUKqfS0bDnXFbHVgDDzAktzPWbIU3rpwAU9uHArAspTi57hjwR2YQm7BL+oP8vc/xsD/Li+1\n7VCyJG12gY3QgNKVxUZ/uQxhsLD45Ct8fvULfL78BH5R85i4ag2/LLoIgD2vDMHXVL01caHNwfxt\nxxjRrSlC5zfXaDS1gDa/n4c4nRKL3ekuHFPEkRNmrA4n3605TNfYhlzXTaWgveKdpQxs35gvVx7E\n5pAYAg4TFP8pTlsI+Qf+jU/IDvybzDwbj1Jtcne/SEjbFyvtZ89r7VXqFryV+sbDWdzw6UouaLOf\ne3sOJzl/L3f27I9RGOn6dV+EUZXMjQ6IZ9/WmwhurSIQCo9dj9MShaMgnkOThlVr7hN/28FXKw8x\n9c5eXNomkrScQuZuPUa35g3p1jysSmMcSM8jLNCXsCDfat1bo9Gc3+g9dU0pzFY7TqlKw645cIKp\nqw9zJNOMMOYR3OYVCpLH4CiIxRSyDf/ouRQk34ww5REcmoQ9YLMa49C9OAriQVgJaffC2X2garLt\ntm2cLDzJ3C1pPPfLXvwa/4pv+Gr3+Vif/iRZl4NwVjpW4fGhPHThOOIiArm2a3H+/pSTBUxYdQ+t\nwlrynz7/8brm/u83Mn9bKh/d0o1Jy2aSkhqFdKiqUFVdIMRPmEd4kC+bnh/objNb7Xy8ZB93XNyC\nAquD2PDAKo2l0WjOH7RS11SK0ylJeGZ+qfZPR3fngRlzcVqaAMqMn/Dcz/g0XIv1xBUUFZ4JjPsE\nY+CRMznl0yI3cZLbJG89cTG+EStPezxQCjktp5D1SSk88O0u9z0eazWHfWk5JJ8sYHCHGJbsPsbC\nnScQPhkEt3obhyUKa8YAjAGH8A1fw5/XrSUmNKDMe1336QK2pe/BYU5w39Nqd2I0CP67cI9X2uHt\nEwcjwF1QSErJzE0pDOsUQ4CvEavdydbkk/SID/e6x+akk4T4m4gNCyQjz0KThmouBVYHWWar+7NG\noznzVFWp6z31eozBIPhibA9aRQWzPSUbh1OSnmth8AXRvJBzJSN7xGIQIIQgKiiC4ycG8PdTl/Pr\n5hTu79+KhGecgCSk/bNn+1GqhDHgkPv4dBU6gPA54c4b0O+zZ/CLWojB/yH3+Tc3P6FS+hpgzcpL\n8Y1YTkBs8baA0S+NgKY/uvu/8OsOBrZvjENKPl6yj4ggX359sB+7UnPYY3yDwLh0cndNBGkkOctM\nvzeW0Cs+nH+SstQzNVqEqcEWOk60gIRPb+nDkE4x/L03gyemb2Fr8kleurYjb/yxiykrDjL3oX4E\n+BppGRnMop3HGTdVLZb/dWEzpm9MZvvEwQT7mbjtq3WsO5hZrjXhnyNZCCHoGltcalhKyf70fFpF\nVVyfev2hTLrGNjztaAWnU6VKMhq0r4KmfqPf1DVVot8bi0nOKmDVhCvcb2zxE+YBYArZRkCz73FY\nojD6pbmviRM3sj93MwafTAx+Ge52pzWcq5rcwRXtI3nur8+x+x4AYGiLobQNvpT/bqv9uPqawGGO\no+DYSFo1KSQ14OPTHk/YoinM6or1RH932yMDWvP+X3u9nP6ctlDy9z2NMOUgHX4EtXwbg09uqfFy\nEyfxyIDWxIT6M2HWNoZ1imFkj2bc8ZV31r5p4y9i9Hc/gLDiyG8FBis4A3l6SDte/31X0eTo07Ih\n3995GWabg2A/E4t3HScqxJ+rP1wBeG8hzP4nhUd/2sxXd/Tk8rZR7E7NZWvySUZe2IyJv+3kXz2a\nceSEmfu+38Q9lyXw9JD2XnP6eMk+ujVvSN+WjSqUmZSSgxn53PLFWmwOJxs9tiU0mrqENr9rapR9\nabn8vCGZp4e0c3tub0/JJjW7kMvaRtL62d/dfd8dE8mG9KW82v9JLHYnl/0wHDNJTBs2jcL8xjil\ngZ4u02+exU6fad1oG9aOGddMR0pJ56mdz8oznivkJr6CMOUh7aGYQjdhCtmBT8hOrz52cxymwMMV\njpO//zGc1qgq3bNkpIDT0giDXwb5+x8DJIEtPkIYbAwJ+o6fNySz+YWBdH1pIaaQ7RiDdmNJvYG5\nD/Vj4tztbEzZjdMWgU/YamyZfRnRrTm//KMq+oUHGckPnok181KkTf0NNAn1Z/4jl/DzhiRu6xuP\nj8FAq4mTkfYGHHx1FAAOp+RgRh47jubwyLTNfDK6O0M7xfDT+iNM+FVZXaS9QYW+CQVWBzanE7PF\nQXSoqr1gttrZeDiLzs0akpVvJb5RUJXkVRmLdh7n7T930yoqmI9u6c6Oo9k0axhIaGDpaIszzdLd\naUSF+NOhyZkp9aypGbRS15xRbA4n3685TPuYBvRO8E5lm5KXwux9s7m/y/1lhnJZHBYMwoCPQX3h\ndfqmk9d5KQ2YDz5YpcQ5nfzHsK3wu9N4krpH/oFHCUp4D/OROxDCTkDstwCYj9yFMOVgz76wylkH\ni/wIYkL9OZZd6L6uqN03cgF+jZZgy+6CT+gWCo+NwHayNwbf4wifk+D0JTD+M+zmeAqP3uhW7J4M\naBfFOnEnTnsw2+5Yxdgv17FiX4ZHDwfClMe13WKYvd7sNYcDrw3F4DLBm612TAaDO/SwyLIE8Mno\n7nRr3pA3/9jtXnAUseeVIaQXpPLRsh082K8vTRuWr+jfWrCL/Wn5fDy6OzaHk3bP/8GlbSJZvifd\n3WfuQ/24+uNF4PRh/2vDS20RXPvxSnrGhfHc1R0qlH112XE0m/UHM7n94hbutgU7Urnn241A1Z0z\nq0NSppnPlx9gbJ84bv5iLXMf6udeQGlOD63UNectU9ck8p+5m/n1gd5kWJJp4t+VNlEhdPm28khf\nAwAAFclJREFU7Df4ToanyPVdSfbRK1j88Ei6fdcFgzDSKXg4W3Jn19i8zIfHERg3ucbGOx/J3TUR\nU0gi9pzOgMGtUG3ZnXEUxGEK2YEp6IC7v9MagS2nM36NlgBgPnwXgXHF1f/MR+5QJn+8wzNLLhYA\nfCOW4Be1wKuf+cjtBDb/GoD8Q/fhLIjj3Ru78NjPW9x9bundnP5tIhnvUmYKifDJ9K6lIKwYfE7i\ntEa5729JH8ieJ94tvkpKjmSaiYsIotDmoN3zf7jPrZpwBX0nLQbA4HcUg28m9tyO7udxFEZjPvgo\nix67jEKbg45NQ4HixcYbN3Tip/VJ3N+/FVd2KE4i5XRK7p66gaQsM/MevoTU7EJiwwORUvLT+iSG\ndIopM99C0bhFyvvFOTv4etUh9/mi9sl/H2DBjlS+G9cbP9PplVC+/pOVbDpyks7NQtmanM1/hnfg\nDo9FRVVIyy2kYYBvmXkg9qfnERHkS8PA+hfSqZW65rxGSlnqrT7hha/wazyX5bd9hZ18YoJjyC20\nEeBj9MoTX3St1WHlzfVv0iu6F48ve9x9PsjYiHxHBuWxccxGPtj0Ad/s/MbdZsoawYzRj3Pd/H41\n+JTnL/a81ghjIcaApNMey5JxBdb0QQDqjd6UT2Dc54BS6n7Rs8Dpi2/EikrHyt31EkjXF76wYvDN\nRDpNCIMdpyUaY+ABwInwySagyXTMh8bjKEjAGHCIwPj/lX5OcxwFh+/jw5u7UWB1sGj3QRbt28l3\nt47krq83UGAvAGmiODmnExCEtH8agILk0Qifk/g3Vgq28Nh12E6qBEaNgv3IyLOU+Rxf3t6DO79W\n33OmoL0Iv1RsmZe4zwtTNsaAI9hzOzGgXRRTbu/pPpdvsXMsu4Ar310OwMJ/X8qyPem8Mi/R6x6v\nXNeRMRfFeVkw+raM4L+jurpLQ5fFzxuSeGrGVlpFBRPoa+RYdiHzHu5HiJ8P7V/4w6vvwA6N+eiW\nblVeLDickpbPzOfK9o2ZfFtp/VVyoVIVFuxIpXeL8FpbCOQU2nA4ZK3njtBKXaPx4MVVLzFz73QA\n5o/4g3fmpzF781H+eqI3ceENybZk0+PVBRh8M9j/wsPu6zYe38jG/Q6GtOtIbHggn27+nE+2lF8V\nrzIchdEY/VNP+3nqC057IAaTuXrXWMPVW7I5HlPgIXe7Oek2AmO/8eprz2+Bs7BphQsGT2tBYPzH\nGAOSyE18jSLlLZ0mzAcfxukIIqTNy5XOL2//40hrZOkTwopv+CqsJy5BmPJBGpCOYLfVwJw0Fkde\nO/yb/IRP6BaPtg68OLwDrRuHMHNTMrM2pZQe2wsnwmhGOoLxD0rGUtjQnS/BGLQHYSxg3zPPUGhz\ncPRkAU3DApiy4iCJx3IxGUSp7QrvZ7BgCt6NPbfYqta4gR9rn1HprI+cMJNnsdM+JgQhBIt2Hmd/\neh7bUrKZu/UYM+7tw8j/FeeOGNGtKY8MaM3l7yzl7ZFdeHy6eu6ibJkWu4OUrAJ2HsshPiLIbf0o\nIj3XQs9XF2E0CGbd15cuHhEa/zdjKz9tSGL9s1cSGeJX5uOk5RTyxd8HmDCkPZP/PsDQTjHM2JjM\nnRe3YMfRbLYfzea1+cqZtGihkVNoI8TPVONZI7VS12g8sDvtfLX9K8Z0GEOAKYACq4MdR7O9YrW/\nXX2I6RuTmfNg+W/jNqeNeQfm8fzK5wHoE9OH1cdWl+r32oUzmL5tBf9Y3/Nq/+qyZXy5+y3ah7cj\nLaU7E6/pWO62gubcIXfXKyBNNVIcyZI+AGvGAMCAf9Nvsed2wp7TFb+o+fhGLMd6ol+VrBJFeC4S\nfMJW4rRF4Mhrp04KC8KUR0CzqVjSrsaRn+AOQS0qyyydPjgKm1B49EaCW70FwPKRG+n28sIqzkAi\njPn4hK3FL1Jdk3/wQXwjlmNJuwppC3dvORRFShRhDDiIdPrjtMRUML7T9WNC+KYjHYH8PO5KLHYH\nt05Z59Xz8YFteGfhHm7uFcuP65K4sn0Ui3YfAacvYEAY85COIMBb4c64tw9dPEIri6I3EhoFcSAj\nn2u6NGHOlqMVSuGihHAeuLwVt05ZhxBw8PWa9VnQSl2jOQNsS9/GLfNvASDEJ4RcmwotK0pJO2vv\nLGbumcnWjK0E+wSz+pbSC4BOX/YFY+mQtIr47brfGD57eJnnbm/1PJsO2NjqnFTmec2p4bBEYvRL\nr7xjFbBm9sWSNoSQdmpx6CiIPa2tDJW/oLjMckHSrWCwEdB02qmN57JOCJ8MTMF7sWX1AWEBgx2c\nPhh8ThIQ+w0G3xNlXu+0NcDgkwOoBVBRIiuPHmAoJKTtS+77+Ub+gSO/DY7CaPwiF2FJuwphsBDQ\nfApG/1Ty9z9GUMt3veZXEQa/FIISSlvVClOvwZbVF7UNk4m0FYdN+poMTBt/Edd/sso9T2HKQdob\nlhqnMmraEVErdY3mDGJ1WBEIDuYcJMQnhJhg7zePAnsBRmHE11h63y3PUkifaWpPdN6IeQz7RX0Z\nDEsYRu/o3rywSqXj3XbbNn7b/xsdG3WkRahyPnJKJ6+tfY0x7ccQGRjJj7t+5I4L7sApnXT/rnuV\n5//D0B8QtihuXqjMpC1CW/Be//dIaJjAJ5s/4dMtn1ZfKB5EB0WTmq+3Hc4X8g8+iLOwGUGtX8Zg\nykdKgRBKVzjtwRhMedUar6QSDkx41yunRUHKTdVagBSk3ITD3AJpD0WYcgAH0h6G8DlBcKu3MB8e\nT0DsFITBUeb1tpwL8GmwA4DC48Ow57UrtSVi8D2OX+N5mIL3kH/wAfwi/8SSfhUGnwykIwgpfXAW\nxAJOAuO+wBh42B31YT5yO/uff7yMO586WqlrNOcZRQ5+ZpsZp3QS7Kv2OX/Z+wup5lTu63JftcZ7\nbvGntA6PY0f2Un4/9DsTek3gmpbXUGgvZNGRRZwoOEGIbwhvb3ibpTcuJSIggi3pWwg0BdI6rLXX\nWA6ng67fdgVAIFD527wZ22EsQ1uovc5Rc0fRKKARlzW7DB+DD0/3fpqJqycya+8sAB7t/hjvbXq3\n1BiV8fv1vzNk1hCvtq+v+ppCeyH3Lrq32uNpzhyns2VxJihaeBiDdwIGAmO/PuWxnNYItt61pEYz\nHGqlrtFoAKWQbU4b/qbSHs1SShzSgclQecboN9a9wXeJ3/Fqv1e5OuFqAPad3McNc24AvKvgHcs7\nRpBvEA18vROcHM45jEM6iA6MpvcPvcu8z2dXTOVw/i5eW/saAOM7j+fiJheTmJnI6PajMdvMbD56\nmNaRjUgvSKdDhIrvLpnfoDImXTKJCX+XH59/adPLWJ6yrFpjajRFrL9lc4WlsauLzv2u0WgAMBqM\nGA1lf7kIITCJqn0NPNTtIRr4NWBoi6EYhHIoahPWhh6Ne3Bx04u9+pbcfigirkEcoBYa0UHRPNL9\nEa5OuBqzzcyerD20atiKYN9g+tKNVg1b0S68HSG+IQB0b6y2EwJ9Aukbp9LKRgYWm0xHthnJjD0z\nmDF8BouTFvPJ5k8AWHHTCvpNK3Z+XDhyIdFB0YDa4kg8kUizkGb8cegPViSvYHHSYka1HcWEXhPo\n9m03r/mH+4eTWZgJwM3tbubHXT96nY8OiubLwV8ydNZQOkd25qa2N5GYmUiToCasPbaWpclLqyTr\nsvAz+mFxlB0Cpzn3KLTba1SpVxX9pq7RaOocTumky9QuRAdFs3Ck8si2OWzsO7mP9hHty70uoyCD\nMfPH8L8r/0d8aDxH846y8uhKLm5yMZGBkZiEd6iS2WbG6rDS0L9yRyqzzUzvH3ozodcEJq0r3mNO\nCE3gQHZxwp7B8YO5/YLbGf/neHJtuWwZuwWDMJBmTsPhdLA4aTGbjm/inf7v8O8l/2bRkUWV3ntY\nwjBiQ2L589CfOKWTmKAYVh9bja/Bl8U3LqbftH40CmhERkH5+RsqIsgniHxbPqPajuK4+ThLk5ae\n0jh1iRWjVhHqH1Jj42nzu0ajqdcUfbfVdLxwTZBvy+en3T8xtsNYTAYTNqeNb3d+y5j2Y9zOlIey\nD7EudR03tr2x3HGc0kniiUReW/caW9O38tnAz1iWtIwfdv0AwJj2Y/i/Xv9X5rW7MncRExRDqF8o\nTunEIAxIKen9Q2+VVKcMJg+ajMVhIcwvjMZBjYkKLK4tsOn4JjpHdnZv5fx+8HeScpPYlr6tTAvF\noLhBXNrsUlqHtWb10dW8t+m9Un3+HvU3Dung8WWPM3nQZEwGU7W2WeZcN4ct6VvcIahF+Bp8WTd6\nHRuOb2Dcn+OqPF5FrLhpBetS1/HY0scAWD96fZlbXqfKOaHUhRBXAe+jckBOllJOKnFeuM4PBczA\n7VLKTRWNqZW6RqPRVExGQQbjFozjwwEfEhsSe9rj5VnzWHV0FYPiB53S9f+k/YOvwZcjuUdIzk1m\naMJQmgY3LXUPh3RwovAEP+36iS6RXRiaMLTM8eYemMvTfz9NVGAUaeY0pg6ZSnRgNOEB4fgZ/ViW\ntIw2YW3c20B/J/+N1WklJiiG3Zm76dG4B7ENlFy6fdsNu9Ne6h6bbt2Ej8GH9ze9z9KkpXSL6sb0\nPdMZ33k8Df0asun4Jt7t/y4LDi1gQPMB+BhVqt6swiwc0kGjgIorDFaXs67UhRBGYA8wEEgG1gM3\nSyl3evQZCjyEUuq9gfellGV7z7jQSl2j0Wg0Ncn0PdNpHNiYNmFt+HrH12QUZPD2ZW+f7Wl5cS44\nyvUC9kkpD7gmNA24FvCsIXktMFWqlcUaIURDIUSMlPJYLc5Lo9FoNBo3/2rzL/fxhF5Vq1h4rlK6\nDE7N0RTwTJGU7Gqrbh+NRqPRaDRVoDaVeo0hhBgvhNgghNiQnl4zaRo1Go1Go6lr1KZSTwE8PTSa\nudqq2wcp5edSyh5Syh6RkWVUN9JoNBqNRlOrSn090FoI0UII4QvcBMwp0WcOMFYoLgKy9X66RqPR\naDSnRq05ykkp7UKIB4EFqJC2L6WUO4QQ97rO/w+Yj/J834cKabujtuaj0Wg0Gk1dp1bTxEop56MU\nt2fb/zyOJfBAbc5Bo9FoNJr6wnnhKKfRaDQajaZytFLXaDQajaaOoJW6RqPRaDR1BK3UNRqNRqOp\nI2ilrtFoNBpNHUErdY1Go9Fo6ghaqWs0Go1GU0fQSl2j0Wg0mjqCVuoajUaj0dQRhErqdv4ghEgH\nDtfgkI2AjBoc73xHy8MbLY9itCy80fLwRsujmNqQRZyUstKKZuedUq9phBAbpJQ9zvY8zhW0PLzR\n8ihGy8IbLQ9vtDyKOZuy0OZ3jUaj0WjqCFqpazQajUZTR9BKHT4/2xM4x9Dy8EbLoxgtC2+0PLzR\n8ijmrMmi3u+pazQajUZTV9Bv6hqNRqPR1BHqtVIXQlwlhNgthNgnhJhwtudTGwghvhRCpAkhtnu0\nhQshFgoh9rp+h3mce9olj91CiMEe7RcKIba5zn0ghBBn+llqAiFErBBiiRBipxBihxDiEVd7vZOJ\nEMJfCLFOCLHFJYuJrvZ6JwtPhBBGIcQ/Qoi5rs/1Vh5CiEOu59gshNjgaquX8hBCNBRCzBBC7BJC\nJAoh+pyTspBS1ssfwAjsBxIAX2AL0OFsz6sWnvNSoDuw3aPtTWCC63gC8IbruINLDn5AC5d8jK5z\n64CLAAH8Dgw52892ivKIAbq7jkOAPa7nrncycc072HXsA6x1PU+9k0UJuTwG/ADMdX2ut/IADgGN\nSrTVS3kA3wDjXMe+QMNzURb1+U29F7BPSnlASmkFpgHXnuU51ThSyuVAZonma1F/oLh+X+fRPk1K\naZFSHgT2Ab2EEDFAAynlGqn+Kqd6XHNeIaU8JqXc5DrOBRKBptRDmUhFnuujj+tHUg9lUYQQohkw\nDJjs0Vxv5VEO9U4eQohQ1AvSFAAppVVKeZJzUBb1Wak3BZI8Pie72uoDjaWUx1zHqUBj13F5Mmnq\nOi7Zfl4jhIgHuqHeUOulTFym5s1AGrBQSllvZeHiPeApwOnRVp/lIYFFQoiNQojxrrb6KI8WQDrw\nlWtrZrIQIohzUBb1WalrUG9rqP+49QohRDAwE3hUSpnjea4+yURK6ZBSdgWaod4kOpY4X29kIYS4\nGkiTUm4sr099koeLfq6/jyHAA0KISz1P1iN5mFDbmJ9KKbsB+Shzu5tzRRb1WamnALEen5u52uoD\nx11mIFy/01zt5ckkxXVcsv28RAjhg1Lo30spZ7ma67VMXKbEJcBV1F9ZXAxcI4Q4hNqOu0II8R31\nVx5IKVNcv9OAX1DblvVRHslAssuSBTADpeTPOVnUZ6W+HmgthGghhPAFbgLmnOU5nSnmALe5jm8D\nfvVov0kI4SeEaAG0Bta5zEs5QoiLXJ6aYz2uOa9wzX8KkCilfNfjVL2TiRAiUgjR0HUcAAwEdlEP\nZQEgpXxaStlMShmP+j5YLKUcQz2VhxAiSAgRUnQMDAK2Uw/lIaVMBZKEEG1dTQOAnZyLsqhpD8Hz\n6QcYivJ+3g88e7bnU0vP+CNwDLChVpt3ARHAX8BeYBEQ7tH/WZc8duPhlQn0QP2H3g98hCtx0fn2\nA/RDmci2AptdP0Pro0yAzsA/LllsB15wtdc7WZQhm/4Ue7/XS3mgIoO2uH52FH1H1mN5dAU2uP6/\nzAbCzkVZ6IxyGo1Go9HUEeqz+V2j0Wg0mjqFVuoajUaj0dQRtFLXaDQajaaOoJW6RqPRaDR1BK3U\nNRqNRqOpI2ilrtHUUYQQea7f8UKIW2p47GdKfF5Vk+NrNJpTQyt1jabuEw9US6kLIUyVdPFS6lLK\nvtWck0ajqQW0Utdo6j6TgEtcNbH/7Sri8pYQYr0QYqsQ4h4AIUR/IcTfQog5qGxZCCFmu4p57Cgq\n6CGEmAQEuMb73tVWZBUQrrG3u2pGj/IYe6korkf9fY3XkdZoNFS2GtdoNOc/E4AnpJRXA7iUc7aU\nsqcQwg9YKYT409W3O9BRqnKRAHdKKTNdaWTXCyFmSiknCCEelKrQR0muR2Xe6gI0cl2z3HWuG3AB\ncBRYicq1vqLmH1ejqb/oN3WNpv4xCBjrKrm6FpXqsrXr3DoPhQ7wsBBiC7AGVaCiNRXTD/hRqupv\nx4FlQE+PsZOllE5Uet74GnkajUbjRr+pazT1DwE8JKVc4NUoRH9USUnPz1cCfaSUZiHEUsD/NO5r\n8Th2oL9/NJoaR7+pazR1n1wgxOPzAuA+VwlahBBtXFW4ShIKZLkUejvgIo9ztqLrS/A3MMq1bx8J\nXAqsq5Gn0Gg0laJXyhpN3Wcr4HCZ0b8G3keZvje5nNXSgevKuO4P4F4hRCKq0tQaj3OfA1uFEJuk\nlKM92n8B+qAqe0ngKSllqmtRoNFoahldpU2j0Wg0mjqCNr9rNBqNRlNH0Epdo9FoNJo6glbqGo1G\no9HUEbRS12g0Go2mjqCVukaj0Wg0dQSt1DUajUajqSNopa7RaDQaTR1BK3WNRqPRaOoI/w/KU1if\nwY0nmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f35f58bdb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAYERSIZE = 50\n",
    "epochs = 20\n",
    "\n",
    "test_runs = 10\n",
    "\n",
    "int_lr = 0.1\n",
    "syn_lr = 0.003\n",
    "\n",
    "run_mnist_experiment(int_lr, syn_lr, epochs, test_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR-10 Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batchSize = 200\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batchSize,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batchSize,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training IP Net. Run 1\n",
      "[1] loss: 1.995\n",
      "[2] loss: 1.826\n",
      "[3] loss: 1.782\n",
      "[4] loss: 1.729\n",
      "[5] loss: 1.699\n",
      "[6] loss: 1.666\n",
      "[7] loss: 1.643\n",
      "[8] loss: 1.608\n",
      "[9] loss: 1.594\n",
      "[10] loss: 1.571\n",
      "[11] loss: 1.552\n",
      "[12] loss: 1.528\n",
      "[13] loss: 1.518\n",
      "[14] loss: 1.490\n",
      "[15] loss: 1.484\n",
      "[16] loss: 1.466\n",
      "[17] loss: 1.455\n",
      "[18] loss: 1.433\n",
      "[19] loss: 1.416\n",
      "[20] loss: 1.417\n",
      "[21] loss: 1.403\n",
      "[22] loss: 1.392\n",
      "[23] loss: 1.372\n",
      "[24] loss: 1.362\n",
      "[25] loss: 1.358\n",
      "[26] loss: 1.343\n",
      "[27] loss: 1.334\n",
      "[28] loss: 1.314\n",
      "[29] loss: 1.306\n",
      "[30] loss: 1.296\n",
      "[31] loss: 1.289\n",
      "[32] loss: 1.277\n",
      "[33] loss: 1.271\n",
      "[34] loss: 1.271\n",
      "[35] loss: 1.247\n",
      "[36] loss: 1.243\n",
      "[37] loss: 1.238\n",
      "[38] loss: 1.228\n",
      "[39] loss: 1.218\n",
      "[40] loss: 1.210\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 1\n",
      "[1] loss: 2.011\n",
      "[2] loss: 1.862\n",
      "[3] loss: 1.821\n",
      "[4] loss: 1.797\n",
      "[5] loss: 1.788\n",
      "[6] loss: 1.757\n",
      "[7] loss: 1.759\n",
      "[8] loss: 1.745\n",
      "[9] loss: 1.738\n",
      "[10] loss: 1.751\n",
      "[11] loss: 1.708\n",
      "[12] loss: 1.709\n",
      "[13] loss: 1.718\n",
      "[14] loss: 1.669\n",
      "[15] loss: 1.683\n",
      "[16] loss: 1.701\n",
      "[17] loss: 1.660\n",
      "[18] loss: 1.662\n",
      "[19] loss: 1.664\n",
      "[20] loss: 1.632\n",
      "[21] loss: 1.649\n",
      "[22] loss: 1.656\n",
      "[23] loss: 1.617\n",
      "[24] loss: 1.631\n",
      "[25] loss: 1.626\n",
      "[26] loss: 1.613\n",
      "[27] loss: 1.627\n",
      "[28] loss: 1.586\n",
      "[29] loss: 1.586\n",
      "[30] loss: 1.596\n",
      "[31] loss: 1.583\n",
      "[32] loss: 1.592\n",
      "[33] loss: 1.568\n",
      "[34] loss: 1.567\n",
      "[35] loss: 1.559\n",
      "[36] loss: 1.555\n",
      "[37] loss: 1.552\n",
      "[38] loss: 1.543\n",
      "[39] loss: 1.536\n",
      "[40] loss: 1.530\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 1\n",
      "[1] loss: 2.013\n",
      "[2] loss: 1.941\n",
      "[3] loss: 1.975\n",
      "[4] loss: 1.989\n",
      "[5] loss: 1.988\n",
      "[6] loss: 1.994\n",
      "[7] loss: 1.961\n",
      "[8] loss: 1.953\n",
      "[9] loss: 1.926\n",
      "[10] loss: 1.956\n",
      "[11] loss: 1.931\n",
      "[12] loss: 1.927\n",
      "[13] loss: 1.936\n",
      "[14] loss: 1.908\n",
      "[15] loss: 1.903\n",
      "[16] loss: 1.899\n",
      "[17] loss: 1.899\n",
      "[18] loss: 1.872\n",
      "[19] loss: 1.874\n",
      "[20] loss: 1.863\n",
      "[21] loss: 1.856\n",
      "[22] loss: 1.854\n",
      "[23] loss: 1.852\n",
      "[24] loss: 1.839\n",
      "[25] loss: 1.861\n",
      "[26] loss: 1.887\n",
      "[27] loss: 1.868\n",
      "[28] loss: 1.874\n",
      "[29] loss: 1.884\n",
      "[30] loss: 1.873\n",
      "[31] loss: 1.863\n",
      "[32] loss: 1.862\n",
      "[33] loss: 1.854\n",
      "[34] loss: 1.888\n",
      "[35] loss: 1.987\n",
      "[36] loss: 1.935\n",
      "[37] loss: 1.964\n",
      "[38] loss: 1.948\n",
      "[39] loss: 1.936\n",
      "[40] loss: 1.938\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 1\n",
      "[1] loss: 2.038\n",
      "[2] loss: 1.879\n",
      "[3] loss: 1.830\n",
      "[4] loss: 1.790\n",
      "[5] loss: 1.763\n",
      "[6] loss: 1.734\n",
      "[7] loss: 1.711\n",
      "[8] loss: 1.686\n",
      "[9] loss: 1.675\n",
      "[10] loss: 1.647\n",
      "[11] loss: 1.620\n",
      "[12] loss: 1.614\n",
      "[13] loss: 1.604\n",
      "[14] loss: 1.575\n",
      "[15] loss: 1.568\n",
      "[16] loss: 1.551\n",
      "[17] loss: 1.555\n",
      "[18] loss: 1.539\n",
      "[19] loss: 1.509\n",
      "[20] loss: 1.514\n",
      "[21] loss: 1.502\n",
      "[22] loss: 1.498\n",
      "[23] loss: 1.498\n",
      "[24] loss: 1.483\n",
      "[25] loss: 1.476\n",
      "[26] loss: 1.464\n",
      "[27] loss: 1.462\n",
      "[28] loss: 1.453\n",
      "[29] loss: 1.441\n",
      "[30] loss: 1.437\n",
      "[31] loss: 1.425\n",
      "[32] loss: 1.428\n",
      "[33] loss: 1.423\n",
      "[34] loss: 1.413\n",
      "[35] loss: 1.404\n",
      "[36] loss: 1.397\n",
      "[37] loss: 1.397\n",
      "[38] loss: 1.394\n",
      "[39] loss: 1.384\n",
      "[40] loss: 1.377\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 2\n",
      "[1] loss: 2.011\n",
      "[2] loss: 1.848\n",
      "[3] loss: 1.784\n",
      "[4] loss: 1.743\n",
      "[5] loss: 1.720\n",
      "[6] loss: 1.687\n",
      "[7] loss: 1.657\n",
      "[8] loss: 1.634\n",
      "[9] loss: 1.604\n",
      "[10] loss: 1.589\n",
      "[11] loss: 1.562\n",
      "[12] loss: 1.544\n",
      "[13] loss: 1.531\n",
      "[14] loss: 1.508\n",
      "[15] loss: 1.491\n",
      "[16] loss: 1.484\n",
      "[17] loss: 1.469\n",
      "[18] loss: 1.454\n",
      "[19] loss: 1.440\n",
      "[20] loss: 1.430\n",
      "[21] loss: 1.416\n",
      "[22] loss: 1.402\n",
      "[23] loss: 1.396\n",
      "[24] loss: 1.380\n",
      "[25] loss: 1.380\n",
      "[26] loss: 1.361\n",
      "[27] loss: 1.354\n",
      "[28] loss: 1.339\n",
      "[29] loss: 1.328\n",
      "[30] loss: 1.319\n",
      "[31] loss: 1.311\n",
      "[32] loss: 1.302\n",
      "[33] loss: 1.294\n",
      "[34] loss: 1.288\n",
      "[35] loss: 1.269\n",
      "[36] loss: 1.271\n",
      "[37] loss: 1.251\n",
      "[38] loss: 1.244\n",
      "[39] loss: 1.236\n",
      "[40] loss: 1.229\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 2\n",
      "[1] loss: 2.045\n",
      "[2] loss: 1.899\n",
      "[3] loss: 1.843\n",
      "[4] loss: 1.815\n",
      "[5] loss: 1.810\n",
      "[6] loss: 1.782\n",
      "[7] loss: 1.758\n",
      "[8] loss: 1.743\n",
      "[9] loss: 1.732\n",
      "[10] loss: 1.715\n",
      "[11] loss: 1.695\n",
      "[12] loss: 1.672\n",
      "[13] loss: 1.674\n",
      "[14] loss: 1.659\n",
      "[15] loss: 1.631\n",
      "[16] loss: 1.618\n",
      "[17] loss: 1.597\n",
      "[18] loss: 1.589\n",
      "[19] loss: 1.569\n",
      "[20] loss: 1.562\n",
      "[21] loss: 1.547\n",
      "[22] loss: 1.538\n",
      "[23] loss: 1.531\n",
      "[24] loss: 1.521\n",
      "[25] loss: 1.510\n",
      "[26] loss: 1.494\n",
      "[27] loss: 1.488\n",
      "[28] loss: 1.478\n",
      "[29] loss: 1.459\n",
      "[30] loss: 1.449\n",
      "[31] loss: 1.439\n",
      "[32] loss: 1.425\n",
      "[33] loss: 1.421\n",
      "[34] loss: 1.411\n",
      "[35] loss: 1.398\n",
      "[36] loss: 1.386\n",
      "[37] loss: 1.378\n",
      "[38] loss: 1.369\n",
      "[39] loss: 1.361\n",
      "[40] loss: 1.348\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 2\n",
      "[1] loss: 2.026\n",
      "[2] loss: 1.939\n",
      "[3] loss: 1.959\n",
      "[4] loss: 1.998\n",
      "[5] loss: 1.950\n",
      "[6] loss: 1.942\n",
      "[7] loss: 1.968\n",
      "[8] loss: 1.964\n",
      "[9] loss: 1.948\n",
      "[10] loss: 1.929\n",
      "[11] loss: 1.926\n",
      "[12] loss: 1.918\n",
      "[13] loss: 1.896\n",
      "[14] loss: 1.924\n",
      "[15] loss: 1.914\n",
      "[16] loss: 1.906\n",
      "[17] loss: 1.937\n",
      "[18] loss: 1.886\n",
      "[19] loss: 1.890\n",
      "[20] loss: 1.934\n",
      "[21] loss: 1.914\n",
      "[22] loss: 1.887\n",
      "[23] loss: 1.868\n",
      "[24] loss: 1.882\n",
      "[25] loss: 1.858\n",
      "[26] loss: 1.882\n",
      "[27] loss: 1.880\n",
      "[28] loss: 1.855\n",
      "[29] loss: 1.853\n",
      "[30] loss: 1.838\n",
      "[31] loss: 1.851\n",
      "[32] loss: 1.907\n",
      "[33] loss: 1.848\n",
      "[34] loss: 1.853\n",
      "[35] loss: 1.848\n",
      "[36] loss: 1.818\n",
      "[37] loss: 1.805\n",
      "[38] loss: 1.841\n",
      "[39] loss: 1.905\n",
      "[40] loss: 1.908\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 2\n",
      "[1] loss: 2.075\n",
      "[2] loss: 1.912\n",
      "[3] loss: 1.840\n",
      "[4] loss: 1.795\n",
      "[5] loss: 1.772\n",
      "[6] loss: 1.751\n",
      "[7] loss: 1.728\n",
      "[8] loss: 1.700\n",
      "[9] loss: 1.673\n",
      "[10] loss: 1.659\n",
      "[11] loss: 1.649\n",
      "[12] loss: 1.628\n",
      "[13] loss: 1.601\n",
      "[14] loss: 1.585\n",
      "[15] loss: 1.578\n",
      "[16] loss: 1.563\n",
      "[17] loss: 1.554\n",
      "[18] loss: 1.543\n",
      "[19] loss: 1.527\n",
      "[20] loss: 1.523\n",
      "[21] loss: 1.511\n",
      "[22] loss: 1.499\n",
      "[23] loss: 1.490\n",
      "[24] loss: 1.489\n",
      "[25] loss: 1.481\n",
      "[26] loss: 1.461\n",
      "[27] loss: 1.466\n",
      "[28] loss: 1.465\n",
      "[29] loss: 1.443\n",
      "[30] loss: 1.439\n",
      "[31] loss: 1.434\n",
      "[32] loss: 1.419\n",
      "[33] loss: 1.420\n",
      "[34] loss: 1.419\n",
      "[35] loss: 1.390\n",
      "[36] loss: 1.390\n",
      "[37] loss: 1.390\n",
      "[38] loss: 1.374\n",
      "[39] loss: 1.384\n",
      "[40] loss: 1.359\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 3\n",
      "[1] loss: 2.004\n",
      "[2] loss: 1.839\n",
      "[3] loss: 1.781\n",
      "[4] loss: 1.733\n",
      "[5] loss: 1.706\n",
      "[6] loss: 1.677\n",
      "[7] loss: 1.651\n",
      "[8] loss: 1.622\n",
      "[9] loss: 1.602\n",
      "[10] loss: 1.577\n",
      "[11] loss: 1.555\n",
      "[12] loss: 1.533\n",
      "[13] loss: 1.517\n",
      "[14] loss: 1.496\n",
      "[15] loss: 1.484\n",
      "[16] loss: 1.462\n",
      "[17] loss: 1.447\n",
      "[18] loss: 1.433\n",
      "[19] loss: 1.420\n",
      "[20] loss: 1.405\n",
      "[21] loss: 1.394\n",
      "[22] loss: 1.378\n",
      "[23] loss: 1.366\n",
      "[24] loss: 1.357\n",
      "[25] loss: 1.346\n",
      "[26] loss: 1.332\n",
      "[27] loss: 1.324\n",
      "[28] loss: 1.320\n",
      "[29] loss: 1.298\n",
      "[30] loss: 1.291\n",
      "[31] loss: 1.285\n",
      "[32] loss: 1.280\n",
      "[33] loss: 1.266\n",
      "[34] loss: 1.261\n",
      "[35] loss: 1.249\n",
      "[36] loss: 1.245\n",
      "[37] loss: 1.237\n",
      "[38] loss: 1.223\n",
      "[39] loss: 1.209\n",
      "[40] loss: 1.204\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 3\n",
      "[1] loss: 2.036\n",
      "[2] loss: 1.895\n",
      "[3] loss: 1.846\n",
      "[4] loss: 1.832\n",
      "[5] loss: 1.805\n",
      "[6] loss: 1.779\n",
      "[7] loss: 1.748\n",
      "[8] loss: 1.737\n",
      "[9] loss: 1.719\n",
      "[10] loss: 1.696\n",
      "[11] loss: 1.686\n",
      "[12] loss: 1.674\n",
      "[13] loss: 1.668\n",
      "[14] loss: 1.652\n",
      "[15] loss: 1.624\n",
      "[16] loss: 1.612\n",
      "[17] loss: 1.593\n",
      "[18] loss: 1.579\n",
      "[19] loss: 1.572\n",
      "[20] loss: 1.557\n",
      "[21] loss: 1.548\n",
      "[22] loss: 1.549\n",
      "[23] loss: 1.548\n",
      "[24] loss: 1.558\n",
      "[25] loss: 1.534\n",
      "[26] loss: 1.509\n",
      "[27] loss: 1.484\n",
      "[28] loss: 1.480\n",
      "[29] loss: 1.466\n",
      "[30] loss: 1.451\n",
      "[31] loss: 1.443\n",
      "[32] loss: 1.437\n",
      "[33] loss: 1.421\n",
      "[34] loss: 1.411\n",
      "[35] loss: 1.397\n",
      "[36] loss: 1.390\n",
      "[37] loss: 1.376\n",
      "[38] loss: 1.367\n",
      "[39] loss: 1.355\n",
      "[40] loss: 1.347\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 3\n",
      "[1] loss: 2.023\n",
      "[2] loss: 1.953\n",
      "[3] loss: 1.971\n",
      "[4] loss: 1.987\n",
      "[5] loss: 1.993\n",
      "[6] loss: 1.995\n",
      "[7] loss: 1.983\n",
      "[8] loss: 1.970\n",
      "[9] loss: 1.945\n",
      "[10] loss: 1.959\n",
      "[11] loss: 1.931\n",
      "[12] loss: 1.914\n",
      "[13] loss: 1.912\n",
      "[14] loss: 1.904\n",
      "[15] loss: 1.899\n",
      "[16] loss: 1.887\n",
      "[17] loss: 1.895\n",
      "[18] loss: 1.889\n",
      "[19] loss: 1.893\n",
      "[20] loss: 1.907\n",
      "[21] loss: 1.910\n",
      "[22] loss: 1.989\n",
      "[23] loss: 1.885\n",
      "[24] loss: 1.899\n",
      "[25] loss: 1.910\n",
      "[26] loss: 1.917\n",
      "[27] loss: 1.938\n",
      "[28] loss: 1.909\n",
      "[29] loss: 1.874\n",
      "[30] loss: 1.876\n",
      "[31] loss: 1.901\n",
      "[32] loss: 1.884\n",
      "[33] loss: 1.884\n",
      "[34] loss: 1.889\n",
      "[35] loss: 1.879\n",
      "[36] loss: 1.942\n",
      "[37] loss: 1.930\n",
      "[38] loss: 2.034\n",
      "[39] loss: 1.967\n",
      "[40] loss: 2.085\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 3\n",
      "[1] loss: 2.088\n",
      "[2] loss: 1.921\n",
      "[3] loss: 1.856\n",
      "[4] loss: 1.804\n",
      "[5] loss: 1.764\n",
      "[6] loss: 1.744\n",
      "[7] loss: 1.717\n",
      "[8] loss: 1.689\n",
      "[9] loss: 1.672\n",
      "[10] loss: 1.655\n",
      "[11] loss: 1.632\n",
      "[12] loss: 1.617\n",
      "[13] loss: 1.601\n",
      "[14] loss: 1.586\n",
      "[15] loss: 1.574\n",
      "[16] loss: 1.559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17] loss: 1.547\n",
      "[18] loss: 1.533\n",
      "[19] loss: 1.523\n",
      "[20] loss: 1.511\n",
      "[21] loss: 1.508\n",
      "[22] loss: 1.504\n",
      "[23] loss: 1.482\n",
      "[24] loss: 1.480\n",
      "[25] loss: 1.484\n",
      "[26] loss: 1.472\n",
      "[27] loss: 1.459\n",
      "[28] loss: 1.452\n",
      "[29] loss: 1.436\n",
      "[30] loss: 1.439\n",
      "[31] loss: 1.426\n",
      "[32] loss: 1.417\n",
      "[33] loss: 1.408\n",
      "[34] loss: 1.408\n",
      "[35] loss: 1.403\n",
      "[36] loss: 1.398\n",
      "[37] loss: 1.388\n",
      "[38] loss: 1.386\n",
      "[39] loss: 1.377\n",
      "[40] loss: 1.378\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 4\n",
      "[1] loss: 1.998\n",
      "[2] loss: 1.835\n",
      "[3] loss: 1.779\n",
      "[4] loss: 1.744\n",
      "[5] loss: 1.708\n",
      "[6] loss: 1.668\n",
      "[7] loss: 1.643\n",
      "[8] loss: 1.614\n",
      "[9] loss: 1.589\n",
      "[10] loss: 1.573\n",
      "[11] loss: 1.549\n",
      "[12] loss: 1.534\n",
      "[13] loss: 1.521\n",
      "[14] loss: 1.508\n",
      "[15] loss: 1.496\n",
      "[16] loss: 1.478\n",
      "[17] loss: 1.458\n",
      "[18] loss: 1.450\n",
      "[19] loss: 1.438\n",
      "[20] loss: 1.415\n",
      "[21] loss: 1.421\n",
      "[22] loss: 1.398\n",
      "[23] loss: 1.390\n",
      "[24] loss: 1.371\n",
      "[25] loss: 1.367\n",
      "[26] loss: 1.351\n",
      "[27] loss: 1.340\n",
      "[28] loss: 1.331\n",
      "[29] loss: 1.317\n",
      "[30] loss: 1.311\n",
      "[31] loss: 1.300\n",
      "[32] loss: 1.292\n",
      "[33] loss: 1.285\n",
      "[34] loss: 1.269\n",
      "[35] loss: 1.267\n",
      "[36] loss: 1.254\n",
      "[37] loss: 1.244\n",
      "[38] loss: 1.241\n",
      "[39] loss: 1.228\n",
      "[40] loss: 1.213\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 4\n",
      "[1] loss: 2.019\n",
      "[2] loss: 1.884\n",
      "[3] loss: 1.844\n",
      "[4] loss: 1.831\n",
      "[5] loss: 1.811\n",
      "[6] loss: 1.799\n",
      "[7] loss: 1.798\n",
      "[8] loss: 1.764\n",
      "[9] loss: 1.755\n",
      "[10] loss: 1.777\n",
      "[11] loss: 1.748\n",
      "[12] loss: 1.740\n",
      "[13] loss: 1.767\n",
      "[14] loss: 1.720\n",
      "[15] loss: 1.727\n",
      "[16] loss: 1.732\n",
      "[17] loss: 1.696\n",
      "[18] loss: 1.700\n",
      "[19] loss: 1.702\n",
      "[20] loss: 1.666\n",
      "[21] loss: 1.680\n",
      "[22] loss: 1.694\n",
      "[23] loss: 1.659\n",
      "[24] loss: 1.673\n",
      "[25] loss: 1.660\n",
      "[26] loss: 1.653\n",
      "[27] loss: 1.655\n",
      "[28] loss: 1.631\n",
      "[29] loss: 1.625\n",
      "[30] loss: 1.636\n",
      "[31] loss: 1.622\n",
      "[32] loss: 1.622\n",
      "[33] loss: 1.618\n",
      "[34] loss: 1.609\n",
      "[35] loss: 1.596\n",
      "[36] loss: 1.589\n",
      "[37] loss: 1.587\n",
      "[38] loss: 1.588\n",
      "[39] loss: 1.573\n",
      "[40] loss: 1.565\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 4\n",
      "[1] loss: 2.055\n",
      "[2] loss: 1.986\n",
      "[3] loss: 2.023\n",
      "[4] loss: 2.048\n",
      "[5] loss: 2.039\n",
      "[6] loss: 1.996\n",
      "[7] loss: 1.984\n",
      "[8] loss: 1.992\n",
      "[9] loss: 1.983\n",
      "[10] loss: 1.968\n",
      "[11] loss: 1.989\n",
      "[12] loss: 1.987\n",
      "[13] loss: 1.957\n",
      "[14] loss: 1.966\n",
      "[15] loss: 1.982\n",
      "[16] loss: 1.932\n",
      "[17] loss: 1.938\n",
      "[18] loss: 1.934\n",
      "[19] loss: 1.940\n",
      "[20] loss: 1.942\n",
      "[21] loss: 1.929\n",
      "[22] loss: 1.925\n",
      "[23] loss: 1.971\n",
      "[24] loss: 1.986\n",
      "[25] loss: 1.935\n",
      "[26] loss: 1.976\n",
      "[27] loss: 1.934\n",
      "[28] loss: 1.915\n",
      "[29] loss: 1.904\n",
      "[30] loss: 1.909\n",
      "[31] loss: 1.871\n",
      "[32] loss: 1.861\n",
      "[33] loss: 1.863\n",
      "[34] loss: 1.850\n",
      "[35] loss: 1.868\n",
      "[36] loss: 1.910\n",
      "[37] loss: 1.948\n",
      "[38] loss: 1.895\n",
      "[39] loss: 1.877\n",
      "[40] loss: 1.872\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 4\n",
      "[1] loss: 2.055\n",
      "[2] loss: 1.907\n",
      "[3] loss: 1.842\n",
      "[4] loss: 1.808\n",
      "[5] loss: 1.768\n",
      "[6] loss: 1.741\n",
      "[7] loss: 1.707\n",
      "[8] loss: 1.689\n",
      "[9] loss: 1.660\n",
      "[10] loss: 1.642\n",
      "[11] loss: 1.634\n",
      "[12] loss: 1.628\n",
      "[13] loss: 1.593\n",
      "[14] loss: 1.583\n",
      "[15] loss: 1.581\n",
      "[16] loss: 1.557\n",
      "[17] loss: 1.544\n",
      "[18] loss: 1.529\n",
      "[19] loss: 1.526\n",
      "[20] loss: 1.514\n",
      "[21] loss: 1.520\n",
      "[22] loss: 1.499\n",
      "[23] loss: 1.500\n",
      "[24] loss: 1.490\n",
      "[25] loss: 1.480\n",
      "[26] loss: 1.467\n",
      "[27] loss: 1.467\n",
      "[28] loss: 1.462\n",
      "[29] loss: 1.449\n",
      "[30] loss: 1.450\n",
      "[31] loss: 1.432\n",
      "[32] loss: 1.421\n",
      "[33] loss: 1.426\n",
      "[34] loss: 1.403\n",
      "[35] loss: 1.405\n",
      "[36] loss: 1.402\n",
      "[37] loss: 1.396\n",
      "[38] loss: 1.397\n",
      "[39] loss: 1.385\n",
      "[40] loss: 1.374\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 5\n",
      "[1] loss: 1.999\n",
      "[2] loss: 1.836\n",
      "[3] loss: 1.774\n",
      "[4] loss: 1.735\n",
      "[5] loss: 1.706\n",
      "[6] loss: 1.675\n",
      "[7] loss: 1.639\n",
      "[8] loss: 1.613\n",
      "[9] loss: 1.595\n",
      "[10] loss: 1.575\n",
      "[11] loss: 1.556\n",
      "[12] loss: 1.532\n",
      "[13] loss: 1.512\n",
      "[14] loss: 1.500\n",
      "[15] loss: 1.471\n",
      "[16] loss: 1.470\n",
      "[17] loss: 1.459\n",
      "[18] loss: 1.435\n",
      "[19] loss: 1.423\n",
      "[20] loss: 1.410\n",
      "[21] loss: 1.398\n",
      "[22] loss: 1.387\n",
      "[23] loss: 1.375\n",
      "[24] loss: 1.356\n",
      "[25] loss: 1.357\n",
      "[26] loss: 1.337\n",
      "[27] loss: 1.330\n",
      "[28] loss: 1.325\n",
      "[29] loss: 1.313\n",
      "[30] loss: 1.304\n",
      "[31] loss: 1.291\n",
      "[32] loss: 1.284\n",
      "[33] loss: 1.278\n",
      "[34] loss: 1.267\n",
      "[35] loss: 1.257\n",
      "[36] loss: 1.247\n",
      "[37] loss: 1.237\n",
      "[38] loss: 1.234\n",
      "[39] loss: 1.222\n",
      "[40] loss: 1.215\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 5\n",
      "[1] loss: 2.019\n",
      "[2] loss: 1.886\n",
      "[3] loss: 1.841\n",
      "[4] loss: 1.816\n",
      "[5] loss: 1.803\n",
      "[6] loss: 1.799\n",
      "[7] loss: 1.782\n",
      "[8] loss: 1.769\n",
      "[9] loss: 1.760\n",
      "[10] loss: 1.731\n",
      "[11] loss: 1.729\n",
      "[12] loss: 1.725\n",
      "[13] loss: 1.703\n",
      "[14] loss: 1.691\n",
      "[15] loss: 1.675\n",
      "[16] loss: 1.670\n",
      "[17] loss: 1.670\n",
      "[18] loss: 1.653\n",
      "[19] loss: 1.633\n",
      "[20] loss: 1.620\n",
      "[21] loss: 1.608\n",
      "[22] loss: 1.593\n",
      "[23] loss: 1.586\n",
      "[24] loss: 1.574\n",
      "[25] loss: 1.566\n",
      "[26] loss: 1.556\n",
      "[27] loss: 1.548\n",
      "[28] loss: 1.528\n",
      "[29] loss: 1.526\n",
      "[30] loss: 1.512\n",
      "[31] loss: 1.499\n",
      "[32] loss: 1.494\n",
      "[33] loss: 1.482\n",
      "[34] loss: 1.470\n",
      "[35] loss: 1.460\n",
      "[36] loss: 1.453\n",
      "[37] loss: 1.440\n",
      "[38] loss: 1.439\n",
      "[39] loss: 1.429\n",
      "[40] loss: 1.419\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 5\n",
      "[1] loss: 2.026\n",
      "[2] loss: 1.953\n",
      "[3] loss: 2.011\n",
      "[4] loss: 1.991\n",
      "[5] loss: 1.986\n",
      "[6] loss: 2.019\n",
      "[7] loss: 1.983\n",
      "[8] loss: 1.969\n",
      "[9] loss: 1.972\n",
      "[10] loss: 1.977\n",
      "[11] loss: 2.008\n",
      "[12] loss: 1.994\n",
      "[13] loss: 1.982\n",
      "[14] loss: 1.955\n",
      "[15] loss: 1.966\n",
      "[16] loss: 1.946\n",
      "[17] loss: 1.944\n",
      "[18] loss: 1.915\n",
      "[19] loss: 1.919\n",
      "[20] loss: 1.900\n",
      "[21] loss: 1.917\n",
      "[22] loss: 1.909\n",
      "[23] loss: 1.884\n",
      "[24] loss: 1.867\n",
      "[25] loss: 1.841\n",
      "[26] loss: 1.835\n",
      "[27] loss: 1.875\n",
      "[28] loss: 1.875\n",
      "[29] loss: 1.908\n",
      "[30] loss: 1.870\n",
      "[31] loss: 1.852\n",
      "[32] loss: 1.909\n",
      "[33] loss: 1.876\n",
      "[34] loss: 1.867\n",
      "[35] loss: 1.856\n",
      "[36] loss: 1.854\n",
      "[37] loss: 1.847\n",
      "[38] loss: 1.832\n",
      "[39] loss: 1.824\n",
      "[40] loss: 1.819\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 5\n",
      "[1] loss: 2.043\n",
      "[2] loss: 1.916\n",
      "[3] loss: 1.844\n",
      "[4] loss: 1.799\n",
      "[5] loss: 1.771\n",
      "[6] loss: 1.737\n",
      "[7] loss: 1.722\n",
      "[8] loss: 1.683\n",
      "[9] loss: 1.676\n",
      "[10] loss: 1.651\n",
      "[11] loss: 1.634\n",
      "[12] loss: 1.617\n",
      "[13] loss: 1.597\n",
      "[14] loss: 1.590\n",
      "[15] loss: 1.568\n",
      "[16] loss: 1.567\n",
      "[17] loss: 1.545\n",
      "[18] loss: 1.538\n",
      "[19] loss: 1.533\n",
      "[20] loss: 1.528\n",
      "[21] loss: 1.511\n",
      "[22] loss: 1.505\n",
      "[23] loss: 1.499\n",
      "[24] loss: 1.495\n",
      "[25] loss: 1.481\n",
      "[26] loss: 1.478\n",
      "[27] loss: 1.469\n",
      "[28] loss: 1.471\n",
      "[29] loss: 1.453\n",
      "[30] loss: 1.449\n",
      "[31] loss: 1.438\n",
      "[32] loss: 1.436\n",
      "[33] loss: 1.439\n",
      "[34] loss: 1.419\n",
      "[35] loss: 1.426\n",
      "[36] loss: 1.415\n",
      "[37] loss: 1.404\n",
      "[38] loss: 1.405\n",
      "[39] loss: 1.397\n",
      "[40] loss: 1.383\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 6\n",
      "[1] loss: 2.008\n",
      "[2] loss: 1.843\n",
      "[3] loss: 1.783\n",
      "[4] loss: 1.737\n",
      "[5] loss: 1.707\n",
      "[6] loss: 1.681\n",
      "[7] loss: 1.664\n",
      "[8] loss: 1.634\n",
      "[9] loss: 1.607\n",
      "[10] loss: 1.585\n",
      "[11] loss: 1.569\n",
      "[12] loss: 1.542\n",
      "[13] loss: 1.521\n",
      "[14] loss: 1.510\n",
      "[15] loss: 1.486\n",
      "[16] loss: 1.471\n",
      "[17] loss: 1.459\n",
      "[18] loss: 1.439\n",
      "[19] loss: 1.430\n",
      "[20] loss: 1.417\n",
      "[21] loss: 1.403\n",
      "[22] loss: 1.385\n",
      "[23] loss: 1.388\n",
      "[24] loss: 1.366\n",
      "[25] loss: 1.355\n",
      "[26] loss: 1.350\n",
      "[27] loss: 1.336\n",
      "[28] loss: 1.320\n",
      "[29] loss: 1.314\n",
      "[30] loss: 1.308\n",
      "[31] loss: 1.290\n",
      "[32] loss: 1.282\n",
      "[33] loss: 1.277\n",
      "[34] loss: 1.266\n",
      "[35] loss: 1.254\n",
      "[36] loss: 1.254\n",
      "[37] loss: 1.240\n",
      "[38] loss: 1.238\n",
      "[39] loss: 1.226\n",
      "[40] loss: 1.217\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 6\n",
      "[1] loss: 2.017\n",
      "[2] loss: 1.888\n",
      "[3] loss: 1.829\n",
      "[4] loss: 1.794\n",
      "[5] loss: 1.776\n",
      "[6] loss: 1.751\n",
      "[7] loss: 1.734\n",
      "[8] loss: 1.715\n",
      "[9] loss: 1.709\n",
      "[10] loss: 1.679\n",
      "[11] loss: 1.664\n",
      "[12] loss: 1.661\n",
      "[13] loss: 1.643\n",
      "[14] loss: 1.625\n",
      "[15] loss: 1.607\n",
      "[16] loss: 1.597\n",
      "[17] loss: 1.585\n",
      "[18] loss: 1.571\n",
      "[19] loss: 1.564\n",
      "[20] loss: 1.558\n",
      "[21] loss: 1.541\n",
      "[22] loss: 1.527\n",
      "[23] loss: 1.521\n",
      "[24] loss: 1.523\n",
      "[25] loss: 1.536\n",
      "[26] loss: 1.514\n",
      "[27] loss: 1.487\n",
      "[28] loss: 1.472\n",
      "[29] loss: 1.462\n",
      "[30] loss: 1.447\n",
      "[31] loss: 1.437\n",
      "[32] loss: 1.429\n",
      "[33] loss: 1.421\n",
      "[34] loss: 1.403\n",
      "[35] loss: 1.396\n",
      "[36] loss: 1.388\n",
      "[37] loss: 1.379\n",
      "[38] loss: 1.375\n",
      "[39] loss: 1.356\n",
      "[40] loss: 1.350\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 6\n",
      "[1] loss: 2.041\n",
      "[2] loss: 1.950\n",
      "[3] loss: 2.025\n",
      "[4] loss: 2.004\n",
      "[5] loss: 2.037\n",
      "[6] loss: 2.046\n",
      "[7] loss: 2.003\n",
      "[8] loss: 1.996\n",
      "[9] loss: 1.979\n",
      "[10] loss: 1.961\n",
      "[11] loss: 1.952\n",
      "[12] loss: 1.939\n",
      "[13] loss: 1.948\n",
      "[14] loss: 1.936\n",
      "[15] loss: 1.967\n",
      "[16] loss: 1.945\n",
      "[17] loss: 1.952\n",
      "[18] loss: 1.948\n",
      "[19] loss: 1.923\n",
      "[20] loss: 1.930\n",
      "[21] loss: 1.921\n",
      "[22] loss: 1.921\n",
      "[23] loss: 1.902\n",
      "[24] loss: 1.893\n",
      "[25] loss: 1.871\n",
      "[26] loss: 1.853\n",
      "[27] loss: 1.847\n",
      "[28] loss: 1.851\n",
      "[29] loss: 1.895\n",
      "[30] loss: 1.900\n",
      "[31] loss: 1.860\n",
      "[32] loss: 1.858\n",
      "[33] loss: 1.853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34] loss: 1.874\n",
      "[35] loss: 1.850\n",
      "[36] loss: 1.861\n",
      "[37] loss: 1.852\n",
      "[38] loss: 1.845\n",
      "[39] loss: 1.843\n",
      "[40] loss: 1.839\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 6\n",
      "[1] loss: 2.068\n",
      "[2] loss: 1.891\n",
      "[3] loss: 1.828\n",
      "[4] loss: 1.783\n",
      "[5] loss: 1.758\n",
      "[6] loss: 1.719\n",
      "[7] loss: 1.689\n",
      "[8] loss: 1.664\n",
      "[9] loss: 1.646\n",
      "[10] loss: 1.620\n",
      "[11] loss: 1.611\n",
      "[12] loss: 1.588\n",
      "[13] loss: 1.574\n",
      "[14] loss: 1.565\n",
      "[15] loss: 1.547\n",
      "[16] loss: 1.536\n",
      "[17] loss: 1.534\n",
      "[18] loss: 1.513\n",
      "[19] loss: 1.516\n",
      "[20] loss: 1.510\n",
      "[21] loss: 1.498\n",
      "[22] loss: 1.478\n",
      "[23] loss: 1.476\n",
      "[24] loss: 1.473\n",
      "[25] loss: 1.467\n",
      "[26] loss: 1.463\n",
      "[27] loss: 1.451\n",
      "[28] loss: 1.441\n",
      "[29] loss: 1.434\n",
      "[30] loss: 1.419\n",
      "[31] loss: 1.417\n",
      "[32] loss: 1.404\n",
      "[33] loss: 1.403\n",
      "[34] loss: 1.390\n",
      "[35] loss: 1.379\n",
      "[36] loss: 1.388\n",
      "[37] loss: 1.368\n",
      "[38] loss: 1.361\n",
      "[39] loss: 1.370\n",
      "[40] loss: 1.349\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 7\n",
      "[1] loss: 2.015\n",
      "[2] loss: 1.838\n",
      "[3] loss: 1.770\n",
      "[4] loss: 1.732\n",
      "[5] loss: 1.702\n",
      "[6] loss: 1.667\n",
      "[7] loss: 1.640\n",
      "[8] loss: 1.619\n",
      "[9] loss: 1.597\n",
      "[10] loss: 1.574\n",
      "[11] loss: 1.553\n",
      "[12] loss: 1.540\n",
      "[13] loss: 1.519\n",
      "[14] loss: 1.503\n",
      "[15] loss: 1.495\n",
      "[16] loss: 1.473\n",
      "[17] loss: 1.471\n",
      "[18] loss: 1.454\n",
      "[19] loss: 1.445\n",
      "[20] loss: 1.433\n",
      "[21] loss: 1.414\n",
      "[22] loss: 1.409\n",
      "[23] loss: 1.394\n",
      "[24] loss: 1.381\n",
      "[25] loss: 1.372\n",
      "[26] loss: 1.370\n",
      "[27] loss: 1.356\n",
      "[28] loss: 1.346\n",
      "[29] loss: 1.338\n",
      "[30] loss: 1.329\n",
      "[31] loss: 1.320\n",
      "[32] loss: 1.312\n",
      "[33] loss: 1.297\n",
      "[34] loss: 1.292\n",
      "[35] loss: 1.280\n",
      "[36] loss: 1.269\n",
      "[37] loss: 1.269\n",
      "[38] loss: 1.262\n",
      "[39] loss: 1.249\n",
      "[40] loss: 1.241\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 7\n",
      "[1] loss: 2.017\n",
      "[2] loss: 1.885\n",
      "[3] loss: 1.849\n",
      "[4] loss: 1.822\n",
      "[5] loss: 1.807\n",
      "[6] loss: 1.787\n",
      "[7] loss: 1.781\n",
      "[8] loss: 1.783\n",
      "[9] loss: 1.743\n",
      "[10] loss: 1.754\n",
      "[11] loss: 1.773\n",
      "[12] loss: 1.729\n",
      "[13] loss: 1.722\n",
      "[14] loss: 1.753\n",
      "[15] loss: 1.715\n",
      "[16] loss: 1.682\n",
      "[17] loss: 1.706\n",
      "[18] loss: 1.722\n",
      "[19] loss: 1.681\n",
      "[20] loss: 1.672\n",
      "[21] loss: 1.700\n",
      "[22] loss: 1.659\n",
      "[23] loss: 1.678\n",
      "[24] loss: 1.706\n",
      "[25] loss: 1.654\n",
      "[26] loss: 1.636\n",
      "[27] loss: 1.690\n",
      "[28] loss: 1.645\n",
      "[29] loss: 1.655\n",
      "[30] loss: 1.673\n",
      "[31] loss: 1.620\n",
      "[32] loss: 1.624\n",
      "[33] loss: 1.644\n",
      "[34] loss: 1.605\n",
      "[35] loss: 1.645\n",
      "[36] loss: 1.630\n",
      "[37] loss: 1.616\n",
      "[38] loss: 1.622\n",
      "[39] loss: 1.588\n",
      "[40] loss: 1.621\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 7\n",
      "[1] loss: 2.015\n",
      "[2] loss: 1.962\n",
      "[3] loss: 1.996\n",
      "[4] loss: 2.033\n",
      "[5] loss: 2.021\n",
      "[6] loss: 2.016\n",
      "[7] loss: 2.007\n",
      "[8] loss: 1.986\n",
      "[9] loss: 1.978\n",
      "[10] loss: 2.007\n",
      "[11] loss: 1.951\n",
      "[12] loss: 1.927\n",
      "[13] loss: 1.933\n",
      "[14] loss: 1.932\n",
      "[15] loss: 1.940\n",
      "[16] loss: 1.938\n",
      "[17] loss: 1.948\n",
      "[18] loss: 1.926\n",
      "[19] loss: 1.924\n",
      "[20] loss: 1.912\n",
      "[21] loss: 1.926\n",
      "[22] loss: 1.933\n",
      "[23] loss: 1.938\n",
      "[24] loss: 1.931\n",
      "[25] loss: 1.906\n",
      "[26] loss: 1.933\n",
      "[27] loss: 1.922\n",
      "[28] loss: 1.923\n",
      "[29] loss: 1.911\n",
      "[30] loss: 1.930\n",
      "[31] loss: 1.910\n",
      "[32] loss: 1.918\n",
      "[33] loss: 1.881\n",
      "[34] loss: 1.944\n",
      "[35] loss: 1.882\n",
      "[36] loss: 1.865\n",
      "[37] loss: 1.862\n",
      "[38] loss: 1.869\n",
      "[39] loss: 1.855\n",
      "[40] loss: 1.838\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 7\n",
      "[1] loss: 2.032\n",
      "[2] loss: 1.882\n",
      "[3] loss: 1.821\n",
      "[4] loss: 1.770\n",
      "[5] loss: 1.737\n",
      "[6] loss: 1.713\n",
      "[7] loss: 1.685\n",
      "[8] loss: 1.662\n",
      "[9] loss: 1.642\n",
      "[10] loss: 1.630\n",
      "[11] loss: 1.621\n",
      "[12] loss: 1.579\n",
      "[13] loss: 1.567\n",
      "[14] loss: 1.552\n",
      "[15] loss: 1.541\n",
      "[16] loss: 1.530\n",
      "[17] loss: 1.517\n",
      "[18] loss: 1.503\n",
      "[19] loss: 1.498\n",
      "[20] loss: 1.493\n",
      "[21] loss: 1.485\n",
      "[22] loss: 1.463\n",
      "[23] loss: 1.467\n",
      "[24] loss: 1.455\n",
      "[25] loss: 1.445\n",
      "[26] loss: 1.439\n",
      "[27] loss: 1.428\n",
      "[28] loss: 1.427\n",
      "[29] loss: 1.410\n",
      "[30] loss: 1.407\n",
      "[31] loss: 1.406\n",
      "[32] loss: 1.392\n",
      "[33] loss: 1.392\n",
      "[34] loss: 1.378\n",
      "[35] loss: 1.371\n",
      "[36] loss: 1.366\n",
      "[37] loss: 1.364\n",
      "[38] loss: 1.356\n",
      "[39] loss: 1.347\n",
      "[40] loss: 1.350\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 8\n",
      "[1] loss: 2.012\n",
      "[2] loss: 1.853\n",
      "[3] loss: 1.788\n",
      "[4] loss: 1.740\n",
      "[5] loss: 1.708\n",
      "[6] loss: 1.670\n",
      "[7] loss: 1.647\n",
      "[8] loss: 1.613\n",
      "[9] loss: 1.592\n",
      "[10] loss: 1.570\n",
      "[11] loss: 1.555\n",
      "[12] loss: 1.527\n",
      "[13] loss: 1.524\n",
      "[14] loss: 1.500\n",
      "[15] loss: 1.485\n",
      "[16] loss: 1.462\n",
      "[17] loss: 1.453\n",
      "[18] loss: 1.435\n",
      "[19] loss: 1.420\n",
      "[20] loss: 1.406\n",
      "[21] loss: 1.402\n",
      "[22] loss: 1.386\n",
      "[23] loss: 1.381\n",
      "[24] loss: 1.366\n",
      "[25] loss: 1.355\n",
      "[26] loss: 1.335\n",
      "[27] loss: 1.329\n",
      "[28] loss: 1.323\n",
      "[29] loss: 1.308\n",
      "[30] loss: 1.305\n",
      "[31] loss: 1.293\n",
      "[32] loss: 1.285\n",
      "[33] loss: 1.277\n",
      "[34] loss: 1.269\n",
      "[35] loss: 1.259\n",
      "[36] loss: 1.247\n",
      "[37] loss: 1.240\n",
      "[38] loss: 1.233\n",
      "[39] loss: 1.215\n",
      "[40] loss: 1.211\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 8\n",
      "[1] loss: 2.032\n",
      "[2] loss: 1.902\n",
      "[3] loss: 1.840\n",
      "[4] loss: 1.826\n",
      "[5] loss: 1.787\n",
      "[6] loss: 1.753\n",
      "[7] loss: 1.757\n",
      "[8] loss: 1.731\n",
      "[9] loss: 1.702\n",
      "[10] loss: 1.704\n",
      "[11] loss: 1.685\n",
      "[12] loss: 1.655\n",
      "[13] loss: 1.642\n",
      "[14] loss: 1.634\n",
      "[15] loss: 1.609\n",
      "[16] loss: 1.595\n",
      "[17] loss: 1.592\n",
      "[18] loss: 1.586\n",
      "[19] loss: 1.573\n",
      "[20] loss: 1.549\n",
      "[21] loss: 1.545\n",
      "[22] loss: 1.536\n",
      "[23] loss: 1.522\n",
      "[24] loss: 1.520\n",
      "[25] loss: 1.514\n",
      "[26] loss: 1.521\n",
      "[27] loss: 1.516\n",
      "[28] loss: 1.497\n",
      "[29] loss: 1.481\n",
      "[30] loss: 1.464\n",
      "[31] loss: 1.452\n",
      "[32] loss: 1.447\n",
      "[33] loss: 1.434\n",
      "[34] loss: 1.428\n",
      "[35] loss: 1.416\n",
      "[36] loss: 1.409\n",
      "[37] loss: 1.396\n",
      "[38] loss: 1.396\n",
      "[39] loss: 1.380\n",
      "[40] loss: 1.376\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 8\n",
      "[1] loss: 2.035\n",
      "[2] loss: 1.935\n",
      "[3] loss: 1.992\n",
      "[4] loss: 1.986\n",
      "[5] loss: 2.009\n",
      "[6] loss: 1.994\n",
      "[7] loss: 1.962\n",
      "[8] loss: 1.952\n",
      "[9] loss: 1.974\n",
      "[10] loss: 1.968\n",
      "[11] loss: 1.957\n",
      "[12] loss: 1.950\n",
      "[13] loss: 1.951\n",
      "[14] loss: 1.940\n",
      "[15] loss: 1.945\n",
      "[16] loss: 1.970\n",
      "[17] loss: 1.966\n",
      "[18] loss: 1.975\n",
      "[19] loss: 1.970\n",
      "[20] loss: 1.935\n",
      "[21] loss: 1.967\n",
      "[22] loss: 1.982\n",
      "[23] loss: 1.963\n",
      "[24] loss: 1.965\n",
      "[25] loss: 1.933\n",
      "[26] loss: 1.924\n",
      "[27] loss: 1.930\n",
      "[28] loss: 1.930\n",
      "[29] loss: 1.903\n",
      "[30] loss: 1.922\n",
      "[31] loss: 1.923\n",
      "[32] loss: 1.928\n",
      "[33] loss: 1.932\n",
      "[34] loss: 1.928\n",
      "[35] loss: 1.912\n",
      "[36] loss: 1.949\n",
      "[37] loss: 1.957\n",
      "[38] loss: 1.974\n",
      "[39] loss: 1.952\n",
      "[40] loss: 2.027\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 8\n",
      "[1] loss: 2.087\n",
      "[2] loss: 1.931\n",
      "[3] loss: 1.873\n",
      "[4] loss: 1.826\n",
      "[5] loss: 1.799\n",
      "[6] loss: 1.749\n",
      "[7] loss: 1.723\n",
      "[8] loss: 1.693\n",
      "[9] loss: 1.676\n",
      "[10] loss: 1.656\n",
      "[11] loss: 1.628\n",
      "[12] loss: 1.609\n",
      "[13] loss: 1.599\n",
      "[14] loss: 1.575\n",
      "[15] loss: 1.569\n",
      "[16] loss: 1.555\n",
      "[17] loss: 1.552\n",
      "[18] loss: 1.537\n",
      "[19] loss: 1.519\n",
      "[20] loss: 1.507\n",
      "[21] loss: 1.506\n",
      "[22] loss: 1.500\n",
      "[23] loss: 1.487\n",
      "[24] loss: 1.474\n",
      "[25] loss: 1.469\n",
      "[26] loss: 1.456\n",
      "[27] loss: 1.453\n",
      "[28] loss: 1.445\n",
      "[29] loss: 1.447\n",
      "[30] loss: 1.429\n",
      "[31] loss: 1.416\n",
      "[32] loss: 1.421\n",
      "[33] loss: 1.414\n",
      "[34] loss: 1.408\n",
      "[35] loss: 1.399\n",
      "[36] loss: 1.390\n",
      "[37] loss: 1.383\n",
      "[38] loss: 1.384\n",
      "[39] loss: 1.363\n",
      "[40] loss: 1.361\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 9\n",
      "[1] loss: 2.006\n",
      "[2] loss: 1.851\n",
      "[3] loss: 1.792\n",
      "[4] loss: 1.741\n",
      "[5] loss: 1.699\n",
      "[6] loss: 1.673\n",
      "[7] loss: 1.652\n",
      "[8] loss: 1.618\n",
      "[9] loss: 1.594\n",
      "[10] loss: 1.578\n",
      "[11] loss: 1.552\n",
      "[12] loss: 1.538\n",
      "[13] loss: 1.520\n",
      "[14] loss: 1.500\n",
      "[15] loss: 1.485\n",
      "[16] loss: 1.472\n",
      "[17] loss: 1.465\n",
      "[18] loss: 1.441\n",
      "[19] loss: 1.425\n",
      "[20] loss: 1.419\n",
      "[21] loss: 1.404\n",
      "[22] loss: 1.397\n",
      "[23] loss: 1.383\n",
      "[24] loss: 1.366\n",
      "[25] loss: 1.362\n",
      "[26] loss: 1.349\n",
      "[27] loss: 1.349\n",
      "[28] loss: 1.333\n",
      "[29] loss: 1.313\n",
      "[30] loss: 1.303\n",
      "[31] loss: 1.302\n",
      "[32] loss: 1.289\n",
      "[33] loss: 1.278\n",
      "[34] loss: 1.276\n",
      "[35] loss: 1.254\n",
      "[36] loss: 1.240\n",
      "[37] loss: 1.242\n",
      "[38] loss: 1.231\n",
      "[39] loss: 1.222\n",
      "[40] loss: 1.213\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 9\n",
      "[1] loss: 2.009\n",
      "[2] loss: 1.881\n",
      "[3] loss: 1.837\n",
      "[4] loss: 1.796\n",
      "[5] loss: 1.780\n",
      "[6] loss: 1.764\n",
      "[7] loss: 1.735\n",
      "[8] loss: 1.721\n",
      "[9] loss: 1.709\n",
      "[10] loss: 1.695\n",
      "[11] loss: 1.669\n",
      "[12] loss: 1.654\n",
      "[13] loss: 1.647\n",
      "[14] loss: 1.642\n",
      "[15] loss: 1.621\n",
      "[16] loss: 1.603\n",
      "[17] loss: 1.605\n",
      "[18] loss: 1.631\n",
      "[19] loss: 1.669\n",
      "[20] loss: 1.605\n",
      "[21] loss: 1.573\n",
      "[22] loss: 1.558\n",
      "[23] loss: 1.545\n",
      "[24] loss: 1.532\n",
      "[25] loss: 1.518\n",
      "[26] loss: 1.512\n",
      "[27] loss: 1.501\n",
      "[28] loss: 1.491\n",
      "[29] loss: 1.476\n",
      "[30] loss: 1.463\n",
      "[31] loss: 1.454\n",
      "[32] loss: 1.453\n",
      "[33] loss: 1.440\n",
      "[34] loss: 1.431\n",
      "[35] loss: 1.419\n",
      "[36] loss: 1.408\n",
      "[37] loss: 1.402\n",
      "[38] loss: 1.395\n",
      "[39] loss: 1.382\n",
      "[40] loss: 1.376\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 9\n",
      "[1] loss: 2.008\n",
      "[2] loss: 1.940\n",
      "[3] loss: 1.943\n",
      "[4] loss: 1.958\n",
      "[5] loss: 1.959\n",
      "[6] loss: 1.947\n",
      "[7] loss: 1.976\n",
      "[8] loss: 1.958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9] loss: 1.955\n",
      "[10] loss: 1.943\n",
      "[11] loss: 1.932\n",
      "[12] loss: 1.939\n",
      "[13] loss: 1.958\n",
      "[14] loss: 1.916\n",
      "[15] loss: 1.917\n",
      "[16] loss: 1.927\n",
      "[17] loss: 1.918\n",
      "[18] loss: 1.914\n",
      "[19] loss: 1.931\n",
      "[20] loss: 1.900\n",
      "[21] loss: 1.899\n",
      "[22] loss: 1.906\n",
      "[23] loss: 1.899\n",
      "[24] loss: 1.895\n",
      "[25] loss: 1.884\n",
      "[26] loss: 1.883\n",
      "[27] loss: 1.892\n",
      "[28] loss: 1.887\n",
      "[29] loss: 1.951\n",
      "[30] loss: 1.924\n",
      "[31] loss: 1.917\n",
      "[32] loss: 1.884\n",
      "[33] loss: 1.872\n",
      "[34] loss: 1.874\n",
      "[35] loss: 1.944\n",
      "[36] loss: 1.887\n",
      "[37] loss: 1.894\n",
      "[38] loss: 1.871\n",
      "[39] loss: 1.858\n",
      "[40] loss: 1.887\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 9\n",
      "[1] loss: 2.072\n",
      "[2] loss: 1.885\n",
      "[3] loss: 1.826\n",
      "[4] loss: 1.782\n",
      "[5] loss: 1.745\n",
      "[6] loss: 1.724\n",
      "[7] loss: 1.696\n",
      "[8] loss: 1.679\n",
      "[9] loss: 1.651\n",
      "[10] loss: 1.630\n",
      "[11] loss: 1.611\n",
      "[12] loss: 1.586\n",
      "[13] loss: 1.581\n",
      "[14] loss: 1.556\n",
      "[15] loss: 1.552\n",
      "[16] loss: 1.552\n",
      "[17] loss: 1.525\n",
      "[18] loss: 1.515\n",
      "[19] loss: 1.512\n",
      "[20] loss: 1.512\n",
      "[21] loss: 1.503\n",
      "[22] loss: 1.506\n",
      "[23] loss: 1.485\n",
      "[24] loss: 1.470\n",
      "[25] loss: 1.459\n",
      "[26] loss: 1.456\n",
      "[27] loss: 1.461\n",
      "[28] loss: 1.459\n",
      "[29] loss: 1.430\n",
      "[30] loss: 1.435\n",
      "[31] loss: 1.420\n",
      "[32] loss: 1.409\n",
      "[33] loss: 1.408\n",
      "[34] loss: 1.403\n",
      "[35] loss: 1.390\n",
      "[36] loss: 1.378\n",
      "[37] loss: 1.381\n",
      "[38] loss: 1.372\n",
      "[39] loss: 1.374\n",
      "[40] loss: 1.353\n",
      "Finished training!\n",
      "\n",
      "Training IP Net. Run 10\n",
      "[1] loss: 1.995\n",
      "[2] loss: 1.823\n",
      "[3] loss: 1.774\n",
      "[4] loss: 1.724\n",
      "[5] loss: 1.706\n",
      "[6] loss: 1.665\n",
      "[7] loss: 1.649\n",
      "[8] loss: 1.623\n",
      "[9] loss: 1.603\n",
      "[10] loss: 1.576\n",
      "[11] loss: 1.555\n",
      "[12] loss: 1.530\n",
      "[13] loss: 1.519\n",
      "[14] loss: 1.502\n",
      "[15] loss: 1.486\n",
      "[16] loss: 1.462\n",
      "[17] loss: 1.457\n",
      "[18] loss: 1.449\n",
      "[19] loss: 1.424\n",
      "[20] loss: 1.418\n",
      "[21] loss: 1.399\n",
      "[22] loss: 1.382\n",
      "[23] loss: 1.372\n",
      "[24] loss: 1.371\n",
      "[25] loss: 1.350\n",
      "[26] loss: 1.344\n",
      "[27] loss: 1.334\n",
      "[28] loss: 1.327\n",
      "[29] loss: 1.315\n",
      "[30] loss: 1.298\n",
      "[31] loss: 1.292\n",
      "[32] loss: 1.282\n",
      "[33] loss: 1.274\n",
      "[34] loss: 1.263\n",
      "[35] loss: 1.253\n",
      "[36] loss: 1.247\n",
      "[37] loss: 1.235\n",
      "[38] loss: 1.231\n",
      "[39] loss: 1.222\n",
      "[40] loss: 1.212\n",
      "Finished training!\n",
      "\n",
      "Training Incremental BN. Run 10\n",
      "[1] loss: 2.009\n",
      "[2] loss: 1.884\n",
      "[3] loss: 1.839\n",
      "[4] loss: 1.790\n",
      "[5] loss: 1.792\n",
      "[6] loss: 1.766\n",
      "[7] loss: 1.739\n",
      "[8] loss: 1.738\n",
      "[9] loss: 1.711\n",
      "[10] loss: 1.714\n",
      "[11] loss: 1.710\n",
      "[12] loss: 1.679\n",
      "[13] loss: 1.666\n",
      "[14] loss: 1.663\n",
      "[15] loss: 1.642\n",
      "[16] loss: 1.637\n",
      "[17] loss: 1.647\n",
      "[18] loss: 1.626\n",
      "[19] loss: 1.610\n",
      "[20] loss: 1.603\n",
      "[21] loss: 1.590\n",
      "[22] loss: 1.589\n",
      "[23] loss: 1.582\n",
      "[24] loss: 1.566\n",
      "[25] loss: 1.566\n",
      "[26] loss: 1.571\n",
      "[27] loss: 1.586\n",
      "[28] loss: 1.608\n",
      "[29] loss: 1.577\n",
      "[30] loss: 1.553\n",
      "[31] loss: 1.531\n",
      "[32] loss: 1.521\n",
      "[33] loss: 1.510\n",
      "[34] loss: 1.507\n",
      "[35] loss: 1.489\n",
      "[36] loss: 1.479\n",
      "[37] loss: 1.468\n",
      "[38] loss: 1.458\n",
      "[39] loss: 1.452\n",
      "[40] loss: 1.441\n",
      "Finished training!\n",
      "\n",
      "Training Infomax Net. Run 10\n",
      "[1] loss: 2.031\n",
      "[2] loss: 1.980\n",
      "[3] loss: 2.034\n",
      "[4] loss: 2.015\n",
      "[5] loss: 2.000\n",
      "[6] loss: 2.001\n",
      "[7] loss: 1.992\n",
      "[8] loss: 2.000\n",
      "[9] loss: 1.981\n",
      "[10] loss: 1.989\n",
      "[11] loss: 1.966\n",
      "[12] loss: 1.981\n",
      "[13] loss: 1.965\n",
      "[14] loss: 1.977\n",
      "[15] loss: 1.972\n",
      "[16] loss: 1.963\n",
      "[17] loss: 1.946\n",
      "[18] loss: 1.955\n",
      "[19] loss: 1.937\n",
      "[20] loss: 1.924\n",
      "[21] loss: 1.934\n",
      "[22] loss: 1.905\n",
      "[23] loss: 1.898\n",
      "[24] loss: 1.887\n",
      "[25] loss: 1.860\n",
      "[26] loss: 1.888\n",
      "[27] loss: 1.875\n",
      "[28] loss: 1.881\n",
      "[29] loss: 1.865\n",
      "[30] loss: 1.864\n",
      "[31] loss: 1.844\n",
      "[32] loss: 1.875\n",
      "[33] loss: 1.850\n",
      "[34] loss: 1.837\n",
      "[35] loss: 1.847\n",
      "[36] loss: 1.836\n",
      "[37] loss: 1.820\n",
      "[38] loss: 1.852\n",
      "[39] loss: 1.860\n",
      "[40] loss: 1.870\n",
      "Finished training!\n",
      "\n",
      "Training Standard Net. Run 10\n",
      "[1] loss: 2.012\n",
      "[2] loss: 1.878\n",
      "[3] loss: 1.824\n",
      "[4] loss: 1.780\n",
      "[5] loss: 1.751\n",
      "[6] loss: 1.715\n",
      "[7] loss: 1.699\n",
      "[8] loss: 1.681\n",
      "[9] loss: 1.649\n",
      "[10] loss: 1.644\n",
      "[11] loss: 1.618\n",
      "[12] loss: 1.606\n",
      "[13] loss: 1.588\n",
      "[14] loss: 1.581\n",
      "[15] loss: 1.552\n",
      "[16] loss: 1.547\n",
      "[17] loss: 1.539\n",
      "[18] loss: 1.523\n",
      "[19] loss: 1.514\n",
      "[20] loss: 1.508\n",
      "[21] loss: 1.485\n",
      "[22] loss: 1.492\n",
      "[23] loss: 1.486\n",
      "[24] loss: 1.476\n",
      "[25] loss: 1.456\n",
      "[26] loss: 1.449\n",
      "[27] loss: 1.445\n",
      "[28] loss: 1.448\n",
      "[29] loss: 1.443\n",
      "[30] loss: 1.426\n",
      "[31] loss: 1.416\n",
      "[32] loss: 1.410\n",
      "[33] loss: 1.411\n",
      "[34] loss: 1.397\n",
      "[35] loss: 1.395\n",
      "[36] loss: 1.388\n",
      "[37] loss: 1.372\n",
      "[38] loss: 1.364\n",
      "[39] loss: 1.353\n",
      "[40] loss: 1.350\n",
      "Finished training!\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAHkCAYAAAAnwrYvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f367afd8908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "LAYERSIZE = 150\n",
    "epochs = 40\n",
    "\n",
    "test_runs = 10\n",
    "\n",
    "int_lr = 0.1\n",
    "syn_lr = 0.001\n",
    "\n",
    "run_cifar_experiment(int_lr, syn_lr, epochs, test_runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
